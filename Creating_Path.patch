Index: venv/Lib/site-packages/py/_code/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/__init__.py	(date 1543190975868)
+++ venv/Lib/site-packages/py/_code/__init__.py	(date 1543190975868)
@@ -0,0 +1,1 @@
+""" python inspection/code generation API """
Index: venv/Lib/site-packages/py/_code/source.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/source.py	(date 1543190975880)
+++ venv/Lib/site-packages/py/_code/source.py	(date 1543190975880)
@@ -0,0 +1,410 @@
+from __future__ import generators
+
+from bisect import bisect_right
+import sys
+import inspect, tokenize
+import py
+from types import ModuleType
+cpy_compile = compile
+
+try:
+    import _ast
+    from _ast import PyCF_ONLY_AST as _AST_FLAG
+except ImportError:
+    _AST_FLAG = 0
+    _ast = None
+
+
+class Source(object):
+    """ a immutable object holding a source code fragment,
+        possibly deindenting it.
+    """
+    _compilecounter = 0
+    def __init__(self, *parts, **kwargs):
+        self.lines = lines = []
+        de = kwargs.get('deindent', True)
+        rstrip = kwargs.get('rstrip', True)
+        for part in parts:
+            if not part:
+                partlines = []
+            if isinstance(part, Source):
+                partlines = part.lines
+            elif isinstance(part, (tuple, list)):
+                partlines = [x.rstrip("\n") for x in part]
+            elif isinstance(part, py.builtin._basestring):
+                partlines = part.split('\n')
+                if rstrip:
+                    while partlines:
+                        if partlines[-1].strip():
+                            break
+                        partlines.pop()
+            else:
+                partlines = getsource(part, deindent=de).lines
+            if de:
+                partlines = deindent(partlines)
+            lines.extend(partlines)
+
+    def __eq__(self, other):
+        try:
+            return self.lines == other.lines
+        except AttributeError:
+            if isinstance(other, str):
+                return str(self) == other
+            return False
+
+    def __getitem__(self, key):
+        if isinstance(key, int):
+            return self.lines[key]
+        else:
+            if key.step not in (None, 1):
+                raise IndexError("cannot slice a Source with a step")
+            return self.__getslice__(key.start, key.stop)
+
+    def __len__(self):
+        return len(self.lines)
+
+    def __getslice__(self, start, end):
+        newsource = Source()
+        newsource.lines = self.lines[start:end]
+        return newsource
+
+    def strip(self):
+        """ return new source object with trailing
+            and leading blank lines removed.
+        """
+        start, end = 0, len(self)
+        while start < end and not self.lines[start].strip():
+            start += 1
+        while end > start and not self.lines[end-1].strip():
+            end -= 1
+        source = Source()
+        source.lines[:] = self.lines[start:end]
+        return source
+
+    def putaround(self, before='', after='', indent=' ' * 4):
+        """ return a copy of the source object with
+            'before' and 'after' wrapped around it.
+        """
+        before = Source(before)
+        after = Source(after)
+        newsource = Source()
+        lines = [ (indent + line) for line in self.lines]
+        newsource.lines = before.lines + lines +  after.lines
+        return newsource
+
+    def indent(self, indent=' ' * 4):
+        """ return a copy of the source object with
+            all lines indented by the given indent-string.
+        """
+        newsource = Source()
+        newsource.lines = [(indent+line) for line in self.lines]
+        return newsource
+
+    def getstatement(self, lineno, assertion=False):
+        """ return Source statement which contains the
+            given linenumber (counted from 0).
+        """
+        start, end = self.getstatementrange(lineno, assertion)
+        return self[start:end]
+
+    def getstatementrange(self, lineno, assertion=False):
+        """ return (start, end) tuple which spans the minimal
+            statement region which containing the given lineno.
+        """
+        if not (0 <= lineno < len(self)):
+            raise IndexError("lineno out of range")
+        ast, start, end = getstatementrange_ast(lineno, self)
+        return start, end
+
+    def deindent(self, offset=None):
+        """ return a new source object deindented by offset.
+            If offset is None then guess an indentation offset from
+            the first non-blank line.  Subsequent lines which have a
+            lower indentation offset will be copied verbatim as
+            they are assumed to be part of multilines.
+        """
+        # XXX maybe use the tokenizer to properly handle multiline
+        #     strings etc.pp?
+        newsource = Source()
+        newsource.lines[:] = deindent(self.lines, offset)
+        return newsource
+
+    def isparseable(self, deindent=True):
+        """ return True if source is parseable, heuristically
+            deindenting it by default.
+        """
+        try:
+            import parser
+        except ImportError:
+            syntax_checker = lambda x: compile(x, 'asd', 'exec')
+        else:
+            syntax_checker = parser.suite
+
+        if deindent:
+            source = str(self.deindent())
+        else:
+            source = str(self)
+        try:
+            #compile(source+'\n', "x", "exec")
+            syntax_checker(source+'\n')
+        except KeyboardInterrupt:
+            raise
+        except Exception:
+            return False
+        else:
+            return True
+
+    def __str__(self):
+        return "\n".join(self.lines)
+
+    def compile(self, filename=None, mode='exec',
+                flag=generators.compiler_flag,
+                dont_inherit=0, _genframe=None):
+        """ return compiled code object. if filename is None
+            invent an artificial filename which displays
+            the source/line position of the caller frame.
+        """
+        if not filename or py.path.local(filename).check(file=0):
+            if _genframe is None:
+                _genframe = sys._getframe(1) # the caller
+            fn,lineno = _genframe.f_code.co_filename, _genframe.f_lineno
+            base = "<%d-codegen " % self._compilecounter
+            self.__class__._compilecounter += 1
+            if not filename:
+                filename = base + '%s:%d>' % (fn, lineno)
+            else:
+                filename = base + '%r %s:%d>' % (filename, fn, lineno)
+        source = "\n".join(self.lines) + '\n'
+        try:
+            co = cpy_compile(source, filename, mode, flag)
+        except SyntaxError:
+            ex = sys.exc_info()[1]
+            # re-represent syntax errors from parsing python strings
+            msglines = self.lines[:ex.lineno]
+            if ex.offset:
+                msglines.append(" "*ex.offset + '^')
+            msglines.append("(code was compiled probably from here: %s)" % filename)
+            newex = SyntaxError('\n'.join(msglines))
+            newex.offset = ex.offset
+            newex.lineno = ex.lineno
+            newex.text = ex.text
+            raise newex
+        else:
+            if flag & _AST_FLAG:
+                return co
+            lines = [(x + "\n") for x in self.lines]
+            import linecache
+            linecache.cache[filename] = (1, None, lines, filename)
+            return co
+
+#
+# public API shortcut functions
+#
+
+def compile_(source, filename=None, mode='exec', flags=
+            generators.compiler_flag, dont_inherit=0):
+    """ compile the given source to a raw code object,
+        and maintain an internal cache which allows later
+        retrieval of the source code for the code object
+        and any recursively created code objects.
+    """
+    if _ast is not None and isinstance(source, _ast.AST):
+        # XXX should Source support having AST?
+        return cpy_compile(source, filename, mode, flags, dont_inherit)
+    _genframe = sys._getframe(1) # the caller
+    s = Source(source)
+    co = s.compile(filename, mode, flags, _genframe=_genframe)
+    return co
+
+
+def getfslineno(obj):
+    """ Return source location (path, lineno) for the given object.
+    If the source cannot be determined return ("", -1)
+    """
+    try:
+        code = py.code.Code(obj)
+    except TypeError:
+        try:
+            fn = (inspect.getsourcefile(obj) or
+                  inspect.getfile(obj))
+        except TypeError:
+            return "", -1
+
+        fspath = fn and py.path.local(fn) or None
+        lineno = -1
+        if fspath:
+            try:
+                _, lineno = findsource(obj)
+            except IOError:
+                pass
+    else:
+        fspath = code.path
+        lineno = code.firstlineno
+    assert isinstance(lineno, int)
+    return fspath, lineno
+
+#
+# helper functions
+#
+
+def findsource(obj):
+    try:
+        sourcelines, lineno = inspect.findsource(obj)
+    except py.builtin._sysex:
+        raise
+    except:
+        return None, -1
+    source = Source()
+    source.lines = [line.rstrip() for line in sourcelines]
+    return source, lineno
+
+def getsource(obj, **kwargs):
+    obj = py.code.getrawcode(obj)
+    try:
+        strsrc = inspect.getsource(obj)
+    except IndentationError:
+        strsrc = "\"Buggy python version consider upgrading, cannot get source\""
+    assert isinstance(strsrc, str)
+    return Source(strsrc, **kwargs)
+
+def deindent(lines, offset=None):
+    if offset is None:
+        for line in lines:
+            line = line.expandtabs()
+            s = line.lstrip()
+            if s:
+                offset = len(line)-len(s)
+                break
+        else:
+            offset = 0
+    if offset == 0:
+        return list(lines)
+    newlines = []
+    def readline_generator(lines):
+        for line in lines:
+            yield line + '\n'
+        while True:
+            yield ''
+
+    it = readline_generator(lines)
+
+    try:
+        for _, _, (sline, _), (eline, _), _ in tokenize.generate_tokens(lambda: next(it)):
+            if sline > len(lines):
+                break # End of input reached
+            if sline > len(newlines):
+                line = lines[sline - 1].expandtabs()
+                if line.lstrip() and line[:offset].isspace():
+                    line = line[offset:] # Deindent
+                newlines.append(line)
+
+            for i in range(sline, eline):
+                # Don't deindent continuing lines of
+                # multiline tokens (i.e. multiline strings)
+                newlines.append(lines[i])
+    except (IndentationError, tokenize.TokenError):
+        pass
+    # Add any lines we didn't see. E.g. if an exception was raised.
+    newlines.extend(lines[len(newlines):])
+    return newlines
+
+
+def get_statement_startend2(lineno, node):
+    import ast
+    # flatten all statements and except handlers into one lineno-list
+    # AST's line numbers start indexing at 1
+    l = []
+    for x in ast.walk(node):
+        if isinstance(x, _ast.stmt) or isinstance(x, _ast.ExceptHandler):
+            l.append(x.lineno - 1)
+            for name in "finalbody", "orelse":
+                val = getattr(x, name, None)
+                if val:
+                    # treat the finally/orelse part as its own statement
+                    l.append(val[0].lineno - 1 - 1)
+    l.sort()
+    insert_index = bisect_right(l, lineno)
+    start = l[insert_index - 1]
+    if insert_index >= len(l):
+        end = None
+    else:
+        end = l[insert_index]
+    return start, end
+
+
+def getstatementrange_ast(lineno, source, assertion=False, astnode=None):
+    if astnode is None:
+        content = str(source)
+        try:
+            astnode = compile(content, "source", "exec", 1024)  # 1024 for AST
+        except ValueError:
+            start, end = getstatementrange_old(lineno, source, assertion)
+            return None, start, end
+    start, end = get_statement_startend2(lineno, astnode)
+    # we need to correct the end:
+    # - ast-parsing strips comments
+    # - there might be empty lines
+    # - we might have lesser indented code blocks at the end
+    if end is None:
+        end = len(source.lines)
+
+    if end > start + 1:
+        # make sure we don't span differently indented code blocks
+        # by using the BlockFinder helper used which inspect.getsource() uses itself
+        block_finder = inspect.BlockFinder()
+        # if we start with an indented line, put blockfinder to "started" mode
+        block_finder.started = source.lines[start][0].isspace()
+        it = ((x + "\n") for x in source.lines[start:end])
+        try:
+            for tok in tokenize.generate_tokens(lambda: next(it)):
+                block_finder.tokeneater(*tok)
+        except (inspect.EndOfBlock, IndentationError):
+            end = block_finder.last + start
+        except Exception:
+            pass
+
+    # the end might still point to a comment or empty line, correct it
+    while end:
+        line = source.lines[end - 1].lstrip()
+        if line.startswith("#") or not line:
+            end -= 1
+        else:
+            break
+    return astnode, start, end
+
+
+def getstatementrange_old(lineno, source, assertion=False):
+    """ return (start, end) tuple which spans the minimal
+        statement region which containing the given lineno.
+        raise an IndexError if no such statementrange can be found.
+    """
+    # XXX this logic is only used on python2.4 and below
+    # 1. find the start of the statement
+    from codeop import compile_command
+    for start in range(lineno, -1, -1):
+        if assertion:
+            line = source.lines[start]
+            # the following lines are not fully tested, change with care
+            if 'super' in line and 'self' in line and '__init__' in line:
+                raise IndexError("likely a subclass")
+            if "assert" not in line and "raise" not in line:
+                continue
+        trylines = source.lines[start:lineno+1]
+        # quick hack to prepare parsing an indented line with
+        # compile_command() (which errors on "return" outside defs)
+        trylines.insert(0, 'def xxx():')
+        trysource = '\n '.join(trylines)
+        #              ^ space here
+        try:
+            compile_command(trysource)
+        except (SyntaxError, OverflowError, ValueError):
+            continue
+
+        # 2. find the end of the statement
+        for end in range(lineno+1, len(source)+1):
+            trysource = source[start:end]
+            if trysource.isparseable():
+                return start, end
+    raise SyntaxError("no valid source range around line %d " % (lineno,))
+
+
Index: venv/Lib/site-packages/py/_path/common.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_path/common.py	(date 1543190975891)
+++ venv/Lib/site-packages/py/_path/common.py	(date 1543190975891)
@@ -0,0 +1,453 @@
+"""
+"""
+import warnings
+import os
+import sys
+import posixpath
+import fnmatch
+import py
+
+# Moved from local.py.
+iswin32 = sys.platform == "win32" or (getattr(os, '_name', False) == 'nt')
+
+try:
+    from os import fspath
+except ImportError:
+    def fspath(path):
+        """
+        Return the string representation of the path.
+        If str or bytes is passed in, it is returned unchanged.
+        This code comes from PEP 519, modified to support earlier versions of
+        python.
+
+        This is required for python < 3.6.
+        """
+        if isinstance(path, (py.builtin.text, py.builtin.bytes)):
+            return path
+
+        # Work from the object's type to match method resolution of other magic
+        # methods.
+        path_type = type(path)
+        try:
+            return path_type.__fspath__(path)
+        except AttributeError:
+            if hasattr(path_type, '__fspath__'):
+                raise
+            try:
+                import pathlib
+            except ImportError:
+                pass
+            else:
+                if isinstance(path, pathlib.PurePath):
+                    return py.builtin.text(path)
+
+            raise TypeError("expected str, bytes or os.PathLike object, not "
+                            + path_type.__name__)
+
+class Checkers:
+    _depend_on_existence = 'exists', 'link', 'dir', 'file'
+
+    def __init__(self, path):
+        self.path = path
+
+    def dir(self):
+        raise NotImplementedError
+
+    def file(self):
+        raise NotImplementedError
+
+    def dotfile(self):
+        return self.path.basename.startswith('.')
+
+    def ext(self, arg):
+        if not arg.startswith('.'):
+            arg = '.' + arg
+        return self.path.ext == arg
+
+    def exists(self):
+        raise NotImplementedError
+
+    def basename(self, arg):
+        return self.path.basename == arg
+
+    def basestarts(self, arg):
+        return self.path.basename.startswith(arg)
+
+    def relto(self, arg):
+        return self.path.relto(arg)
+
+    def fnmatch(self, arg):
+        return self.path.fnmatch(arg)
+
+    def endswith(self, arg):
+        return str(self.path).endswith(arg)
+
+    def _evaluate(self, kw):
+        for name, value in kw.items():
+            invert = False
+            meth = None
+            try:
+                meth = getattr(self, name)
+            except AttributeError:
+                if name[:3] == 'not':
+                    invert = True
+                    try:
+                        meth = getattr(self, name[3:])
+                    except AttributeError:
+                        pass
+            if meth is None:
+                raise TypeError(
+                    "no %r checker available for %r" % (name, self.path))
+            try:
+                if py.code.getrawcode(meth).co_argcount > 1:
+                    if (not meth(value)) ^ invert:
+                        return False
+                else:
+                    if bool(value) ^ bool(meth()) ^ invert:
+                        return False
+            except (py.error.ENOENT, py.error.ENOTDIR, py.error.EBUSY):
+                # EBUSY feels not entirely correct,
+                # but its kind of necessary since ENOMEDIUM
+                # is not accessible in python
+                for name in self._depend_on_existence:
+                    if name in kw:
+                        if kw.get(name):
+                            return False
+                    name = 'not' + name
+                    if name in kw:
+                        if not kw.get(name):
+                            return False
+        return True
+
+class NeverRaised(Exception):
+    pass
+
+class PathBase(object):
+    """ shared implementation for filesystem path objects."""
+    Checkers = Checkers
+
+    def __div__(self, other):
+        return self.join(fspath(other))
+    __truediv__ = __div__ # py3k
+
+    def basename(self):
+        """ basename part of path. """
+        return self._getbyspec('basename')[0]
+    basename = property(basename, None, None, basename.__doc__)
+
+    def dirname(self):
+        """ dirname part of path. """
+        return self._getbyspec('dirname')[0]
+    dirname = property(dirname, None, None, dirname.__doc__)
+
+    def purebasename(self):
+        """ pure base name of the path."""
+        return self._getbyspec('purebasename')[0]
+    purebasename = property(purebasename, None, None, purebasename.__doc__)
+
+    def ext(self):
+        """ extension of the path (including the '.')."""
+        return self._getbyspec('ext')[0]
+    ext = property(ext, None, None, ext.__doc__)
+
+    def dirpath(self, *args, **kwargs):
+        """ return the directory path joined with any given path arguments.  """
+        return self.new(basename='').join(*args, **kwargs)
+
+    def read_binary(self):
+        """ read and return a bytestring from reading the path. """
+        with self.open('rb') as f:
+            return f.read()
+
+    def read_text(self, encoding):
+        """ read and return a Unicode string from reading the path. """
+        with self.open("r", encoding=encoding) as f:
+            return f.read()
+
+
+    def read(self, mode='r'):
+        """ read and return a bytestring from reading the path. """
+        with self.open(mode) as f:
+            return f.read()
+
+    def readlines(self, cr=1):
+        """ read and return a list of lines from the path. if cr is False, the
+newline will be removed from the end of each line. """
+        if sys.version_info < (3, ):
+            mode = 'rU'
+        else:  # python 3 deprecates mode "U" in favor of "newline" option
+            mode = 'r'
+
+        if not cr:
+            content = self.read(mode)
+            return content.split('\n')
+        else:
+            f = self.open(mode)
+            try:
+                return f.readlines()
+            finally:
+                f.close()
+
+    def load(self):
+        """ (deprecated) return object unpickled from self.read() """
+        f = self.open('rb')
+        try:
+            import pickle
+            return py.error.checked_call(pickle.load, f)
+        finally:
+            f.close()
+
+    def move(self, target):
+        """ move this path to target. """
+        if target.relto(self):
+            raise py.error.EINVAL(
+                target,
+                "cannot move path into a subdirectory of itself")
+        try:
+            self.rename(target)
+        except py.error.EXDEV:  # invalid cross-device link
+            self.copy(target)
+            self.remove()
+
+    def __repr__(self):
+        """ return a string representation of this path. """
+        return repr(str(self))
+
+    def check(self, **kw):
+        """ check a path for existence and properties.
+
+            Without arguments, return True if the path exists, otherwise False.
+
+            valid checkers::
+
+                file=1    # is a file
+                file=0    # is not a file (may not even exist)
+                dir=1     # is a dir
+                link=1    # is a link
+                exists=1  # exists
+
+            You can specify multiple checker definitions, for example::
+
+                path.check(file=1, link=1)  # a link pointing to a file
+        """
+        if not kw:
+            kw = {'exists': 1}
+        return self.Checkers(self)._evaluate(kw)
+
+    def fnmatch(self, pattern):
+        """return true if the basename/fullname matches the glob-'pattern'.
+
+        valid pattern characters::
+
+            *       matches everything
+            ?       matches any single character
+            [seq]   matches any character in seq
+            [!seq]  matches any char not in seq
+
+        If the pattern contains a path-separator then the full path
+        is used for pattern matching and a '*' is prepended to the
+        pattern.
+
+        if the pattern doesn't contain a path-separator the pattern
+        is only matched against the basename.
+        """
+        return FNMatcher(pattern)(self)
+
+    def relto(self, relpath):
+        """ return a string which is the relative part of the path
+        to the given 'relpath'.
+        """
+        if not isinstance(relpath, (str, PathBase)):
+            raise TypeError("%r: not a string or path object" %(relpath,))
+        strrelpath = str(relpath)
+        if strrelpath and strrelpath[-1] != self.sep:
+            strrelpath += self.sep
+        #assert strrelpath[-1] == self.sep
+        #assert strrelpath[-2] != self.sep
+        strself = self.strpath
+        if sys.platform == "win32" or getattr(os, '_name', None) == 'nt':
+            if os.path.normcase(strself).startswith(
+               os.path.normcase(strrelpath)):
+                return strself[len(strrelpath):]
+        elif strself.startswith(strrelpath):
+            return strself[len(strrelpath):]
+        return ""
+
+    def ensure_dir(self, *args):
+        """ ensure the path joined with args is a directory. """
+        return self.ensure(*args, **{"dir": True})
+
+    def bestrelpath(self, dest):
+        """ return a string which is a relative path from self
+            (assumed to be a directory) to dest such that
+            self.join(bestrelpath) == dest and if not such
+            path can be determined return dest.
+        """
+        try:
+            if self == dest:
+                return os.curdir
+            base = self.common(dest)
+            if not base:  # can be the case on windows
+                return str(dest)
+            self2base = self.relto(base)
+            reldest = dest.relto(base)
+            if self2base:
+                n = self2base.count(self.sep) + 1
+            else:
+                n = 0
+            l = [os.pardir] * n
+            if reldest:
+                l.append(reldest)
+            target = dest.sep.join(l)
+            return target
+        except AttributeError:
+            return str(dest)
+
+    def exists(self):
+        return self.check()
+
+    def isdir(self):
+        return self.check(dir=1)
+
+    def isfile(self):
+        return self.check(file=1)
+
+    def parts(self, reverse=False):
+        """ return a root-first list of all ancestor directories
+            plus the path itself.
+        """
+        current = self
+        l = [self]
+        while 1:
+            last = current
+            current = current.dirpath()
+            if last == current:
+                break
+            l.append(current)
+        if not reverse:
+            l.reverse()
+        return l
+
+    def common(self, other):
+        """ return the common part shared with the other path
+            or None if there is no common part.
+        """
+        last = None
+        for x, y in zip(self.parts(), other.parts()):
+            if x != y:
+                return last
+            last = x
+        return last
+
+    def __add__(self, other):
+        """ return new path object with 'other' added to the basename"""
+        return self.new(basename=self.basename+str(other))
+
+    def __cmp__(self, other):
+        """ return sort value (-1, 0, +1). """
+        try:
+            return cmp(self.strpath, other.strpath)
+        except AttributeError:
+            return cmp(str(self), str(other)) # self.path, other.path)
+
+    def __lt__(self, other):
+        try:
+            return self.strpath < other.strpath
+        except AttributeError:
+            return str(self) < str(other)
+
+    def visit(self, fil=None, rec=None, ignore=NeverRaised, bf=False, sort=False):
+        """ yields all paths below the current one
+
+            fil is a filter (glob pattern or callable), if not matching the
+            path will not be yielded, defaulting to None (everything is
+            returned)
+
+            rec is a filter (glob pattern or callable) that controls whether
+            a node is descended, defaulting to None
+
+            ignore is an Exception class that is ignoredwhen calling dirlist()
+            on any of the paths (by default, all exceptions are reported)
+
+            bf if True will cause a breadthfirst search instead of the
+            default depthfirst. Default: False
+
+            sort if True will sort entries within each directory level.
+        """
+        for x in Visitor(fil, rec, ignore, bf, sort).gen(self):
+            yield x
+
+    def _sortlist(self, res, sort):
+        if sort:
+            if hasattr(sort, '__call__'):
+                warnings.warn(DeprecationWarning(
+                    "listdir(sort=callable) is deprecated and breaks on python3"
+                ), stacklevel=3)
+                res.sort(sort)
+            else:
+                res.sort()
+
+    def samefile(self, other):
+        """ return True if other refers to the same stat object as self. """
+        return self.strpath == str(other)
+
+    def __fspath__(self):
+        return self.strpath
+
+class Visitor:
+    def __init__(self, fil, rec, ignore, bf, sort):
+        if isinstance(fil, py.builtin._basestring):
+            fil = FNMatcher(fil)
+        if isinstance(rec, py.builtin._basestring):
+            self.rec = FNMatcher(rec)
+        elif not hasattr(rec, '__call__') and rec:
+            self.rec = lambda path: True
+        else:
+            self.rec = rec
+        self.fil = fil
+        self.ignore = ignore
+        self.breadthfirst = bf
+        self.optsort = sort and sorted or (lambda x: x)
+
+    def gen(self, path):
+        try:
+            entries = path.listdir()
+        except self.ignore:
+            return
+        rec = self.rec
+        dirs = self.optsort([p for p in entries
+                    if p.check(dir=1) and (rec is None or rec(p))])
+        if not self.breadthfirst:
+            for subdir in dirs:
+                for p in self.gen(subdir):
+                    yield p
+        for p in self.optsort(entries):
+            if self.fil is None or self.fil(p):
+                yield p
+        if self.breadthfirst:
+            for subdir in dirs:
+                for p in self.gen(subdir):
+                    yield p
+
+class FNMatcher:
+    def __init__(self, pattern):
+        self.pattern = pattern
+
+    def __call__(self, path):
+        pattern = self.pattern
+
+        if (pattern.find(path.sep) == -1 and
+        iswin32 and
+        pattern.find(posixpath.sep) != -1):
+            # Running on Windows, the pattern has no Windows path separators,
+            # and the pattern has one or more Posix path separators. Replace
+            # the Posix path separators with the Windows path separator.
+            pattern = pattern.replace(posixpath.sep, path.sep)
+
+        if pattern.find(path.sep) == -1:
+            name = path.basename
+        else:
+            name = str(path) # path.strpath # XXX svn?
+            if not os.path.isabs(pattern):
+                pattern = '*' + path.sep + pattern
+        return fnmatch.fnmatch(name, pattern)
Index: venv/Lib/site-packages/py/_path/svnurl.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_path/svnurl.py	(date 1543190975900)
+++ venv/Lib/site-packages/py/_path/svnurl.py	(date 1543190975900)
@@ -0,0 +1,380 @@
+"""
+module defining a subversion path object based on the external
+command 'svn'. This modules aims to work with svn 1.3 and higher
+but might also interact well with earlier versions.
+"""
+
+import os, sys, time, re
+import py
+from py import path, process
+from py._path import common
+from py._path import svnwc as svncommon
+from py._path.cacheutil import BuildcostAccessCache, AgingCache
+
+DEBUG=False
+
+class SvnCommandPath(svncommon.SvnPathBase):
+    """ path implementation that offers access to (possibly remote) subversion
+    repositories. """
+
+    _lsrevcache = BuildcostAccessCache(maxentries=128)
+    _lsnorevcache = AgingCache(maxentries=1000, maxseconds=60.0)
+
+    def __new__(cls, path, rev=None, auth=None):
+        self = object.__new__(cls)
+        if isinstance(path, cls):
+            rev = path.rev
+            auth = path.auth
+            path = path.strpath
+        svncommon.checkbadchars(path)
+        path = path.rstrip('/')
+        self.strpath = path
+        self.rev = rev
+        self.auth = auth
+        return self
+
+    def __repr__(self):
+        if self.rev == -1:
+            return 'svnurl(%r)' % self.strpath
+        else:
+            return 'svnurl(%r, %r)' % (self.strpath, self.rev)
+
+    def _svnwithrev(self, cmd, *args):
+        """ execute an svn command, append our own url and revision """
+        if self.rev is None:
+            return self._svnwrite(cmd, *args)
+        else:
+            args = ['-r', self.rev] + list(args)
+            return self._svnwrite(cmd, *args)
+
+    def _svnwrite(self, cmd, *args):
+        """ execute an svn command, append our own url """
+        l = ['svn %s' % cmd]
+        args = ['"%s"' % self._escape(item) for item in args]
+        l.extend(args)
+        l.append('"%s"' % self._encodedurl())
+        # fixing the locale because we can't otherwise parse
+        string = " ".join(l)
+        if DEBUG:
+            print("execing %s" % string)
+        out = self._svncmdexecauth(string)
+        return out
+
+    def _svncmdexecauth(self, cmd):
+        """ execute an svn command 'as is' """
+        cmd = svncommon.fixlocale() + cmd
+        if self.auth is not None:
+            cmd += ' ' + self.auth.makecmdoptions()
+        return self._cmdexec(cmd)
+
+    def _cmdexec(self, cmd):
+        try:
+            out = process.cmdexec(cmd)
+        except py.process.cmdexec.Error:
+            e = sys.exc_info()[1]
+            if (e.err.find('File Exists') != -1 or
+                            e.err.find('File already exists') != -1):
+                raise py.error.EEXIST(self)
+            raise
+        return out
+
+    def _svnpopenauth(self, cmd):
+        """ execute an svn command, return a pipe for reading stdin """
+        cmd = svncommon.fixlocale() + cmd
+        if self.auth is not None:
+            cmd += ' ' + self.auth.makecmdoptions()
+        return self._popen(cmd)
+
+    def _popen(self, cmd):
+        return os.popen(cmd)
+
+    def _encodedurl(self):
+        return self._escape(self.strpath)
+
+    def _norev_delentry(self, path):
+        auth = self.auth and self.auth.makecmdoptions() or None
+        self._lsnorevcache.delentry((str(path), auth))
+
+    def open(self, mode='r'):
+        """ return an opened file with the given mode. """
+        if mode not in ("r", "rU",):
+            raise ValueError("mode %r not supported" % (mode,))
+        assert self.check(file=1) # svn cat returns an empty file otherwise
+        if self.rev is None:
+            return self._svnpopenauth('svn cat "%s"' % (
+                                      self._escape(self.strpath), ))
+        else:
+            return self._svnpopenauth('svn cat -r %s "%s"' % (
+                                      self.rev, self._escape(self.strpath)))
+
+    def dirpath(self, *args, **kwargs):
+        """ return the directory path of the current path joined
+            with any given path arguments.
+        """
+        l = self.strpath.split(self.sep)
+        if len(l) < 4:
+            raise py.error.EINVAL(self, "base is not valid")
+        elif len(l) == 4:
+            return self.join(*args, **kwargs)
+        else:
+            return self.new(basename='').join(*args, **kwargs)
+
+    # modifying methods (cache must be invalidated)
+    def mkdir(self, *args, **kwargs):
+        """ create & return the directory joined with args.
+        pass a 'msg' keyword argument to set the commit message.
+        """
+        commit_msg = kwargs.get('msg', "mkdir by py lib invocation")
+        createpath = self.join(*args)
+        createpath._svnwrite('mkdir', '-m', commit_msg)
+        self._norev_delentry(createpath.dirpath())
+        return createpath
+
+    def copy(self, target, msg='copied by py lib invocation'):
+        """ copy path to target with checkin message msg."""
+        if getattr(target, 'rev', None) is not None:
+            raise py.error.EINVAL(target, "revisions are immutable")
+        self._svncmdexecauth('svn copy -m "%s" "%s" "%s"' %(msg,
+                             self._escape(self), self._escape(target)))
+        self._norev_delentry(target.dirpath())
+
+    def rename(self, target, msg="renamed by py lib invocation"):
+        """ rename this path to target with checkin message msg. """
+        if getattr(self, 'rev', None) is not None:
+            raise py.error.EINVAL(self, "revisions are immutable")
+        self._svncmdexecauth('svn move -m "%s" --force "%s" "%s"' %(
+                             msg, self._escape(self), self._escape(target)))
+        self._norev_delentry(self.dirpath())
+        self._norev_delentry(self)
+
+    def remove(self, rec=1, msg='removed by py lib invocation'):
+        """ remove a file or directory (or a directory tree if rec=1) with
+checkin message msg."""
+        if self.rev is not None:
+            raise py.error.EINVAL(self, "revisions are immutable")
+        self._svncmdexecauth('svn rm -m "%s" "%s"' %(msg, self._escape(self)))
+        self._norev_delentry(self.dirpath())
+
+    def export(self, topath):
+        """ export to a local path
+
+            topath should not exist prior to calling this, returns a
+            py.path.local instance
+        """
+        topath = py.path.local(topath)
+        args = ['"%s"' % (self._escape(self),),
+                '"%s"' % (self._escape(topath),)]
+        if self.rev is not None:
+            args = ['-r', str(self.rev)] + args
+        self._svncmdexecauth('svn export %s' % (' '.join(args),))
+        return topath
+
+    def ensure(self, *args, **kwargs):
+        """ ensure that an args-joined path exists (by default as
+            a file). If you specify a keyword argument 'dir=True'
+            then the path is forced to be a directory path.
+        """
+        if getattr(self, 'rev', None) is not None:
+            raise py.error.EINVAL(self, "revisions are immutable")
+        target = self.join(*args)
+        dir = kwargs.get('dir', 0)
+        for x in target.parts(reverse=True):
+            if x.check():
+                break
+        else:
+            raise py.error.ENOENT(target, "has not any valid base!")
+        if x == target:
+            if not x.check(dir=dir):
+                raise dir and py.error.ENOTDIR(x) or py.error.EISDIR(x)
+            return x
+        tocreate = target.relto(x)
+        basename = tocreate.split(self.sep, 1)[0]
+        tempdir = py.path.local.mkdtemp()
+        try:
+            tempdir.ensure(tocreate, dir=dir)
+            cmd = 'svn import -m "%s" "%s" "%s"' % (
+                    "ensure %s" % self._escape(tocreate),
+                    self._escape(tempdir.join(basename)),
+                    x.join(basename)._encodedurl())
+            self._svncmdexecauth(cmd)
+            self._norev_delentry(x)
+        finally:
+            tempdir.remove()
+        return target
+
+    # end of modifying methods
+    def _propget(self, name):
+        res = self._svnwithrev('propget', name)
+        return res[:-1] # strip trailing newline
+
+    def _proplist(self):
+        res = self._svnwithrev('proplist')
+        lines = res.split('\n')
+        lines = [x.strip() for x in lines[1:]]
+        return svncommon.PropListDict(self, lines)
+
+    def info(self):
+        """ return an Info structure with svn-provided information. """
+        parent = self.dirpath()
+        nameinfo_seq = parent._listdir_nameinfo()
+        bn = self.basename
+        for name, info in nameinfo_seq:
+            if name == bn:
+                return info
+        raise py.error.ENOENT(self)
+
+
+    def _listdir_nameinfo(self):
+        """ return sequence of name-info directory entries of self """
+        def builder():
+            try:
+                res = self._svnwithrev('ls', '-v')
+            except process.cmdexec.Error:
+                e = sys.exc_info()[1]
+                if e.err.find('non-existent in that revision') != -1:
+                    raise py.error.ENOENT(self, e.err)
+                elif e.err.find("E200009:") != -1:
+                    raise py.error.ENOENT(self, e.err)
+                elif e.err.find('File not found') != -1:
+                    raise py.error.ENOENT(self, e.err)
+                elif e.err.find('not part of a repository')!=-1:
+                    raise py.error.ENOENT(self, e.err)
+                elif e.err.find('Unable to open')!=-1:
+                    raise py.error.ENOENT(self, e.err)
+                elif e.err.lower().find('method not allowed')!=-1:
+                    raise py.error.EACCES(self, e.err)
+                raise py.error.Error(e.err)
+            lines = res.split('\n')
+            nameinfo_seq = []
+            for lsline in lines:
+                if lsline:
+                    info = InfoSvnCommand(lsline)
+                    if info._name != '.':  # svn 1.5 produces '.' dirs,
+                        nameinfo_seq.append((info._name, info))
+            nameinfo_seq.sort()
+            return nameinfo_seq
+        auth = self.auth and self.auth.makecmdoptions() or None
+        if self.rev is not None:
+            return self._lsrevcache.getorbuild((self.strpath, self.rev, auth),
+                                               builder)
+        else:
+            return self._lsnorevcache.getorbuild((self.strpath, auth),
+                                                 builder)
+
+    def listdir(self, fil=None, sort=None):
+        """ list directory contents, possibly filter by the given fil func
+            and possibly sorted.
+        """
+        if isinstance(fil, str):
+            fil = common.FNMatcher(fil)
+        nameinfo_seq = self._listdir_nameinfo()
+        if len(nameinfo_seq) == 1:
+            name, info = nameinfo_seq[0]
+            if name == self.basename and info.kind == 'file':
+                #if not self.check(dir=1):
+                raise py.error.ENOTDIR(self)
+        paths = [self.join(name) for (name, info) in nameinfo_seq]
+        if fil:
+            paths = [x for x in paths if fil(x)]
+        self._sortlist(paths, sort)
+        return paths
+
+
+    def log(self, rev_start=None, rev_end=1, verbose=False):
+        """ return a list of LogEntry instances for this path.
+rev_start is the starting revision (defaulting to the first one).
+rev_end is the last revision (defaulting to HEAD).
+if verbose is True, then the LogEntry instances also know which files changed.
+"""
+        assert self.check() #make it simpler for the pipe
+        rev_start = rev_start is None and "HEAD" or rev_start
+        rev_end = rev_end is None and "HEAD" or rev_end
+
+        if rev_start == "HEAD" and rev_end == 1:
+            rev_opt = ""
+        else:
+            rev_opt = "-r %s:%s" % (rev_start, rev_end)
+        verbose_opt = verbose and "-v" or ""
+        xmlpipe =  self._svnpopenauth('svn log --xml %s %s "%s"' %
+                                      (rev_opt, verbose_opt, self.strpath))
+        from xml.dom import minidom
+        tree = minidom.parse(xmlpipe)
+        result = []
+        for logentry in filter(None, tree.firstChild.childNodes):
+            if logentry.nodeType == logentry.ELEMENT_NODE:
+                result.append(svncommon.LogEntry(logentry))
+        return result
+
+#01234567890123456789012345678901234567890123467
+#   2256      hpk        165 Nov 24 17:55 __init__.py
+# XXX spotted by Guido, SVN 1.3.0 has different aligning, breaks the code!!!
+#   1312 johnny           1627 May 05 14:32 test_decorators.py
+#
+class InfoSvnCommand:
+    # the '0?' part in the middle is an indication of whether the resource is
+    # locked, see 'svn help ls'
+    lspattern = re.compile(
+        r'^ *(?P<rev>\d+) +(?P<author>.+?) +(0? *(?P<size>\d+))? '
+            r'*(?P<date>\w+ +\d{2} +[\d:]+) +(?P<file>.*)$')
+    def __init__(self, line):
+        # this is a typical line from 'svn ls http://...'
+        #_    1127      jum        0 Jul 13 15:28 branch/
+        match = self.lspattern.match(line)
+        data = match.groupdict()
+        self._name = data['file']
+        if self._name[-1] == '/':
+            self._name = self._name[:-1]
+            self.kind = 'dir'
+        else:
+            self.kind = 'file'
+        #self.has_props = l.pop(0) == 'P'
+        self.created_rev = int(data['rev'])
+        self.last_author = data['author']
+        self.size = data['size'] and int(data['size']) or 0
+        self.mtime = parse_time_with_missing_year(data['date'])
+        self.time = self.mtime * 1000000
+
+    def __eq__(self, other):
+        return self.__dict__ == other.__dict__
+
+
+#____________________________________________________
+#
+# helper functions
+#____________________________________________________
+def parse_time_with_missing_year(timestr):
+    """ analyze the time part from a single line of "svn ls -v"
+    the svn output doesn't show the year makes the 'timestr'
+    ambigous.
+    """
+    import calendar
+    t_now = time.gmtime()
+
+    tparts = timestr.split()
+    month = time.strptime(tparts.pop(0), '%b')[1]
+    day = time.strptime(tparts.pop(0), '%d')[2]
+    last = tparts.pop(0) # year or hour:minute
+    try:
+        if ":" in last:
+            raise ValueError()
+        year = time.strptime(last, '%Y')[0]
+        hour = minute = 0
+    except ValueError:
+        hour, minute = time.strptime(last, '%H:%M')[3:5]
+        year = t_now[0]
+
+        t_result = (year, month, day, hour, minute, 0,0,0,0)
+        if t_result > t_now:
+            year -= 1
+    t_result = (year, month, day, hour, minute, 0,0,0,0)
+    return calendar.timegm(t_result)
+
+class PathEntry:
+    def __init__(self, ppart):
+        self.strpath = ppart.firstChild.nodeValue.encode('UTF-8')
+        self.action = ppart.getAttribute('action').encode('UTF-8')
+        if self.action == 'A':
+            self.copyfrom_path = ppart.getAttribute('copyfrom-path').encode('UTF-8')
+            if self.copyfrom_path:
+                self.copyfrom_rev = int(ppart.getAttribute('copyfrom-rev'))
+
Index: venv/Lib/site-packages/py/_path/svnwc.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_path/svnwc.py	(date 1543190975924)
+++ venv/Lib/site-packages/py/_path/svnwc.py	(date 1543190975924)
@@ -0,0 +1,1240 @@
+"""
+svn-Command based Implementation of a Subversion WorkingCopy Path.
+
+  SvnWCCommandPath  is the main class.
+
+"""
+
+import os, sys, time, re, calendar
+import py
+import subprocess
+from py._path import common
+
+#-----------------------------------------------------------
+# Caching latest repository revision and repo-paths
+# (getting them is slow with the current implementations)
+#
+# XXX make mt-safe
+#-----------------------------------------------------------
+
+class cache:
+    proplist = {}
+    info = {}
+    entries = {}
+    prop = {}
+
+class RepoEntry:
+    def __init__(self, url, rev, timestamp):
+        self.url = url
+        self.rev = rev
+        self.timestamp = timestamp
+
+    def __str__(self):
+        return "repo: %s;%s  %s" %(self.url, self.rev, self.timestamp)
+
+class RepoCache:
+    """ The Repocache manages discovered repository paths
+    and their revisions.  If inside a timeout the cache
+    will even return the revision of the root.
+    """
+    timeout = 20 # seconds after which we forget that we know the last revision
+
+    def __init__(self):
+        self.repos = []
+
+    def clear(self):
+        self.repos = []
+
+    def put(self, url, rev, timestamp=None):
+        if rev is None:
+            return
+        if timestamp is None:
+            timestamp = time.time()
+
+        for entry in self.repos:
+            if url == entry.url:
+                entry.timestamp = timestamp
+                entry.rev = rev
+                #print "set repo", entry
+                break
+        else:
+            entry = RepoEntry(url, rev, timestamp)
+            self.repos.append(entry)
+            #print "appended repo", entry
+
+    def get(self, url):
+        now = time.time()
+        for entry in self.repos:
+            if url.startswith(entry.url):
+                if now < entry.timestamp + self.timeout:
+                    #print "returning immediate Etrny", entry
+                    return entry.url, entry.rev
+                return entry.url, -1
+        return url, -1
+
+repositories = RepoCache()
+
+
+# svn support code
+
+ALLOWED_CHARS = "_ -/\\=$.~+%" #add characters as necessary when tested
+if sys.platform == "win32":
+    ALLOWED_CHARS += ":"
+ALLOWED_CHARS_HOST = ALLOWED_CHARS + '@:'
+
+def _getsvnversion(ver=[]):
+    try:
+        return ver[0]
+    except IndexError:
+        v = py.process.cmdexec("svn -q --version")
+        v.strip()
+        v = '.'.join(v.split('.')[:2])
+        ver.append(v)
+        return v
+
+def _escape_helper(text):
+    text = str(text)
+    if sys.platform != 'win32':
+        text = str(text).replace('$', '\\$')
+    return text
+
+def _check_for_bad_chars(text, allowed_chars=ALLOWED_CHARS):
+    for c in str(text):
+        if c.isalnum():
+            continue
+        if c in allowed_chars:
+            continue
+        return True
+    return False
+
+def checkbadchars(url):
+    # (hpk) not quite sure about the exact purpose, guido w.?
+    proto, uri = url.split("://", 1)
+    if proto != "file":
+        host, uripath = uri.split('/', 1)
+        # only check for bad chars in the non-protocol parts
+        if (_check_for_bad_chars(host, ALLOWED_CHARS_HOST) \
+            or _check_for_bad_chars(uripath, ALLOWED_CHARS)):
+            raise ValueError("bad char in %r" % (url, ))
+
+
+#_______________________________________________________________
+
+class SvnPathBase(common.PathBase):
+    """ Base implementation for SvnPath implementations. """
+    sep = '/'
+
+    def _geturl(self):
+        return self.strpath
+    url = property(_geturl, None, None, "url of this svn-path.")
+
+    def __str__(self):
+        """ return a string representation (including rev-number) """
+        return self.strpath
+
+    def __hash__(self):
+        return hash(self.strpath)
+
+    def new(self, **kw):
+        """ create a modified version of this path. A 'rev' argument
+            indicates a new revision.
+            the following keyword arguments modify various path parts::
+
+              http://host.com/repo/path/file.ext
+              |-----------------------|          dirname
+                                        |------| basename
+                                        |--|     purebasename
+                                            |--| ext
+        """
+        obj = object.__new__(self.__class__)
+        obj.rev = kw.get('rev', self.rev)
+        obj.auth = kw.get('auth', self.auth)
+        dirname, basename, purebasename, ext = self._getbyspec(
+             "dirname,basename,purebasename,ext")
+        if 'basename' in kw:
+            if 'purebasename' in kw or 'ext' in kw:
+                raise ValueError("invalid specification %r" % kw)
+        else:
+            pb = kw.setdefault('purebasename', purebasename)
+            ext = kw.setdefault('ext', ext)
+            if ext and not ext.startswith('.'):
+                ext = '.' + ext
+            kw['basename'] = pb + ext
+
+        kw.setdefault('dirname', dirname)
+        kw.setdefault('sep', self.sep)
+        if kw['basename']:
+            obj.strpath = "%(dirname)s%(sep)s%(basename)s" % kw
+        else:
+            obj.strpath = "%(dirname)s" % kw
+        return obj
+
+    def _getbyspec(self, spec):
+        """ get specified parts of the path.  'arg' is a string
+            with comma separated path parts. The parts are returned
+            in exactly the order of the specification.
+
+            you may specify the following parts:
+
+            http://host.com/repo/path/file.ext
+            |-----------------------|          dirname
+                                      |------| basename
+                                      |--|     purebasename
+                                          |--| ext
+        """
+        res = []
+        parts = self.strpath.split(self.sep)
+        for name in spec.split(','):
+            name = name.strip()
+            if name == 'dirname':
+                res.append(self.sep.join(parts[:-1]))
+            elif name == 'basename':
+                res.append(parts[-1])
+            else:
+                basename = parts[-1]
+                i = basename.rfind('.')
+                if i == -1:
+                    purebasename, ext = basename, ''
+                else:
+                    purebasename, ext = basename[:i], basename[i:]
+                if name == 'purebasename':
+                    res.append(purebasename)
+                elif name == 'ext':
+                    res.append(ext)
+                else:
+                    raise NameError("Don't know part %r" % name)
+        return res
+
+    def __eq__(self, other):
+        """ return true if path and rev attributes each match """
+        return (str(self) == str(other) and
+               (self.rev == other.rev or self.rev == other.rev))
+
+    def __ne__(self, other):
+        return not self == other
+
+    def join(self, *args):
+        """ return a new Path (with the same revision) which is composed
+            of the self Path followed by 'args' path components.
+        """
+        if not args:
+            return self
+
+        args = tuple([arg.strip(self.sep) for arg in args])
+        parts = (self.strpath, ) + args
+        newpath = self.__class__(self.sep.join(parts), self.rev, self.auth)
+        return newpath
+
+    def propget(self, name):
+        """ return the content of the given property. """
+        value = self._propget(name)
+        return value
+
+    def proplist(self):
+        """ list all property names. """
+        content = self._proplist()
+        return content
+
+    def size(self):
+        """ Return the size of the file content of the Path. """
+        return self.info().size
+
+    def mtime(self):
+        """ Return the last modification time of the file. """
+        return self.info().mtime
+
+    # shared help methods
+
+    def _escape(self, cmd):
+        return _escape_helper(cmd)
+
+
+    #def _childmaxrev(self):
+    #    """ return maximum revision number of childs (or self.rev if no childs) """
+    #    rev = self.rev
+    #    for name, info in self._listdir_nameinfo():
+    #        rev = max(rev, info.created_rev)
+    #    return rev
+
+    #def _getlatestrevision(self):
+    #    """ return latest repo-revision for this path. """
+    #    url = self.strpath
+    #    path = self.__class__(url, None)
+    #
+    #    # we need a long walk to find the root-repo and revision
+    #    while 1:
+    #        try:
+    #            rev = max(rev, path._childmaxrev())
+    #            previous = path
+    #            path = path.dirpath()
+    #        except (IOError, process.cmdexec.Error):
+    #            break
+    #    if rev is None:
+    #        raise IOError, "could not determine newest repo revision for %s" % self
+    #    return rev
+
+    class Checkers(common.Checkers):
+        def dir(self):
+            try:
+                return self.path.info().kind == 'dir'
+            except py.error.Error:
+                return self._listdirworks()
+
+        def _listdirworks(self):
+            try:
+                self.path.listdir()
+            except py.error.ENOENT:
+                return False
+            else:
+                return True
+
+        def file(self):
+            try:
+                return self.path.info().kind == 'file'
+            except py.error.ENOENT:
+                return False
+
+        def exists(self):
+            try:
+                return self.path.info()
+            except py.error.ENOENT:
+                return self._listdirworks()
+
+def parse_apr_time(timestr):
+    i = timestr.rfind('.')
+    if i == -1:
+        raise ValueError("could not parse %s" % timestr)
+    timestr = timestr[:i]
+    parsedtime = time.strptime(timestr, "%Y-%m-%dT%H:%M:%S")
+    return time.mktime(parsedtime)
+
+class PropListDict(dict):
+    """ a Dictionary which fetches values (InfoSvnCommand instances) lazily"""
+    def __init__(self, path, keynames):
+        dict.__init__(self, [(x, None) for x in keynames])
+        self.path = path
+
+    def __getitem__(self, key):
+        value = dict.__getitem__(self, key)
+        if value is None:
+            value = self.path.propget(key)
+            dict.__setitem__(self, key, value)
+        return value
+
+def fixlocale():
+    if sys.platform != 'win32':
+        return 'LC_ALL=C '
+    return ''
+
+# some nasty chunk of code to solve path and url conversion and quoting issues
+ILLEGAL_CHARS = '* | \\ / : < > ? \t \n \x0b \x0c \r'.split(' ')
+if os.sep in ILLEGAL_CHARS:
+    ILLEGAL_CHARS.remove(os.sep)
+ISWINDOWS = sys.platform == 'win32'
+_reg_allow_disk = re.compile(r'^([a-z]\:\\)?[^:]+$', re.I)
+def _check_path(path):
+    illegal = ILLEGAL_CHARS[:]
+    sp = path.strpath
+    if ISWINDOWS:
+        illegal.remove(':')
+        if not _reg_allow_disk.match(sp):
+            raise ValueError('path may not contain a colon (:)')
+    for char in sp:
+        if char not in string.printable or char in illegal:
+            raise ValueError('illegal character %r in path' % (char,))
+
+def path_to_fspath(path, addat=True):
+    _check_path(path)
+    sp = path.strpath
+    if addat and path.rev != -1:
+        sp = '%s@%s' % (sp, path.rev)
+    elif addat:
+        sp = '%s@HEAD' % (sp,)
+    return sp
+
+def url_from_path(path):
+    fspath = path_to_fspath(path, False)
+    from urllib import quote
+    if ISWINDOWS:
+        match = _reg_allow_disk.match(fspath)
+        fspath = fspath.replace('\\', '/')
+        if match.group(1):
+            fspath = '/%s%s' % (match.group(1).replace('\\', '/'),
+                                quote(fspath[len(match.group(1)):]))
+        else:
+            fspath = quote(fspath)
+    else:
+        fspath = quote(fspath)
+    if path.rev != -1:
+        fspath = '%s@%s' % (fspath, path.rev)
+    else:
+        fspath = '%s@HEAD' % (fspath,)
+    return 'file://%s' % (fspath,)
+
+class SvnAuth(object):
+    """ container for auth information for Subversion """
+    def __init__(self, username, password, cache_auth=True, interactive=True):
+        self.username = username
+        self.password = password
+        self.cache_auth = cache_auth
+        self.interactive = interactive
+
+    def makecmdoptions(self):
+        uname = self.username.replace('"', '\\"')
+        passwd = self.password.replace('"', '\\"')
+        ret = []
+        if uname:
+            ret.append('--username="%s"' % (uname,))
+        if passwd:
+            ret.append('--password="%s"' % (passwd,))
+        if not self.cache_auth:
+            ret.append('--no-auth-cache')
+        if not self.interactive:
+            ret.append('--non-interactive')
+        return ' '.join(ret)
+
+    def __str__(self):
+        return "<SvnAuth username=%s ...>" %(self.username,)
+
+rex_blame = re.compile(r'\s*(\d+)\s*(\S+) (.*)')
+
+class SvnWCCommandPath(common.PathBase):
+    """ path implementation offering access/modification to svn working copies.
+        It has methods similar to the functions in os.path and similar to the
+        commands of the svn client.
+    """
+    sep = os.sep
+
+    def __new__(cls, wcpath=None, auth=None):
+        self = object.__new__(cls)
+        if isinstance(wcpath, cls):
+            if wcpath.__class__ == cls:
+                return wcpath
+            wcpath = wcpath.localpath
+        if _check_for_bad_chars(str(wcpath),
+                                          ALLOWED_CHARS):
+            raise ValueError("bad char in wcpath %s" % (wcpath, ))
+        self.localpath = py.path.local(wcpath)
+        self.auth = auth
+        return self
+
+    strpath = property(lambda x: str(x.localpath), None, None, "string path")
+    rev = property(lambda x: x.info(usecache=0).rev, None, None, "revision")
+
+    def __eq__(self, other):
+        return self.localpath == getattr(other, 'localpath', None)
+
+    def _geturl(self):
+        if getattr(self, '_url', None) is None:
+            info = self.info()
+            self._url = info.url #SvnPath(info.url, info.rev)
+        assert isinstance(self._url, py.builtin._basestring)
+        return self._url
+
+    url = property(_geturl, None, None, "url of this WC item")
+
+    def _escape(self, cmd):
+        return _escape_helper(cmd)
+
+    def dump(self, obj):
+        """ pickle object into path location"""
+        return self.localpath.dump(obj)
+
+    def svnurl(self):
+        """ return current SvnPath for this WC-item. """
+        info = self.info()
+        return py.path.svnurl(info.url)
+
+    def __repr__(self):
+        return "svnwc(%r)" % (self.strpath) # , self._url)
+
+    def __str__(self):
+        return str(self.localpath)
+
+    def _makeauthoptions(self):
+        if self.auth is None:
+            return ''
+        return self.auth.makecmdoptions()
+
+    def _authsvn(self, cmd, args=None):
+        args = args and list(args) or []
+        args.append(self._makeauthoptions())
+        return self._svn(cmd, *args)
+
+    def _svn(self, cmd, *args):
+        l = ['svn %s' % cmd]
+        args = [self._escape(item) for item in args]
+        l.extend(args)
+        l.append('"%s"' % self._escape(self.strpath))
+        # try fixing the locale because we can't otherwise parse
+        string = fixlocale() + " ".join(l)
+        try:
+            try:
+                key = 'LC_MESSAGES'
+                hold = os.environ.get(key)
+                os.environ[key] = 'C'
+                out = py.process.cmdexec(string)
+            finally:
+                if hold:
+                    os.environ[key] = hold
+                else:
+                    del os.environ[key]
+        except py.process.cmdexec.Error:
+            e = sys.exc_info()[1]
+            strerr = e.err.lower()
+            if strerr.find('not found') != -1:
+                raise py.error.ENOENT(self)
+            elif strerr.find("E200009:") != -1:
+                raise py.error.ENOENT(self)
+            if (strerr.find('file exists') != -1 or
+                strerr.find('file already exists') != -1 or
+                strerr.find('w150002:') != -1 or
+                strerr.find("can't create directory") != -1):
+                raise py.error.EEXIST(strerr) #self)
+            raise
+        return out
+
+    def switch(self, url):
+        """ switch to given URL. """
+        self._authsvn('switch', [url])
+
+    def checkout(self, url=None, rev=None):
+        """ checkout from url to local wcpath. """
+        args = []
+        if url is None:
+            url = self.url
+        if rev is None or rev == -1:
+            if (sys.platform != 'win32' and
+                    _getsvnversion() == '1.3'):
+                url += "@HEAD"
+        else:
+            if _getsvnversion() == '1.3':
+                url += "@%d" % rev
+            else:
+                args.append('-r' + str(rev))
+        args.append(url)
+        self._authsvn('co', args)
+
+    def update(self, rev='HEAD', interactive=True):
+        """ update working copy item to given revision. (None -> HEAD). """
+        opts = ['-r', rev]
+        if not interactive:
+            opts.append("--non-interactive")
+        self._authsvn('up', opts)
+
+    def write(self, content, mode='w'):
+        """ write content into local filesystem wc. """
+        self.localpath.write(content, mode)
+
+    def dirpath(self, *args):
+        """ return the directory Path of the current Path. """
+        return self.__class__(self.localpath.dirpath(*args), auth=self.auth)
+
+    def _ensuredirs(self):
+        parent = self.dirpath()
+        if parent.check(dir=0):
+            parent._ensuredirs()
+        if self.check(dir=0):
+            self.mkdir()
+        return self
+
+    def ensure(self, *args, **kwargs):
+        """ ensure that an args-joined path exists (by default as
+            a file). if you specify a keyword argument 'directory=True'
+            then the path is forced  to be a directory path.
+        """
+        p = self.join(*args)
+        if p.check():
+            if p.check(versioned=False):
+                p.add()
+            return p
+        if kwargs.get('dir', 0):
+            return p._ensuredirs()
+        parent = p.dirpath()
+        parent._ensuredirs()
+        p.write("")
+        p.add()
+        return p
+
+    def mkdir(self, *args):
+        """ create & return the directory joined with args. """
+        if args:
+            return self.join(*args).mkdir()
+        else:
+            self._svn('mkdir')
+            return self
+
+    def add(self):
+        """ add ourself to svn """
+        self._svn('add')
+
+    def remove(self, rec=1, force=1):
+        """ remove a file or a directory tree. 'rec'ursive is
+            ignored and considered always true (because of
+            underlying svn semantics.
+        """
+        assert rec, "svn cannot remove non-recursively"
+        if not self.check(versioned=True):
+            # not added to svn (anymore?), just remove
+            py.path.local(self).remove()
+            return
+        flags = []
+        if force:
+            flags.append('--force')
+        self._svn('remove', *flags)
+
+    def copy(self, target):
+        """ copy path to target."""
+        py.process.cmdexec("svn copy %s %s" %(str(self), str(target)))
+
+    def rename(self, target):
+        """ rename this path to target. """
+        py.process.cmdexec("svn move --force %s %s" %(str(self), str(target)))
+
+    def lock(self):
+        """ set a lock (exclusive) on the resource """
+        out = self._authsvn('lock').strip()
+        if not out:
+            # warning or error, raise exception
+            raise ValueError("unknown error in svn lock command")
+
+    def unlock(self):
+        """ unset a previously set lock """
+        out = self._authsvn('unlock').strip()
+        if out.startswith('svn:'):
+            # warning or error, raise exception
+            raise Exception(out[4:])
+
+    def cleanup(self):
+        """ remove any locks from the resource """
+        # XXX should be fixed properly!!!
+        try:
+            self.unlock()
+        except:
+            pass
+
+    def status(self, updates=0, rec=0, externals=0):
+        """ return (collective) Status object for this file. """
+        # http://svnbook.red-bean.com/book.html#svn-ch-3-sect-4.3.1
+        #             2201     2192        jum   test
+        # XXX
+        if externals:
+            raise ValueError("XXX cannot perform status() "
+                             "on external items yet")
+        else:
+            #1.2 supports: externals = '--ignore-externals'
+            externals = ''
+        if rec:
+            rec= ''
+        else:
+            rec = '--non-recursive'
+
+        # XXX does not work on all subversion versions
+        #if not externals:
+        #    externals = '--ignore-externals'
+
+        if updates:
+            updates = '-u'
+        else:
+            updates = ''
+
+        try:
+            cmd = 'status -v --xml --no-ignore %s %s %s' % (
+                    updates, rec, externals)
+            out = self._authsvn(cmd)
+        except py.process.cmdexec.Error:
+            cmd = 'status -v --no-ignore %s %s %s' % (
+                    updates, rec, externals)
+            out = self._authsvn(cmd)
+            rootstatus = WCStatus(self).fromstring(out, self)
+        else:
+            rootstatus = XMLWCStatus(self).fromstring(out, self)
+        return rootstatus
+
+    def diff(self, rev=None):
+        """ return a diff of the current path against revision rev (defaulting
+            to the last one).
+        """
+        args = []
+        if rev is not None:
+            args.append("-r %d" % rev)
+        out = self._authsvn('diff', args)
+        return out
+
+    def blame(self):
+        """ return a list of tuples of three elements:
+            (revision, commiter, line)
+        """
+        out = self._svn('blame')
+        result = []
+        blamelines = out.splitlines()
+        reallines = py.path.svnurl(self.url).readlines()
+        for i, (blameline, line) in enumerate(
+                zip(blamelines, reallines)):
+            m = rex_blame.match(blameline)
+            if not m:
+                raise ValueError("output line %r of svn blame does not match "
+                                 "expected format" % (line, ))
+            rev, name, _ = m.groups()
+            result.append((int(rev), name, line))
+        return result
+
+    _rex_commit = re.compile(r'.*Committed revision (\d+)\.$', re.DOTALL)
+    def commit(self, msg='', rec=1):
+        """ commit with support for non-recursive commits """
+        # XXX i guess escaping should be done better here?!?
+        cmd = 'commit -m "%s" --force-log' % (msg.replace('"', '\\"'),)
+        if not rec:
+            cmd += ' -N'
+        out = self._authsvn(cmd)
+        try:
+            del cache.info[self]
+        except KeyError:
+            pass
+        if out:
+            m = self._rex_commit.match(out)
+            return int(m.group(1))
+
+    def propset(self, name, value, *args):
+        """ set property name to value on this path. """
+        d = py.path.local.mkdtemp()
+        try:
+            p = d.join('value')
+            p.write(value)
+            self._svn('propset', name, '--file', str(p), *args)
+        finally:
+            d.remove()
+
+    def propget(self, name):
+        """ get property name on this path. """
+        res = self._svn('propget', name)
+        return res[:-1] # strip trailing newline
+
+    def propdel(self, name):
+        """ delete property name on this path. """
+        res = self._svn('propdel', name)
+        return res[:-1] # strip trailing newline
+
+    def proplist(self, rec=0):
+        """ return a mapping of property names to property values.
+If rec is True, then return a dictionary mapping sub-paths to such mappings.
+"""
+        if rec:
+            res = self._svn('proplist -R')
+            return make_recursive_propdict(self, res)
+        else:
+            res = self._svn('proplist')
+            lines = res.split('\n')
+            lines = [x.strip() for x in lines[1:]]
+            return PropListDict(self, lines)
+
+    def revert(self, rec=0):
+        """ revert the local changes of this path. if rec is True, do so
+recursively. """
+        if rec:
+            result = self._svn('revert -R')
+        else:
+            result = self._svn('revert')
+        return result
+
+    def new(self, **kw):
+        """ create a modified version of this path. A 'rev' argument
+            indicates a new revision.
+            the following keyword arguments modify various path parts:
+
+              http://host.com/repo/path/file.ext
+              |-----------------------|          dirname
+                                        |------| basename
+                                        |--|     purebasename
+                                            |--| ext
+        """
+        if kw:
+            localpath = self.localpath.new(**kw)
+        else:
+            localpath = self.localpath
+        return self.__class__(localpath, auth=self.auth)
+
+    def join(self, *args, **kwargs):
+        """ return a new Path (with the same revision) which is composed
+            of the self Path followed by 'args' path components.
+        """
+        if not args:
+            return self
+        localpath = self.localpath.join(*args, **kwargs)
+        return self.__class__(localpath, auth=self.auth)
+
+    def info(self, usecache=1):
+        """ return an Info structure with svn-provided information. """
+        info = usecache and cache.info.get(self)
+        if not info:
+            try:
+                output = self._svn('info')
+            except py.process.cmdexec.Error:
+                e = sys.exc_info()[1]
+                if e.err.find('Path is not a working copy directory') != -1:
+                    raise py.error.ENOENT(self, e.err)
+                elif e.err.find("is not under version control") != -1:
+                    raise py.error.ENOENT(self, e.err)
+                raise
+            # XXX SVN 1.3 has output on stderr instead of stdout (while it does
+            # return 0!), so a bit nasty, but we assume no output is output
+            # to stderr...
+            if (output.strip() == '' or
+                    output.lower().find('not a versioned resource') != -1):
+                raise py.error.ENOENT(self, output)
+            info = InfoSvnWCCommand(output)
+
+            # Can't reliably compare on Windows without access to win32api
+            if sys.platform != 'win32':
+                if info.path != self.localpath:
+                    raise py.error.ENOENT(self, "not a versioned resource:" +
+                            " %s != %s" % (info.path, self.localpath))
+            cache.info[self] = info
+        return info
+
+    def listdir(self, fil=None, sort=None):
+        """ return a sequence of Paths.
+
+        listdir will return either a tuple or a list of paths
+        depending on implementation choices.
+        """
+        if isinstance(fil, str):
+            fil = common.FNMatcher(fil)
+        # XXX unify argument naming with LocalPath.listdir
+        def notsvn(path):
+            return path.basename != '.svn'
+
+        paths = []
+        for localpath in self.localpath.listdir(notsvn):
+            p = self.__class__(localpath, auth=self.auth)
+            if notsvn(p) and (not fil or fil(p)):
+                paths.append(p)
+        self._sortlist(paths, sort)
+        return paths
+
+    def open(self, mode='r'):
+        """ return an opened file with the given mode. """
+        return open(self.strpath, mode)
+
+    def _getbyspec(self, spec):
+        return self.localpath._getbyspec(spec)
+
+    class Checkers(py.path.local.Checkers):
+        def __init__(self, path):
+            self.svnwcpath = path
+            self.path = path.localpath
+        def versioned(self):
+            try:
+                s = self.svnwcpath.info()
+            except (py.error.ENOENT, py.error.EEXIST):
+                return False
+            except py.process.cmdexec.Error:
+                e = sys.exc_info()[1]
+                if e.err.find('is not a working copy')!=-1:
+                    return False
+                if e.err.lower().find('not a versioned resource') != -1:
+                    return False
+                raise
+            else:
+                return True
+
+    def log(self, rev_start=None, rev_end=1, verbose=False):
+        """ return a list of LogEntry instances for this path.
+rev_start is the starting revision (defaulting to the first one).
+rev_end is the last revision (defaulting to HEAD).
+if verbose is True, then the LogEntry instances also know which files changed.
+"""
+        assert self.check()   # make it simpler for the pipe
+        rev_start = rev_start is None and "HEAD" or rev_start
+        rev_end = rev_end is None and "HEAD" or rev_end
+        if rev_start == "HEAD" and rev_end == 1:
+                rev_opt = ""
+        else:
+            rev_opt = "-r %s:%s" % (rev_start, rev_end)
+        verbose_opt = verbose and "-v" or ""
+        locale_env = fixlocale()
+        # some blather on stderr
+        auth_opt = self._makeauthoptions()
+        #stdin, stdout, stderr  = os.popen3(locale_env +
+        #                                   'svn log --xml %s %s %s "%s"' % (
+        #                                    rev_opt, verbose_opt, auth_opt,
+        #                                    self.strpath))
+        cmd = locale_env + 'svn log --xml %s %s %s "%s"' % (
+            rev_opt, verbose_opt, auth_opt, self.strpath)
+
+        popen = subprocess.Popen(cmd,
+                    stdout=subprocess.PIPE,
+                    stderr=subprocess.PIPE,
+                    shell=True,
+        )
+        stdout, stderr = popen.communicate()
+        stdout = py.builtin._totext(stdout, sys.getdefaultencoding())
+        minidom,ExpatError = importxml()
+        try:
+            tree = minidom.parseString(stdout)
+        except ExpatError:
+            raise ValueError('no such revision')
+        result = []
+        for logentry in filter(None, tree.firstChild.childNodes):
+            if logentry.nodeType == logentry.ELEMENT_NODE:
+                result.append(LogEntry(logentry))
+        return result
+
+    def size(self):
+        """ Return the size of the file content of the Path. """
+        return self.info().size
+
+    def mtime(self):
+        """ Return the last modification time of the file. """
+        return self.info().mtime
+
+    def __hash__(self):
+        return hash((self.strpath, self.__class__, self.auth))
+
+
+class WCStatus:
+    attrnames = ('modified','added', 'conflict', 'unchanged', 'external',
+                'deleted', 'prop_modified', 'unknown', 'update_available',
+                'incomplete', 'kindmismatch', 'ignored', 'locked', 'replaced'
+                )
+
+    def __init__(self, wcpath, rev=None, modrev=None, author=None):
+        self.wcpath = wcpath
+        self.rev = rev
+        self.modrev = modrev
+        self.author = author
+
+        for name in self.attrnames:
+            setattr(self, name, [])
+
+    def allpath(self, sort=True, **kw):
+        d = {}
+        for name in self.attrnames:
+            if name not in kw or kw[name]:
+                for path in getattr(self, name):
+                    d[path] = 1
+        l = d.keys()
+        if sort:
+            l.sort()
+        return l
+
+    # XXX a bit scary to assume there's always 2 spaces between username and
+    # path, however with win32 allowing spaces in user names there doesn't
+    # seem to be a more solid approach :(
+    _rex_status = re.compile(r'\s+(\d+|-)\s+(\S+)\s+(.+?)\s{2,}(.*)')
+
+    def fromstring(data, rootwcpath, rev=None, modrev=None, author=None):
+        """ return a new WCStatus object from data 's'
+        """
+        rootstatus = WCStatus(rootwcpath, rev, modrev, author)
+        update_rev = None
+        for line in data.split('\n'):
+            if not line.strip():
+                continue
+            #print "processing %r" % line
+            flags, rest = line[:8], line[8:]
+            # first column
+            c0,c1,c2,c3,c4,c5,x6,c7 = flags
+            #if '*' in line:
+            #    print "flags", repr(flags), "rest", repr(rest)
+
+            if c0 in '?XI':
+                fn = line.split(None, 1)[1]
+                if c0 == '?':
+                    wcpath = rootwcpath.join(fn, abs=1)
+                    rootstatus.unknown.append(wcpath)
+                elif c0 == 'X':
+                    wcpath = rootwcpath.__class__(
+                        rootwcpath.localpath.join(fn, abs=1),
+                        auth=rootwcpath.auth)
+                    rootstatus.external.append(wcpath)
+                elif c0 == 'I':
+                    wcpath = rootwcpath.join(fn, abs=1)
+                    rootstatus.ignored.append(wcpath)
+
+                continue
+
+            #elif c0 in '~!' or c4 == 'S':
+            #    raise NotImplementedError("received flag %r" % c0)
+
+            m = WCStatus._rex_status.match(rest)
+            if not m:
+                if c7 == '*':
+                    fn = rest.strip()
+                    wcpath = rootwcpath.join(fn, abs=1)
+                    rootstatus.update_available.append(wcpath)
+                    continue
+                if line.lower().find('against revision:')!=-1:
+                    update_rev = int(rest.split(':')[1].strip())
+                    continue
+                if line.lower().find('status on external') > -1:
+                    # XXX not sure what to do here... perhaps we want to
+                    # store some state instead of just continuing, as right
+                    # now it makes the top-level external get added twice
+                    # (once as external, once as 'normal' unchanged item)
+                    # because of the way SVN presents external items
+                    continue
+                # keep trying
+                raise ValueError("could not parse line %r" % line)
+            else:
+                rev, modrev, author, fn = m.groups()
+            wcpath = rootwcpath.join(fn, abs=1)
+            #assert wcpath.check()
+            if c0 == 'M':
+                assert wcpath.check(file=1), "didn't expect a directory with changed content here"
+                rootstatus.modified.append(wcpath)
+            elif c0 == 'A' or c3 == '+' :
+                rootstatus.added.append(wcpath)
+            elif c0 == 'D':
+                rootstatus.deleted.append(wcpath)
+            elif c0 == 'C':
+                rootstatus.conflict.append(wcpath)
+            elif c0 == '~':
+                rootstatus.kindmismatch.append(wcpath)
+            elif c0 == '!':
+                rootstatus.incomplete.append(wcpath)
+            elif c0 == 'R':
+                rootstatus.replaced.append(wcpath)
+            elif not c0.strip():
+                rootstatus.unchanged.append(wcpath)
+            else:
+                raise NotImplementedError("received flag %r" % c0)
+
+            if c1 == 'M':
+                rootstatus.prop_modified.append(wcpath)
+            # XXX do we cover all client versions here?
+            if c2 == 'L' or c5 == 'K':
+                rootstatus.locked.append(wcpath)
+            if c7 == '*':
+                rootstatus.update_available.append(wcpath)
+
+            if wcpath == rootwcpath:
+                rootstatus.rev = rev
+                rootstatus.modrev = modrev
+                rootstatus.author = author
+                if update_rev:
+                    rootstatus.update_rev = update_rev
+                continue
+        return rootstatus
+    fromstring = staticmethod(fromstring)
+
+class XMLWCStatus(WCStatus):
+    def fromstring(data, rootwcpath, rev=None, modrev=None, author=None):
+        """ parse 'data' (XML string as outputted by svn st) into a status obj
+        """
+        # XXX for externals, the path is shown twice: once
+        # with external information, and once with full info as if
+        # the item was a normal non-external... the current way of
+        # dealing with this issue is by ignoring it - this does make
+        # externals appear as external items as well as 'normal',
+        # unchanged ones in the status object so this is far from ideal
+        rootstatus = WCStatus(rootwcpath, rev, modrev, author)
+        update_rev = None
+        minidom, ExpatError = importxml()
+        try:
+            doc = minidom.parseString(data)
+        except ExpatError:
+            e = sys.exc_info()[1]
+            raise ValueError(str(e))
+        urevels = doc.getElementsByTagName('against')
+        if urevels:
+            rootstatus.update_rev = urevels[-1].getAttribute('revision')
+        for entryel in doc.getElementsByTagName('entry'):
+            path = entryel.getAttribute('path')
+            statusel = entryel.getElementsByTagName('wc-status')[0]
+            itemstatus = statusel.getAttribute('item')
+
+            if itemstatus == 'unversioned':
+                wcpath = rootwcpath.join(path, abs=1)
+                rootstatus.unknown.append(wcpath)
+                continue
+            elif itemstatus == 'external':
+                wcpath = rootwcpath.__class__(
+                    rootwcpath.localpath.join(path, abs=1),
+                    auth=rootwcpath.auth)
+                rootstatus.external.append(wcpath)
+                continue
+            elif itemstatus == 'ignored':
+                wcpath = rootwcpath.join(path, abs=1)
+                rootstatus.ignored.append(wcpath)
+                continue
+            elif itemstatus == 'incomplete':
+                wcpath = rootwcpath.join(path, abs=1)
+                rootstatus.incomplete.append(wcpath)
+                continue
+
+            rev = statusel.getAttribute('revision')
+            if itemstatus == 'added' or itemstatus == 'none':
+                rev = '0'
+                modrev = '?'
+                author = '?'
+                date = ''
+            elif itemstatus == "replaced":
+                pass
+            else:
+                #print entryel.toxml()
+                commitel = entryel.getElementsByTagName('commit')[0]
+                if commitel:
+                    modrev = commitel.getAttribute('revision')
+                    author = ''
+                    author_els = commitel.getElementsByTagName('author')
+                    if author_els:
+                        for c in author_els[0].childNodes:
+                            author += c.nodeValue
+                    date = ''
+                    for c in commitel.getElementsByTagName('date')[0]\
+                            .childNodes:
+                        date += c.nodeValue
+
+            wcpath = rootwcpath.join(path, abs=1)
+
+            assert itemstatus != 'modified' or wcpath.check(file=1), (
+                'did\'t expect a directory with changed content here')
+
+            itemattrname = {
+                'normal': 'unchanged',
+                'unversioned': 'unknown',
+                'conflicted': 'conflict',
+                'none': 'added',
+            }.get(itemstatus, itemstatus)
+
+            attr = getattr(rootstatus, itemattrname)
+            attr.append(wcpath)
+
+            propsstatus = statusel.getAttribute('props')
+            if propsstatus not in ('none', 'normal'):
+                rootstatus.prop_modified.append(wcpath)
+
+            if wcpath == rootwcpath:
+                rootstatus.rev = rev
+                rootstatus.modrev = modrev
+                rootstatus.author = author
+                rootstatus.date = date
+
+            # handle repos-status element (remote info)
+            rstatusels = entryel.getElementsByTagName('repos-status')
+            if rstatusels:
+                rstatusel = rstatusels[0]
+                ritemstatus = rstatusel.getAttribute('item')
+                if ritemstatus in ('added', 'modified'):
+                    rootstatus.update_available.append(wcpath)
+
+            lockels = entryel.getElementsByTagName('lock')
+            if len(lockels):
+                rootstatus.locked.append(wcpath)
+
+        return rootstatus
+    fromstring = staticmethod(fromstring)
+
+class InfoSvnWCCommand:
+    def __init__(self, output):
+        # Path: test
+        # URL: http://codespeak.net/svn/std.path/trunk/dist/std.path/test
+        # Repository UUID: fd0d7bf2-dfb6-0310-8d31-b7ecfe96aada
+        # Revision: 2151
+        # Node Kind: directory
+        # Schedule: normal
+        # Last Changed Author: hpk
+        # Last Changed Rev: 2100
+        # Last Changed Date: 2003-10-27 20:43:14 +0100 (Mon, 27 Oct 2003)
+        # Properties Last Updated: 2003-11-03 14:47:48 +0100 (Mon, 03 Nov 2003)
+
+        d = {}
+        for line in output.split('\n'):
+            if not line.strip():
+                continue
+            key, value = line.split(':', 1)
+            key = key.lower().replace(' ', '')
+            value = value.strip()
+            d[key] = value
+        try:
+            self.url = d['url']
+        except KeyError:
+            raise  ValueError("Not a versioned resource")
+            #raise ValueError, "Not a versioned resource %r" % path
+        self.kind = d['nodekind'] == 'directory' and 'dir' or d['nodekind']
+        try:
+            self.rev = int(d['revision'])
+        except KeyError:
+            self.rev = None
+
+        self.path = py.path.local(d['path'])
+        self.size = self.path.size()
+        if 'lastchangedrev' in d:
+            self.created_rev = int(d['lastchangedrev'])
+        if 'lastchangedauthor' in d:
+            self.last_author = d['lastchangedauthor']
+        if 'lastchangeddate' in d:
+            self.mtime = parse_wcinfotime(d['lastchangeddate'])
+            self.time = self.mtime * 1000000
+
+    def __eq__(self, other):
+        return self.__dict__ == other.__dict__
+
+def parse_wcinfotime(timestr):
+    """ Returns seconds since epoch, UTC. """
+    # example: 2003-10-27 20:43:14 +0100 (Mon, 27 Oct 2003)
+    m = re.match(r'(\d+-\d+-\d+ \d+:\d+:\d+) ([+-]\d+) .*', timestr)
+    if not m:
+        raise ValueError("timestring %r does not match" % timestr)
+    timestr, timezone = m.groups()
+    # do not handle timezone specially, return value should be UTC
+    parsedtime = time.strptime(timestr, "%Y-%m-%d %H:%M:%S")
+    return calendar.timegm(parsedtime)
+
+def make_recursive_propdict(wcroot,
+                            output,
+                            rex = re.compile("Properties on '(.*)':")):
+    """ Return a dictionary of path->PropListDict mappings. """
+    lines = [x for x in output.split('\n') if x]
+    pdict = {}
+    while lines:
+        line = lines.pop(0)
+        m = rex.match(line)
+        if not m:
+            raise ValueError("could not parse propget-line: %r" % line)
+        path = m.groups()[0]
+        wcpath = wcroot.join(path, abs=1)
+        propnames = []
+        while lines and lines[0].startswith('  '):
+            propname = lines.pop(0).strip()
+            propnames.append(propname)
+        assert propnames, "must have found properties!"
+        pdict[wcpath] = PropListDict(wcpath, propnames)
+    return pdict
+
+
+def importxml(cache=[]):
+    if cache:
+        return cache
+    from xml.dom import minidom
+    from xml.parsers.expat import ExpatError
+    cache.extend([minidom, ExpatError])
+    return cache
+
+class LogEntry:
+    def __init__(self, logentry):
+        self.rev = int(logentry.getAttribute('revision'))
+        for lpart in filter(None, logentry.childNodes):
+            if lpart.nodeType == lpart.ELEMENT_NODE:
+                if lpart.nodeName == 'author':
+                    self.author = lpart.firstChild.nodeValue
+                elif lpart.nodeName == 'msg':
+                    if lpart.firstChild:
+                        self.msg = lpart.firstChild.nodeValue
+                    else:
+                        self.msg = ''
+                elif lpart.nodeName == 'date':
+                    #2003-07-29T20:05:11.598637Z
+                    timestr = lpart.firstChild.nodeValue
+                    self.date = parse_apr_time(timestr)
+                elif lpart.nodeName == 'paths':
+                    self.strpaths = []
+                    for ppart in filter(None, lpart.childNodes):
+                        if ppart.nodeType == ppart.ELEMENT_NODE:
+                            self.strpaths.append(PathEntry(ppart))
+    def __repr__(self):
+        return '<Logentry rev=%d author=%s date=%s>' % (
+            self.rev, self.author, self.date)
+
+
Index: venv/Lib/site-packages/py/_path/local.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_path/local.py	(date 1543190975936)
+++ venv/Lib/site-packages/py/_path/local.py	(date 1543190975936)
@@ -0,0 +1,994 @@
+"""
+local path implementation.
+"""
+from __future__ import with_statement
+
+from contextlib import contextmanager
+import sys, os, atexit, io, uuid
+import py
+from py._path import common
+from py._path.common import iswin32, fspath
+from stat import S_ISLNK, S_ISDIR, S_ISREG
+
+from os.path import abspath, normpath, isabs, exists, isdir, isfile, islink, dirname
+
+if sys.version_info > (3,0):
+    def map_as_list(func, iter):
+        return list(map(func, iter))
+else:
+    map_as_list = map
+
+class Stat(object):
+    def __getattr__(self, name):
+        return getattr(self._osstatresult, "st_" + name)
+
+    def __init__(self, path, osstatresult):
+        self.path = path
+        self._osstatresult = osstatresult
+
+    @property
+    def owner(self):
+        if iswin32:
+            raise NotImplementedError("XXX win32")
+        import pwd
+        entry = py.error.checked_call(pwd.getpwuid, self.uid)
+        return entry[0]
+
+    @property
+    def group(self):
+        """ return group name of file. """
+        if iswin32:
+            raise NotImplementedError("XXX win32")
+        import grp
+        entry = py.error.checked_call(grp.getgrgid, self.gid)
+        return entry[0]
+
+    def isdir(self):
+        return S_ISDIR(self._osstatresult.st_mode)
+
+    def isfile(self):
+        return S_ISREG(self._osstatresult.st_mode)
+
+    def islink(self):
+        st = self.path.lstat()
+        return S_ISLNK(self._osstatresult.st_mode)
+
+class PosixPath(common.PathBase):
+    def chown(self, user, group, rec=0):
+        """ change ownership to the given user and group.
+            user and group may be specified by a number or
+            by a name.  if rec is True change ownership
+            recursively.
+        """
+        uid = getuserid(user)
+        gid = getgroupid(group)
+        if rec:
+            for x in self.visit(rec=lambda x: x.check(link=0)):
+                if x.check(link=0):
+                    py.error.checked_call(os.chown, str(x), uid, gid)
+        py.error.checked_call(os.chown, str(self), uid, gid)
+
+    def readlink(self):
+        """ return value of a symbolic link. """
+        return py.error.checked_call(os.readlink, self.strpath)
+
+    def mklinkto(self, oldname):
+        """ posix style hard link to another name. """
+        py.error.checked_call(os.link, str(oldname), str(self))
+
+    def mksymlinkto(self, value, absolute=1):
+        """ create a symbolic link with the given value (pointing to another name). """
+        if absolute:
+            py.error.checked_call(os.symlink, str(value), self.strpath)
+        else:
+            base = self.common(value)
+            # with posix local paths '/' is always a common base
+            relsource = self.__class__(value).relto(base)
+            reldest = self.relto(base)
+            n = reldest.count(self.sep)
+            target = self.sep.join(('..', )*n + (relsource, ))
+            py.error.checked_call(os.symlink, target, self.strpath)
+
+def getuserid(user):
+    import pwd
+    if not isinstance(user, int):
+        user = pwd.getpwnam(user)[2]
+    return user
+
+def getgroupid(group):
+    import grp
+    if not isinstance(group, int):
+        group = grp.getgrnam(group)[2]
+    return group
+
+FSBase = not iswin32 and PosixPath or common.PathBase
+
+class LocalPath(FSBase):
+    """ object oriented interface to os.path and other local filesystem
+        related information.
+    """
+    class ImportMismatchError(ImportError):
+        """ raised on pyimport() if there is a mismatch of __file__'s"""
+
+    sep = os.sep
+    class Checkers(common.Checkers):
+        def _stat(self):
+            try:
+                return self._statcache
+            except AttributeError:
+                try:
+                    self._statcache = self.path.stat()
+                except py.error.ELOOP:
+                    self._statcache = self.path.lstat()
+                return self._statcache
+
+        def dir(self):
+            return S_ISDIR(self._stat().mode)
+
+        def file(self):
+            return S_ISREG(self._stat().mode)
+
+        def exists(self):
+            return self._stat()
+
+        def link(self):
+            st = self.path.lstat()
+            return S_ISLNK(st.mode)
+
+    def __init__(self, path=None, expanduser=False):
+        """ Initialize and return a local Path instance.
+
+        Path can be relative to the current directory.
+        If path is None it defaults to the current working directory.
+        If expanduser is True, tilde-expansion is performed.
+        Note that Path instances always carry an absolute path.
+        Note also that passing in a local path object will simply return
+        the exact same path object. Use new() to get a new copy.
+        """
+        if path is None:
+            self.strpath = py.error.checked_call(os.getcwd)
+        else:
+            try:
+                path = fspath(path)
+            except TypeError:
+                raise ValueError("can only pass None, Path instances "
+                                 "or non-empty strings to LocalPath")
+            if expanduser:
+                path = os.path.expanduser(path)
+            self.strpath = abspath(path)
+
+    def __hash__(self):
+        return hash(self.strpath)
+
+    def __eq__(self, other):
+        s1 = fspath(self)
+        try:
+            s2 = fspath(other)
+        except TypeError:
+            return False
+        if iswin32:
+            s1 = s1.lower()
+            try:
+                s2 = s2.lower()
+            except AttributeError:
+                return False
+        return s1 == s2
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __lt__(self, other):
+        return fspath(self) < fspath(other)
+
+    def __gt__(self, other):
+        return fspath(self) > fspath(other)
+
+    def samefile(self, other):
+        """ return True if 'other' references the same file as 'self'.
+        """
+        other = fspath(other)
+        if not isabs(other):
+            other = abspath(other)
+        if self == other:
+            return True
+        if iswin32:
+            return False # there is no samefile
+        return py.error.checked_call(
+                os.path.samefile, self.strpath, other)
+
+    def remove(self, rec=1, ignore_errors=False):
+        """ remove a file or directory (or a directory tree if rec=1).
+        if ignore_errors is True, errors while removing directories will
+        be ignored.
+        """
+        if self.check(dir=1, link=0):
+            if rec:
+                # force remove of readonly files on windows
+                if iswin32:
+                    self.chmod(0o700, rec=1)
+                import shutil
+                py.error.checked_call(
+                    shutil.rmtree, self.strpath,
+                    ignore_errors=ignore_errors)
+            else:
+                py.error.checked_call(os.rmdir, self.strpath)
+        else:
+            if iswin32:
+                self.chmod(0o700)
+            py.error.checked_call(os.remove, self.strpath)
+
+    def computehash(self, hashtype="md5", chunksize=524288):
+        """ return hexdigest of hashvalue for this file. """
+        try:
+            try:
+                import hashlib as mod
+            except ImportError:
+                if hashtype == "sha1":
+                    hashtype = "sha"
+                mod = __import__(hashtype)
+            hash = getattr(mod, hashtype)()
+        except (AttributeError, ImportError):
+            raise ValueError("Don't know how to compute %r hash" %(hashtype,))
+        f = self.open('rb')
+        try:
+            while 1:
+                buf = f.read(chunksize)
+                if not buf:
+                    return hash.hexdigest()
+                hash.update(buf)
+        finally:
+            f.close()
+
+    def new(self, **kw):
+        """ create a modified version of this path.
+            the following keyword arguments modify various path parts::
+
+              a:/some/path/to/a/file.ext
+              xx                           drive
+              xxxxxxxxxxxxxxxxx            dirname
+                                xxxxxxxx   basename
+                                xxxx       purebasename
+                                     xxx   ext
+        """
+        obj = object.__new__(self.__class__)
+        if not kw:
+            obj.strpath = self.strpath
+            return obj
+        drive, dirname, basename, purebasename,ext = self._getbyspec(
+             "drive,dirname,basename,purebasename,ext")
+        if 'basename' in kw:
+            if 'purebasename' in kw or 'ext' in kw:
+                raise ValueError("invalid specification %r" % kw)
+        else:
+            pb = kw.setdefault('purebasename', purebasename)
+            try:
+                ext = kw['ext']
+            except KeyError:
+                pass
+            else:
+                if ext and not ext.startswith('.'):
+                    ext = '.' + ext
+            kw['basename'] = pb + ext
+
+        if ('dirname' in kw and not kw['dirname']):
+            kw['dirname'] = drive
+        else:
+            kw.setdefault('dirname', dirname)
+        kw.setdefault('sep', self.sep)
+        obj.strpath = normpath(
+            "%(dirname)s%(sep)s%(basename)s" % kw)
+        return obj
+
+    def _getbyspec(self, spec):
+        """ see new for what 'spec' can be. """
+        res = []
+        parts = self.strpath.split(self.sep)
+
+        args = filter(None, spec.split(',') )
+        append = res.append
+        for name in args:
+            if name == 'drive':
+                append(parts[0])
+            elif name == 'dirname':
+                append(self.sep.join(parts[:-1]))
+            else:
+                basename = parts[-1]
+                if name == 'basename':
+                    append(basename)
+                else:
+                    i = basename.rfind('.')
+                    if i == -1:
+                        purebasename, ext = basename, ''
+                    else:
+                        purebasename, ext = basename[:i], basename[i:]
+                    if name == 'purebasename':
+                        append(purebasename)
+                    elif name == 'ext':
+                        append(ext)
+                    else:
+                        raise ValueError("invalid part specification %r" % name)
+        return res
+
+    def dirpath(self, *args, **kwargs):
+        """ return the directory path joined with any given path arguments.  """
+        if not kwargs:
+            path = object.__new__(self.__class__)
+            path.strpath = dirname(self.strpath)
+            if args:
+                path = path.join(*args)
+            return path
+        return super(LocalPath, self).dirpath(*args, **kwargs)
+
+    def join(self, *args, **kwargs):
+        """ return a new path by appending all 'args' as path
+        components.  if abs=1 is used restart from root if any
+        of the args is an absolute path.
+        """
+        sep = self.sep
+        strargs = [fspath(arg) for arg in args]
+        strpath = self.strpath
+        if kwargs.get('abs'):
+            newargs = []
+            for arg in reversed(strargs):
+                if isabs(arg):
+                    strpath = arg
+                    strargs = newargs
+                    break
+                newargs.insert(0, arg)
+        # special case for when we have e.g. strpath == "/"
+        actual_sep = "" if strpath.endswith(sep) else sep
+        for arg in strargs:
+            arg = arg.strip(sep)
+            if iswin32:
+                # allow unix style paths even on windows.
+                arg = arg.strip('/')
+                arg = arg.replace('/', sep)
+            strpath = strpath + actual_sep + arg
+            actual_sep = sep
+        obj = object.__new__(self.__class__)
+        obj.strpath = normpath(strpath)
+        return obj
+
+    def open(self, mode='r', ensure=False, encoding=None):
+        """ return an opened file with the given mode.
+
+        If ensure is True, create parent directories if needed.
+        """
+        if ensure:
+            self.dirpath().ensure(dir=1)
+        if encoding:
+            return py.error.checked_call(io.open, self.strpath, mode, encoding=encoding)
+        return py.error.checked_call(open, self.strpath, mode)
+
+    def _fastjoin(self, name):
+        child = object.__new__(self.__class__)
+        child.strpath = self.strpath + self.sep + name
+        return child
+
+    def islink(self):
+        return islink(self.strpath)
+
+    def check(self, **kw):
+        if not kw:
+            return exists(self.strpath)
+        if len(kw) == 1:
+            if "dir" in kw:
+                return not kw["dir"] ^ isdir(self.strpath)
+            if "file" in kw:
+                return not kw["file"] ^ isfile(self.strpath)
+        return super(LocalPath, self).check(**kw)
+
+    _patternchars = set("*?[" + os.path.sep)
+    def listdir(self, fil=None, sort=None):
+        """ list directory contents, possibly filter by the given fil func
+            and possibly sorted.
+        """
+        if fil is None and sort is None:
+            names = py.error.checked_call(os.listdir, self.strpath)
+            return map_as_list(self._fastjoin, names)
+        if isinstance(fil, py.builtin._basestring):
+            if not self._patternchars.intersection(fil):
+                child = self._fastjoin(fil)
+                if exists(child.strpath):
+                    return [child]
+                return []
+            fil = common.FNMatcher(fil)
+        names = py.error.checked_call(os.listdir, self.strpath)
+        res = []
+        for name in names:
+            child = self._fastjoin(name)
+            if fil is None or fil(child):
+                res.append(child)
+        self._sortlist(res, sort)
+        return res
+
+    def size(self):
+        """ return size of the underlying file object """
+        return self.stat().size
+
+    def mtime(self):
+        """ return last modification time of the path. """
+        return self.stat().mtime
+
+    def copy(self, target, mode=False, stat=False):
+        """ copy path to target.
+
+            If mode is True, will copy copy permission from path to target.
+            If stat is True, copy permission, last modification
+            time, last access time, and flags from path to target.
+        """
+        if self.check(file=1):
+            if target.check(dir=1):
+                target = target.join(self.basename)
+            assert self!=target
+            copychunked(self, target)
+            if mode:
+                copymode(self.strpath, target.strpath)
+            if stat:
+                copystat(self, target)
+        else:
+            def rec(p):
+                return p.check(link=0)
+            for x in self.visit(rec=rec):
+                relpath = x.relto(self)
+                newx = target.join(relpath)
+                newx.dirpath().ensure(dir=1)
+                if x.check(link=1):
+                    newx.mksymlinkto(x.readlink())
+                    continue
+                elif x.check(file=1):
+                    copychunked(x, newx)
+                elif x.check(dir=1):
+                    newx.ensure(dir=1)
+                if mode:
+                    copymode(x.strpath, newx.strpath)
+                if stat:
+                    copystat(x, newx)
+
+    def rename(self, target):
+        """ rename this path to target. """
+        target = fspath(target)
+        return py.error.checked_call(os.rename, self.strpath, target)
+
+    def dump(self, obj, bin=1):
+        """ pickle object into path location"""
+        f = self.open('wb')
+        import pickle
+        try:
+            py.error.checked_call(pickle.dump, obj, f, bin)
+        finally:
+            f.close()
+
+    def mkdir(self, *args):
+        """ create & return the directory joined with args. """
+        p = self.join(*args)
+        py.error.checked_call(os.mkdir, fspath(p))
+        return p
+
+    def write_binary(self, data, ensure=False):
+        """ write binary data into path.   If ensure is True create
+        missing parent directories.
+        """
+        if ensure:
+            self.dirpath().ensure(dir=1)
+        with self.open('wb') as f:
+            f.write(data)
+
+    def write_text(self, data, encoding, ensure=False):
+        """ write text data into path using the specified encoding.
+        If ensure is True create missing parent directories.
+        """
+        if ensure:
+            self.dirpath().ensure(dir=1)
+        with self.open('w', encoding=encoding) as f:
+            f.write(data)
+
+    def write(self, data, mode='w', ensure=False):
+        """ write data into path.   If ensure is True create
+        missing parent directories.
+        """
+        if ensure:
+            self.dirpath().ensure(dir=1)
+        if 'b' in mode:
+            if not py.builtin._isbytes(data):
+                raise ValueError("can only process bytes")
+        else:
+            if not py.builtin._istext(data):
+                if not py.builtin._isbytes(data):
+                    data = str(data)
+                else:
+                    data = py.builtin._totext(data, sys.getdefaultencoding())
+        f = self.open(mode)
+        try:
+            f.write(data)
+        finally:
+            f.close()
+
+    def _ensuredirs(self):
+        parent = self.dirpath()
+        if parent == self:
+            return self
+        if parent.check(dir=0):
+            parent._ensuredirs()
+        if self.check(dir=0):
+            try:
+                self.mkdir()
+            except py.error.EEXIST:
+                # race condition: file/dir created by another thread/process.
+                # complain if it is not a dir
+                if self.check(dir=0):
+                    raise
+        return self
+
+    def ensure(self, *args, **kwargs):
+        """ ensure that an args-joined path exists (by default as
+            a file). if you specify a keyword argument 'dir=True'
+            then the path is forced to be a directory path.
+        """
+        p = self.join(*args)
+        if kwargs.get('dir', 0):
+            return p._ensuredirs()
+        else:
+            p.dirpath()._ensuredirs()
+            if not p.check(file=1):
+                p.open('w').close()
+            return p
+
+    def stat(self, raising=True):
+        """ Return an os.stat() tuple. """
+        if raising == True:
+            return Stat(self, py.error.checked_call(os.stat, self.strpath))
+        try:
+            return Stat(self, os.stat(self.strpath))
+        except KeyboardInterrupt:
+            raise
+        except Exception:
+            return None
+
+    def lstat(self):
+        """ Return an os.lstat() tuple. """
+        return Stat(self, py.error.checked_call(os.lstat, self.strpath))
+
+    def setmtime(self, mtime=None):
+        """ set modification time for the given path.  if 'mtime' is None
+        (the default) then the file's mtime is set to current time.
+
+        Note that the resolution for 'mtime' is platform dependent.
+        """
+        if mtime is None:
+            return py.error.checked_call(os.utime, self.strpath, mtime)
+        try:
+            return py.error.checked_call(os.utime, self.strpath, (-1, mtime))
+        except py.error.EINVAL:
+            return py.error.checked_call(os.utime, self.strpath, (self.atime(), mtime))
+
+    def chdir(self):
+        """ change directory to self and return old current directory """
+        try:
+            old = self.__class__()
+        except py.error.ENOENT:
+            old = None
+        py.error.checked_call(os.chdir, self.strpath)
+        return old
+
+
+    @contextmanager
+    def as_cwd(self):
+        """ return context manager which changes to current dir during the
+        managed "with" context. On __enter__ it returns the old dir.
+        """
+        old = self.chdir()
+        try:
+            yield old
+        finally:
+            old.chdir()
+
+    def realpath(self):
+        """ return a new path which contains no symbolic links."""
+        return self.__class__(os.path.realpath(self.strpath))
+
+    def atime(self):
+        """ return last access time of the path. """
+        return self.stat().atime
+
+    def __repr__(self):
+        return 'local(%r)' % self.strpath
+
+    def __str__(self):
+        """ return string representation of the Path. """
+        return self.strpath
+
+    def chmod(self, mode, rec=0):
+        """ change permissions to the given mode. If mode is an
+            integer it directly encodes the os-specific modes.
+            if rec is True perform recursively.
+        """
+        if not isinstance(mode, int):
+            raise TypeError("mode %r must be an integer" % (mode,))
+        if rec:
+            for x in self.visit(rec=rec):
+                py.error.checked_call(os.chmod, str(x), mode)
+        py.error.checked_call(os.chmod, self.strpath, mode)
+
+    def pypkgpath(self):
+        """ return the Python package path by looking for the last
+        directory upwards which still contains an __init__.py.
+        Return None if a pkgpath can not be determined.
+        """
+        pkgpath = None
+        for parent in self.parts(reverse=True):
+            if parent.isdir():
+                if not parent.join('__init__.py').exists():
+                    break
+                if not isimportable(parent.basename):
+                    break
+                pkgpath = parent
+        return pkgpath
+
+    def _ensuresyspath(self, ensuremode, path):
+        if ensuremode:
+            s = str(path)
+            if ensuremode == "append":
+                if s not in sys.path:
+                    sys.path.append(s)
+            else:
+                if s != sys.path[0]:
+                    sys.path.insert(0, s)
+
+    def pyimport(self, modname=None, ensuresyspath=True):
+        """ return path as an imported python module.
+
+        If modname is None, look for the containing package
+        and construct an according module name.
+        The module will be put/looked up in sys.modules.
+        if ensuresyspath is True then the root dir for importing
+        the file (taking __init__.py files into account) will
+        be prepended to sys.path if it isn't there already.
+        If ensuresyspath=="append" the root dir will be appended
+        if it isn't already contained in sys.path.
+        if ensuresyspath is False no modification of syspath happens.
+        """
+        if not self.check():
+            raise py.error.ENOENT(self)
+
+        pkgpath = None
+        if modname is None:
+            pkgpath = self.pypkgpath()
+            if pkgpath is not None:
+                pkgroot = pkgpath.dirpath()
+                names = self.new(ext="").relto(pkgroot).split(self.sep)
+                if names[-1] == "__init__":
+                    names.pop()
+                modname = ".".join(names)
+            else:
+                pkgroot = self.dirpath()
+                modname = self.purebasename
+
+            self._ensuresyspath(ensuresyspath, pkgroot)
+            __import__(modname)
+            mod = sys.modules[modname]
+            if self.basename == "__init__.py":
+                return mod # we don't check anything as we might
+                       # be in a namespace package ... too icky to check
+            modfile = mod.__file__
+            if modfile[-4:] in ('.pyc', '.pyo'):
+                modfile = modfile[:-1]
+            elif modfile.endswith('$py.class'):
+                modfile = modfile[:-9] + '.py'
+            if modfile.endswith(os.path.sep + "__init__.py"):
+                if self.basename != "__init__.py":
+                    modfile = modfile[:-12]
+            try:
+                issame = self.samefile(modfile)
+            except py.error.ENOENT:
+                issame = False
+            if not issame:
+                ignore = os.getenv('PY_IGNORE_IMPORTMISMATCH')
+                if ignore != '1':
+                    raise self.ImportMismatchError(modname, modfile, self)
+            return mod
+        else:
+            try:
+                return sys.modules[modname]
+            except KeyError:
+                # we have a custom modname, do a pseudo-import
+                import types
+                mod = types.ModuleType(modname)
+                mod.__file__ = str(self)
+                sys.modules[modname] = mod
+                try:
+                    py.builtin.execfile(str(self), mod.__dict__)
+                except:
+                    del sys.modules[modname]
+                    raise
+                return mod
+
+    def sysexec(self, *argv, **popen_opts):
+        """ return stdout text from executing a system child process,
+            where the 'self' path points to executable.
+            The process is directly invoked and not through a system shell.
+        """
+        from subprocess import Popen, PIPE
+        argv = map_as_list(str, argv)
+        popen_opts['stdout'] = popen_opts['stderr'] = PIPE
+        proc = Popen([str(self)] + argv, **popen_opts)
+        stdout, stderr = proc.communicate()
+        ret = proc.wait()
+        if py.builtin._isbytes(stdout):
+            stdout = py.builtin._totext(stdout, sys.getdefaultencoding())
+        if ret != 0:
+            if py.builtin._isbytes(stderr):
+                stderr = py.builtin._totext(stderr, sys.getdefaultencoding())
+            raise py.process.cmdexec.Error(ret, ret, str(self),
+                                           stdout, stderr,)
+        return stdout
+
+    def sysfind(cls, name, checker=None, paths=None):
+        """ return a path object found by looking at the systems
+            underlying PATH specification. If the checker is not None
+            it will be invoked to filter matching paths.  If a binary
+            cannot be found, None is returned
+            Note: This is probably not working on plain win32 systems
+            but may work on cygwin.
+        """
+        if isabs(name):
+            p = py.path.local(name)
+            if p.check(file=1):
+                return p
+        else:
+            if paths is None:
+                if iswin32:
+                    paths = os.environ['Path'].split(';')
+                    if '' not in paths and '.' not in paths:
+                        paths.append('.')
+                    try:
+                        systemroot = os.environ['SYSTEMROOT']
+                    except KeyError:
+                        pass
+                    else:
+                        paths = [path.replace('%SystemRoot%', systemroot)
+                                 for path in paths]
+                else:
+                    paths = os.environ['PATH'].split(':')
+            tryadd = []
+            if iswin32:
+                tryadd += os.environ['PATHEXT'].split(os.pathsep)
+            tryadd.append("")
+
+            for x in paths:
+                for addext in tryadd:
+                    p = py.path.local(x).join(name, abs=True) + addext
+                    try:
+                        if p.check(file=1):
+                            if checker:
+                                if not checker(p):
+                                    continue
+                            return p
+                    except py.error.EACCES:
+                        pass
+        return None
+    sysfind = classmethod(sysfind)
+
+    def _gethomedir(cls):
+        try:
+            x = os.environ['HOME']
+        except KeyError:
+            try:
+                x = os.environ["HOMEDRIVE"] + os.environ['HOMEPATH']
+            except KeyError:
+                return None
+        return cls(x)
+    _gethomedir = classmethod(_gethomedir)
+
+    # """
+    # special class constructors for local filesystem paths
+    # """
+    @classmethod
+    def get_temproot(cls):
+        """ return the system's temporary directory
+            (where tempfiles are usually created in)
+        """
+        import tempfile
+        return py.path.local(tempfile.gettempdir())
+
+    @classmethod
+    def mkdtemp(cls, rootdir=None):
+        """ return a Path object pointing to a fresh new temporary directory
+            (which we created ourself).
+        """
+        import tempfile
+        if rootdir is None:
+            rootdir = cls.get_temproot()
+        return cls(py.error.checked_call(tempfile.mkdtemp, dir=str(rootdir)))
+
+    def make_numbered_dir(cls, prefix='session-', rootdir=None, keep=3,
+                          lock_timeout=172800):   # two days
+        """ return unique directory with a number greater than the current
+            maximum one.  The number is assumed to start directly after prefix.
+            if keep is true directories with a number less than (maxnum-keep)
+            will be removed. If .lock files are used (lock_timeout non-zero),
+            algorithm is multi-process safe.
+        """
+        if rootdir is None:
+            rootdir = cls.get_temproot()
+
+        nprefix = prefix.lower()
+        def parse_num(path):
+            """ parse the number out of a path (if it matches the prefix) """
+            nbasename = path.basename.lower()
+            if nbasename.startswith(nprefix):
+                try:
+                    return int(nbasename[len(nprefix):])
+                except ValueError:
+                    pass
+
+        def create_lockfile(path):
+            """ exclusively create lockfile. Throws when failed """
+            mypid = os.getpid()
+            lockfile = path.join('.lock')
+            if hasattr(lockfile, 'mksymlinkto'):
+                lockfile.mksymlinkto(str(mypid))
+            else:
+                fd = py.error.checked_call(os.open, str(lockfile), os.O_WRONLY | os.O_CREAT | os.O_EXCL, 0o644)
+                with os.fdopen(fd, 'w') as f:
+                    f.write(str(mypid))
+            return lockfile
+
+        def atexit_remove_lockfile(lockfile):
+            """ ensure lockfile is removed at process exit """
+            mypid = os.getpid()
+            def try_remove_lockfile():
+                # in a fork() situation, only the last process should
+                # remove the .lock, otherwise the other processes run the
+                # risk of seeing their temporary dir disappear.  For now
+                # we remove the .lock in the parent only (i.e. we assume
+                # that the children finish before the parent).
+                if os.getpid() != mypid:
+                    return
+                try:
+                    lockfile.remove()
+                except py.error.Error:
+                    pass
+            atexit.register(try_remove_lockfile)
+
+        # compute the maximum number currently in use with the prefix
+        lastmax = None
+        while True:
+            maxnum = -1
+            for path in rootdir.listdir():
+                num = parse_num(path)
+                if num is not None:
+                    maxnum = max(maxnum, num)
+
+            # make the new directory
+            try:
+                udir = rootdir.mkdir(prefix + str(maxnum+1))
+                if lock_timeout:
+                    lockfile = create_lockfile(udir)
+                    atexit_remove_lockfile(lockfile)
+            except (py.error.EEXIST, py.error.ENOENT, py.error.EBUSY):
+                # race condition (1): another thread/process created the dir
+                #                     in the meantime - try again
+                # race condition (2): another thread/process spuriously acquired
+                #                     lock treating empty directory as candidate
+                #                     for removal - try again
+                # race condition (3): another thread/process tried to create the lock at
+                #                     the same time (happened in Python 3.3 on Windows)
+                # https://ci.appveyor.com/project/pytestbot/py/build/1.0.21/job/ffi85j4c0lqwsfwa
+                if lastmax == maxnum:
+                    raise
+                lastmax = maxnum
+                continue
+            break
+
+        def get_mtime(path):
+            """ read file modification time """
+            try:
+                return path.lstat().mtime
+            except py.error.Error:
+                pass
+
+        garbage_prefix = prefix + 'garbage-'
+
+        def is_garbage(path):
+            """ check if path denotes directory scheduled for removal """
+            bn = path.basename
+            return bn.startswith(garbage_prefix)
+
+        # prune old directories
+        udir_time = get_mtime(udir)
+        if keep and udir_time:
+            for path in rootdir.listdir():
+                num = parse_num(path)
+                if num is not None and num <= (maxnum - keep):
+                    try:
+                        # try acquiring lock to remove directory as exclusive user
+                        if lock_timeout:
+                            create_lockfile(path)
+                    except (py.error.EEXIST, py.error.ENOENT, py.error.EBUSY):
+                        path_time = get_mtime(path)
+                        if not path_time:
+                            # assume directory doesn't exist now
+                            continue
+                        if abs(udir_time - path_time) < lock_timeout:
+                            # assume directory with lockfile exists
+                            # and lock timeout hasn't expired yet
+                            continue
+
+                    # path dir locked for exclusive use
+                    # and scheduled for removal to avoid another thread/process
+                    # treating it as a new directory or removal candidate
+                    garbage_path = rootdir.join(garbage_prefix + str(uuid.uuid4()))
+                    try:
+                        path.rename(garbage_path)
+                        garbage_path.remove(rec=1)
+                    except KeyboardInterrupt:
+                        raise
+                    except: # this might be py.error.Error, WindowsError ...
+                        pass
+                if is_garbage(path):
+                    try:
+                        path.remove(rec=1)
+                    except KeyboardInterrupt:
+                        raise
+                    except: # this might be py.error.Error, WindowsError ...
+                        pass
+
+        # make link...
+        try:
+            username = os.environ['USER']           #linux, et al
+        except KeyError:
+            try:
+                username = os.environ['USERNAME']   #windows
+            except KeyError:
+                username = 'current'
+
+        src  = str(udir)
+        dest = src[:src.rfind('-')] + '-' + username
+        try:
+            os.unlink(dest)
+        except OSError:
+            pass
+        try:
+            os.symlink(src, dest)
+        except (OSError, AttributeError, NotImplementedError):
+            pass
+
+        return udir
+    make_numbered_dir = classmethod(make_numbered_dir)
+
+
+def copymode(src, dest):
+    """ copy permission from src to dst. """
+    import shutil
+    shutil.copymode(src, dest)
+
+
+def copystat(src, dest):
+    """ copy permission,  last modification time,
+    last access time, and flags from src to dst."""
+    import shutil
+    shutil.copystat(str(src), str(dest))
+
+
+def copychunked(src, dest):
+    chunksize = 524288  # half a meg of bytes
+    fsrc = src.open('rb')
+    try:
+        fdest = dest.open('wb')
+        try:
+            while 1:
+                buf = fsrc.read(chunksize)
+                if not buf:
+                    break
+                fdest.write(buf)
+        finally:
+            fdest.close()
+    finally:
+        fsrc.close()
+
+
+def isimportable(name):
+    if name and (name[0].isalpha() or name[0] == '_'):
+        name = name.replace("_", '')
+        return not name or name.isalnum()
Index: venv/Lib/site-packages/py/_path/cacheutil.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_path/cacheutil.py	(date 1543190975944)
+++ venv/Lib/site-packages/py/_path/cacheutil.py	(date 1543190975944)
@@ -0,0 +1,114 @@
+"""
+This module contains multithread-safe cache implementations.
+
+All Caches have
+
+    getorbuild(key, builder)
+    delentry(key)
+
+methods and allow configuration when instantiating the cache class.
+"""
+from time import time as gettime
+
+class BasicCache(object):
+    def __init__(self, maxentries=128):
+        self.maxentries = maxentries
+        self.prunenum = int(maxentries - maxentries/8)
+        self._dict = {}
+
+    def clear(self):
+        self._dict.clear()
+
+    def _getentry(self, key):
+        return self._dict[key]
+
+    def _putentry(self, key, entry):
+        self._prunelowestweight()
+        self._dict[key] = entry
+
+    def delentry(self, key, raising=False):
+        try:
+            del self._dict[key]
+        except KeyError:
+            if raising:
+                raise
+
+    def getorbuild(self, key, builder):
+        try:
+            entry = self._getentry(key)
+        except KeyError:
+            entry = self._build(key, builder)
+            self._putentry(key, entry)
+        return entry.value
+
+    def _prunelowestweight(self):
+        """ prune out entries with lowest weight. """
+        numentries = len(self._dict)
+        if numentries >= self.maxentries:
+            # evict according to entry's weight
+            items = [(entry.weight, key)
+                        for key, entry in self._dict.items()]
+            items.sort()
+            index = numentries - self.prunenum
+            if index > 0:
+                for weight, key in items[:index]:
+                    # in MT situations the element might be gone
+                    self.delentry(key, raising=False)
+
+class BuildcostAccessCache(BasicCache):
+    """ A BuildTime/Access-counting cache implementation.
+        the weight of a value is computed as the product of
+
+            num-accesses-of-a-value * time-to-build-the-value
+
+        The values with the least such weights are evicted
+        if the cache maxentries threshold is superceded.
+        For implementation flexibility more than one object
+        might be evicted at a time.
+    """
+    # time function to use for measuring build-times
+
+    def _build(self, key, builder):
+        start = gettime()
+        val = builder()
+        end = gettime()
+        return WeightedCountingEntry(val, end-start)
+
+
+class WeightedCountingEntry(object):
+    def __init__(self, value, oneweight):
+        self._value = value
+        self.weight = self._oneweight = oneweight
+
+    def value(self):
+        self.weight += self._oneweight
+        return self._value
+    value = property(value)
+
+class AgingCache(BasicCache):
+    """ This cache prunes out cache entries that are too old.
+    """
+    def __init__(self, maxentries=128, maxseconds=10.0):
+        super(AgingCache, self).__init__(maxentries)
+        self.maxseconds = maxseconds
+
+    def _getentry(self, key):
+        entry = self._dict[key]
+        if entry.isexpired():
+            self.delentry(key)
+            raise KeyError(key)
+        return entry
+
+    def _build(self, key, builder):
+        val = builder()
+        entry = AgingEntry(val, gettime() + self.maxseconds)
+        return entry
+
+class AgingEntry(object):
+    def __init__(self, value, expirationtime):
+        self.value = value
+        self.weight = expirationtime
+
+    def isexpired(self):
+        t = gettime()
+        return t >= self.weight
Index: venv/Lib/site-packages/py/_path/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_path/__init__.py	(date 1543190975956)
+++ venv/Lib/site-packages/py/_path/__init__.py	(date 1543190975956)
@@ -0,0 +1,1 @@
+""" unified file system api """
Index: venv/Lib/site-packages/py/_process/killproc.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_process/killproc.py	(date 1543190975964)
+++ venv/Lib/site-packages/py/_process/killproc.py	(date 1543190975964)
@@ -0,0 +1,23 @@
+import py
+import os, sys
+
+if sys.platform == "win32" or getattr(os, '_name', '') == 'nt':
+    try:
+        import ctypes
+    except ImportError:
+        def dokill(pid):
+            py.process.cmdexec("taskkill /F /PID %d" %(pid,))
+    else:
+        def dokill(pid):
+            PROCESS_TERMINATE = 1
+            handle = ctypes.windll.kernel32.OpenProcess(
+                        PROCESS_TERMINATE, False, pid)
+            ctypes.windll.kernel32.TerminateProcess(handle, -1)
+            ctypes.windll.kernel32.CloseHandle(handle)
+else:
+    def dokill(pid):
+        os.kill(pid, 15)
+
+def kill(pid):
+    """ kill process by id. """
+    dokill(pid)
Index: venv/Lib/site-packages/py/_process/forkedfunc.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_process/forkedfunc.py	(date 1543190975980)
+++ venv/Lib/site-packages/py/_process/forkedfunc.py	(date 1543190975980)
@@ -0,0 +1,120 @@
+
+"""
+    ForkedFunc provides a way to run a function in a forked process
+    and get at its return value, stdout and stderr output as well
+    as signals and exitstatusus.
+"""
+
+import py
+import os
+import sys
+import marshal
+
+
+def get_unbuffered_io(fd, filename):
+    f = open(str(filename), "w")
+    if fd != f.fileno():
+        os.dup2(f.fileno(), fd)
+    class AutoFlush:
+        def write(self, data):
+            f.write(data)
+            f.flush()
+        def __getattr__(self, name):
+            return getattr(f, name)
+    return AutoFlush()
+
+
+class ForkedFunc:
+    EXITSTATUS_EXCEPTION = 3
+
+
+    def __init__(self, fun, args=None, kwargs=None, nice_level=0,
+                 child_on_start=None, child_on_exit=None):
+        if args is None:
+            args = []
+        if kwargs is None:
+            kwargs = {}
+        self.fun = fun
+        self.args = args
+        self.kwargs = kwargs
+        self.tempdir = tempdir = py.path.local.mkdtemp()
+        self.RETVAL = tempdir.ensure('retval')
+        self.STDOUT = tempdir.ensure('stdout')
+        self.STDERR = tempdir.ensure('stderr')
+
+        pid = os.fork()
+        if pid:  # in parent process
+            self.pid = pid
+        else:  # in child process
+            self.pid = None
+            self._child(nice_level, child_on_start, child_on_exit)
+
+    def _child(self, nice_level, child_on_start, child_on_exit):
+        # right now we need to call a function, but first we need to
+        # map all IO that might happen
+        sys.stdout = stdout = get_unbuffered_io(1, self.STDOUT)
+        sys.stderr = stderr = get_unbuffered_io(2, self.STDERR)
+        retvalf = self.RETVAL.open("wb")
+        EXITSTATUS = 0
+        try:
+            if nice_level:
+                os.nice(nice_level)
+            try:
+                if child_on_start is not None:
+                    child_on_start()
+                retval = self.fun(*self.args, **self.kwargs)
+                retvalf.write(marshal.dumps(retval))
+                if child_on_exit is not None:
+                    child_on_exit()
+            except:
+                excinfo = py.code.ExceptionInfo()
+                stderr.write(str(excinfo._getreprcrash()))
+                EXITSTATUS = self.EXITSTATUS_EXCEPTION
+        finally:
+            stdout.close()
+            stderr.close()
+            retvalf.close()
+        os.close(1)
+        os.close(2)
+        os._exit(EXITSTATUS)
+
+    def waitfinish(self, waiter=os.waitpid):
+        pid, systemstatus = waiter(self.pid, 0)
+        if systemstatus:
+            if os.WIFSIGNALED(systemstatus):
+                exitstatus = os.WTERMSIG(systemstatus) + 128
+            else:
+                exitstatus = os.WEXITSTATUS(systemstatus)
+        else:
+            exitstatus = 0
+        signal = systemstatus & 0x7f
+        if not exitstatus and not signal:
+            retval = self.RETVAL.open('rb')
+            try:
+                retval_data = retval.read()
+            finally:
+                retval.close()
+            retval = marshal.loads(retval_data)
+        else:
+            retval = None
+        stdout = self.STDOUT.read()
+        stderr = self.STDERR.read()
+        self._removetemp()
+        return Result(exitstatus, signal, retval, stdout, stderr)
+
+    def _removetemp(self):
+        if self.tempdir.check():
+            self.tempdir.remove()
+
+    def __del__(self):
+        if self.pid is not None:  # only clean up in main process
+            self._removetemp()
+
+
+class Result(object):
+    def __init__(self, exitstatus, signal, retval, stdout, stderr):
+        self.exitstatus = exitstatus
+        self.signal = signal
+        self.retval = retval
+        self.out = stdout
+        self.err = stderr
Index: venv/Lib/site-packages/py/_process/cmdexec.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_process/cmdexec.py	(date 1543190975991)
+++ venv/Lib/site-packages/py/_process/cmdexec.py	(date 1543190975991)
@@ -0,0 +1,49 @@
+import sys
+import subprocess
+import py
+from subprocess import Popen, PIPE
+
+def cmdexec(cmd):
+    """ return unicode output of executing 'cmd' in a separate process.
+
+    raise cmdexec.Error exeception if the command failed.
+    the exception will provide an 'err' attribute containing
+    the error-output from the command.
+    if the subprocess module does not provide a proper encoding/unicode strings
+    sys.getdefaultencoding() will be used, if that does not exist, 'UTF-8'.
+    """
+    process = subprocess.Popen(cmd, shell=True,
+            universal_newlines=True,
+            stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+    out, err = process.communicate()
+    if sys.version_info[0] < 3: # on py3 we get unicode strings, on py2 not
+        try:
+            default_encoding = sys.getdefaultencoding() # jython may not have it
+        except AttributeError:
+            default_encoding = sys.stdout.encoding or 'UTF-8'
+        out = unicode(out, process.stdout.encoding or default_encoding)
+        err = unicode(err, process.stderr.encoding or default_encoding)
+    status = process.poll()
+    if status:
+        raise ExecutionFailed(status, status, cmd, out, err)
+    return out
+
+class ExecutionFailed(py.error.Error):
+    def __init__(self, status, systemstatus, cmd, out, err):
+        Exception.__init__(self)
+        self.status = status
+        self.systemstatus = systemstatus
+        self.cmd = cmd
+        self.err = err
+        self.out = out
+
+    def __str__(self):
+        return "ExecutionFailed: %d  %s\n%s" %(self.status, self.cmd, self.err)
+
+# export the exception under the name 'py.process.cmdexec.Error'
+cmdexec.Error = ExecutionFailed
+try:
+    ExecutionFailed.__module__ = 'py.process.cmdexec'
+    ExecutionFailed.__name__ = 'Error'
+except (AttributeError, TypeError):
+    pass
Index: venv/Lib/site-packages/py/_process/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_process/__init__.py	(date 1543190976001)
+++ venv/Lib/site-packages/py/_process/__init__.py	(date 1543190976001)
@@ -0,0 +1,1 @@
+""" high-level sub-process handling """
Index: venv/Lib/site-packages/py/_vendored_packages/apipkg.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_vendored_packages/apipkg.py	(date 1543190976013)
+++ venv/Lib/site-packages/py/_vendored_packages/apipkg.py	(date 1543190976013)
@@ -0,0 +1,205 @@
+"""
+apipkg: control the exported namespace of a python package.
+
+see http://pypi.python.org/pypi/apipkg
+
+(c) holger krekel, 2009 - MIT license
+"""
+import os
+import sys
+from types import ModuleType
+
+
+__version__ = '1.4'
+
+
+def _py_abspath(path):
+    """
+    special version of abspath
+    that will leave paths from jython jars alone
+    """
+    if path.startswith('__pyclasspath__'):
+
+        return path
+    else:
+        return os.path.abspath(path)
+
+
+def distribution_version(name):
+    """try to get the version of the named distribution,
+    returs None on failure"""
+    from pkg_resources import get_distribution, DistributionNotFound
+    try:
+        dist = get_distribution(name)
+    except DistributionNotFound:
+        pass
+    else:
+        return dist.version
+
+
+def initpkg(pkgname, exportdefs, attr=dict(), eager=False):
+    """ initialize given package from the export definitions. """
+    oldmod = sys.modules.get(pkgname)
+    d = {}
+    f = getattr(oldmod, '__file__', None)
+    if f:
+        f = _py_abspath(f)
+    d['__file__'] = f
+    if hasattr(oldmod, '__version__'):
+        d['__version__'] = oldmod.__version__
+    if hasattr(oldmod, '__loader__'):
+        d['__loader__'] = oldmod.__loader__
+    if hasattr(oldmod, '__path__'):
+        d['__path__'] = [_py_abspath(p) for p in oldmod.__path__]
+    if '__doc__' not in exportdefs and getattr(oldmod, '__doc__', None):
+        d['__doc__'] = oldmod.__doc__
+    d.update(attr)
+    if hasattr(oldmod, "__dict__"):
+        oldmod.__dict__.update(d)
+    mod = ApiModule(pkgname, exportdefs, implprefix=pkgname, attr=d)
+    sys.modules[pkgname] = mod
+    # eagerload in bypthon to avoid their monkeypatching breaking packages
+    if 'bpython' in sys.modules or eager:
+        for module in sys.modules.values():
+            if isinstance(module, ApiModule):
+                module.__dict__
+
+
+def importobj(modpath, attrname):
+    module = __import__(modpath, None, None, ['__doc__'])
+    if not attrname:
+        return module
+
+    retval = module
+    names = attrname.split(".")
+    for x in names:
+        retval = getattr(retval, x)
+    return retval
+
+
+class ApiModule(ModuleType):
+    def __docget(self):
+        try:
+            return self.__doc
+        except AttributeError:
+            if '__doc__' in self.__map__:
+                return self.__makeattr('__doc__')
+
+    def __docset(self, value):
+        self.__doc = value
+    __doc__ = property(__docget, __docset)
+
+    def __init__(self, name, importspec, implprefix=None, attr=None):
+        self.__name__ = name
+        self.__all__ = [x for x in importspec if x != '__onfirstaccess__']
+        self.__map__ = {}
+        self.__implprefix__ = implprefix or name
+        if attr:
+            for name, val in attr.items():
+                # print "setting", self.__name__, name, val
+                setattr(self, name, val)
+        for name, importspec in importspec.items():
+            if isinstance(importspec, dict):
+                subname = '%s.%s' % (self.__name__, name)
+                apimod = ApiModule(subname, importspec, implprefix)
+                sys.modules[subname] = apimod
+                setattr(self, name, apimod)
+            else:
+                parts = importspec.split(':')
+                modpath = parts.pop(0)
+                attrname = parts and parts[0] or ""
+                if modpath[0] == '.':
+                    modpath = implprefix + modpath
+
+                if not attrname:
+                    subname = '%s.%s' % (self.__name__, name)
+                    apimod = AliasModule(subname, modpath)
+                    sys.modules[subname] = apimod
+                    if '.' not in name:
+                        setattr(self, name, apimod)
+                else:
+                    self.__map__[name] = (modpath, attrname)
+
+    def __repr__(self):
+        l = []
+        if hasattr(self, '__version__'):
+            l.append("version=" + repr(self.__version__))
+        if hasattr(self, '__file__'):
+            l.append('from ' + repr(self.__file__))
+        if l:
+            return '<ApiModule %r %s>' % (self.__name__, " ".join(l))
+        return '<ApiModule %r>' % (self.__name__,)
+
+    def __makeattr(self, name):
+        """lazily compute value for name or raise AttributeError if unknown."""
+        # print "makeattr", self.__name__, name
+        target = None
+        if '__onfirstaccess__' in self.__map__:
+            target = self.__map__.pop('__onfirstaccess__')
+            importobj(*target)()
+        try:
+            modpath, attrname = self.__map__[name]
+        except KeyError:
+            if target is not None and name != '__onfirstaccess__':
+                # retry, onfirstaccess might have set attrs
+                return getattr(self, name)
+            raise AttributeError(name)
+        else:
+            result = importobj(modpath, attrname)
+            setattr(self, name, result)
+            try:
+                del self.__map__[name]
+            except KeyError:
+                pass  # in a recursive-import situation a double-del can happen
+            return result
+
+    __getattr__ = __makeattr
+
+    @property
+    def __dict__(self):
+        # force all the content of the module
+        # to be loaded when __dict__ is read
+        dictdescr = ModuleType.__dict__['__dict__']
+        dict = dictdescr.__get__(self)
+        if dict is not None:
+            hasattr(self, 'some')
+            for name in self.__all__:
+                try:
+                    self.__makeattr(name)
+                except AttributeError:
+                    pass
+        return dict
+
+
+def AliasModule(modname, modpath, attrname=None):
+    mod = []
+
+    def getmod():
+        if not mod:
+            x = importobj(modpath, None)
+            if attrname is not None:
+                x = getattr(x, attrname)
+            mod.append(x)
+        return mod[0]
+
+    class AliasModule(ModuleType):
+
+        def __repr__(self):
+            x = modpath
+            if attrname:
+                x += "." + attrname
+            return '<AliasModule %r for %r>' % (modname, x)
+
+        def __getattribute__(self, name):
+            try:
+                return getattr(getmod(), name)
+            except ImportError:
+                return None
+
+        def __setattr__(self, name, value):
+            setattr(getmod(), name, value)
+
+        def __delattr__(self, name):
+            delattr(getmod(), name)
+
+    return AliasModule(str(modname))
Index: venv/Lib/site-packages/py/_vendored_packages/iniconfig.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_vendored_packages/iniconfig.py	(date 1543190976021)
+++ venv/Lib/site-packages/py/_vendored_packages/iniconfig.py	(date 1543190976021)
@@ -0,0 +1,165 @@
+""" brain-dead simple parser for ini-style files.
+(C) Ronny Pfannschmidt, Holger Krekel -- MIT licensed
+"""
+__all__ = ['IniConfig', 'ParseError']
+
+COMMENTCHARS = "#;"
+
+
+class ParseError(Exception):
+    def __init__(self, path, lineno, msg):
+        Exception.__init__(self, path, lineno, msg)
+        self.path = path
+        self.lineno = lineno
+        self.msg = msg
+
+    def __str__(self):
+        return "%s:%s: %s" % (self.path, self.lineno+1, self.msg)
+
+
+class SectionWrapper(object):
+    def __init__(self, config, name):
+        self.config = config
+        self.name = name
+
+    def lineof(self, name):
+        return self.config.lineof(self.name, name)
+
+    def get(self, key, default=None, convert=str):
+        return self.config.get(self.name, key,
+                               convert=convert, default=default)
+
+    def __getitem__(self, key):
+        return self.config.sections[self.name][key]
+
+    def __iter__(self):
+        section = self.config.sections.get(self.name, [])
+
+        def lineof(key):
+            return self.config.lineof(self.name, key)
+        for name in sorted(section, key=lineof):
+            yield name
+
+    def items(self):
+        for name in self:
+            yield name, self[name]
+
+
+class IniConfig(object):
+    def __init__(self, path, data=None):
+        self.path = str(path)  # convenience
+        if data is None:
+            f = open(self.path)
+            try:
+                tokens = self._parse(iter(f))
+            finally:
+                f.close()
+        else:
+            tokens = self._parse(data.splitlines(True))
+
+        self._sources = {}
+        self.sections = {}
+
+        for lineno, section, name, value in tokens:
+            if section is None:
+                self._raise(lineno, 'no section header defined')
+            self._sources[section, name] = lineno
+            if name is None:
+                if section in self.sections:
+                    self._raise(lineno, 'duplicate section %r' % (section, ))
+                self.sections[section] = {}
+            else:
+                if name in self.sections[section]:
+                    self._raise(lineno, 'duplicate name %r' % (name, ))
+                self.sections[section][name] = value
+
+    def _raise(self, lineno, msg):
+        raise ParseError(self.path, lineno, msg)
+
+    def _parse(self, line_iter):
+        result = []
+        section = None
+        for lineno, line in enumerate(line_iter):
+            name, data = self._parseline(line, lineno)
+            # new value
+            if name is not None and data is not None:
+                result.append((lineno, section, name, data))
+            # new section
+            elif name is not None and data is None:
+                if not name:
+                    self._raise(lineno, 'empty section name')
+                section = name
+                result.append((lineno, section, None, None))
+            # continuation
+            elif name is None and data is not None:
+                if not result:
+                    self._raise(lineno, 'unexpected value continuation')
+                last = result.pop()
+                last_name, last_data = last[-2:]
+                if last_name is None:
+                    self._raise(lineno, 'unexpected value continuation')
+
+                if last_data:
+                    data = '%s\n%s' % (last_data, data)
+                result.append(last[:-1] + (data,))
+        return result
+
+    def _parseline(self, line, lineno):
+        # blank lines
+        if iscommentline(line):
+            line = ""
+        else:
+            line = line.rstrip()
+        if not line:
+            return None, None
+        # section
+        if line[0] == '[':
+            realline = line
+            for c in COMMENTCHARS:
+                line = line.split(c)[0].rstrip()
+            if line[-1] == "]":
+                return line[1:-1], None
+            return None, realline.strip()
+        # value
+        elif not line[0].isspace():
+            try:
+                name, value = line.split('=', 1)
+                if ":" in name:
+                    raise ValueError()
+            except ValueError:
+                try:
+                    name, value = line.split(":", 1)
+                except ValueError:
+                    self._raise(lineno, 'unexpected line: %r' % line)
+            return name.strip(), value.strip()
+        # continuation
+        else:
+            return None, line.strip()
+
+    def lineof(self, section, name=None):
+        lineno = self._sources.get((section, name))
+        if lineno is not None:
+            return lineno + 1
+
+    def get(self, section, name, default=None, convert=str):
+        try:
+            return convert(self.sections[section][name])
+        except KeyError:
+            return default
+
+    def __getitem__(self, name):
+        if name not in self.sections:
+            raise KeyError(name)
+        return SectionWrapper(self, name)
+
+    def __iter__(self):
+        for name in sorted(self.sections, key=self.lineof):
+            yield SectionWrapper(self, name)
+
+    def __contains__(self, arg):
+        return arg in self.sections
+
+
+def iscommentline(line):
+    c = line.lstrip()[:1]
+    return c in COMMENTCHARS
Index: venv/Lib/site-packages/py/_vendored_packages/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_vendored_packages/__init__.py	(date 1543190974772)
+++ venv/Lib/site-packages/py/_vendored_packages/__init__.py	(date 1543190974772)
@@ -0,0 +1,0 @@
Index: venv/Lib/site-packages/pytest-4.0.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pytest-4.0.0.dist-info/WHEEL	(date 1543190976033)
+++ venv/Lib/site-packages/pytest-4.0.0.dist-info/WHEEL	(date 1543190976033)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.32.2)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/pytest-4.0.0.dist-info/entry_points.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pytest-4.0.0.dist-info/entry_points.txt	(date 1543190976045)
+++ venv/Lib/site-packages/pytest-4.0.0.dist-info/entry_points.txt	(date 1543190976045)
@@ -0,0 +1,4 @@
+[console_scripts]
+py.test = pytest:main
+pytest = pytest:main
+
Index: venv/Lib/site-packages/pytest-4.0.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pytest-4.0.0.dist-info/top_level.txt	(date 1543190976053)
+++ venv/Lib/site-packages/pytest-4.0.0.dist-info/top_level.txt	(date 1543190976053)
@@ -0,0 +1,2 @@
+_pytest
+pytest
Index: venv/Lib/site-packages/pytest-4.0.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pytest-4.0.0.dist-info/INSTALLER	(date 1543190976065)
+++ venv/Lib/site-packages/pytest-4.0.0.dist-info/INSTALLER	(date 1543190976065)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/pytest-4.0.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pytest-4.0.0.dist-info/METADATA	(date 1543190976077)
+++ venv/Lib/site-packages/pytest-4.0.0.dist-info/METADATA	(date 1543190976077)
@@ -0,0 +1,163 @@
+Metadata-Version: 2.1
+Name: pytest
+Version: 4.0.0
+Summary: pytest: simple powerful testing with Python
+Home-page: https://docs.pytest.org/en/latest/
+Author: Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin and others
+License: MIT license
+Project-URL: Source, https://github.com/pytest-dev/pytest
+Project-URL: Tracker, https://github.com/pytest-dev/pytest/issues
+Keywords: test,unittest
+Platform: unix
+Platform: linux
+Platform: osx
+Platform: cygwin
+Platform: win32
+Classifier: Development Status :: 6 - Mature
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Topic :: Software Development :: Testing
+Classifier: Topic :: Software Development :: Libraries
+Classifier: Topic :: Utilities
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*
+Requires-Dist: py (>=1.5.0)
+Requires-Dist: six (>=1.10.0)
+Requires-Dist: setuptools
+Requires-Dist: attrs (>=17.4.0)
+Requires-Dist: more-itertools (>=4.0.0)
+Requires-Dist: atomicwrites (>=1.0)
+Requires-Dist: pluggy (>=0.7)
+Requires-Dist: funcsigs; python_version < "3.0"
+Requires-Dist: pathlib2 (>=2.2.0); python_version < "3.6"
+Requires-Dist: colorama; sys_platform == "win32"
+
+.. image:: https://docs.pytest.org/en/latest/_static/pytest1.png
+   :target: https://docs.pytest.org/en/latest/
+   :align: center
+   :alt: pytest
+
+
+------
+
+.. image:: https://img.shields.io/pypi/v/pytest.svg
+    :target: https://pypi.org/project/pytest/
+
+.. image:: https://img.shields.io/conda/vn/conda-forge/pytest.svg
+    :target: https://anaconda.org/conda-forge/pytest
+
+.. image:: https://img.shields.io/pypi/pyversions/pytest.svg
+    :target: https://pypi.org/project/pytest/
+
+.. image:: https://codecov.io/gh/pytest-dev/pytest/branch/master/graph/badge.svg
+    :target: https://codecov.io/gh/pytest-dev/pytest
+    :alt: Code coverage Status
+
+.. image:: https://travis-ci.org/pytest-dev/pytest.svg?branch=master
+    :target: https://travis-ci.org/pytest-dev/pytest
+
+.. image:: https://ci.appveyor.com/api/projects/status/mrgbjaua7t33pg6b?svg=true
+    :target: https://ci.appveyor.com/project/pytestbot/pytest
+
+.. image:: https://img.shields.io/badge/code%20style-black-000000.svg
+    :target: https://github.com/ambv/black
+
+.. image:: https://www.codetriage.com/pytest-dev/pytest/badges/users.svg
+    :target: https://www.codetriage.com/pytest-dev/pytest
+
+The ``pytest`` framework makes it easy to write small tests, yet
+scales to support complex functional testing for applications and libraries.
+
+An example of a simple test:
+
+.. code-block:: python
+
+    # content of test_sample.py
+    def inc(x):
+        return x + 1
+
+
+    def test_answer():
+        assert inc(3) == 5
+
+
+To execute it::
+
+    $ pytest
+    ============================= test session starts =============================
+    collected 1 items
+
+    test_sample.py F
+
+    ================================== FAILURES ===================================
+    _________________________________ test_answer _________________________________
+
+        def test_answer():
+    >       assert inc(3) == 5
+    E       assert 4 == 5
+    E        +  where 4 = inc(3)
+
+    test_sample.py:5: AssertionError
+    ========================== 1 failed in 0.04 seconds ===========================
+
+
+Due to ``pytest``'s detailed assertion introspection, only plain ``assert`` statements are used. See `getting-started <https://docs.pytest.org/en/latest/getting-started.html#our-first-test-run>`_ for more examples.
+
+
+Features
+--------
+
+- Detailed info on failing `assert statements <https://docs.pytest.org/en/latest/assert.html>`_ (no need to remember ``self.assert*`` names);
+
+- `Auto-discovery
+  <https://docs.pytest.org/en/latest/goodpractices.html#python-test-discovery>`_
+  of test modules and functions;
+
+- `Modular fixtures <https://docs.pytest.org/en/latest/fixture.html>`_ for
+  managing small or parametrized long-lived test resources;
+
+- Can run `unittest <https://docs.pytest.org/en/latest/unittest.html>`_ (or trial),
+  `nose <https://docs.pytest.org/en/latest/nose.html>`_ test suites out of the box;
+
+- Python 2.7, Python 3.4+, PyPy 2.3, Jython 2.5 (untested);
+
+- Rich plugin architecture, with over 315+ `external plugins <http://plugincompat.herokuapp.com>`_ and thriving community;
+
+
+Documentation
+-------------
+
+For full documentation, including installation, tutorials and PDF documents, please see https://docs.pytest.org/en/latest/.
+
+
+Bugs/Requests
+-------------
+
+Please use the `GitHub issue tracker <https://github.com/pytest-dev/pytest/issues>`_ to submit bugs or request features.
+
+
+Changelog
+---------
+
+Consult the `Changelog <https://docs.pytest.org/en/latest/changelog.html>`__ page for fixes and enhancements of each version.
+
+
+License
+-------
+
+Copyright Holger Krekel and others, 2004-2018.
+
+Distributed under the terms of the `MIT`_ license, pytest is free and open source software.
+
+.. _`MIT`: https://github.com/pytest-dev/pytest/blob/master/LICENSE
+
+
Index: venv/Lib/site-packages/attr/_make.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/_make.py	(date 1543190976099)
+++ venv/Lib/site-packages/attr/_make.py	(date 1543190976099)
@@ -0,0 +1,2034 @@
+from __future__ import absolute_import, division, print_function
+
+import copy
+import hashlib
+import linecache
+import sys
+import threading
+import warnings
+
+from operator import itemgetter
+
+from . import _config
+from ._compat import (
+    PY2,
+    isclass,
+    iteritems,
+    metadata_proxy,
+    ordered_dict,
+    set_closure_cell,
+)
+from .exceptions import (
+    DefaultAlreadySetError,
+    FrozenInstanceError,
+    NotAnAttrsClassError,
+    PythonTooOldError,
+    UnannotatedAttributeError,
+)
+
+
+# This is used at least twice, so cache it here.
+_obj_setattr = object.__setattr__
+_init_converter_pat = "__attr_converter_{}"
+_init_factory_pat = "__attr_factory_{}"
+_tuple_property_pat = (
+    "    {attr_name} = _attrs_property(_attrs_itemgetter({index}))"
+)
+_classvar_prefixes = ("typing.ClassVar", "t.ClassVar", "ClassVar")
+# we don't use a double-underscore prefix because that triggers
+# name mangling when trying to create a slot for the field
+# (when slots=True)
+_hash_cache_field = "_attrs_cached_hash"
+
+_empty_metadata_singleton = metadata_proxy({})
+
+
+class _Nothing(object):
+    """
+    Sentinel class to indicate the lack of a value when ``None`` is ambiguous.
+
+    ``_Nothing`` is a singleton. There is only ever one of it.
+    """
+
+    _singleton = None
+
+    def __new__(cls):
+        if _Nothing._singleton is None:
+            _Nothing._singleton = super(_Nothing, cls).__new__(cls)
+        return _Nothing._singleton
+
+    def __repr__(self):
+        return "NOTHING"
+
+
+NOTHING = _Nothing()
+"""
+Sentinel to indicate the lack of a value when ``None`` is ambiguous.
+"""
+
+
+def attrib(
+    default=NOTHING,
+    validator=None,
+    repr=True,
+    cmp=True,
+    hash=None,
+    init=True,
+    convert=None,
+    metadata=None,
+    type=None,
+    converter=None,
+    factory=None,
+    kw_only=False,
+):
+    """
+    Create a new attribute on a class.
+
+    ..  warning::
+
+        Does *not* do anything unless the class is also decorated with
+        :func:`attr.s`!
+
+    :param default: A value that is used if an ``attrs``-generated ``__init__``
+        is used and no value is passed while instantiating or the attribute is
+        excluded using ``init=False``.
+
+        If the value is an instance of :class:`Factory`, its callable will be
+        used to construct a new value (useful for mutable data types like lists
+        or dicts).
+
+        If a default is not set (or set manually to ``attr.NOTHING``), a value
+        *must* be supplied when instantiating; otherwise a :exc:`TypeError`
+        will be raised.
+
+        The default can also be set using decorator notation as shown below.
+
+    :type default: Any value.
+
+    :param callable factory: Syntactic sugar for
+        ``default=attr.Factory(callable)``.
+
+    :param validator: :func:`callable` that is called by ``attrs``-generated
+        ``__init__`` methods after the instance has been initialized.  They
+        receive the initialized instance, the :class:`Attribute`, and the
+        passed value.
+
+        The return value is *not* inspected so the validator has to throw an
+        exception itself.
+
+        If a ``list`` is passed, its items are treated as validators and must
+        all pass.
+
+        Validators can be globally disabled and re-enabled using
+        :func:`get_run_validators`.
+
+        The validator can also be set using decorator notation as shown below.
+
+    :type validator: ``callable`` or a ``list`` of ``callable``\\ s.
+
+    :param bool repr: Include this attribute in the generated ``__repr__``
+        method.
+    :param bool cmp: Include this attribute in the generated comparison methods
+        (``__eq__`` et al).
+    :param hash: Include this attribute in the generated ``__hash__``
+        method.  If ``None`` (default), mirror *cmp*'s value.  This is the
+        correct behavior according the Python spec.  Setting this value to
+        anything else than ``None`` is *discouraged*.
+    :type hash: ``bool`` or ``None``
+    :param bool init: Include this attribute in the generated ``__init__``
+        method.  It is possible to set this to ``False`` and set a default
+        value.  In that case this attributed is unconditionally initialized
+        with the specified default value or factory.
+    :param callable converter: :func:`callable` that is called by
+        ``attrs``-generated ``__init__`` methods to converter attribute's value
+        to the desired format.  It is given the passed-in value, and the
+        returned value will be used as the new value of the attribute.  The
+        value is converted before being passed to the validator, if any.
+    :param metadata: An arbitrary mapping, to be used by third-party
+        components.  See :ref:`extending_metadata`.
+    :param type: The type of the attribute.  In Python 3.6 or greater, the
+        preferred method to specify the type is using a variable annotation
+        (see `PEP 526 <https://www.python.org/dev/peps/pep-0526/>`_).
+        This argument is provided for backward compatibility.
+        Regardless of the approach used, the type will be stored on
+        ``Attribute.type``.
+
+        Please note that ``attrs`` doesn't do anything with this metadata by
+        itself. You can use it as part of your own code or for
+        :doc:`static type checking <types>`.
+    :param kw_only: Make this attribute keyword-only (Python 3+)
+        in the generated ``__init__`` (if ``init`` is ``False``, this
+        parameter is ignored).
+
+    .. versionadded:: 15.2.0 *convert*
+    .. versionadded:: 16.3.0 *metadata*
+    .. versionchanged:: 17.1.0 *validator* can be a ``list`` now.
+    .. versionchanged:: 17.1.0
+       *hash* is ``None`` and therefore mirrors *cmp* by default.
+    .. versionadded:: 17.3.0 *type*
+    .. deprecated:: 17.4.0 *convert*
+    .. versionadded:: 17.4.0 *converter* as a replacement for the deprecated
+       *convert* to achieve consistency with other noun-based arguments.
+    .. versionadded:: 18.1.0
+       ``factory=f`` is syntactic sugar for ``default=attr.Factory(f)``.
+    .. versionadded:: 18.2.0 *kw_only*
+    """
+    if hash is not None and hash is not True and hash is not False:
+        raise TypeError(
+            "Invalid value for hash.  Must be True, False, or None."
+        )
+
+    if convert is not None:
+        if converter is not None:
+            raise RuntimeError(
+                "Can't pass both `convert` and `converter`.  "
+                "Please use `converter` only."
+            )
+        warnings.warn(
+            "The `convert` argument is deprecated in favor of `converter`.  "
+            "It will be removed after 2019/01.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
+        converter = convert
+
+    if factory is not None:
+        if default is not NOTHING:
+            raise ValueError(
+                "The `default` and `factory` arguments are mutually "
+                "exclusive."
+            )
+        if not callable(factory):
+            raise ValueError("The `factory` argument must be a callable.")
+        default = Factory(factory)
+
+    if metadata is None:
+        metadata = {}
+
+    return _CountingAttr(
+        default=default,
+        validator=validator,
+        repr=repr,
+        cmp=cmp,
+        hash=hash,
+        init=init,
+        converter=converter,
+        metadata=metadata,
+        type=type,
+        kw_only=kw_only,
+    )
+
+
+def _make_attr_tuple_class(cls_name, attr_names):
+    """
+    Create a tuple subclass to hold `Attribute`s for an `attrs` class.
+
+    The subclass is a bare tuple with properties for names.
+
+    class MyClassAttributes(tuple):
+        __slots__ = ()
+        x = property(itemgetter(0))
+    """
+    attr_class_name = "{}Attributes".format(cls_name)
+    attr_class_template = [
+        "class {}(tuple):".format(attr_class_name),
+        "    __slots__ = ()",
+    ]
+    if attr_names:
+        for i, attr_name in enumerate(attr_names):
+            attr_class_template.append(
+                _tuple_property_pat.format(index=i, attr_name=attr_name)
+            )
+    else:
+        attr_class_template.append("    pass")
+    globs = {"_attrs_itemgetter": itemgetter, "_attrs_property": property}
+    eval(compile("\n".join(attr_class_template), "", "exec"), globs)
+
+    return globs[attr_class_name]
+
+
+# Tuple class for extracted attributes from a class definition.
+# `base_attrs` is a subset of `attrs`.
+_Attributes = _make_attr_tuple_class(
+    "_Attributes",
+    [
+        # all attributes to build dunder methods for
+        "attrs",
+        # attributes that have been inherited
+        "base_attrs",
+        # map inherited attributes to their originating classes
+        "base_attrs_map",
+    ],
+)
+
+
+def _is_class_var(annot):
+    """
+    Check whether *annot* is a typing.ClassVar.
+
+    The string comparison hack is used to avoid evaluating all string
+    annotations which would put attrs-based classes at a performance
+    disadvantage compared to plain old classes.
+    """
+    return str(annot).startswith(_classvar_prefixes)
+
+
+def _get_annotations(cls):
+    """
+    Get annotations for *cls*.
+    """
+    anns = getattr(cls, "__annotations__", None)
+    if anns is None:
+        return {}
+
+    # Verify that the annotations aren't merely inherited.
+    for base_cls in cls.__mro__[1:]:
+        if anns is getattr(base_cls, "__annotations__", None):
+            return {}
+
+    return anns
+
+
+def _counter_getter(e):
+    """
+    Key function for sorting to avoid re-creating a lambda for every class.
+    """
+    return e[1].counter
+
+
+def _transform_attrs(cls, these, auto_attribs, kw_only):
+    """
+    Transform all `_CountingAttr`s on a class into `Attribute`s.
+
+    If *these* is passed, use that and don't look for them on the class.
+
+    Return an `_Attributes`.
+    """
+    cd = cls.__dict__
+    anns = _get_annotations(cls)
+
+    if these is not None:
+        ca_list = [(name, ca) for name, ca in iteritems(these)]
+
+        if not isinstance(these, ordered_dict):
+            ca_list.sort(key=_counter_getter)
+    elif auto_attribs is True:
+        ca_names = {
+            name
+            for name, attr in cd.items()
+            if isinstance(attr, _CountingAttr)
+        }
+        ca_list = []
+        annot_names = set()
+        for attr_name, type in anns.items():
+            if _is_class_var(type):
+                continue
+            annot_names.add(attr_name)
+            a = cd.get(attr_name, NOTHING)
+            if not isinstance(a, _CountingAttr):
+                if a is NOTHING:
+                    a = attrib()
+                else:
+                    a = attrib(default=a)
+            ca_list.append((attr_name, a))
+
+        unannotated = ca_names - annot_names
+        if len(unannotated) > 0:
+            raise UnannotatedAttributeError(
+                "The following `attr.ib`s lack a type annotation: "
+                + ", ".join(
+                    sorted(unannotated, key=lambda n: cd.get(n).counter)
+                )
+                + "."
+            )
+    else:
+        ca_list = sorted(
+            (
+                (name, attr)
+                for name, attr in cd.items()
+                if isinstance(attr, _CountingAttr)
+            ),
+            key=lambda e: e[1].counter,
+        )
+
+    own_attrs = [
+        Attribute.from_counting_attr(
+            name=attr_name, ca=ca, type=anns.get(attr_name)
+        )
+        for attr_name, ca in ca_list
+    ]
+
+    base_attrs = []
+    base_attr_map = {}  # A dictionary of base attrs to their classes.
+    taken_attr_names = {a.name: a for a in own_attrs}
+
+    # Traverse the MRO and collect attributes.
+    for base_cls in cls.__mro__[1:-1]:
+        sub_attrs = getattr(base_cls, "__attrs_attrs__", None)
+        if sub_attrs is not None:
+            for a in sub_attrs:
+                prev_a = taken_attr_names.get(a.name)
+                # Only add an attribute if it hasn't been defined before.  This
+                # allows for overwriting attribute definitions by subclassing.
+                if prev_a is None:
+                    base_attrs.append(a)
+                    taken_attr_names[a.name] = a
+                    base_attr_map[a.name] = base_cls
+
+    attr_names = [a.name for a in base_attrs + own_attrs]
+
+    AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)
+
+    if kw_only:
+        own_attrs = [a._assoc(kw_only=True) for a in own_attrs]
+        base_attrs = [a._assoc(kw_only=True) for a in base_attrs]
+
+    attrs = AttrsClass(base_attrs + own_attrs)
+
+    had_default = False
+    was_kw_only = False
+    for a in attrs:
+        if (
+            was_kw_only is False
+            and had_default is True
+            and a.default is NOTHING
+            and a.init is True
+            and a.kw_only is False
+        ):
+            raise ValueError(
+                "No mandatory attributes allowed after an attribute with a "
+                "default value or factory.  Attribute in question: %r" % (a,)
+            )
+        elif (
+            had_default is False
+            and a.default is not NOTHING
+            and a.init is not False
+            and
+            # Keyword-only attributes without defaults can be specified
+            # after keyword-only attributes with defaults.
+            a.kw_only is False
+        ):
+            had_default = True
+        if was_kw_only is True and a.kw_only is False:
+            raise ValueError(
+                "Non keyword-only attributes are not allowed after a "
+                "keyword-only attribute.  Attribute in question: {a!r}".format(
+                    a=a
+                )
+            )
+        if was_kw_only is False and a.init is True and a.kw_only is True:
+            was_kw_only = True
+
+    return _Attributes((attrs, base_attrs, base_attr_map))
+
+
+def _frozen_setattrs(self, name, value):
+    """
+    Attached to frozen classes as __setattr__.
+    """
+    raise FrozenInstanceError()
+
+
+def _frozen_delattrs(self, name):
+    """
+    Attached to frozen classes as __delattr__.
+    """
+    raise FrozenInstanceError()
+
+
+class _ClassBuilder(object):
+    """
+    Iteratively build *one* class.
+    """
+
+    __slots__ = (
+        "_cls",
+        "_cls_dict",
+        "_attrs",
+        "_base_names",
+        "_attr_names",
+        "_slots",
+        "_frozen",
+        "_weakref_slot",
+        "_cache_hash",
+        "_has_post_init",
+        "_delete_attribs",
+        "_base_attr_map",
+    )
+
+    def __init__(
+        self,
+        cls,
+        these,
+        slots,
+        frozen,
+        weakref_slot,
+        auto_attribs,
+        kw_only,
+        cache_hash,
+    ):
+        attrs, base_attrs, base_map = _transform_attrs(
+            cls, these, auto_attribs, kw_only
+        )
+
+        self._cls = cls
+        self._cls_dict = dict(cls.__dict__) if slots else {}
+        self._attrs = attrs
+        self._base_names = set(a.name for a in base_attrs)
+        self._base_attr_map = base_map
+        self._attr_names = tuple(a.name for a in attrs)
+        self._slots = slots
+        self._frozen = frozen or _has_frozen_base_class(cls)
+        self._weakref_slot = weakref_slot
+        self._cache_hash = cache_hash
+        self._has_post_init = bool(getattr(cls, "__attrs_post_init__", False))
+        self._delete_attribs = not bool(these)
+
+        self._cls_dict["__attrs_attrs__"] = self._attrs
+
+        if frozen:
+            self._cls_dict["__setattr__"] = _frozen_setattrs
+            self._cls_dict["__delattr__"] = _frozen_delattrs
+
+    def __repr__(self):
+        return "<_ClassBuilder(cls={cls})>".format(cls=self._cls.__name__)
+
+    def build_class(self):
+        """
+        Finalize class based on the accumulated configuration.
+
+        Builder cannot be used after calling this method.
+        """
+        if self._slots is True:
+            return self._create_slots_class()
+        else:
+            return self._patch_original_class()
+
+    def _patch_original_class(self):
+        """
+        Apply accumulated methods and return the class.
+        """
+        cls = self._cls
+        base_names = self._base_names
+
+        # Clean class of attribute definitions (`attr.ib()`s).
+        if self._delete_attribs:
+            for name in self._attr_names:
+                if (
+                    name not in base_names
+                    and getattr(cls, name, None) is not None
+                ):
+                    try:
+                        delattr(cls, name)
+                    except AttributeError:
+                        # This can happen if a base class defines a class
+                        # variable and we want to set an attribute with the
+                        # same name by using only a type annotation.
+                        pass
+
+        # Attach our dunder methods.
+        for name, value in self._cls_dict.items():
+            setattr(cls, name, value)
+
+        return cls
+
+    def _create_slots_class(self):
+        """
+        Build and return a new class with a `__slots__` attribute.
+        """
+        base_names = self._base_names
+        cd = {
+            k: v
+            for k, v in iteritems(self._cls_dict)
+            if k not in tuple(self._attr_names) + ("__dict__", "__weakref__")
+        }
+
+        weakref_inherited = False
+
+        # Traverse the MRO to check for an existing __weakref__.
+        for base_cls in self._cls.__mro__[1:-1]:
+            if "__weakref__" in getattr(base_cls, "__dict__", ()):
+                weakref_inherited = True
+                break
+
+        names = self._attr_names
+        if (
+            self._weakref_slot
+            and "__weakref__" not in getattr(self._cls, "__slots__", ())
+            and "__weakref__" not in names
+            and not weakref_inherited
+        ):
+            names += ("__weakref__",)
+
+        # We only add the names of attributes that aren't inherited.
+        # Settings __slots__ to inherited attributes wastes memory.
+        slot_names = [name for name in names if name not in base_names]
+        if self._cache_hash:
+            slot_names.append(_hash_cache_field)
+        cd["__slots__"] = tuple(slot_names)
+
+        qualname = getattr(self._cls, "__qualname__", None)
+        if qualname is not None:
+            cd["__qualname__"] = qualname
+
+        # __weakref__ is not writable.
+        state_attr_names = tuple(
+            an for an in self._attr_names if an != "__weakref__"
+        )
+
+        def slots_getstate(self):
+            """
+            Automatically created by attrs.
+            """
+            return tuple(getattr(self, name) for name in state_attr_names)
+
+        def slots_setstate(self, state):
+            """
+            Automatically created by attrs.
+            """
+            __bound_setattr = _obj_setattr.__get__(self, Attribute)
+            for name, value in zip(state_attr_names, state):
+                __bound_setattr(name, value)
+
+        # slots and frozen require __getstate__/__setstate__ to work
+        cd["__getstate__"] = slots_getstate
+        cd["__setstate__"] = slots_setstate
+
+        # Create new class based on old class and our methods.
+        cls = type(self._cls)(self._cls.__name__, self._cls.__bases__, cd)
+
+        # The following is a fix for
+        # https://github.com/python-attrs/attrs/issues/102.  On Python 3,
+        # if a method mentions `__class__` or uses the no-arg super(), the
+        # compiler will bake a reference to the class in the method itself
+        # as `method.__closure__`.  Since we replace the class with a
+        # clone, we rewrite these references so it keeps working.
+        for item in cls.__dict__.values():
+            if isinstance(item, (classmethod, staticmethod)):
+                # Class- and staticmethods hide their functions inside.
+                # These might need to be rewritten as well.
+                closure_cells = getattr(item.__func__, "__closure__", None)
+            else:
+                closure_cells = getattr(item, "__closure__", None)
+
+            if not closure_cells:  # Catch None or the empty list.
+                continue
+            for cell in closure_cells:
+                if cell.cell_contents is self._cls:
+                    set_closure_cell(cell, cls)
+
+        return cls
+
+    def add_repr(self, ns):
+        self._cls_dict["__repr__"] = self._add_method_dunders(
+            _make_repr(self._attrs, ns=ns)
+        )
+        return self
+
+    def add_str(self):
+        repr = self._cls_dict.get("__repr__")
+        if repr is None:
+            raise ValueError(
+                "__str__ can only be generated if a __repr__ exists."
+            )
+
+        def __str__(self):
+            return self.__repr__()
+
+        self._cls_dict["__str__"] = self._add_method_dunders(__str__)
+        return self
+
+    def make_unhashable(self):
+        self._cls_dict["__hash__"] = None
+        return self
+
+    def add_hash(self):
+        self._cls_dict["__hash__"] = self._add_method_dunders(
+            _make_hash(
+                self._attrs, frozen=self._frozen, cache_hash=self._cache_hash
+            )
+        )
+
+        return self
+
+    def add_init(self):
+        self._cls_dict["__init__"] = self._add_method_dunders(
+            _make_init(
+                self._attrs,
+                self._has_post_init,
+                self._frozen,
+                self._slots,
+                self._cache_hash,
+                self._base_attr_map,
+            )
+        )
+
+        return self
+
+    def add_cmp(self):
+        cd = self._cls_dict
+
+        cd["__eq__"], cd["__ne__"], cd["__lt__"], cd["__le__"], cd[
+            "__gt__"
+        ], cd["__ge__"] = (
+            self._add_method_dunders(meth) for meth in _make_cmp(self._attrs)
+        )
+
+        return self
+
+    def _add_method_dunders(self, method):
+        """
+        Add __module__ and __qualname__ to a *method* if possible.
+        """
+        try:
+            method.__module__ = self._cls.__module__
+        except AttributeError:
+            pass
+
+        try:
+            method.__qualname__ = ".".join(
+                (self._cls.__qualname__, method.__name__)
+            )
+        except AttributeError:
+            pass
+
+        return method
+
+
+def attrs(
+    maybe_cls=None,
+    these=None,
+    repr_ns=None,
+    repr=True,
+    cmp=True,
+    hash=None,
+    init=True,
+    slots=False,
+    frozen=False,
+    weakref_slot=True,
+    str=False,
+    auto_attribs=False,
+    kw_only=False,
+    cache_hash=False,
+):
+    r"""
+    A class decorator that adds `dunder
+    <https://wiki.python.org/moin/DunderAlias>`_\ -methods according to the
+    specified attributes using :func:`attr.ib` or the *these* argument.
+
+    :param these: A dictionary of name to :func:`attr.ib` mappings.  This is
+        useful to avoid the definition of your attributes within the class body
+        because you can't (e.g. if you want to add ``__repr__`` methods to
+        Django models) or don't want to.
+
+        If *these* is not ``None``, ``attrs`` will *not* search the class body
+        for attributes and will *not* remove any attributes from it.
+
+        If *these* is an ordered dict (:class:`dict` on Python 3.6+,
+        :class:`collections.OrderedDict` otherwise), the order is deduced from
+        the order of the attributes inside *these*.  Otherwise the order
+        of the definition of the attributes is used.
+
+    :type these: :class:`dict` of :class:`str` to :func:`attr.ib`
+
+    :param str repr_ns: When using nested classes, there's no way in Python 2
+        to automatically detect that.  Therefore it's possible to set the
+        namespace explicitly for a more meaningful ``repr`` output.
+    :param bool repr: Create a ``__repr__`` method with a human readable
+        representation of ``attrs`` attributes..
+    :param bool str: Create a ``__str__`` method that is identical to
+        ``__repr__``.  This is usually not necessary except for
+        :class:`Exception`\ s.
+    :param bool cmp: Create ``__eq__``, ``__ne__``, ``__lt__``, ``__le__``,
+        ``__gt__``, and ``__ge__`` methods that compare the class as if it were
+        a tuple of its ``attrs`` attributes.  But the attributes are *only*
+        compared, if the types of both classes are *identical*!
+    :param hash: If ``None`` (default), the ``__hash__`` method is generated
+        according how *cmp* and *frozen* are set.
+
+        1. If *both* are True, ``attrs`` will generate a ``__hash__`` for you.
+        2. If *cmp* is True and *frozen* is False, ``__hash__`` will be set to
+           None, marking it unhashable (which it is).
+        3. If *cmp* is False, ``__hash__`` will be left untouched meaning the
+           ``__hash__`` method of the base class will be used (if base class is
+           ``object``, this means it will fall back to id-based hashing.).
+
+        Although not recommended, you can decide for yourself and force
+        ``attrs`` to create one (e.g. if the class is immutable even though you
+        didn't freeze it programmatically) by passing ``True`` or not.  Both of
+        these cases are rather special and should be used carefully.
+
+        See the `Python documentation \
+        <https://docs.python.org/3/reference/datamodel.html#object.__hash__>`_
+        and the `GitHub issue that led to the default behavior \
+        <https://github.com/python-attrs/attrs/issues/136>`_ for more details.
+    :type hash: ``bool`` or ``None``
+    :param bool init: Create a ``__init__`` method that initializes the
+        ``attrs`` attributes.  Leading underscores are stripped for the
+        argument name.  If a ``__attrs_post_init__`` method exists on the
+        class, it will be called after the class is fully initialized.
+    :param bool slots: Create a slots_-style class that's more
+        memory-efficient.  See :ref:`slots` for further ramifications.
+    :param bool frozen: Make instances immutable after initialization.  If
+        someone attempts to modify a frozen instance,
+        :exc:`attr.exceptions.FrozenInstanceError` is raised.
+
+        Please note:
+
+            1. This is achieved by installing a custom ``__setattr__`` method
+               on your class so you can't implement an own one.
+
+            2. True immutability is impossible in Python.
+
+            3. This *does* have a minor a runtime performance :ref:`impact
+               <how-frozen>` when initializing new instances.  In other words:
+               ``__init__`` is slightly slower with ``frozen=True``.
+
+            4. If a class is frozen, you cannot modify ``self`` in
+               ``__attrs_post_init__`` or a self-written ``__init__``. You can
+               circumvent that limitation by using
+               ``object.__setattr__(self, "attribute_name", value)``.
+
+        ..  _slots: https://docs.python.org/3/reference/datamodel.html#slots
+    :param bool weakref_slot: Make instances weak-referenceable.  This has no
+        effect unless ``slots`` is also enabled.
+    :param bool auto_attribs: If True, collect `PEP 526`_-annotated attributes
+        (Python 3.6 and later only) from the class body.
+
+        In this case, you **must** annotate every field.  If ``attrs``
+        encounters a field that is set to an :func:`attr.ib` but lacks a type
+        annotation, an :exc:`attr.exceptions.UnannotatedAttributeError` is
+        raised.  Use ``field_name: typing.Any = attr.ib(...)`` if you don't
+        want to set a type.
+
+        If you assign a value to those attributes (e.g. ``x: int = 42``), that
+        value becomes the default value like if it were passed using
+        ``attr.ib(default=42)``.  Passing an instance of :class:`Factory` also
+        works as expected.
+
+        Attributes annotated as :data:`typing.ClassVar` are **ignored**.
+
+        .. _`PEP 526`: https://www.python.org/dev/peps/pep-0526/
+    :param bool kw_only: Make all attributes keyword-only (Python 3+)
+        in the generated ``__init__`` (if ``init`` is ``False``, this
+        parameter is ignored).
+    :param bool cache_hash: Ensure that the object's hash code is computed
+        only once and stored on the object.  If this is set to ``True``,
+        hashing must be either explicitly or implicitly enabled for this
+        class.  If the hash code is cached, then no attributes of this
+        class which participate in hash code computation may be mutated
+        after object creation.
+
+
+    .. versionadded:: 16.0.0 *slots*
+    .. versionadded:: 16.1.0 *frozen*
+    .. versionadded:: 16.3.0 *str*
+    .. versionadded:: 16.3.0 Support for ``__attrs_post_init__``.
+    .. versionchanged:: 17.1.0
+       *hash* supports ``None`` as value which is also the default now.
+    .. versionadded:: 17.3.0 *auto_attribs*
+    .. versionchanged:: 18.1.0
+       If *these* is passed, no attributes are deleted from the class body.
+    .. versionchanged:: 18.1.0 If *these* is ordered, the order is retained.
+    .. versionadded:: 18.2.0 *weakref_slot*
+    .. deprecated:: 18.2.0
+       ``__lt__``, ``__le__``, ``__gt__``, and ``__ge__`` now raise a
+       :class:`DeprecationWarning` if the classes compared are subclasses of
+       each other. ``__eq`` and ``__ne__`` never tried to compared subclasses
+       to each other.
+    .. versionadded:: 18.2.0 *kw_only*
+    .. versionadded:: 18.2.0 *cache_hash*
+    """
+
+    def wrap(cls):
+        if getattr(cls, "__class__", None) is None:
+            raise TypeError("attrs only works with new-style classes.")
+
+        builder = _ClassBuilder(
+            cls,
+            these,
+            slots,
+            frozen,
+            weakref_slot,
+            auto_attribs,
+            kw_only,
+            cache_hash,
+        )
+
+        if repr is True:
+            builder.add_repr(repr_ns)
+        if str is True:
+            builder.add_str()
+        if cmp is True:
+            builder.add_cmp()
+
+        if hash is not True and hash is not False and hash is not None:
+            # Can't use `hash in` because 1 == True for example.
+            raise TypeError(
+                "Invalid value for hash.  Must be True, False, or None."
+            )
+        elif hash is False or (hash is None and cmp is False):
+            if cache_hash:
+                raise TypeError(
+                    "Invalid value for cache_hash.  To use hash caching,"
+                    " hashing must be either explicitly or implicitly "
+                    "enabled."
+                )
+        elif hash is True or (hash is None and cmp is True and frozen is True):
+            builder.add_hash()
+        else:
+            if cache_hash:
+                raise TypeError(
+                    "Invalid value for cache_hash.  To use hash caching,"
+                    " hashing must be either explicitly or implicitly "
+                    "enabled."
+                )
+            builder.make_unhashable()
+
+        if init is True:
+            builder.add_init()
+        else:
+            if cache_hash:
+                raise TypeError(
+                    "Invalid value for cache_hash.  To use hash caching,"
+                    " init must be True."
+                )
+
+        return builder.build_class()
+
+    # maybe_cls's type depends on the usage of the decorator.  It's a class
+    # if it's used as `@attrs` but ``None`` if used as `@attrs()`.
+    if maybe_cls is None:
+        return wrap
+    else:
+        return wrap(maybe_cls)
+
+
+_attrs = attrs
+"""
+Internal alias so we can use it in functions that take an argument called
+*attrs*.
+"""
+
+
+if PY2:
+
+    def _has_frozen_base_class(cls):
+        """
+        Check whether *cls* has a frozen ancestor by looking at its
+        __setattr__.
+        """
+        return (
+            getattr(cls.__setattr__, "__module__", None)
+            == _frozen_setattrs.__module__
+            and cls.__setattr__.__name__ == _frozen_setattrs.__name__
+        )
+
+
+else:
+
+    def _has_frozen_base_class(cls):
+        """
+        Check whether *cls* has a frozen ancestor by looking at its
+        __setattr__.
+        """
+        return cls.__setattr__ == _frozen_setattrs
+
+
+def _attrs_to_tuple(obj, attrs):
+    """
+    Create a tuple of all values of *obj*'s *attrs*.
+    """
+    return tuple(getattr(obj, a.name) for a in attrs)
+
+
+def _make_hash(attrs, frozen, cache_hash):
+    attrs = tuple(
+        a
+        for a in attrs
+        if a.hash is True or (a.hash is None and a.cmp is True)
+    )
+
+    tab = "        "
+
+    # We cache the generated hash methods for the same kinds of attributes.
+    sha1 = hashlib.sha1()
+    sha1.update(repr(attrs).encode("utf-8"))
+    unique_filename = "<attrs generated hash %s>" % (sha1.hexdigest(),)
+    type_hash = hash(unique_filename)
+
+    method_lines = ["def __hash__(self):"]
+
+    def append_hash_computation_lines(prefix, indent):
+        """
+        Generate the code for actually computing the hash code.
+        Below this will either be returned directly or used to compute
+        a value which is then cached, depending on the value of cache_hash
+        """
+        method_lines.extend(
+            [indent + prefix + "hash((", indent + "        %d," % (type_hash,)]
+        )
+
+        for a in attrs:
+            method_lines.append(indent + "        self.%s," % a.name)
+
+        method_lines.append(indent + "    ))")
+
+    if cache_hash:
+        method_lines.append(tab + "if self.%s is None:" % _hash_cache_field)
+        if frozen:
+            append_hash_computation_lines(
+                "object.__setattr__(self, '%s', " % _hash_cache_field, tab * 2
+            )
+            method_lines.append(tab * 2 + ")")  # close __setattr__
+        else:
+            append_hash_computation_lines(
+                "self.%s = " % _hash_cache_field, tab * 2
+            )
+        method_lines.append(tab + "return self.%s" % _hash_cache_field)
+    else:
+        append_hash_computation_lines("return ", tab)
+
+    script = "\n".join(method_lines)
+    globs = {}
+    locs = {}
+    bytecode = compile(script, unique_filename, "exec")
+    eval(bytecode, globs, locs)
+
+    # In order of debuggers like PDB being able to step through the code,
+    # we add a fake linecache entry.
+    linecache.cache[unique_filename] = (
+        len(script),
+        None,
+        script.splitlines(True),
+        unique_filename,
+    )
+
+    return locs["__hash__"]
+
+
+def _add_hash(cls, attrs):
+    """
+    Add a hash method to *cls*.
+    """
+    cls.__hash__ = _make_hash(attrs, frozen=False, cache_hash=False)
+    return cls
+
+
+def __ne__(self, other):
+    """
+    Check equality and either forward a NotImplemented or return the result
+    negated.
+    """
+    result = self.__eq__(other)
+    if result is NotImplemented:
+        return NotImplemented
+
+    return not result
+
+
+WARNING_CMP_ISINSTANCE = (
+    "Comparision of subclasses using __%s__ is deprecated and will be removed "
+    "in 2019."
+)
+
+
+def _make_cmp(attrs):
+    attrs = [a for a in attrs if a.cmp]
+
+    # We cache the generated eq methods for the same kinds of attributes.
+    sha1 = hashlib.sha1()
+    sha1.update(repr(attrs).encode("utf-8"))
+    unique_filename = "<attrs generated eq %s>" % (sha1.hexdigest(),)
+    lines = [
+        "def __eq__(self, other):",
+        "    if other.__class__ is not self.__class__:",
+        "        return NotImplemented",
+    ]
+    # We can't just do a big self.x = other.x and... clause due to
+    # irregularities like nan == nan is false but (nan,) == (nan,) is true.
+    if attrs:
+        lines.append("    return  (")
+        others = ["    ) == ("]
+        for a in attrs:
+            lines.append("        self.%s," % (a.name,))
+            others.append("        other.%s," % (a.name,))
+
+        lines += others + ["    )"]
+    else:
+        lines.append("    return True")
+
+    script = "\n".join(lines)
+    globs = {}
+    locs = {}
+    bytecode = compile(script, unique_filename, "exec")
+    eval(bytecode, globs, locs)
+
+    # In order of debuggers like PDB being able to step through the code,
+    # we add a fake linecache entry.
+    linecache.cache[unique_filename] = (
+        len(script),
+        None,
+        script.splitlines(True),
+        unique_filename,
+    )
+    eq = locs["__eq__"]
+    ne = __ne__
+
+    def attrs_to_tuple(obj):
+        """
+        Save us some typing.
+        """
+        return _attrs_to_tuple(obj, attrs)
+
+    def __lt__(self, other):
+        """
+        Automatically created by attrs.
+        """
+        if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("lt",), DeprecationWarning
+                )
+            return attrs_to_tuple(self) < attrs_to_tuple(other)
+        else:
+            return NotImplemented
+
+    def __le__(self, other):
+        """
+        Automatically created by attrs.
+        """
+        if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("le",), DeprecationWarning
+                )
+            return attrs_to_tuple(self) <= attrs_to_tuple(other)
+        else:
+            return NotImplemented
+
+    def __gt__(self, other):
+        """
+        Automatically created by attrs.
+        """
+        if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("gt",), DeprecationWarning
+                )
+            return attrs_to_tuple(self) > attrs_to_tuple(other)
+        else:
+            return NotImplemented
+
+    def __ge__(self, other):
+        """
+        Automatically created by attrs.
+        """
+        if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("ge",), DeprecationWarning
+                )
+            return attrs_to_tuple(self) >= attrs_to_tuple(other)
+        else:
+            return NotImplemented
+
+    return eq, ne, __lt__, __le__, __gt__, __ge__
+
+
+def _add_cmp(cls, attrs=None):
+    """
+    Add comparison methods to *cls*.
+    """
+    if attrs is None:
+        attrs = cls.__attrs_attrs__
+
+    cls.__eq__, cls.__ne__, cls.__lt__, cls.__le__, cls.__gt__, cls.__ge__ = _make_cmp(  # noqa
+        attrs
+    )
+
+    return cls
+
+
+_already_repring = threading.local()
+
+
+def _make_repr(attrs, ns):
+    """
+    Make a repr method for *attr_names* adding *ns* to the full name.
+    """
+    attr_names = tuple(a.name for a in attrs if a.repr)
+
+    def __repr__(self):
+        """
+        Automatically created by attrs.
+        """
+        try:
+            working_set = _already_repring.working_set
+        except AttributeError:
+            working_set = set()
+            _already_repring.working_set = working_set
+
+        if id(self) in working_set:
+            return "..."
+        real_cls = self.__class__
+        if ns is None:
+            qualname = getattr(real_cls, "__qualname__", None)
+            if qualname is not None:
+                class_name = qualname.rsplit(">.", 1)[-1]
+            else:
+                class_name = real_cls.__name__
+        else:
+            class_name = ns + "." + real_cls.__name__
+
+        # Since 'self' remains on the stack (i.e.: strongly referenced) for the
+        # duration of this call, it's safe to depend on id(...) stability, and
+        # not need to track the instance and therefore worry about properties
+        # like weakref- or hash-ability.
+        working_set.add(id(self))
+        try:
+            result = [class_name, "("]
+            first = True
+            for name in attr_names:
+                if first:
+                    first = False
+                else:
+                    result.append(", ")
+                result.extend((name, "=", repr(getattr(self, name, NOTHING))))
+            return "".join(result) + ")"
+        finally:
+            working_set.remove(id(self))
+
+    return __repr__
+
+
+def _add_repr(cls, ns=None, attrs=None):
+    """
+    Add a repr method to *cls*.
+    """
+    if attrs is None:
+        attrs = cls.__attrs_attrs__
+
+    cls.__repr__ = _make_repr(attrs, ns)
+    return cls
+
+
+def _make_init(attrs, post_init, frozen, slots, cache_hash, base_attr_map):
+    attrs = [a for a in attrs if a.init or a.default is not NOTHING]
+
+    # We cache the generated init methods for the same kinds of attributes.
+    sha1 = hashlib.sha1()
+    sha1.update(repr(attrs).encode("utf-8"))
+    unique_filename = "<attrs generated init {0}>".format(sha1.hexdigest())
+
+    script, globs, annotations = _attrs_to_init_script(
+        attrs, frozen, slots, post_init, cache_hash, base_attr_map
+    )
+    locs = {}
+    bytecode = compile(script, unique_filename, "exec")
+    attr_dict = dict((a.name, a) for a in attrs)
+    globs.update({"NOTHING": NOTHING, "attr_dict": attr_dict})
+    if frozen is True:
+        # Save the lookup overhead in __init__ if we need to circumvent
+        # immutability.
+        globs["_cached_setattr"] = _obj_setattr
+    eval(bytecode, globs, locs)
+
+    # In order of debuggers like PDB being able to step through the code,
+    # we add a fake linecache entry.
+    linecache.cache[unique_filename] = (
+        len(script),
+        None,
+        script.splitlines(True),
+        unique_filename,
+    )
+
+    __init__ = locs["__init__"]
+    __init__.__annotations__ = annotations
+    return __init__
+
+
+def _add_init(cls, frozen):
+    """
+    Add a __init__ method to *cls*.  If *frozen* is True, make it immutable.
+    """
+    cls.__init__ = _make_init(
+        cls.__attrs_attrs__,
+        getattr(cls, "__attrs_post_init__", False),
+        frozen,
+        _is_slot_cls(cls),
+        cache_hash=False,
+        base_attr_map={},
+    )
+    return cls
+
+
+def fields(cls):
+    """
+    Return the tuple of ``attrs`` attributes for a class.
+
+    The tuple also allows accessing the fields by their names (see below for
+    examples).
+
+    :param type cls: Class to introspect.
+
+    :raise TypeError: If *cls* is not a class.
+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``
+        class.
+
+    :rtype: tuple (with name accessors) of :class:`attr.Attribute`
+
+    ..  versionchanged:: 16.2.0 Returned tuple allows accessing the fields
+        by name.
+    """
+    if not isclass(cls):
+        raise TypeError("Passed object must be a class.")
+    attrs = getattr(cls, "__attrs_attrs__", None)
+    if attrs is None:
+        raise NotAnAttrsClassError(
+            "{cls!r} is not an attrs-decorated class.".format(cls=cls)
+        )
+    return attrs
+
+
+def fields_dict(cls):
+    """
+    Return an ordered dictionary of ``attrs`` attributes for a class, whose
+    keys are the attribute names.
+
+    :param type cls: Class to introspect.
+
+    :raise TypeError: If *cls* is not a class.
+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``
+        class.
+
+    :rtype: an ordered dict where keys are attribute names and values are
+        :class:`attr.Attribute`\\ s. This will be a :class:`dict` if it's
+        naturally ordered like on Python 3.6+ or an
+        :class:`~collections.OrderedDict` otherwise.
+
+    .. versionadded:: 18.1.0
+    """
+    if not isclass(cls):
+        raise TypeError("Passed object must be a class.")
+    attrs = getattr(cls, "__attrs_attrs__", None)
+    if attrs is None:
+        raise NotAnAttrsClassError(
+            "{cls!r} is not an attrs-decorated class.".format(cls=cls)
+        )
+    return ordered_dict(((a.name, a) for a in attrs))
+
+
+def validate(inst):
+    """
+    Validate all attributes on *inst* that have a validator.
+
+    Leaves all exceptions through.
+
+    :param inst: Instance of a class with ``attrs`` attributes.
+    """
+    if _config._run_validators is False:
+        return
+
+    for a in fields(inst.__class__):
+        v = a.validator
+        if v is not None:
+            v(inst, a, getattr(inst, a.name))
+
+
+def _is_slot_cls(cls):
+    return "__slots__" in cls.__dict__
+
+
+def _is_slot_attr(a_name, base_attr_map):
+    """
+    Check if the attribute name comes from a slot class.
+    """
+    return a_name in base_attr_map and _is_slot_cls(base_attr_map[a_name])
+
+
+def _attrs_to_init_script(
+    attrs, frozen, slots, post_init, cache_hash, base_attr_map
+):
+    """
+    Return a script of an initializer for *attrs* and a dict of globals.
+
+    The globals are expected by the generated script.
+
+    If *frozen* is True, we cannot set the attributes directly so we use
+    a cached ``object.__setattr__``.
+    """
+    lines = []
+    any_slot_ancestors = any(
+        _is_slot_attr(a.name, base_attr_map) for a in attrs
+    )
+    if frozen is True:
+        if slots is True:
+            lines.append(
+                # Circumvent the __setattr__ descriptor to save one lookup per
+                # assignment.
+                # Note _setattr will be used again below if cache_hash is True
+                "_setattr = _cached_setattr.__get__(self, self.__class__)"
+            )
+
+            def fmt_setter(attr_name, value_var):
+                return "_setattr('%(attr_name)s', %(value_var)s)" % {
+                    "attr_name": attr_name,
+                    "value_var": value_var,
+                }
+
+            def fmt_setter_with_converter(attr_name, value_var):
+                conv_name = _init_converter_pat.format(attr_name)
+                return "_setattr('%(attr_name)s', %(conv)s(%(value_var)s))" % {
+                    "attr_name": attr_name,
+                    "value_var": value_var,
+                    "conv": conv_name,
+                }
+
+        else:
+            # Dict frozen classes assign directly to __dict__.
+            # But only if the attribute doesn't come from an ancestor slot
+            # class.
+            # Note _inst_dict will be used again below if cache_hash is True
+            lines.append("_inst_dict = self.__dict__")
+            if any_slot_ancestors:
+                lines.append(
+                    # Circumvent the __setattr__ descriptor to save one lookup
+                    # per assignment.
+                    "_setattr = _cached_setattr.__get__(self, self.__class__)"
+                )
+
+            def fmt_setter(attr_name, value_var):
+                if _is_slot_attr(attr_name, base_attr_map):
+                    res = "_setattr('%(attr_name)s', %(value_var)s)" % {
+                        "attr_name": attr_name,
+                        "value_var": value_var,
+                    }
+                else:
+                    res = "_inst_dict['%(attr_name)s'] = %(value_var)s" % {
+                        "attr_name": attr_name,
+                        "value_var": value_var,
+                    }
+                return res
+
+            def fmt_setter_with_converter(attr_name, value_var):
+                conv_name = _init_converter_pat.format(attr_name)
+                if _is_slot_attr(attr_name, base_attr_map):
+                    tmpl = "_setattr('%(attr_name)s', %(c)s(%(value_var)s))"
+                else:
+                    tmpl = "_inst_dict['%(attr_name)s'] = %(c)s(%(value_var)s)"
+                return tmpl % {
+                    "attr_name": attr_name,
+                    "value_var": value_var,
+                    "c": conv_name,
+                }
+
+    else:
+        # Not frozen.
+        def fmt_setter(attr_name, value):
+            return "self.%(attr_name)s = %(value)s" % {
+                "attr_name": attr_name,
+                "value": value,
+            }
+
+        def fmt_setter_with_converter(attr_name, value_var):
+            conv_name = _init_converter_pat.format(attr_name)
+            return "self.%(attr_name)s = %(conv)s(%(value_var)s)" % {
+                "attr_name": attr_name,
+                "value_var": value_var,
+                "conv": conv_name,
+            }
+
+    args = []
+    kw_only_args = []
+    attrs_to_validate = []
+
+    # This is a dictionary of names to validator and converter callables.
+    # Injecting this into __init__ globals lets us avoid lookups.
+    names_for_globals = {}
+    annotations = {"return": None}
+
+    for a in attrs:
+        if a.validator:
+            attrs_to_validate.append(a)
+        attr_name = a.name
+        arg_name = a.name.lstrip("_")
+        has_factory = isinstance(a.default, Factory)
+        if has_factory and a.default.takes_self:
+            maybe_self = "self"
+        else:
+            maybe_self = ""
+        if a.init is False:
+            if has_factory:
+                init_factory_name = _init_factory_pat.format(a.name)
+                if a.converter is not None:
+                    lines.append(
+                        fmt_setter_with_converter(
+                            attr_name,
+                            init_factory_name + "({0})".format(maybe_self),
+                        )
+                    )
+                    conv_name = _init_converter_pat.format(a.name)
+                    names_for_globals[conv_name] = a.converter
+                else:
+                    lines.append(
+                        fmt_setter(
+                            attr_name,
+                            init_factory_name + "({0})".format(maybe_self),
+                        )
+                    )
+                names_for_globals[init_factory_name] = a.default.factory
+            else:
+                if a.converter is not None:
+                    lines.append(
+                        fmt_setter_with_converter(
+                            attr_name,
+                            "attr_dict['{attr_name}'].default".format(
+                                attr_name=attr_name
+                            ),
+                        )
+                    )
+                    conv_name = _init_converter_pat.format(a.name)
+                    names_for_globals[conv_name] = a.converter
+                else:
+                    lines.append(
+                        fmt_setter(
+                            attr_name,
+                            "attr_dict['{attr_name}'].default".format(
+                                attr_name=attr_name
+                            ),
+                        )
+                    )
+        elif a.default is not NOTHING and not has_factory:
+            arg = "{arg_name}=attr_dict['{attr_name}'].default".format(
+                arg_name=arg_name, attr_name=attr_name
+            )
+            if a.kw_only:
+                kw_only_args.append(arg)
+            else:
+                args.append(arg)
+            if a.converter is not None:
+                lines.append(fmt_setter_with_converter(attr_name, arg_name))
+                names_for_globals[
+                    _init_converter_pat.format(a.name)
+                ] = a.converter
+            else:
+                lines.append(fmt_setter(attr_name, arg_name))
+        elif has_factory:
+            arg = "{arg_name}=NOTHING".format(arg_name=arg_name)
+            if a.kw_only:
+                kw_only_args.append(arg)
+            else:
+                args.append(arg)
+            lines.append(
+                "if {arg_name} is not NOTHING:".format(arg_name=arg_name)
+            )
+            init_factory_name = _init_factory_pat.format(a.name)
+            if a.converter is not None:
+                lines.append(
+                    "    " + fmt_setter_with_converter(attr_name, arg_name)
+                )
+                lines.append("else:")
+                lines.append(
+                    "    "
+                    + fmt_setter_with_converter(
+                        attr_name,
+                        init_factory_name + "({0})".format(maybe_self),
+                    )
+                )
+                names_for_globals[
+                    _init_converter_pat.format(a.name)
+                ] = a.converter
+            else:
+                lines.append("    " + fmt_setter(attr_name, arg_name))
+                lines.append("else:")
+                lines.append(
+                    "    "
+                    + fmt_setter(
+                        attr_name,
+                        init_factory_name + "({0})".format(maybe_self),
+                    )
+                )
+            names_for_globals[init_factory_name] = a.default.factory
+        else:
+            if a.kw_only:
+                kw_only_args.append(arg_name)
+            else:
+                args.append(arg_name)
+            if a.converter is not None:
+                lines.append(fmt_setter_with_converter(attr_name, arg_name))
+                names_for_globals[
+                    _init_converter_pat.format(a.name)
+                ] = a.converter
+            else:
+                lines.append(fmt_setter(attr_name, arg_name))
+
+        if a.init is True and a.converter is None and a.type is not None:
+            annotations[arg_name] = a.type
+
+    if attrs_to_validate:  # we can skip this if there are no validators.
+        names_for_globals["_config"] = _config
+        lines.append("if _config._run_validators is True:")
+        for a in attrs_to_validate:
+            val_name = "__attr_validator_{}".format(a.name)
+            attr_name = "__attr_{}".format(a.name)
+            lines.append(
+                "    {}(self, {}, self.{})".format(val_name, attr_name, a.name)
+            )
+            names_for_globals[val_name] = a.validator
+            names_for_globals[attr_name] = a
+    if post_init:
+        lines.append("self.__attrs_post_init__()")
+
+    # because this is set only after __attrs_post_init is called, a crash
+    # will result if post-init tries to access the hash code.  This seemed
+    # preferable to setting this beforehand, in which case alteration to
+    # field values during post-init combined with post-init accessing the
+    # hash code would result in silent bugs.
+    if cache_hash:
+        if frozen:
+            if slots:
+                # if frozen and slots, then _setattr defined above
+                init_hash_cache = "_setattr('%s', %s)"
+            else:
+                # if frozen and not slots, then _inst_dict defined above
+                init_hash_cache = "_inst_dict['%s'] = %s"
+        else:
+            init_hash_cache = "self.%s = %s"
+        lines.append(init_hash_cache % (_hash_cache_field, "None"))
+
+    args = ", ".join(args)
+    if kw_only_args:
+        if PY2:
+            raise PythonTooOldError(
+                "Keyword-only arguments only work on Python 3 and later."
+            )
+
+        args += "{leading_comma}*, {kw_only_args}".format(
+            leading_comma=", " if args else "",
+            kw_only_args=", ".join(kw_only_args),
+        )
+    return (
+        """\
+def __init__(self, {args}):
+    {lines}
+""".format(
+            args=args, lines="\n    ".join(lines) if lines else "pass"
+        ),
+        names_for_globals,
+        annotations,
+    )
+
+
+class Attribute(object):
+    """
+    *Read-only* representation of an attribute.
+
+    :attribute name: The name of the attribute.
+
+    Plus *all* arguments of :func:`attr.ib`.
+
+    For the version history of the fields, see :func:`attr.ib`.
+    """
+
+    __slots__ = (
+        "name",
+        "default",
+        "validator",
+        "repr",
+        "cmp",
+        "hash",
+        "init",
+        "metadata",
+        "type",
+        "converter",
+        "kw_only",
+    )
+
+    def __init__(
+        self,
+        name,
+        default,
+        validator,
+        repr,
+        cmp,
+        hash,
+        init,
+        convert=None,
+        metadata=None,
+        type=None,
+        converter=None,
+        kw_only=False,
+    ):
+        # Cache this descriptor here to speed things up later.
+        bound_setattr = _obj_setattr.__get__(self, Attribute)
+
+        # Despite the big red warning, people *do* instantiate `Attribute`
+        # themselves.
+        if convert is not None:
+            if converter is not None:
+                raise RuntimeError(
+                    "Can't pass both `convert` and `converter`.  "
+                    "Please use `converter` only."
+                )
+            warnings.warn(
+                "The `convert` argument is deprecated in favor of `converter`."
+                "  It will be removed after 2019/01.",
+                DeprecationWarning,
+                stacklevel=2,
+            )
+            converter = convert
+
+        bound_setattr("name", name)
+        bound_setattr("default", default)
+        bound_setattr("validator", validator)
+        bound_setattr("repr", repr)
+        bound_setattr("cmp", cmp)
+        bound_setattr("hash", hash)
+        bound_setattr("init", init)
+        bound_setattr("converter", converter)
+        bound_setattr(
+            "metadata",
+            (
+                metadata_proxy(metadata)
+                if metadata
+                else _empty_metadata_singleton
+            ),
+        )
+        bound_setattr("type", type)
+        bound_setattr("kw_only", kw_only)
+
+    def __setattr__(self, name, value):
+        raise FrozenInstanceError()
+
+    @property
+    def convert(self):
+        warnings.warn(
+            "The `convert` attribute is deprecated in favor of `converter`.  "
+            "It will be removed after 2019/01.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
+        return self.converter
+
+    @classmethod
+    def from_counting_attr(cls, name, ca, type=None):
+        # type holds the annotated value. deal with conflicts:
+        if type is None:
+            type = ca.type
+        elif ca.type is not None:
+            raise ValueError(
+                "Type annotation and type argument cannot both be present"
+            )
+        inst_dict = {
+            k: getattr(ca, k)
+            for k in Attribute.__slots__
+            if k
+            not in (
+                "name",
+                "validator",
+                "default",
+                "type",
+                "convert",
+            )  # exclude methods and deprecated alias
+        }
+        return cls(
+            name=name,
+            validator=ca._validator,
+            default=ca._default,
+            type=type,
+            **inst_dict
+        )
+
+    # Don't use attr.assoc since fields(Attribute) doesn't work
+    def _assoc(self, **changes):
+        """
+        Copy *self* and apply *changes*.
+        """
+        new = copy.copy(self)
+
+        new._setattrs(changes.items())
+
+        return new
+
+    # Don't use _add_pickle since fields(Attribute) doesn't work
+    def __getstate__(self):
+        """
+        Play nice with pickle.
+        """
+        return tuple(
+            getattr(self, name) if name != "metadata" else dict(self.metadata)
+            for name in self.__slots__
+        )
+
+    def __setstate__(self, state):
+        """
+        Play nice with pickle.
+        """
+        self._setattrs(zip(self.__slots__, state))
+
+    def _setattrs(self, name_values_pairs):
+        bound_setattr = _obj_setattr.__get__(self, Attribute)
+        for name, value in name_values_pairs:
+            if name != "metadata":
+                bound_setattr(name, value)
+            else:
+                bound_setattr(
+                    name,
+                    metadata_proxy(value)
+                    if value
+                    else _empty_metadata_singleton,
+                )
+
+
+_a = [
+    Attribute(
+        name=name,
+        default=NOTHING,
+        validator=None,
+        repr=True,
+        cmp=True,
+        hash=(name != "metadata"),
+        init=True,
+    )
+    for name in Attribute.__slots__
+    if name != "convert"  # XXX: remove once `convert` is gone
+]
+
+Attribute = _add_hash(
+    _add_cmp(_add_repr(Attribute, attrs=_a), attrs=_a),
+    attrs=[a for a in _a if a.hash],
+)
+
+
+class _CountingAttr(object):
+    """
+    Intermediate representation of attributes that uses a counter to preserve
+    the order in which the attributes have been defined.
+
+    *Internal* data structure of the attrs library.  Running into is most
+    likely the result of a bug like a forgotten `@attr.s` decorator.
+    """
+
+    __slots__ = (
+        "counter",
+        "_default",
+        "repr",
+        "cmp",
+        "hash",
+        "init",
+        "metadata",
+        "_validator",
+        "converter",
+        "type",
+        "kw_only",
+    )
+    __attrs_attrs__ = tuple(
+        Attribute(
+            name=name,
+            default=NOTHING,
+            validator=None,
+            repr=True,
+            cmp=True,
+            hash=True,
+            init=True,
+            kw_only=False,
+        )
+        for name in ("counter", "_default", "repr", "cmp", "hash", "init")
+    ) + (
+        Attribute(
+            name="metadata",
+            default=None,
+            validator=None,
+            repr=True,
+            cmp=True,
+            hash=False,
+            init=True,
+            kw_only=False,
+        ),
+    )
+    cls_counter = 0
+
+    def __init__(
+        self,
+        default,
+        validator,
+        repr,
+        cmp,
+        hash,
+        init,
+        converter,
+        metadata,
+        type,
+        kw_only,
+    ):
+        _CountingAttr.cls_counter += 1
+        self.counter = _CountingAttr.cls_counter
+        self._default = default
+        # If validator is a list/tuple, wrap it using helper validator.
+        if validator and isinstance(validator, (list, tuple)):
+            self._validator = and_(*validator)
+        else:
+            self._validator = validator
+        self.repr = repr
+        self.cmp = cmp
+        self.hash = hash
+        self.init = init
+        self.converter = converter
+        self.metadata = metadata
+        self.type = type
+        self.kw_only = kw_only
+
+    def validator(self, meth):
+        """
+        Decorator that adds *meth* to the list of validators.
+
+        Returns *meth* unchanged.
+
+        .. versionadded:: 17.1.0
+        """
+        if self._validator is None:
+            self._validator = meth
+        else:
+            self._validator = and_(self._validator, meth)
+        return meth
+
+    def default(self, meth):
+        """
+        Decorator that allows to set the default for an attribute.
+
+        Returns *meth* unchanged.
+
+        :raises DefaultAlreadySetError: If default has been set before.
+
+        .. versionadded:: 17.1.0
+        """
+        if self._default is not NOTHING:
+            raise DefaultAlreadySetError()
+
+        self._default = Factory(meth, takes_self=True)
+
+        return meth
+
+
+_CountingAttr = _add_cmp(_add_repr(_CountingAttr))
+
+
+@attrs(slots=True, init=False, hash=True)
+class Factory(object):
+    """
+    Stores a factory callable.
+
+    If passed as the default value to :func:`attr.ib`, the factory is used to
+    generate a new value.
+
+    :param callable factory: A callable that takes either none or exactly one
+        mandatory positional argument depending on *takes_self*.
+    :param bool takes_self: Pass the partially initialized instance that is
+        being initialized as a positional argument.
+
+    .. versionadded:: 17.1.0  *takes_self*
+    """
+
+    factory = attrib()
+    takes_self = attrib()
+
+    def __init__(self, factory, takes_self=False):
+        """
+        `Factory` is part of the default machinery so if we want a default
+        value here, we have to implement it ourselves.
+        """
+        self.factory = factory
+        self.takes_self = takes_self
+
+
+def make_class(name, attrs, bases=(object,), **attributes_arguments):
+    """
+    A quick way to create a new class called *name* with *attrs*.
+
+    :param name: The name for the new class.
+    :type name: str
+
+    :param attrs: A list of names or a dictionary of mappings of names to
+        attributes.
+
+        If *attrs* is a list or an ordered dict (:class:`dict` on Python 3.6+,
+        :class:`collections.OrderedDict` otherwise), the order is deduced from
+        the order of the names or attributes inside *attrs*.  Otherwise the
+        order of the definition of the attributes is used.
+    :type attrs: :class:`list` or :class:`dict`
+
+    :param tuple bases: Classes that the new class will subclass.
+
+    :param attributes_arguments: Passed unmodified to :func:`attr.s`.
+
+    :return: A new class with *attrs*.
+    :rtype: type
+
+    .. versionadded:: 17.1.0 *bases*
+    .. versionchanged:: 18.1.0 If *attrs* is ordered, the order is retained.
+    """
+    if isinstance(attrs, dict):
+        cls_dict = attrs
+    elif isinstance(attrs, (list, tuple)):
+        cls_dict = dict((a, attrib()) for a in attrs)
+    else:
+        raise TypeError("attrs argument must be a dict or a list.")
+
+    post_init = cls_dict.pop("__attrs_post_init__", None)
+    type_ = type(
+        name,
+        bases,
+        {} if post_init is None else {"__attrs_post_init__": post_init},
+    )
+    # For pickling to work, the __module__ variable needs to be set to the
+    # frame where the class is created.  Bypass this step in environments where
+    # sys._getframe is not defined (Jython for example) or sys._getframe is not
+    # defined for arguments greater than 0 (IronPython).
+    try:
+        type_.__module__ = sys._getframe(1).f_globals.get(
+            "__name__", "__main__"
+        )
+    except (AttributeError, ValueError):
+        pass
+
+    return _attrs(these=cls_dict, **attributes_arguments)(type_)
+
+
+# These are required by within this module so we define them here and merely
+# import into .validators.
+
+
+@attrs(slots=True, hash=True)
+class _AndValidator(object):
+    """
+    Compose many validators to a single one.
+    """
+
+    _validators = attrib()
+
+    def __call__(self, inst, attr, value):
+        for v in self._validators:
+            v(inst, attr, value)
+
+
+def and_(*validators):
+    """
+    A validator that composes multiple validators into one.
+
+    When called on a value, it runs all wrapped validators.
+
+    :param validators: Arbitrary number of validators.
+    :type validators: callables
+
+    .. versionadded:: 17.1.0
+    """
+    vals = []
+    for validator in validators:
+        vals.extend(
+            validator._validators
+            if isinstance(validator, _AndValidator)
+            else [validator]
+        )
+
+    return _AndValidator(tuple(vals))
Index: venv/Lib/site-packages/attr/exceptions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/exceptions.py	(date 1543190976108)
+++ venv/Lib/site-packages/attr/exceptions.py	(date 1543190976108)
@@ -0,0 +1,57 @@
+from __future__ import absolute_import, division, print_function
+
+
+class FrozenInstanceError(AttributeError):
+    """
+    A frozen/immutable instance has been attempted to be modified.
+
+    It mirrors the behavior of ``namedtuples`` by using the same error message
+    and subclassing :exc:`AttributeError`.
+
+    .. versionadded:: 16.1.0
+    """
+
+    msg = "can't set attribute"
+    args = [msg]
+
+
+class AttrsAttributeNotFoundError(ValueError):
+    """
+    An ``attrs`` function couldn't find an attribute that the user asked for.
+
+    .. versionadded:: 16.2.0
+    """
+
+
+class NotAnAttrsClassError(ValueError):
+    """
+    A non-``attrs`` class has been passed into an ``attrs`` function.
+
+    .. versionadded:: 16.2.0
+    """
+
+
+class DefaultAlreadySetError(RuntimeError):
+    """
+    A default has been set using ``attr.ib()`` and is attempted to be reset
+    using the decorator.
+
+    .. versionadded:: 17.1.0
+    """
+
+
+class UnannotatedAttributeError(RuntimeError):
+    """
+    A class with ``auto_attribs=True`` has an ``attr.ib()`` without a type
+    annotation.
+
+    .. versionadded:: 17.3.0
+    """
+
+
+class PythonTooOldError(RuntimeError):
+    """
+    An ``attrs`` feature requiring a more recent python version has been used.
+
+    .. versionadded:: 18.2.0
+    """
Index: venv/Lib/site-packages/attr/validators.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/validators.py	(date 1543190976120)
+++ venv/Lib/site-packages/attr/validators.py	(date 1543190976120)
@@ -0,0 +1,170 @@
+"""
+Commonly useful validators.
+"""
+
+from __future__ import absolute_import, division, print_function
+
+from ._make import _AndValidator, and_, attrib, attrs
+
+
+__all__ = ["and_", "in_", "instance_of", "optional", "provides"]
+
+
+@attrs(repr=False, slots=True, hash=True)
+class _InstanceOfValidator(object):
+    type = attrib()
+
+    def __call__(self, inst, attr, value):
+        """
+        We use a callable class to be able to change the ``__repr__``.
+        """
+        if not isinstance(value, self.type):
+            raise TypeError(
+                "'{name}' must be {type!r} (got {value!r} that is a "
+                "{actual!r}).".format(
+                    name=attr.name,
+                    type=self.type,
+                    actual=value.__class__,
+                    value=value,
+                ),
+                attr,
+                self.type,
+                value,
+            )
+
+    def __repr__(self):
+        return "<instance_of validator for type {type!r}>".format(
+            type=self.type
+        )
+
+
+def instance_of(type):
+    """
+    A validator that raises a :exc:`TypeError` if the initializer is called
+    with a wrong type for this particular attribute (checks are performed using
+    :func:`isinstance` therefore it's also valid to pass a tuple of types).
+
+    :param type: The type to check for.
+    :type type: type or tuple of types
+
+    :raises TypeError: With a human readable error message, the attribute
+        (of type :class:`attr.Attribute`), the expected type, and the value it
+        got.
+    """
+    return _InstanceOfValidator(type)
+
+
+@attrs(repr=False, slots=True, hash=True)
+class _ProvidesValidator(object):
+    interface = attrib()
+
+    def __call__(self, inst, attr, value):
+        """
+        We use a callable class to be able to change the ``__repr__``.
+        """
+        if not self.interface.providedBy(value):
+            raise TypeError(
+                "'{name}' must provide {interface!r} which {value!r} "
+                "doesn't.".format(
+                    name=attr.name, interface=self.interface, value=value
+                ),
+                attr,
+                self.interface,
+                value,
+            )
+
+    def __repr__(self):
+        return "<provides validator for interface {interface!r}>".format(
+            interface=self.interface
+        )
+
+
+def provides(interface):
+    """
+    A validator that raises a :exc:`TypeError` if the initializer is called
+    with an object that does not provide the requested *interface* (checks are
+    performed using ``interface.providedBy(value)`` (see `zope.interface
+    <https://zopeinterface.readthedocs.io/en/latest/>`_).
+
+    :param zope.interface.Interface interface: The interface to check for.
+
+    :raises TypeError: With a human readable error message, the attribute
+        (of type :class:`attr.Attribute`), the expected interface, and the
+        value it got.
+    """
+    return _ProvidesValidator(interface)
+
+
+@attrs(repr=False, slots=True, hash=True)
+class _OptionalValidator(object):
+    validator = attrib()
+
+    def __call__(self, inst, attr, value):
+        if value is None:
+            return
+
+        self.validator(inst, attr, value)
+
+    def __repr__(self):
+        return "<optional validator for {what} or None>".format(
+            what=repr(self.validator)
+        )
+
+
+def optional(validator):
+    """
+    A validator that makes an attribute optional.  An optional attribute is one
+    which can be set to ``None`` in addition to satisfying the requirements of
+    the sub-validator.
+
+    :param validator: A validator (or a list of validators) that is used for
+        non-``None`` values.
+    :type validator: callable or :class:`list` of callables.
+
+    .. versionadded:: 15.1.0
+    .. versionchanged:: 17.1.0 *validator* can be a list of validators.
+    """
+    if isinstance(validator, list):
+        return _OptionalValidator(_AndValidator(validator))
+    return _OptionalValidator(validator)
+
+
+@attrs(repr=False, slots=True, hash=True)
+class _InValidator(object):
+    options = attrib()
+
+    def __call__(self, inst, attr, value):
+        try:
+            in_options = value in self.options
+        except TypeError as e:  # e.g. `1 in "abc"`
+            in_options = False
+
+        if not in_options:
+            raise ValueError(
+                "'{name}' must be in {options!r} (got {value!r})".format(
+                    name=attr.name, options=self.options, value=value
+                )
+            )
+
+    def __repr__(self):
+        return "<in_ validator with options {options!r}>".format(
+            options=self.options
+        )
+
+
+def in_(options):
+    """
+    A validator that raises a :exc:`ValueError` if the initializer is called
+    with a value that does not belong in the options provided.  The check is
+    performed using ``value in options``.
+
+    :param options: Allowed options.
+    :type options: list, tuple, :class:`enum.Enum`, ...
+
+    :raises ValueError: With a human readable error message, the attribute (of
+       type :class:`attr.Attribute`), the expected options, and the value it
+       got.
+
+    .. versionadded:: 17.1.0
+    """
+    return _InValidator(options)
Index: venv/Lib/site-packages/attr/filters.pyi
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/filters.pyi	(date 1543190976128)
+++ venv/Lib/site-packages/attr/filters.pyi	(date 1543190976128)
@@ -0,0 +1,5 @@
+from typing import Union
+from . import Attribute, _FilterType
+
+def include(*what: Union[type, Attribute]) -> _FilterType: ...
+def exclude(*what: Union[type, Attribute]) -> _FilterType: ...
Index: venv/Lib/site-packages/pluggy/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy/__init__.py	(date 1543190976140)
+++ venv/Lib/site-packages/pluggy/__init__.py	(date 1543190976140)
@@ -0,0 +1,18 @@
+try:
+    from ._version import version as __version__
+except ImportError:
+    # broken installation, we don't even try
+    # unknown only works because we do poor mans version compare
+    __version__ = "unknown"
+
+__all__ = [
+    "PluginManager",
+    "PluginValidationError",
+    "HookCallError",
+    "HookspecMarker",
+    "HookimplMarker",
+]
+
+from .manager import PluginManager, PluginValidationError
+from .callers import HookCallError
+from .hooks import HookspecMarker, HookimplMarker
Index: venv/Lib/site-packages/pluggy/manager.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy/manager.py	(date 1543190976152)
+++ venv/Lib/site-packages/pluggy/manager.py	(date 1543190976152)
@@ -0,0 +1,355 @@
+import inspect
+from . import _tracing
+from .hooks import HookImpl, _HookRelay, _HookCaller, normalize_hookimpl_opts
+import warnings
+
+
+def _warn_for_function(warning, function):
+    warnings.warn_explicit(
+        warning,
+        type(warning),
+        lineno=function.__code__.co_firstlineno,
+        filename=function.__code__.co_filename,
+    )
+
+
+class PluginValidationError(Exception):
+    """ plugin failed validation.
+
+    :param object plugin: the plugin which failed validation,
+        may be a module or an arbitrary object.
+    """
+
+    def __init__(self, plugin, message):
+        self.plugin = plugin
+        super(Exception, self).__init__(message)
+
+
+class PluginManager(object):
+    """ Core Pluginmanager class which manages registration
+    of plugin objects and 1:N hook calling.
+
+    You can register new hooks by calling ``add_hookspec(module_or_class)``.
+    You can register plugin objects (which contain hooks) by calling
+    ``register(plugin)``.  The Pluginmanager is initialized with a
+    prefix that is searched for in the names of the dict of registered
+    plugin objects.
+
+    For debugging purposes you can call ``enable_tracing()``
+    which will subsequently send debug information to the trace helper.
+    """
+
+    def __init__(self, project_name, implprefix=None):
+        """If ``implprefix`` is given implementation functions
+        will be recognized if their name matches the implprefix. """
+        self.project_name = project_name
+        self._name2plugin = {}
+        self._plugin2hookcallers = {}
+        self._plugin_distinfo = []
+        self.trace = _tracing.TagTracer().get("pluginmanage")
+        self.hook = _HookRelay(self.trace.root.get("hook"))
+        if implprefix is not None:
+            warnings.warn(
+                "Support for the `implprefix` arg is now deprecated and will "
+                "be removed in an upcoming release. Please use HookimplMarker.",
+                DeprecationWarning,
+            )
+        self._implprefix = implprefix
+        self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(
+            methods,
+            kwargs,
+            firstresult=hook.spec.opts.get("firstresult") if hook.spec else False,
+        )
+
+    def _hookexec(self, hook, methods, kwargs):
+        # called from all hookcaller instances.
+        # enable_tracing will set its own wrapping function at self._inner_hookexec
+        return self._inner_hookexec(hook, methods, kwargs)
+
+    def register(self, plugin, name=None):
+        """ Register a plugin and return its canonical name or None if the name
+        is blocked from registering.  Raise a ValueError if the plugin is already
+        registered. """
+        plugin_name = name or self.get_canonical_name(plugin)
+
+        if plugin_name in self._name2plugin or plugin in self._plugin2hookcallers:
+            if self._name2plugin.get(plugin_name, -1) is None:
+                return  # blocked plugin, return None to indicate no registration
+            raise ValueError(
+                "Plugin already registered: %s=%s\n%s"
+                % (plugin_name, plugin, self._name2plugin)
+            )
+
+        # XXX if an error happens we should make sure no state has been
+        # changed at point of return
+        self._name2plugin[plugin_name] = plugin
+
+        # register matching hook implementations of the plugin
+        self._plugin2hookcallers[plugin] = hookcallers = []
+        for name in dir(plugin):
+            hookimpl_opts = self.parse_hookimpl_opts(plugin, name)
+            if hookimpl_opts is not None:
+                normalize_hookimpl_opts(hookimpl_opts)
+                method = getattr(plugin, name)
+                hookimpl = HookImpl(plugin, plugin_name, method, hookimpl_opts)
+                hook = getattr(self.hook, name, None)
+                if hook is None:
+                    hook = _HookCaller(name, self._hookexec)
+                    setattr(self.hook, name, hook)
+                elif hook.has_spec():
+                    self._verify_hook(hook, hookimpl)
+                    hook._maybe_apply_history(hookimpl)
+                hook._add_hookimpl(hookimpl)
+                hookcallers.append(hook)
+        return plugin_name
+
+    def parse_hookimpl_opts(self, plugin, name):
+        method = getattr(plugin, name)
+        if not inspect.isroutine(method):
+            return
+        try:
+            res = getattr(method, self.project_name + "_impl", None)
+        except Exception:
+            res = {}
+        if res is not None and not isinstance(res, dict):
+            # false positive
+            res = None
+        # TODO: remove when we drop implprefix in 1.0
+        elif res is None and self._implprefix and name.startswith(self._implprefix):
+            _warn_for_function(
+                DeprecationWarning(
+                    "The `implprefix` system is deprecated please decorate "
+                    "this function using an instance of HookimplMarker."
+                ),
+                method,
+            )
+            res = {}
+        return res
+
+    def unregister(self, plugin=None, name=None):
+        """ unregister a plugin object and all its contained hook implementations
+        from internal data structures. """
+        if name is None:
+            assert plugin is not None, "one of name or plugin needs to be specified"
+            name = self.get_name(plugin)
+
+        if plugin is None:
+            plugin = self.get_plugin(name)
+
+        # if self._name2plugin[name] == None registration was blocked: ignore
+        if self._name2plugin.get(name):
+            del self._name2plugin[name]
+
+        for hookcaller in self._plugin2hookcallers.pop(plugin, []):
+            hookcaller._remove_plugin(plugin)
+
+        return plugin
+
+    def set_blocked(self, name):
+        """ block registrations of the given name, unregister if already registered. """
+        self.unregister(name=name)
+        self._name2plugin[name] = None
+
+    def is_blocked(self, name):
+        """ return True if the name blogs registering plugins of that name. """
+        return name in self._name2plugin and self._name2plugin[name] is None
+
+    def add_hookspecs(self, module_or_class):
+        """ add new hook specifications defined in the given module_or_class.
+        Functions are recognized if they have been decorated accordingly. """
+        names = []
+        for name in dir(module_or_class):
+            spec_opts = self.parse_hookspec_opts(module_or_class, name)
+            if spec_opts is not None:
+                hc = getattr(self.hook, name, None)
+                if hc is None:
+                    hc = _HookCaller(name, self._hookexec, module_or_class, spec_opts)
+                    setattr(self.hook, name, hc)
+                else:
+                    # plugins registered this hook without knowing the spec
+                    hc.set_specification(module_or_class, spec_opts)
+                    for hookfunction in hc.get_hookimpls():
+                        self._verify_hook(hc, hookfunction)
+                names.append(name)
+
+        if not names:
+            raise ValueError(
+                "did not find any %r hooks in %r" % (self.project_name, module_or_class)
+            )
+
+    def parse_hookspec_opts(self, module_or_class, name):
+        method = getattr(module_or_class, name)
+        return getattr(method, self.project_name + "_spec", None)
+
+    def get_plugins(self):
+        """ return the set of registered plugins. """
+        return set(self._plugin2hookcallers)
+
+    def is_registered(self, plugin):
+        """ Return True if the plugin is already registered. """
+        return plugin in self._plugin2hookcallers
+
+    def get_canonical_name(self, plugin):
+        """ Return canonical name for a plugin object. Note that a plugin
+        may be registered under a different name which was specified
+        by the caller of register(plugin, name). To obtain the name
+        of an registered plugin use ``get_name(plugin)`` instead."""
+        return getattr(plugin, "__name__", None) or str(id(plugin))
+
+    def get_plugin(self, name):
+        """ Return a plugin or None for the given name. """
+        return self._name2plugin.get(name)
+
+    def has_plugin(self, name):
+        """ Return True if a plugin with the given name is registered. """
+        return self.get_plugin(name) is not None
+
+    def get_name(self, plugin):
+        """ Return name for registered plugin or None if not registered. """
+        for name, val in self._name2plugin.items():
+            if plugin == val:
+                return name
+
+    def _verify_hook(self, hook, hookimpl):
+        if hook.is_historic() and hookimpl.hookwrapper:
+            raise PluginValidationError(
+                hookimpl.plugin,
+                "Plugin %r\nhook %r\nhistoric incompatible to hookwrapper"
+                % (hookimpl.plugin_name, hook.name),
+            )
+        if hook.spec.warn_on_impl:
+            _warn_for_function(hook.spec.warn_on_impl, hookimpl.function)
+        # positional arg checking
+        notinspec = set(hookimpl.argnames) - set(hook.spec.argnames)
+        if notinspec:
+            raise PluginValidationError(
+                hookimpl.plugin,
+                "Plugin %r for hook %r\nhookimpl definition: %s\n"
+                "Argument(s) %s are declared in the hookimpl but "
+                "can not be found in the hookspec"
+                % (
+                    hookimpl.plugin_name,
+                    hook.name,
+                    _formatdef(hookimpl.function),
+                    notinspec,
+                ),
+            )
+
+    def check_pending(self):
+        """ Verify that all hooks which have not been verified against
+        a hook specification are optional, otherwise raise PluginValidationError"""
+        for name in self.hook.__dict__:
+            if name[0] != "_":
+                hook = getattr(self.hook, name)
+                if not hook.has_spec():
+                    for hookimpl in hook.get_hookimpls():
+                        if not hookimpl.optionalhook:
+                            raise PluginValidationError(
+                                hookimpl.plugin,
+                                "unknown hook %r in plugin %r"
+                                % (name, hookimpl.plugin),
+                            )
+
+    def load_setuptools_entrypoints(self, entrypoint_name):
+        """ Load modules from querying the specified setuptools entrypoint name.
+        Return the number of loaded plugins. """
+        from pkg_resources import (
+            iter_entry_points,
+            DistributionNotFound,
+            VersionConflict,
+        )
+
+        for ep in iter_entry_points(entrypoint_name):
+            # is the plugin registered or blocked?
+            if self.get_plugin(ep.name) or self.is_blocked(ep.name):
+                continue
+            try:
+                plugin = ep.load()
+            except DistributionNotFound:
+                continue
+            except VersionConflict as e:
+                raise PluginValidationError(
+                    plugin=None,
+                    message="Plugin %r could not be loaded: %s!" % (ep.name, e),
+                )
+            self.register(plugin, name=ep.name)
+            self._plugin_distinfo.append((plugin, ep.dist))
+        return len(self._plugin_distinfo)
+
+    def list_plugin_distinfo(self):
+        """ return list of distinfo/plugin tuples for all setuptools registered
+        plugins. """
+        return list(self._plugin_distinfo)
+
+    def list_name_plugin(self):
+        """ return list of name/plugin pairs. """
+        return list(self._name2plugin.items())
+
+    def get_hookcallers(self, plugin):
+        """ get all hook callers for the specified plugin. """
+        return self._plugin2hookcallers.get(plugin)
+
+    def add_hookcall_monitoring(self, before, after):
+        """ add before/after tracing functions for all hooks
+        and return an undo function which, when called,
+        will remove the added tracers.
+
+        ``before(hook_name, hook_impls, kwargs)`` will be called ahead
+        of all hook calls and receive a hookcaller instance, a list
+        of HookImpl instances and the keyword arguments for the hook call.
+
+        ``after(outcome, hook_name, hook_impls, kwargs)`` receives the
+        same arguments as ``before`` but also a :py:class:`_Result`` object
+        which represents the result of the overall hook call.
+        """
+        return _tracing._TracedHookExecution(self, before, after).undo
+
+    def enable_tracing(self):
+        """ enable tracing of hook calls and return an undo function. """
+        hooktrace = self.hook._trace
+
+        def before(hook_name, methods, kwargs):
+            hooktrace.root.indent += 1
+            hooktrace(hook_name, kwargs)
+
+        def after(outcome, hook_name, methods, kwargs):
+            if outcome.excinfo is None:
+                hooktrace("finish", hook_name, "-->", outcome.get_result())
+            hooktrace.root.indent -= 1
+
+        return self.add_hookcall_monitoring(before, after)
+
+    def subset_hook_caller(self, name, remove_plugins):
+        """ Return a new _HookCaller instance for the named method
+        which manages calls to all registered plugins except the
+        ones from remove_plugins. """
+        orig = getattr(self.hook, name)
+        plugins_to_remove = [plug for plug in remove_plugins if hasattr(plug, name)]
+        if plugins_to_remove:
+            hc = _HookCaller(
+                orig.name, orig._hookexec, orig.spec.namespace, orig.spec.opts
+            )
+            for hookimpl in orig.get_hookimpls():
+                plugin = hookimpl.plugin
+                if plugin not in plugins_to_remove:
+                    hc._add_hookimpl(hookimpl)
+                    # we also keep track of this hook caller so it
+                    # gets properly removed on plugin unregistration
+                    self._plugin2hookcallers.setdefault(plugin, []).append(hc)
+            return hc
+        return orig
+
+
+if hasattr(inspect, "signature"):
+
+    def _formatdef(func):
+        return "%s%s" % (func.__name__, str(inspect.signature(func)))
+
+
+else:
+
+    def _formatdef(func):
+        return "%s%s" % (
+            func.__name__,
+            inspect.formatargspec(*inspect.getargspec(func)),
+        )
Index: venv/Lib/site-packages/pluggy/_version.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy/_version.py	(date 1543190976160)
+++ venv/Lib/site-packages/pluggy/_version.py	(date 1543190976160)
@@ -0,0 +1,4 @@
+# coding: utf-8
+# file generated by setuptools_scm
+# don't change, don't track in version control
+version = '0.8.0'
Index: venv/Lib/site-packages/pluggy/hooks.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy/hooks.py	(date 1543190976176)
+++ venv/Lib/site-packages/pluggy/hooks.py	(date 1543190976176)
@@ -0,0 +1,357 @@
+"""
+Internal hook annotation, representation and calling machinery.
+"""
+import inspect
+import warnings
+from .callers import _legacymulticall, _multicall
+
+
+class HookspecMarker(object):
+    """ Decorator helper class for marking functions as hook specifications.
+
+    You can instantiate it with a project_name to get a decorator.
+    Calling PluginManager.add_hookspecs later will discover all marked functions
+    if the PluginManager uses the same project_name.
+    """
+
+    def __init__(self, project_name):
+        self.project_name = project_name
+
+    def __call__(
+        self, function=None, firstresult=False, historic=False, warn_on_impl=None
+    ):
+        """ if passed a function, directly sets attributes on the function
+        which will make it discoverable to add_hookspecs().  If passed no
+        function, returns a decorator which can be applied to a function
+        later using the attributes supplied.
+
+        If firstresult is True the 1:N hook call (N being the number of registered
+        hook implementation functions) will stop at I<=N when the I'th function
+        returns a non-None result.
+
+        If historic is True calls to a hook will be memorized and replayed
+        on later registered plugins.
+
+        """
+
+        def setattr_hookspec_opts(func):
+            if historic and firstresult:
+                raise ValueError("cannot have a historic firstresult hook")
+            setattr(
+                func,
+                self.project_name + "_spec",
+                dict(
+                    firstresult=firstresult,
+                    historic=historic,
+                    warn_on_impl=warn_on_impl,
+                ),
+            )
+            return func
+
+        if function is not None:
+            return setattr_hookspec_opts(function)
+        else:
+            return setattr_hookspec_opts
+
+
+class HookimplMarker(object):
+    """ Decorator helper class for marking functions as hook implementations.
+
+    You can instantiate with a project_name to get a decorator.
+    Calling PluginManager.register later will discover all marked functions
+    if the PluginManager uses the same project_name.
+    """
+
+    def __init__(self, project_name):
+        self.project_name = project_name
+
+    def __call__(
+        self,
+        function=None,
+        hookwrapper=False,
+        optionalhook=False,
+        tryfirst=False,
+        trylast=False,
+    ):
+
+        """ if passed a function, directly sets attributes on the function
+        which will make it discoverable to register().  If passed no function,
+        returns a decorator which can be applied to a function later using
+        the attributes supplied.
+
+        If optionalhook is True a missing matching hook specification will not result
+        in an error (by default it is an error if no matching spec is found).
+
+        If tryfirst is True this hook implementation will run as early as possible
+        in the chain of N hook implementations for a specfication.
+
+        If trylast is True this hook implementation will run as late as possible
+        in the chain of N hook implementations.
+
+        If hookwrapper is True the hook implementations needs to execute exactly
+        one "yield".  The code before the yield is run early before any non-hookwrapper
+        function is run.  The code after the yield is run after all non-hookwrapper
+        function have run.  The yield receives a ``_Result`` object representing
+        the exception or result outcome of the inner calls (including other hookwrapper
+        calls).
+
+        """
+
+        def setattr_hookimpl_opts(func):
+            setattr(
+                func,
+                self.project_name + "_impl",
+                dict(
+                    hookwrapper=hookwrapper,
+                    optionalhook=optionalhook,
+                    tryfirst=tryfirst,
+                    trylast=trylast,
+                ),
+            )
+            return func
+
+        if function is None:
+            return setattr_hookimpl_opts
+        else:
+            return setattr_hookimpl_opts(function)
+
+
+def normalize_hookimpl_opts(opts):
+    opts.setdefault("tryfirst", False)
+    opts.setdefault("trylast", False)
+    opts.setdefault("hookwrapper", False)
+    opts.setdefault("optionalhook", False)
+
+
+if hasattr(inspect, "getfullargspec"):
+
+    def _getargspec(func):
+        return inspect.getfullargspec(func)
+
+
+else:
+
+    def _getargspec(func):
+        return inspect.getargspec(func)
+
+
+def varnames(func):
+    """Return tuple of positional and keywrord argument names for a function,
+    method, class or callable.
+
+    In case of a class, its ``__init__`` method is considered.
+    For methods the ``self`` parameter is not included.
+    """
+    cache = getattr(func, "__dict__", {})
+    try:
+        return cache["_varnames"]
+    except KeyError:
+        pass
+
+    if inspect.isclass(func):
+        try:
+            func = func.__init__
+        except AttributeError:
+            return (), ()
+    elif not inspect.isroutine(func):  # callable object?
+        try:
+            func = getattr(func, "__call__", func)
+        except Exception:
+            return ()
+
+    try:  # func MUST be a function or method here or we won't parse any args
+        spec = _getargspec(func)
+    except TypeError:
+        return (), ()
+
+    args, defaults = tuple(spec.args), spec.defaults
+    if defaults:
+        index = -len(defaults)
+        args, defaults = args[:index], tuple(args[index:])
+    else:
+        defaults = ()
+
+    # strip any implicit instance arg
+    if args:
+        if inspect.ismethod(func) or (
+            "." in getattr(func, "__qualname__", ()) and args[0] == "self"
+        ):
+            args = args[1:]
+
+    assert "self" not in args  # best naming practises check?
+    try:
+        cache["_varnames"] = args, defaults
+    except TypeError:
+        pass
+    return args, defaults
+
+
+class _HookRelay(object):
+    """ hook holder object for performing 1:N hook calls where N is the number
+    of registered plugins.
+
+    """
+
+    def __init__(self, trace):
+        self._trace = trace
+
+
+class _HookCaller(object):
+    def __init__(self, name, hook_execute, specmodule_or_class=None, spec_opts=None):
+        self.name = name
+        self._wrappers = []
+        self._nonwrappers = []
+        self._hookexec = hook_execute
+        self.argnames = None
+        self.kwargnames = None
+        self.multicall = _multicall
+        self.spec = None
+        if specmodule_or_class is not None:
+            assert spec_opts is not None
+            self.set_specification(specmodule_or_class, spec_opts)
+
+    def has_spec(self):
+        return self.spec is not None
+
+    def set_specification(self, specmodule_or_class, spec_opts):
+        assert not self.has_spec()
+        self.spec = HookSpec(specmodule_or_class, self.name, spec_opts)
+        if spec_opts.get("historic"):
+            self._call_history = []
+
+    def is_historic(self):
+        return hasattr(self, "_call_history")
+
+    def _remove_plugin(self, plugin):
+        def remove(wrappers):
+            for i, method in enumerate(wrappers):
+                if method.plugin == plugin:
+                    del wrappers[i]
+                    return True
+
+        if remove(self._wrappers) is None:
+            if remove(self._nonwrappers) is None:
+                raise ValueError("plugin %r not found" % (plugin,))
+
+    def get_hookimpls(self):
+        # Order is important for _hookexec
+        return self._nonwrappers + self._wrappers
+
+    def _add_hookimpl(self, hookimpl):
+        """Add an implementation to the callback chain.
+        """
+        if hookimpl.hookwrapper:
+            methods = self._wrappers
+        else:
+            methods = self._nonwrappers
+
+        if hookimpl.trylast:
+            methods.insert(0, hookimpl)
+        elif hookimpl.tryfirst:
+            methods.append(hookimpl)
+        else:
+            # find last non-tryfirst method
+            i = len(methods) - 1
+            while i >= 0 and methods[i].tryfirst:
+                i -= 1
+            methods.insert(i + 1, hookimpl)
+
+        if "__multicall__" in hookimpl.argnames:
+            warnings.warn(
+                "Support for __multicall__ is now deprecated and will be"
+                "removed in an upcoming release.",
+                DeprecationWarning,
+            )
+            self.multicall = _legacymulticall
+
+    def __repr__(self):
+        return "<_HookCaller %r>" % (self.name,)
+
+    def __call__(self, *args, **kwargs):
+        if args:
+            raise TypeError("hook calling supports only keyword arguments")
+        assert not self.is_historic()
+        if self.spec and self.spec.argnames:
+            notincall = (
+                set(self.spec.argnames) - set(["__multicall__"]) - set(kwargs.keys())
+            )
+            if notincall:
+                warnings.warn(
+                    "Argument(s) {} which are declared in the hookspec "
+                    "can not be found in this hook call".format(tuple(notincall)),
+                    stacklevel=2,
+                )
+        return self._hookexec(self, self.get_hookimpls(), kwargs)
+
+    def call_historic(self, result_callback=None, kwargs=None, proc=None):
+        """Call the hook with given ``kwargs`` for all registered plugins and
+        for all plugins which will be registered afterwards.
+
+        If ``result_callback`` is not ``None`` it will be called for for each
+        non-None result obtained from a hook implementation.
+
+        .. note::
+            The ``proc`` argument is now deprecated.
+        """
+        if proc is not None:
+            warnings.warn(
+                "Support for `proc` argument is now deprecated and will be"
+                "removed in an upcoming release.",
+                DeprecationWarning,
+            )
+            result_callback = proc
+
+        self._call_history.append((kwargs or {}, result_callback))
+        # historizing hooks don't return results
+        res = self._hookexec(self, self.get_hookimpls(), kwargs)
+        if result_callback is None:
+            return
+        # XXX: remember firstresult isn't compat with historic
+        for x in res or []:
+            result_callback(x)
+
+    def call_extra(self, methods, kwargs):
+        """ Call the hook with some additional temporarily participating
+        methods using the specified kwargs as call parameters. """
+        old = list(self._nonwrappers), list(self._wrappers)
+        for method in methods:
+            opts = dict(hookwrapper=False, trylast=False, tryfirst=False)
+            hookimpl = HookImpl(None, "<temp>", method, opts)
+            self._add_hookimpl(hookimpl)
+        try:
+            return self(**kwargs)
+        finally:
+            self._nonwrappers, self._wrappers = old
+
+    def _maybe_apply_history(self, method):
+        """Apply call history to a new hookimpl if it is marked as historic.
+        """
+        if self.is_historic():
+            for kwargs, result_callback in self._call_history:
+                res = self._hookexec(self, [method], kwargs)
+                if res and result_callback is not None:
+                    result_callback(res[0])
+
+
+class HookImpl(object):
+    def __init__(self, plugin, plugin_name, function, hook_impl_opts):
+        self.function = function
+        self.argnames, self.kwargnames = varnames(self.function)
+        self.plugin = plugin
+        self.opts = hook_impl_opts
+        self.plugin_name = plugin_name
+        self.__dict__.update(hook_impl_opts)
+
+    def __repr__(self):
+        return "<HookImpl plugin_name=%r, plugin=%r>" % (self.plugin_name, self.plugin)
+
+
+class HookSpec(object):
+    def __init__(self, namespace, name, opts):
+        self.namespace = namespace
+        self.function = function = getattr(namespace, name)
+        self.name = name
+        self.argnames, self.kwargnames = varnames(function)
+        self.opts = opts
+        self.argnames = ["__multicall__"] + list(self.argnames)
+        self.warn_on_impl = opts.get("warn_on_impl")
Index: venv/Lib/site-packages/pluggy/callers.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy/callers.py	(date 1543190976188)
+++ venv/Lib/site-packages/pluggy/callers.py	(date 1543190976188)
@@ -0,0 +1,208 @@
+"""
+Call loop machinery
+"""
+import sys
+import warnings
+
+_py3 = sys.version_info > (3, 0)
+
+
+if not _py3:
+    exec(
+        """
+def _reraise(cls, val, tb):
+    raise cls, val, tb
+"""
+    )
+
+
+def _raise_wrapfail(wrap_controller, msg):
+    co = wrap_controller.gi_code
+    raise RuntimeError(
+        "wrap_controller at %r %s:%d %s"
+        % (co.co_name, co.co_filename, co.co_firstlineno, msg)
+    )
+
+
+class HookCallError(Exception):
+    """ Hook was called wrongly. """
+
+
+class _Result(object):
+    def __init__(self, result, excinfo):
+        self._result = result
+        self._excinfo = excinfo
+
+    @property
+    def excinfo(self):
+        return self._excinfo
+
+    @property
+    def result(self):
+        """Get the result(s) for this hook call (DEPRECATED in favor of ``get_result()``)."""
+        msg = "Use get_result() which forces correct exception handling"
+        warnings.warn(DeprecationWarning(msg), stacklevel=2)
+        return self._result
+
+    @classmethod
+    def from_call(cls, func):
+        __tracebackhide__ = True
+        result = excinfo = None
+        try:
+            result = func()
+        except BaseException:
+            excinfo = sys.exc_info()
+
+        return cls(result, excinfo)
+
+    def force_result(self, result):
+        """Force the result(s) to ``result``.
+
+        If the hook was marked as a ``firstresult`` a single value should
+        be set otherwise set a (modified) list of results. Any exceptions
+        found during invocation will be deleted.
+        """
+        self._result = result
+        self._excinfo = None
+
+    def get_result(self):
+        """Get the result(s) for this hook call.
+
+        If the hook was marked as a ``firstresult`` only a single value
+        will be returned otherwise a list of results.
+        """
+        __tracebackhide__ = True
+        if self._excinfo is None:
+            return self._result
+        else:
+            ex = self._excinfo
+            if _py3:
+                raise ex[1].with_traceback(ex[2])
+            _reraise(*ex)  # noqa
+
+
+def _wrapped_call(wrap_controller, func):
+    """ Wrap calling to a function with a generator which needs to yield
+    exactly once.  The yield point will trigger calling the wrapped function
+    and return its ``_Result`` to the yield point.  The generator then needs
+    to finish (raise StopIteration) in order for the wrapped call to complete.
+    """
+    try:
+        next(wrap_controller)  # first yield
+    except StopIteration:
+        _raise_wrapfail(wrap_controller, "did not yield")
+    call_outcome = _Result.from_call(func)
+    try:
+        wrap_controller.send(call_outcome)
+        _raise_wrapfail(wrap_controller, "has second yield")
+    except StopIteration:
+        pass
+    return call_outcome.get_result()
+
+
+class _LegacyMultiCall(object):
+    """ execute a call into multiple python functions/methods. """
+
+    # XXX note that the __multicall__ argument is supported only
+    # for pytest compatibility reasons.  It was never officially
+    # supported there and is explicitely deprecated since 2.8
+    # so we can remove it soon, allowing to avoid the below recursion
+    # in execute() and simplify/speed up the execute loop.
+
+    def __init__(self, hook_impls, kwargs, firstresult=False):
+        self.hook_impls = hook_impls
+        self.caller_kwargs = kwargs  # come from _HookCaller.__call__()
+        self.caller_kwargs["__multicall__"] = self
+        self.firstresult = firstresult
+
+    def execute(self):
+        caller_kwargs = self.caller_kwargs
+        self.results = results = []
+        firstresult = self.firstresult
+
+        while self.hook_impls:
+            hook_impl = self.hook_impls.pop()
+            try:
+                args = [caller_kwargs[argname] for argname in hook_impl.argnames]
+            except KeyError:
+                for argname in hook_impl.argnames:
+                    if argname not in caller_kwargs:
+                        raise HookCallError(
+                            "hook call must provide argument %r" % (argname,)
+                        )
+            if hook_impl.hookwrapper:
+                return _wrapped_call(hook_impl.function(*args), self.execute)
+            res = hook_impl.function(*args)
+            if res is not None:
+                if firstresult:
+                    return res
+                results.append(res)
+
+        if not firstresult:
+            return results
+
+    def __repr__(self):
+        status = "%d meths" % (len(self.hook_impls),)
+        if hasattr(self, "results"):
+            status = ("%d results, " % len(self.results)) + status
+        return "<_MultiCall %s, kwargs=%r>" % (status, self.caller_kwargs)
+
+
+def _legacymulticall(hook_impls, caller_kwargs, firstresult=False):
+    return _LegacyMultiCall(
+        hook_impls, caller_kwargs, firstresult=firstresult
+    ).execute()
+
+
+def _multicall(hook_impls, caller_kwargs, firstresult=False):
+    """Execute a call into multiple python functions/methods and return the
+    result(s).
+
+    ``caller_kwargs`` comes from _HookCaller.__call__().
+    """
+    __tracebackhide__ = True
+    results = []
+    excinfo = None
+    try:  # run impl and wrapper setup functions in a loop
+        teardowns = []
+        try:
+            for hook_impl in reversed(hook_impls):
+                try:
+                    args = [caller_kwargs[argname] for argname in hook_impl.argnames]
+                except KeyError:
+                    for argname in hook_impl.argnames:
+                        if argname not in caller_kwargs:
+                            raise HookCallError(
+                                "hook call must provide argument %r" % (argname,)
+                            )
+
+                if hook_impl.hookwrapper:
+                    try:
+                        gen = hook_impl.function(*args)
+                        next(gen)  # first yield
+                        teardowns.append(gen)
+                    except StopIteration:
+                        _raise_wrapfail(gen, "did not yield")
+                else:
+                    res = hook_impl.function(*args)
+                    if res is not None:
+                        results.append(res)
+                        if firstresult:  # halt further impl calls
+                            break
+        except BaseException:
+            excinfo = sys.exc_info()
+    finally:
+        if firstresult:  # first result hooks return a single value
+            outcome = _Result(results[0] if results else None, excinfo)
+        else:
+            outcome = _Result(results, excinfo)
+
+        # run all wrapper post-yield blocks
+        for gen in reversed(teardowns):
+            try:
+                gen.send(outcome)
+                _raise_wrapfail(gen, "has second yield")
+            except StopIteration:
+                pass
+
+        return outcome.get_result()
Index: venv/Lib/site-packages/pluggy/_tracing.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy/_tracing.py	(date 1543190976199)
+++ venv/Lib/site-packages/pluggy/_tracing.py	(date 1543190976199)
@@ -0,0 +1,83 @@
+"""
+Tracing utils
+"""
+from .callers import _Result
+
+
+class TagTracer(object):
+    def __init__(self):
+        self._tag2proc = {}
+        self.writer = None
+        self.indent = 0
+
+    def get(self, name):
+        return TagTracerSub(self, (name,))
+
+    def format_message(self, tags, args):
+        if isinstance(args[-1], dict):
+            extra = args[-1]
+            args = args[:-1]
+        else:
+            extra = {}
+
+        content = " ".join(map(str, args))
+        indent = "  " * self.indent
+
+        lines = ["%s%s [%s]\n" % (indent, content, ":".join(tags))]
+
+        for name, value in extra.items():
+            lines.append("%s    %s: %s\n" % (indent, name, value))
+        return lines
+
+    def processmessage(self, tags, args):
+        if self.writer is not None and args:
+            lines = self.format_message(tags, args)
+            self.writer("".join(lines))
+        try:
+            self._tag2proc[tags](tags, args)
+        except KeyError:
+            pass
+
+    def setwriter(self, writer):
+        self.writer = writer
+
+    def setprocessor(self, tags, processor):
+        if isinstance(tags, str):
+            tags = tuple(tags.split(":"))
+        else:
+            assert isinstance(tags, tuple)
+        self._tag2proc[tags] = processor
+
+
+class TagTracerSub(object):
+    def __init__(self, root, tags):
+        self.root = root
+        self.tags = tags
+
+    def __call__(self, *args):
+        self.root.processmessage(self.tags, args)
+
+    def setmyprocessor(self, processor):
+        self.root.setprocessor(self.tags, processor)
+
+    def get(self, name):
+        return self.__class__(self.root, self.tags + (name,))
+
+
+class _TracedHookExecution(object):
+    def __init__(self, pluginmanager, before, after):
+        self.pluginmanager = pluginmanager
+        self.before = before
+        self.after = after
+        self.oldcall = pluginmanager._inner_hookexec
+        assert not isinstance(self.oldcall, _TracedHookExecution)
+        self.pluginmanager._inner_hookexec = self
+
+    def __call__(self, hook, hook_impls, kwargs):
+        self.before(hook.name, hook_impls, kwargs)
+        outcome = _Result.from_call(lambda: self.oldcall(hook, hook_impls, kwargs))
+        self.after(outcome, hook.name, hook_impls, kwargs)
+        return outcome.get_result()
+
+    def undo(self):
+        self.pluginmanager._inner_hookexec = self.oldcall
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/METADATA	(date 1543190976211)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/METADATA	(date 1543190976211)
@@ -0,0 +1,376 @@
+Metadata-Version: 2.0
+Name: colorama
+Version: 0.4.0
+Summary: Cross-platform colored terminal text.
+Home-page: https://github.com/tartley/colorama
+Author: Jonathan Hartley
+Author-email: tartley@tartley.com
+Maintainer: Arnon Yaari
+License: BSD
+Keywords: color colour terminal text ansi windows crossplatform xplatform
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Environment :: Console
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: BSD License
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Topic :: Terminals
+Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*
+
+.. image:: https://img.shields.io/pypi/v/colorama.svg
+    :target: https://pypi.org/project/colorama/
+    :alt: Latest Version
+
+.. image:: https://img.shields.io/pypi/pyversions/colorama.svg
+    :target: https://pypi.org/project/colorama/
+    :alt: Supported Python versions
+
+.. image:: https://travis-ci.org/tartley/colorama.svg?branch=master
+    :target: https://travis-ci.org/tartley/colorama
+    :alt: Build Status
+
+Download and docs:
+    https://pypi.org/project/colorama/
+Source code & Development:
+    https://github.com/tartley/colorama
+
+Description
+===========
+
+Makes ANSI escape character sequences (for producing colored terminal text and
+cursor positioning) work under MS Windows.
+
+ANSI escape character sequences have long been used to produce colored terminal
+text and cursor positioning on Unix and Macs. Colorama makes this work on
+Windows, too, by wrapping ``stdout``, stripping ANSI sequences it finds (which
+would appear as gobbledygook in the output), and converting them into the
+appropriate win32 calls to modify the state of the terminal. On other platforms,
+Colorama does nothing.
+
+Colorama also provides some shortcuts to help generate ANSI sequences
+but works fine in conjunction with any other ANSI sequence generation library,
+such as the venerable Termcolor (https://pypi.org/project/termcolor/)
+or the fabulous Blessings (https://pypi.org/project/blessings/).
+
+This has the upshot of providing a simple cross-platform API for printing
+colored terminal text from Python, and has the happy side-effect that existing
+applications or libraries which use ANSI sequences to produce colored output on
+Linux or Macs can now also work on Windows, simply by calling
+``colorama.init()``.
+
+An alternative approach is to install ``ansi.sys`` on Windows machines, which
+provides the same behaviour for all applications running in terminals. Colorama
+is intended for situations where that isn't easy (e.g., maybe your app doesn't
+have an installer.)
+
+Demo scripts in the source code repository print some colored text using
+ANSI sequences. Compare their output under Gnome-terminal's built in ANSI
+handling, versus on Windows Command-Prompt using Colorama:
+
+.. image:: https://github.com/tartley/colorama/raw/master/screenshots/ubuntu-demo.png
+    :width: 661
+    :height: 357
+    :alt: ANSI sequences on Ubuntu under gnome-terminal.
+
+.. image:: https://github.com/tartley/colorama/raw/master/screenshots/windows-demo.png
+    :width: 668
+    :height: 325
+    :alt: Same ANSI sequences on Windows, using Colorama.
+
+These screengrabs show that, on Windows, Colorama does not support ANSI 'dim
+text'; it looks the same as 'normal text'.
+
+
+License
+=======
+
+Copyright Jonathan Hartley 2013. BSD 3-Clause license; see LICENSE file.
+
+
+Dependencies
+============
+
+None, other than Python. Tested on Python 2.7, 3.4, 3.5 and 3.6.
+
+Usage
+=====
+
+Initialisation
+--------------
+
+Applications should initialise Colorama using:
+
+.. code-block:: python
+
+    from colorama import init
+    init()
+
+On Windows, calling ``init()`` will filter ANSI escape sequences out of any
+text sent to ``stdout`` or ``stderr``, and replace them with equivalent Win32
+calls.
+
+On other platforms, calling ``init()`` has no effect (unless you request other
+optional functionality; see "Init Keyword Args", below). By design, this permits
+applications to call ``init()`` unconditionally on all platforms, after which
+ANSI output should just work.
+
+To stop using colorama before your program exits, simply call ``deinit()``.
+This will restore ``stdout`` and ``stderr`` to their original values, so that
+Colorama is disabled. To resume using Colorama again, call ``reinit()``; it is
+cheaper to calling ``init()`` again (but does the same thing).
+
+
+Colored Output
+--------------
+
+Cross-platform printing of colored text can then be done using Colorama's
+constant shorthand for ANSI escape sequences:
+
+.. code-block:: python
+
+    from colorama import Fore, Back, Style
+    print(Fore.RED + 'some red text')
+    print(Back.GREEN + 'and with a green background')
+    print(Style.DIM + 'and in dim text')
+    print(Style.RESET_ALL)
+    print('back to normal now')
+
+...or simply by manually printing ANSI sequences from your own code:
+
+.. code-block:: python
+
+    print('\033[31m' + 'some red text')
+    print('\033[30m') # and reset to default color
+
+...or, Colorama can be used happily in conjunction with existing ANSI libraries
+such as Termcolor:
+
+.. code-block:: python
+
+    from colorama import init
+    from termcolor import colored
+
+    # use Colorama to make Termcolor work on Windows too
+    init()
+
+    # then use Termcolor for all colored text output
+    print(colored('Hello, World!', 'green', 'on_red'))
+
+Available formatting constants are::
+
+    Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
+    Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
+    Style: DIM, NORMAL, BRIGHT, RESET_ALL
+
+``Style.RESET_ALL`` resets foreground, background, and brightness. Colorama will
+perform this reset automatically on program exit.
+
+
+Cursor Positioning
+------------------
+
+ANSI codes to reposition the cursor are supported. See ``demos/demo06.py`` for
+an example of how to generate them.
+
+
+Init Keyword Args
+-----------------
+
+``init()`` accepts some ``**kwargs`` to override default behaviour.
+
+init(autoreset=False):
+    If you find yourself repeatedly sending reset sequences to turn off color
+    changes at the end of every print, then ``init(autoreset=True)`` will
+    automate that:
+
+    .. code-block:: python
+
+        from colorama import init
+        init(autoreset=True)
+        print(Fore.RED + 'some red text')
+        print('automatically back to default color again')
+
+init(strip=None):
+    Pass ``True`` or ``False`` to override whether ansi codes should be
+    stripped from the output. The default behaviour is to strip if on Windows
+    or if output is redirected (not a tty).
+
+init(convert=None):
+    Pass ``True`` or ``False`` to override whether to convert ANSI codes in the
+    output into win32 calls. The default behaviour is to convert if on Windows
+    and output is to a tty (terminal).
+
+init(wrap=True):
+    On Windows, colorama works by replacing ``sys.stdout`` and ``sys.stderr``
+    with proxy objects, which override the ``.write()`` method to do their work.
+    If this wrapping causes you problems, then this can be disabled by passing
+    ``init(wrap=False)``. The default behaviour is to wrap if ``autoreset`` or
+    ``strip`` or ``convert`` are True.
+
+    When wrapping is disabled, colored printing on non-Windows platforms will
+    continue to work as normal. To do cross-platform colored output, you can
+    use Colorama's ``AnsiToWin32`` proxy directly:
+
+    .. code-block:: python
+
+        import sys
+        from colorama import init, AnsiToWin32
+        init(wrap=False)
+        stream = AnsiToWin32(sys.stderr).stream
+
+        # Python 2
+        print >>stream, Fore.BLUE + 'blue text on stderr'
+
+        # Python 3
+        print(Fore.BLUE + 'blue text on stderr', file=stream)
+
+
+Status & Known Problems
+=======================
+
+I've personally only tested it on Windows XP (CMD, Console2), Ubuntu
+(gnome-terminal, xterm), and OS X.
+
+Some presumably valid ANSI sequences aren't recognised (see details below),
+but to my knowledge nobody has yet complained about this. Puzzling.
+
+See outstanding issues and wishlist:
+https://github.com/tartley/colorama/issues
+
+If anything doesn't work for you, or doesn't do what you expected or hoped for,
+I'd love to hear about it on that issues list, would be delighted by patches,
+and would be happy to grant commit access to anyone who submits a working patch
+or two.
+
+
+Recognised ANSI Sequences
+=========================
+
+ANSI sequences generally take the form:
+
+    ESC [ <param> ; <param> ... <command>
+
+Where ``<param>`` is an integer, and ``<command>`` is a single letter. Zero or
+more params are passed to a ``<command>``. If no params are passed, it is
+generally synonymous with passing a single zero. No spaces exist in the
+sequence; they have been inserted here simply to read more easily.
+
+The only ANSI sequences that colorama converts into win32 calls are::
+
+    ESC [ 0 m       # reset all (colors and brightness)
+    ESC [ 1 m       # bright
+    ESC [ 2 m       # dim (looks same as normal brightness)
+    ESC [ 22 m      # normal brightness
+
+    # FOREGROUND:
+    ESC [ 30 m      # black
+    ESC [ 31 m      # red
+    ESC [ 32 m      # green
+    ESC [ 33 m      # yellow
+    ESC [ 34 m      # blue
+    ESC [ 35 m      # magenta
+    ESC [ 36 m      # cyan
+    ESC [ 37 m      # white
+    ESC [ 39 m      # reset
+
+    # BACKGROUND
+    ESC [ 40 m      # black
+    ESC [ 41 m      # red
+    ESC [ 42 m      # green
+    ESC [ 43 m      # yellow
+    ESC [ 44 m      # blue
+    ESC [ 45 m      # magenta
+    ESC [ 46 m      # cyan
+    ESC [ 47 m      # white
+    ESC [ 49 m      # reset
+
+    # cursor positioning
+    ESC [ y;x H     # position cursor at x across, y down
+    ESC [ y;x f     # position cursor at x across, y down
+    ESC [ n A       # move cursor n lines up
+    ESC [ n B       # move cursor n lines down
+    ESC [ n C       # move cursor n characters forward
+    ESC [ n D       # move cursor n characters backward
+
+    # clear the screen
+    ESC [ mode J    # clear the screen
+
+    # clear the line
+    ESC [ mode K    # clear the line
+
+Multiple numeric params to the ``'m'`` command can be combined into a single
+sequence::
+
+    ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background
+
+All other ANSI sequences of the form ``ESC [ <param> ; <param> ... <command>``
+are silently stripped from the output on Windows.
+
+Any other form of ANSI sequence, such as single-character codes or alternative
+initial characters, are not recognised or stripped. It would be cool to add
+them though. Let me know if it would be useful for you, via the Issues on
+GitHub.
+
+
+Development
+===========
+
+Help and fixes welcome!
+
+Running tests requires:
+
+- Michael Foord's ``mock`` module to be installed.
+- Tests are written using 2010-era updates to ``unittest``
+
+To run tests::
+
+   python -m unittest discover -p *_test.py
+
+This, like a few other handy commands, is captured in a ``Makefile``.
+
+If you use nose to run the tests, you must pass the ``-s`` flag; otherwise,
+``nosetests`` applies its own proxy to ``stdout``, which confuses the unit
+tests.
+
+
+Thanks
+======
+* Marc Schlaich (schlamar) for a ``setup.py`` fix for Python2.5.
+* Marc Abramowitz, reported & fixed a crash on exit with closed ``stdout``,
+  providing a solution to issue #7's setuptools/distutils debate,
+  and other fixes.
+* User 'eryksun', for guidance on correctly instantiating ``ctypes.windll``.
+* Matthew McCormick for politely pointing out a longstanding crash on non-Win.
+* Ben Hoyt, for a magnificent fix under 64-bit Windows.
+* Jesse at Empty Square for submitting a fix for examples in the README.
+* User 'jamessp', an observant documentation fix for cursor positioning.
+* User 'vaal1239', Dave Mckee & Lackner Kristof for a tiny but much-needed Win7
+  fix.
+* Julien Stuyck, for wisely suggesting Python3 compatible updates to README.
+* Daniel Griffith for multiple fabulous patches.
+* Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty
+  output.
+* Roger Binns, for many suggestions, valuable feedback, & bug reports.
+* Tim Golden for thought and much appreciated feedback on the initial idea.
+* User 'Zearin' for updates to the README file.
+* John Szakmeister for adding support for light colors
+* Charles Merriam for adding documentation to demos
+* Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes
+* Florian Bruhin for a fix when stdout or stderr are None
+* Thomas Weininger for fixing ValueError on Windows
+* Remi Rampin for better Github integration and fixes to the README file
+* Simeon Visser for closing a file handle using 'with' and updating classifiers
+  to include Python 3.3 and 3.4
+* Andy Neff for fixing RESET of LIGHT_EX colors.
+* Jonathan Hartley for the initial idea and implementation.
+
+
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/INSTALLER	(date 1543190976221)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/INSTALLER	(date 1543190976221)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/DESCRIPTION.rst
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/DESCRIPTION.rst	(date 1543190976234)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/DESCRIPTION.rst	(date 1543190976234)
@@ -0,0 +1,348 @@
+.. image:: https://img.shields.io/pypi/v/colorama.svg
+    :target: https://pypi.org/project/colorama/
+    :alt: Latest Version
+
+.. image:: https://img.shields.io/pypi/pyversions/colorama.svg
+    :target: https://pypi.org/project/colorama/
+    :alt: Supported Python versions
+
+.. image:: https://travis-ci.org/tartley/colorama.svg?branch=master
+    :target: https://travis-ci.org/tartley/colorama
+    :alt: Build Status
+
+Download and docs:
+    https://pypi.org/project/colorama/
+Source code & Development:
+    https://github.com/tartley/colorama
+
+Description
+===========
+
+Makes ANSI escape character sequences (for producing colored terminal text and
+cursor positioning) work under MS Windows.
+
+ANSI escape character sequences have long been used to produce colored terminal
+text and cursor positioning on Unix and Macs. Colorama makes this work on
+Windows, too, by wrapping ``stdout``, stripping ANSI sequences it finds (which
+would appear as gobbledygook in the output), and converting them into the
+appropriate win32 calls to modify the state of the terminal. On other platforms,
+Colorama does nothing.
+
+Colorama also provides some shortcuts to help generate ANSI sequences
+but works fine in conjunction with any other ANSI sequence generation library,
+such as the venerable Termcolor (https://pypi.org/project/termcolor/)
+or the fabulous Blessings (https://pypi.org/project/blessings/).
+
+This has the upshot of providing a simple cross-platform API for printing
+colored terminal text from Python, and has the happy side-effect that existing
+applications or libraries which use ANSI sequences to produce colored output on
+Linux or Macs can now also work on Windows, simply by calling
+``colorama.init()``.
+
+An alternative approach is to install ``ansi.sys`` on Windows machines, which
+provides the same behaviour for all applications running in terminals. Colorama
+is intended for situations where that isn't easy (e.g., maybe your app doesn't
+have an installer.)
+
+Demo scripts in the source code repository print some colored text using
+ANSI sequences. Compare their output under Gnome-terminal's built in ANSI
+handling, versus on Windows Command-Prompt using Colorama:
+
+.. image:: https://github.com/tartley/colorama/raw/master/screenshots/ubuntu-demo.png
+    :width: 661
+    :height: 357
+    :alt: ANSI sequences on Ubuntu under gnome-terminal.
+
+.. image:: https://github.com/tartley/colorama/raw/master/screenshots/windows-demo.png
+    :width: 668
+    :height: 325
+    :alt: Same ANSI sequences on Windows, using Colorama.
+
+These screengrabs show that, on Windows, Colorama does not support ANSI 'dim
+text'; it looks the same as 'normal text'.
+
+
+License
+=======
+
+Copyright Jonathan Hartley 2013. BSD 3-Clause license; see LICENSE file.
+
+
+Dependencies
+============
+
+None, other than Python. Tested on Python 2.7, 3.4, 3.5 and 3.6.
+
+Usage
+=====
+
+Initialisation
+--------------
+
+Applications should initialise Colorama using:
+
+.. code-block:: python
+
+    from colorama import init
+    init()
+
+On Windows, calling ``init()`` will filter ANSI escape sequences out of any
+text sent to ``stdout`` or ``stderr``, and replace them with equivalent Win32
+calls.
+
+On other platforms, calling ``init()`` has no effect (unless you request other
+optional functionality; see "Init Keyword Args", below). By design, this permits
+applications to call ``init()`` unconditionally on all platforms, after which
+ANSI output should just work.
+
+To stop using colorama before your program exits, simply call ``deinit()``.
+This will restore ``stdout`` and ``stderr`` to their original values, so that
+Colorama is disabled. To resume using Colorama again, call ``reinit()``; it is
+cheaper to calling ``init()`` again (but does the same thing).
+
+
+Colored Output
+--------------
+
+Cross-platform printing of colored text can then be done using Colorama's
+constant shorthand for ANSI escape sequences:
+
+.. code-block:: python
+
+    from colorama import Fore, Back, Style
+    print(Fore.RED + 'some red text')
+    print(Back.GREEN + 'and with a green background')
+    print(Style.DIM + 'and in dim text')
+    print(Style.RESET_ALL)
+    print('back to normal now')
+
+...or simply by manually printing ANSI sequences from your own code:
+
+.. code-block:: python
+
+    print('\033[31m' + 'some red text')
+    print('\033[30m') # and reset to default color
+
+...or, Colorama can be used happily in conjunction with existing ANSI libraries
+such as Termcolor:
+
+.. code-block:: python
+
+    from colorama import init
+    from termcolor import colored
+
+    # use Colorama to make Termcolor work on Windows too
+    init()
+
+    # then use Termcolor for all colored text output
+    print(colored('Hello, World!', 'green', 'on_red'))
+
+Available formatting constants are::
+
+    Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
+    Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
+    Style: DIM, NORMAL, BRIGHT, RESET_ALL
+
+``Style.RESET_ALL`` resets foreground, background, and brightness. Colorama will
+perform this reset automatically on program exit.
+
+
+Cursor Positioning
+------------------
+
+ANSI codes to reposition the cursor are supported. See ``demos/demo06.py`` for
+an example of how to generate them.
+
+
+Init Keyword Args
+-----------------
+
+``init()`` accepts some ``**kwargs`` to override default behaviour.
+
+init(autoreset=False):
+    If you find yourself repeatedly sending reset sequences to turn off color
+    changes at the end of every print, then ``init(autoreset=True)`` will
+    automate that:
+
+    .. code-block:: python
+
+        from colorama import init
+        init(autoreset=True)
+        print(Fore.RED + 'some red text')
+        print('automatically back to default color again')
+
+init(strip=None):
+    Pass ``True`` or ``False`` to override whether ansi codes should be
+    stripped from the output. The default behaviour is to strip if on Windows
+    or if output is redirected (not a tty).
+
+init(convert=None):
+    Pass ``True`` or ``False`` to override whether to convert ANSI codes in the
+    output into win32 calls. The default behaviour is to convert if on Windows
+    and output is to a tty (terminal).
+
+init(wrap=True):
+    On Windows, colorama works by replacing ``sys.stdout`` and ``sys.stderr``
+    with proxy objects, which override the ``.write()`` method to do their work.
+    If this wrapping causes you problems, then this can be disabled by passing
+    ``init(wrap=False)``. The default behaviour is to wrap if ``autoreset`` or
+    ``strip`` or ``convert`` are True.
+
+    When wrapping is disabled, colored printing on non-Windows platforms will
+    continue to work as normal. To do cross-platform colored output, you can
+    use Colorama's ``AnsiToWin32`` proxy directly:
+
+    .. code-block:: python
+
+        import sys
+        from colorama import init, AnsiToWin32
+        init(wrap=False)
+        stream = AnsiToWin32(sys.stderr).stream
+
+        # Python 2
+        print >>stream, Fore.BLUE + 'blue text on stderr'
+
+        # Python 3
+        print(Fore.BLUE + 'blue text on stderr', file=stream)
+
+
+Status & Known Problems
+=======================
+
+I've personally only tested it on Windows XP (CMD, Console2), Ubuntu
+(gnome-terminal, xterm), and OS X.
+
+Some presumably valid ANSI sequences aren't recognised (see details below),
+but to my knowledge nobody has yet complained about this. Puzzling.
+
+See outstanding issues and wishlist:
+https://github.com/tartley/colorama/issues
+
+If anything doesn't work for you, or doesn't do what you expected or hoped for,
+I'd love to hear about it on that issues list, would be delighted by patches,
+and would be happy to grant commit access to anyone who submits a working patch
+or two.
+
+
+Recognised ANSI Sequences
+=========================
+
+ANSI sequences generally take the form:
+
+    ESC [ <param> ; <param> ... <command>
+
+Where ``<param>`` is an integer, and ``<command>`` is a single letter. Zero or
+more params are passed to a ``<command>``. If no params are passed, it is
+generally synonymous with passing a single zero. No spaces exist in the
+sequence; they have been inserted here simply to read more easily.
+
+The only ANSI sequences that colorama converts into win32 calls are::
+
+    ESC [ 0 m       # reset all (colors and brightness)
+    ESC [ 1 m       # bright
+    ESC [ 2 m       # dim (looks same as normal brightness)
+    ESC [ 22 m      # normal brightness
+
+    # FOREGROUND:
+    ESC [ 30 m      # black
+    ESC [ 31 m      # red
+    ESC [ 32 m      # green
+    ESC [ 33 m      # yellow
+    ESC [ 34 m      # blue
+    ESC [ 35 m      # magenta
+    ESC [ 36 m      # cyan
+    ESC [ 37 m      # white
+    ESC [ 39 m      # reset
+
+    # BACKGROUND
+    ESC [ 40 m      # black
+    ESC [ 41 m      # red
+    ESC [ 42 m      # green
+    ESC [ 43 m      # yellow
+    ESC [ 44 m      # blue
+    ESC [ 45 m      # magenta
+    ESC [ 46 m      # cyan
+    ESC [ 47 m      # white
+    ESC [ 49 m      # reset
+
+    # cursor positioning
+    ESC [ y;x H     # position cursor at x across, y down
+    ESC [ y;x f     # position cursor at x across, y down
+    ESC [ n A       # move cursor n lines up
+    ESC [ n B       # move cursor n lines down
+    ESC [ n C       # move cursor n characters forward
+    ESC [ n D       # move cursor n characters backward
+
+    # clear the screen
+    ESC [ mode J    # clear the screen
+
+    # clear the line
+    ESC [ mode K    # clear the line
+
+Multiple numeric params to the ``'m'`` command can be combined into a single
+sequence::
+
+    ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background
+
+All other ANSI sequences of the form ``ESC [ <param> ; <param> ... <command>``
+are silently stripped from the output on Windows.
+
+Any other form of ANSI sequence, such as single-character codes or alternative
+initial characters, are not recognised or stripped. It would be cool to add
+them though. Let me know if it would be useful for you, via the Issues on
+GitHub.
+
+
+Development
+===========
+
+Help and fixes welcome!
+
+Running tests requires:
+
+- Michael Foord's ``mock`` module to be installed.
+- Tests are written using 2010-era updates to ``unittest``
+
+To run tests::
+
+   python -m unittest discover -p *_test.py
+
+This, like a few other handy commands, is captured in a ``Makefile``.
+
+If you use nose to run the tests, you must pass the ``-s`` flag; otherwise,
+``nosetests`` applies its own proxy to ``stdout``, which confuses the unit
+tests.
+
+
+Thanks
+======
+* Marc Schlaich (schlamar) for a ``setup.py`` fix for Python2.5.
+* Marc Abramowitz, reported & fixed a crash on exit with closed ``stdout``,
+  providing a solution to issue #7's setuptools/distutils debate,
+  and other fixes.
+* User 'eryksun', for guidance on correctly instantiating ``ctypes.windll``.
+* Matthew McCormick for politely pointing out a longstanding crash on non-Win.
+* Ben Hoyt, for a magnificent fix under 64-bit Windows.
+* Jesse at Empty Square for submitting a fix for examples in the README.
+* User 'jamessp', an observant documentation fix for cursor positioning.
+* User 'vaal1239', Dave Mckee & Lackner Kristof for a tiny but much-needed Win7
+  fix.
+* Julien Stuyck, for wisely suggesting Python3 compatible updates to README.
+* Daniel Griffith for multiple fabulous patches.
+* Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty
+  output.
+* Roger Binns, for many suggestions, valuable feedback, & bug reports.
+* Tim Golden for thought and much appreciated feedback on the initial idea.
+* User 'Zearin' for updates to the README file.
+* John Szakmeister for adding support for light colors
+* Charles Merriam for adding documentation to demos
+* Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes
+* Florian Bruhin for a fix when stdout or stderr are None
+* Thomas Weininger for fixing ValueError on Windows
+* Remi Rampin for better Github integration and fixes to the README file
+* Simeon Visser for closing a file handle using 'with' and updating classifiers
+  to include Python 3.3 and 3.4
+* Andy Neff for fixing RESET of LIGHT_EX colors.
+* Jonathan Hartley for the initial idea and implementation.
+
+
Index: venv/Lib/site-packages/_pytest/mark/legacy.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/mark/legacy.py	(date 1543190976245)
+++ venv/Lib/site-packages/_pytest/mark/legacy.py	(date 1543190976245)
@@ -0,0 +1,101 @@
+"""
+this is a place where we put datastructures used by legacy apis
+we hope ot remove
+"""
+import keyword
+
+import attr
+
+from _pytest.config import UsageError
+
+
+@attr.s
+class MarkMapping(object):
+    """Provides a local mapping for markers where item access
+    resolves to True if the marker is present. """
+
+    own_mark_names = attr.ib()
+
+    @classmethod
+    def from_item(cls, item):
+        mark_names = {mark.name for mark in item.iter_markers()}
+        return cls(mark_names)
+
+    def __getitem__(self, name):
+        return name in self.own_mark_names
+
+
+class KeywordMapping(object):
+    """Provides a local mapping for keywords.
+    Given a list of names, map any substring of one of these names to True.
+    """
+
+    def __init__(self, names):
+        self._names = names
+
+    @classmethod
+    def from_item(cls, item):
+        mapped_names = set()
+
+        # Add the names of the current item and any parent items
+        import pytest
+
+        for item in item.listchain():
+            if not isinstance(item, pytest.Instance):
+                mapped_names.add(item.name)
+
+        # Add the names added as extra keywords to current or parent items
+        for name in item.listextrakeywords():
+            mapped_names.add(name)
+
+        # Add the names attached to the current function through direct assignment
+        if hasattr(item, "function"):
+            for name in item.function.__dict__:
+                mapped_names.add(name)
+
+        return cls(mapped_names)
+
+    def __getitem__(self, subname):
+        for name in self._names:
+            if subname in name:
+                return True
+        return False
+
+
+python_keywords_allowed_list = ["or", "and", "not"]
+
+
+def matchmark(colitem, markexpr):
+    """Tries to match on any marker names, attached to the given colitem."""
+    try:
+        return eval(markexpr, {}, MarkMapping.from_item(colitem))
+    except SyntaxError as e:
+        raise SyntaxError(str(e) + "\nMarker expression must be valid Python!")
+
+
+def matchkeyword(colitem, keywordexpr):
+    """Tries to match given keyword expression to given collector item.
+
+    Will match on the name of colitem, including the names of its parents.
+    Only matches names of items which are either a :class:`Class` or a
+    :class:`Function`.
+    Additionally, matches on names in the 'extra_keyword_matches' set of
+    any item, as well as names directly assigned to test functions.
+    """
+    mapping = KeywordMapping.from_item(colitem)
+    if " " not in keywordexpr:
+        # special case to allow for simple "-k pass" and "-k 1.3"
+        return mapping[keywordexpr]
+    elif keywordexpr.startswith("not ") and " " not in keywordexpr[4:]:
+        return not mapping[keywordexpr[4:]]
+    for kwd in keywordexpr.split():
+        if keyword.iskeyword(kwd) and kwd not in python_keywords_allowed_list:
+            raise UsageError(
+                "Python keyword '{}' not accepted in expressions passed to '-k'".format(
+                    kwd
+                )
+            )
+    try:
+        return eval(keywordexpr, {}, mapping)
+    except SyntaxError:
+        raise UsageError("Wrong expression passed to '-k': {}".format(keywordexpr))
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/LICENSE.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/LICENSE.txt	(date 1543190976256)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/LICENSE.txt	(date 1543190976256)
@@ -0,0 +1,27 @@
+Copyright (c) 2010 Jonathan Hartley
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this
+  list of conditions and the following disclaimer.
+
+* Redistributions in binary form must reproduce the above copyright notice,
+  this list of conditions and the following disclaimer in the documentation
+  and/or other materials provided with the distribution.
+
+* Neither the name of the copyright holders, nor those of its contributors
+  may be used to endorse or promote products derived from this software without
+  specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
Index: venv/Lib/site-packages/_pytest/junitxml.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/junitxml.py	(date 1543190976269)
+++ venv/Lib/site-packages/_pytest/junitxml.py	(date 1543190976269)
@@ -0,0 +1,569 @@
+"""
+    report test results in JUnit-XML format,
+    for use with Jenkins and build integration servers.
+
+
+Based on initial code from Ross Lawley.
+
+Output conforms to https://github.com/jenkinsci/xunit-plugin/blob/master/
+src/main/resources/org/jenkinsci/plugins/xunit/types/model/xsd/junit-10.xsd
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import functools
+import os
+import re
+import sys
+import time
+
+import py
+
+import pytest
+from _pytest import nodes
+from _pytest.config import filename_arg
+
+# Python 2.X and 3.X compatibility
+if sys.version_info[0] < 3:
+    from codecs import open
+else:
+    unichr = chr
+    unicode = str
+    long = int
+
+
+class Junit(py.xml.Namespace):
+    pass
+
+
+# We need to get the subset of the invalid unicode ranges according to
+# XML 1.0 which are valid in this python build.  Hence we calculate
+# this dynamically instead of hardcoding it.  The spec range of valid
+# chars is: Char ::= #x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD]
+#                    | [#x10000-#x10FFFF]
+_legal_chars = (0x09, 0x0A, 0x0D)
+_legal_ranges = ((0x20, 0x7E), (0x80, 0xD7FF), (0xE000, 0xFFFD), (0x10000, 0x10FFFF))
+_legal_xml_re = [
+    unicode("%s-%s") % (unichr(low), unichr(high))
+    for (low, high) in _legal_ranges
+    if low < sys.maxunicode
+]
+_legal_xml_re = [unichr(x) for x in _legal_chars] + _legal_xml_re
+illegal_xml_re = re.compile(unicode("[^%s]") % unicode("").join(_legal_xml_re))
+del _legal_chars
+del _legal_ranges
+del _legal_xml_re
+
+_py_ext_re = re.compile(r"\.py$")
+
+
+def bin_xml_escape(arg):
+    def repl(matchobj):
+        i = ord(matchobj.group())
+        if i <= 0xFF:
+            return unicode("#x%02X") % i
+        else:
+            return unicode("#x%04X") % i
+
+    return py.xml.raw(illegal_xml_re.sub(repl, py.xml.escape(arg)))
+
+
+class _NodeReporter(object):
+    def __init__(self, nodeid, xml):
+
+        self.id = nodeid
+        self.xml = xml
+        self.add_stats = self.xml.add_stats
+        self.duration = 0
+        self.properties = []
+        self.nodes = []
+        self.testcase = None
+        self.attrs = {}
+
+    def append(self, node):
+        self.xml.add_stats(type(node).__name__)
+        self.nodes.append(node)
+
+    def add_property(self, name, value):
+        self.properties.append((str(name), bin_xml_escape(value)))
+
+    def add_attribute(self, name, value):
+        self.attrs[str(name)] = bin_xml_escape(value)
+
+    def make_properties_node(self):
+        """Return a Junit node containing custom properties, if any.
+        """
+        if self.properties:
+            return Junit.properties(
+                [
+                    Junit.property(name=name, value=value)
+                    for name, value in self.properties
+                ]
+            )
+        return ""
+
+    def record_testreport(self, testreport):
+        assert not self.testcase
+        names = mangle_test_address(testreport.nodeid)
+        existing_attrs = self.attrs
+        classnames = names[:-1]
+        if self.xml.prefix:
+            classnames.insert(0, self.xml.prefix)
+        attrs = {
+            "classname": ".".join(classnames),
+            "name": bin_xml_escape(names[-1]),
+            "file": testreport.location[0],
+        }
+        if testreport.location[1] is not None:
+            attrs["line"] = testreport.location[1]
+        if hasattr(testreport, "url"):
+            attrs["url"] = testreport.url
+        self.attrs = attrs
+        self.attrs.update(existing_attrs)  # restore any user-defined attributes
+
+    def to_xml(self):
+        testcase = Junit.testcase(time=self.duration, **self.attrs)
+        testcase.append(self.make_properties_node())
+        for node in self.nodes:
+            testcase.append(node)
+        return testcase
+
+    def _add_simple(self, kind, message, data=None):
+        data = bin_xml_escape(data)
+        node = kind(data, message=message)
+        self.append(node)
+
+    def write_captured_output(self, report):
+        content_out = report.capstdout
+        content_log = report.caplog
+        content_err = report.capstderr
+
+        if content_log or content_out:
+            if content_log and self.xml.logging == "system-out":
+                if content_out:
+                    # syncing stdout and the log-output is not done yet. It's
+                    # probably not worth the effort. Therefore, first the captured
+                    # stdout is shown and then the captured logs.
+                    content = "\n".join(
+                        [
+                            " Captured Stdout ".center(80, "-"),
+                            content_out,
+                            "",
+                            " Captured Log ".center(80, "-"),
+                            content_log,
+                        ]
+                    )
+                else:
+                    content = content_log
+            else:
+                content = content_out
+
+            if content:
+                tag = getattr(Junit, "system-out")
+                self.append(tag(bin_xml_escape(content)))
+
+        if content_log or content_err:
+            if content_log and self.xml.logging == "system-err":
+                if content_err:
+                    content = "\n".join(
+                        [
+                            " Captured Stderr ".center(80, "-"),
+                            content_err,
+                            "",
+                            " Captured Log ".center(80, "-"),
+                            content_log,
+                        ]
+                    )
+                else:
+                    content = content_log
+            else:
+                content = content_err
+
+            if content:
+                tag = getattr(Junit, "system-err")
+                self.append(tag(bin_xml_escape(content)))
+
+    def append_pass(self, report):
+        self.add_stats("passed")
+
+    def append_failure(self, report):
+        # msg = str(report.longrepr.reprtraceback.extraline)
+        if hasattr(report, "wasxfail"):
+            self._add_simple(Junit.skipped, "xfail-marked test passes unexpectedly")
+        else:
+            if hasattr(report.longrepr, "reprcrash"):
+                message = report.longrepr.reprcrash.message
+            elif isinstance(report.longrepr, (unicode, str)):
+                message = report.longrepr
+            else:
+                message = str(report.longrepr)
+            message = bin_xml_escape(message)
+            fail = Junit.failure(message=message)
+            fail.append(bin_xml_escape(report.longrepr))
+            self.append(fail)
+
+    def append_collect_error(self, report):
+        # msg = str(report.longrepr.reprtraceback.extraline)
+        self.append(
+            Junit.error(bin_xml_escape(report.longrepr), message="collection failure")
+        )
+
+    def append_collect_skipped(self, report):
+        self._add_simple(Junit.skipped, "collection skipped", report.longrepr)
+
+    def append_error(self, report):
+        if getattr(report, "when", None) == "teardown":
+            msg = "test teardown failure"
+        else:
+            msg = "test setup failure"
+        self._add_simple(Junit.error, msg, report.longrepr)
+
+    def append_skipped(self, report):
+        if hasattr(report, "wasxfail"):
+            self._add_simple(Junit.skipped, "expected test failure", report.wasxfail)
+        else:
+            filename, lineno, skipreason = report.longrepr
+            if skipreason.startswith("Skipped: "):
+                skipreason = skipreason[9:]
+            details = "%s:%s: %s" % (filename, lineno, skipreason)
+
+            self.append(
+                Junit.skipped(
+                    bin_xml_escape(details),
+                    type="pytest.skip",
+                    message=bin_xml_escape(skipreason),
+                )
+            )
+            self.write_captured_output(report)
+
+    def finalize(self):
+        data = self.to_xml().unicode(indent=0)
+        self.__dict__.clear()
+        self.to_xml = lambda: py.xml.raw(data)
+
+
+@pytest.fixture
+def record_property(request):
+    """Add an extra properties the calling test.
+    User properties become part of the test report and are available to the
+    configured reporters, like JUnit XML.
+    The fixture is callable with ``(name, value)``, with value being automatically
+    xml-encoded.
+
+    Example::
+
+        def test_function(record_property):
+            record_property("example_key", 1)
+    """
+
+    def append_property(name, value):
+        request.node.user_properties.append((name, value))
+
+    return append_property
+
+
+@pytest.fixture
+def record_xml_property(record_property, request):
+    """(Deprecated) use record_property."""
+    from _pytest import deprecated
+
+    request.node.warn(deprecated.RECORD_XML_PROPERTY)
+
+    return record_property
+
+
+@pytest.fixture
+def record_xml_attribute(request):
+    """Add extra xml attributes to the tag for the calling test.
+    The fixture is callable with ``(name, value)``, with value being
+    automatically xml-encoded
+    """
+    from _pytest.warning_types import PytestWarning
+
+    request.node.warn(PytestWarning("record_xml_attribute is an experimental feature"))
+    xml = getattr(request.config, "_xml", None)
+    if xml is not None:
+        node_reporter = xml.node_reporter(request.node.nodeid)
+        return node_reporter.add_attribute
+    else:
+
+        def add_attr_noop(name, value):
+            pass
+
+        return add_attr_noop
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("terminal reporting")
+    group.addoption(
+        "--junitxml",
+        "--junit-xml",
+        action="store",
+        dest="xmlpath",
+        metavar="path",
+        type=functools.partial(filename_arg, optname="--junitxml"),
+        default=None,
+        help="create junit-xml style report file at given path.",
+    )
+    group.addoption(
+        "--junitprefix",
+        "--junit-prefix",
+        action="store",
+        metavar="str",
+        default=None,
+        help="prepend prefix to classnames in junit-xml output",
+    )
+    parser.addini(
+        "junit_suite_name", "Test suite name for JUnit report", default="pytest"
+    )
+    parser.addini(
+        "junit_logging",
+        "Write captured log messages to JUnit report: "
+        "one of no|system-out|system-err",
+        default="no",
+    )  # choices=['no', 'stdout', 'stderr'])
+
+
+def pytest_configure(config):
+    xmlpath = config.option.xmlpath
+    # prevent opening xmllog on slave nodes (xdist)
+    if xmlpath and not hasattr(config, "slaveinput"):
+        config._xml = LogXML(
+            xmlpath,
+            config.option.junitprefix,
+            config.getini("junit_suite_name"),
+            config.getini("junit_logging"),
+        )
+        config.pluginmanager.register(config._xml)
+
+
+def pytest_unconfigure(config):
+    xml = getattr(config, "_xml", None)
+    if xml:
+        del config._xml
+        config.pluginmanager.unregister(xml)
+
+
+def mangle_test_address(address):
+    path, possible_open_bracket, params = address.partition("[")
+    names = path.split("::")
+    try:
+        names.remove("()")
+    except ValueError:
+        pass
+    # convert file path to dotted path
+    names[0] = names[0].replace(nodes.SEP, ".")
+    names[0] = _py_ext_re.sub("", names[0])
+    # put any params back
+    names[-1] += possible_open_bracket + params
+    return names
+
+
+class LogXML(object):
+    def __init__(self, logfile, prefix, suite_name="pytest", logging="no"):
+        logfile = os.path.expanduser(os.path.expandvars(logfile))
+        self.logfile = os.path.normpath(os.path.abspath(logfile))
+        self.prefix = prefix
+        self.suite_name = suite_name
+        self.logging = logging
+        self.stats = dict.fromkeys(["error", "passed", "failure", "skipped"], 0)
+        self.node_reporters = {}  # nodeid -> _NodeReporter
+        self.node_reporters_ordered = []
+        self.global_properties = []
+        # List of reports that failed on call but teardown is pending.
+        self.open_reports = []
+        self.cnt_double_fail_tests = 0
+
+    def finalize(self, report):
+        nodeid = getattr(report, "nodeid", report)
+        # local hack to handle xdist report order
+        slavenode = getattr(report, "node", None)
+        reporter = self.node_reporters.pop((nodeid, slavenode))
+        if reporter is not None:
+            reporter.finalize()
+
+    def node_reporter(self, report):
+        nodeid = getattr(report, "nodeid", report)
+        # local hack to handle xdist report order
+        slavenode = getattr(report, "node", None)
+
+        key = nodeid, slavenode
+
+        if key in self.node_reporters:
+            # TODO: breasks for --dist=each
+            return self.node_reporters[key]
+
+        reporter = _NodeReporter(nodeid, self)
+
+        self.node_reporters[key] = reporter
+        self.node_reporters_ordered.append(reporter)
+
+        return reporter
+
+    def add_stats(self, key):
+        if key in self.stats:
+            self.stats[key] += 1
+
+    def _opentestcase(self, report):
+        reporter = self.node_reporter(report)
+        reporter.record_testreport(report)
+        return reporter
+
+    def pytest_runtest_logreport(self, report):
+        """handle a setup/call/teardown report, generating the appropriate
+        xml tags as necessary.
+
+        note: due to plugins like xdist, this hook may be called in interlaced
+        order with reports from other nodes. for example:
+
+        usual call order:
+            -> setup node1
+            -> call node1
+            -> teardown node1
+            -> setup node2
+            -> call node2
+            -> teardown node2
+
+        possible call order in xdist:
+            -> setup node1
+            -> call node1
+            -> setup node2
+            -> call node2
+            -> teardown node2
+            -> teardown node1
+        """
+        close_report = None
+        if report.passed:
+            if report.when == "call":  # ignore setup/teardown
+                reporter = self._opentestcase(report)
+                reporter.append_pass(report)
+        elif report.failed:
+            if report.when == "teardown":
+                # The following vars are needed when xdist plugin is used
+                report_wid = getattr(report, "worker_id", None)
+                report_ii = getattr(report, "item_index", None)
+                close_report = next(
+                    (
+                        rep
+                        for rep in self.open_reports
+                        if (
+                            rep.nodeid == report.nodeid
+                            and getattr(rep, "item_index", None) == report_ii
+                            and getattr(rep, "worker_id", None) == report_wid
+                        )
+                    ),
+                    None,
+                )
+                if close_report:
+                    # We need to open new testcase in case we have failure in
+                    # call and error in teardown in order to follow junit
+                    # schema
+                    self.finalize(close_report)
+                    self.cnt_double_fail_tests += 1
+            reporter = self._opentestcase(report)
+            if report.when == "call":
+                reporter.append_failure(report)
+                self.open_reports.append(report)
+            else:
+                reporter.append_error(report)
+        elif report.skipped:
+            reporter = self._opentestcase(report)
+            reporter.append_skipped(report)
+        self.update_testcase_duration(report)
+        if report.when == "teardown":
+            reporter = self._opentestcase(report)
+            reporter.write_captured_output(report)
+
+            for propname, propvalue in report.user_properties:
+                reporter.add_property(propname, propvalue)
+
+            self.finalize(report)
+            report_wid = getattr(report, "worker_id", None)
+            report_ii = getattr(report, "item_index", None)
+            close_report = next(
+                (
+                    rep
+                    for rep in self.open_reports
+                    if (
+                        rep.nodeid == report.nodeid
+                        and getattr(rep, "item_index", None) == report_ii
+                        and getattr(rep, "worker_id", None) == report_wid
+                    )
+                ),
+                None,
+            )
+            if close_report:
+                self.open_reports.remove(close_report)
+
+    def update_testcase_duration(self, report):
+        """accumulates total duration for nodeid from given report and updates
+        the Junit.testcase with the new total if already created.
+        """
+        reporter = self.node_reporter(report)
+        reporter.duration += getattr(report, "duration", 0.0)
+
+    def pytest_collectreport(self, report):
+        if not report.passed:
+            reporter = self._opentestcase(report)
+            if report.failed:
+                reporter.append_collect_error(report)
+            else:
+                reporter.append_collect_skipped(report)
+
+    def pytest_internalerror(self, excrepr):
+        reporter = self.node_reporter("internal")
+        reporter.attrs.update(classname="pytest", name="internal")
+        reporter._add_simple(Junit.error, "internal error", excrepr)
+
+    def pytest_sessionstart(self):
+        self.suite_start_time = time.time()
+
+    def pytest_sessionfinish(self):
+        dirname = os.path.dirname(os.path.abspath(self.logfile))
+        if not os.path.isdir(dirname):
+            os.makedirs(dirname)
+        logfile = open(self.logfile, "w", encoding="utf-8")
+        suite_stop_time = time.time()
+        suite_time_delta = suite_stop_time - self.suite_start_time
+
+        numtests = (
+            self.stats["passed"]
+            + self.stats["failure"]
+            + self.stats["skipped"]
+            + self.stats["error"]
+            - self.cnt_double_fail_tests
+        )
+        logfile.write('<?xml version="1.0" encoding="utf-8"?>')
+
+        logfile.write(
+            Junit.testsuite(
+                self._get_global_properties_node(),
+                [x.to_xml() for x in self.node_reporters_ordered],
+                name=self.suite_name,
+                errors=self.stats["error"],
+                failures=self.stats["failure"],
+                skips=self.stats["skipped"],
+                tests=numtests,
+                time="%.3f" % suite_time_delta,
+            ).unicode(indent=0)
+        )
+        logfile.close()
+
+    def pytest_terminal_summary(self, terminalreporter):
+        terminalreporter.write_sep("-", "generated xml file: %s" % (self.logfile))
+
+    def add_global_property(self, name, value):
+        self.global_properties.append((str(name), bin_xml_escape(value)))
+
+    def _get_global_properties_node(self):
+        """Return a Junit node containing custom properties, if any.
+        """
+        if self.global_properties:
+            return Junit.properties(
+                [
+                    Junit.property(name=name, value=value)
+                    for name, value in self.global_properties
+                ]
+            )
+        return ""
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/top_level.txt	(date 1543190976278)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/top_level.txt	(date 1543190976278)
@@ -0,0 +1,1 @@
+colorama
Index: venv/Lib/site-packages/_pytest/compat.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/compat.py	(date 1543190976292)
+++ venv/Lib/site-packages/_pytest/compat.py	(date 1543190976292)
@@ -0,0 +1,443 @@
+"""
+python version compatibility code
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import codecs
+import functools
+import inspect
+import re
+import sys
+from contextlib import contextmanager
+
+import py
+import six
+from six import text_type
+
+import _pytest
+from _pytest.outcomes import fail
+from _pytest.outcomes import TEST_OUTCOME
+
+try:
+    import enum
+except ImportError:  # pragma: no cover
+    # Only available in Python 3.4+ or as a backport
+    enum = None
+
+_PY3 = sys.version_info > (3, 0)
+_PY2 = not _PY3
+
+
+if _PY3:
+    from inspect import signature, Parameter as Parameter
+else:
+    from funcsigs import signature, Parameter as Parameter
+
+NoneType = type(None)
+NOTSET = object()
+
+PY35 = sys.version_info[:2] >= (3, 5)
+PY36 = sys.version_info[:2] >= (3, 6)
+MODULE_NOT_FOUND_ERROR = "ModuleNotFoundError" if PY36 else "ImportError"
+
+
+if _PY3:
+    from collections.abc import MutableMapping as MappingMixin
+    from collections.abc import Mapping, Sequence
+else:
+    # those raise DeprecationWarnings in Python >=3.7
+    from collections import MutableMapping as MappingMixin  # noqa
+    from collections import Mapping, Sequence  # noqa
+
+
+if sys.version_info >= (3, 4):
+    from importlib.util import spec_from_file_location
+else:
+
+    def spec_from_file_location(*_, **__):
+        return None
+
+
+def _format_args(func):
+    return str(signature(func))
+
+
+isfunction = inspect.isfunction
+isclass = inspect.isclass
+# used to work around a python2 exception info leak
+exc_clear = getattr(sys, "exc_clear", lambda: None)
+# The type of re.compile objects is not exposed in Python.
+REGEX_TYPE = type(re.compile(""))
+
+
+def is_generator(func):
+    genfunc = inspect.isgeneratorfunction(func)
+    return genfunc and not iscoroutinefunction(func)
+
+
+def iscoroutinefunction(func):
+    """Return True if func is a decorated coroutine function.
+
+    Note: copied and modified from Python 3.5's builtin couroutines.py to avoid import asyncio directly,
+    which in turns also initializes the "logging" module as side-effect (see issue #8).
+    """
+    return getattr(func, "_is_coroutine", False) or (
+        hasattr(inspect, "iscoroutinefunction") and inspect.iscoroutinefunction(func)
+    )
+
+
+def getlocation(function, curdir):
+    function = get_real_func(function)
+    fn = py.path.local(inspect.getfile(function))
+    lineno = function.__code__.co_firstlineno
+    if fn.relto(curdir):
+        fn = fn.relto(curdir)
+    return "%s:%d" % (fn, lineno + 1)
+
+
+def num_mock_patch_args(function):
+    """ return number of arguments used up by mock arguments (if any) """
+    patchings = getattr(function, "patchings", None)
+    if not patchings:
+        return 0
+    mock_modules = [sys.modules.get("mock"), sys.modules.get("unittest.mock")]
+    if any(mock_modules):
+        sentinels = [m.DEFAULT for m in mock_modules if m is not None]
+        return len(
+            [p for p in patchings if not p.attribute_name and p.new in sentinels]
+        )
+    return len(patchings)
+
+
+def getfuncargnames(function, is_method=False, cls=None):
+    """Returns the names of a function's mandatory arguments.
+
+    This should return the names of all function arguments that:
+        * Aren't bound to an instance or type as in instance or class methods.
+        * Don't have default values.
+        * Aren't bound with functools.partial.
+        * Aren't replaced with mocks.
+
+    The is_method and cls arguments indicate that the function should
+    be treated as a bound method even though it's not unless, only in
+    the case of cls, the function is a static method.
+
+    @RonnyPfannschmidt: This function should be refactored when we
+    revisit fixtures. The fixture mechanism should ask the node for
+    the fixture names, and not try to obtain directly from the
+    function object well after collection has occurred.
+
+    """
+    # The parameters attribute of a Signature object contains an
+    # ordered mapping of parameter names to Parameter instances.  This
+    # creates a tuple of the names of the parameters that don't have
+    # defaults.
+    try:
+        parameters = signature(function).parameters
+    except (ValueError, TypeError) as e:
+        fail(
+            "Could not determine arguments of {!r}: {}".format(function, e),
+            pytrace=False,
+        )
+
+    arg_names = tuple(
+        p.name
+        for p in parameters.values()
+        if (
+            p.kind is Parameter.POSITIONAL_OR_KEYWORD
+            or p.kind is Parameter.KEYWORD_ONLY
+        )
+        and p.default is Parameter.empty
+    )
+    # If this function should be treated as a bound method even though
+    # it's passed as an unbound method or function, remove the first
+    # parameter name.
+    if is_method or (
+        cls and not isinstance(cls.__dict__.get(function.__name__, None), staticmethod)
+    ):
+        arg_names = arg_names[1:]
+    # Remove any names that will be replaced with mocks.
+    if hasattr(function, "__wrapped__"):
+        arg_names = arg_names[num_mock_patch_args(function) :]
+    return arg_names
+
+
+@contextmanager
+def dummy_context_manager():
+    """Context manager that does nothing, useful in situations where you might need an actual context manager or not
+    depending on some condition. Using this allow to keep the same code"""
+    yield
+
+
+def get_default_arg_names(function):
+    # Note: this code intentionally mirrors the code at the beginning of getfuncargnames,
+    # to get the arguments which were excluded from its result because they had default values
+    return tuple(
+        p.name
+        for p in signature(function).parameters.values()
+        if p.kind in (Parameter.POSITIONAL_OR_KEYWORD, Parameter.KEYWORD_ONLY)
+        and p.default is not Parameter.empty
+    )
+
+
+if _PY3:
+    STRING_TYPES = bytes, str
+    UNICODE_TYPES = six.text_type
+
+    if PY35:
+
+        def _bytes_to_ascii(val):
+            return val.decode("ascii", "backslashreplace")
+
+    else:
+
+        def _bytes_to_ascii(val):
+            if val:
+                # source: http://goo.gl/bGsnwC
+                encoded_bytes, _ = codecs.escape_encode(val)
+                return encoded_bytes.decode("ascii")
+            else:
+                # empty bytes crashes codecs.escape_encode (#1087)
+                return ""
+
+    def ascii_escaped(val):
+        """If val is pure ascii, returns it as a str().  Otherwise, escapes
+        bytes objects into a sequence of escaped bytes:
+
+        b'\xc3\xb4\xc5\xd6' -> u'\\xc3\\xb4\\xc5\\xd6'
+
+        and escapes unicode objects into a sequence of escaped unicode
+        ids, e.g.:
+
+        '4\\nV\\U00043efa\\x0eMXWB\\x1e\\u3028\\u15fd\\xcd\\U0007d944'
+
+        note:
+           the obvious "v.decode('unicode-escape')" will return
+           valid utf-8 unicode if it finds them in bytes, but we
+           want to return escaped bytes for any byte, even if they match
+           a utf-8 string.
+
+        """
+        if isinstance(val, bytes):
+            return _bytes_to_ascii(val)
+        else:
+            return val.encode("unicode_escape").decode("ascii")
+
+
+else:
+    STRING_TYPES = six.string_types
+    UNICODE_TYPES = six.text_type
+
+    def ascii_escaped(val):
+        """In py2 bytes and str are the same type, so return if it's a bytes
+        object, return it unchanged if it is a full ascii string,
+        otherwise escape it into its binary form.
+
+        If it's a unicode string, change the unicode characters into
+        unicode escapes.
+
+        """
+        if isinstance(val, bytes):
+            try:
+                return val.encode("ascii")
+            except UnicodeDecodeError:
+                return val.encode("string-escape")
+        else:
+            return val.encode("unicode-escape")
+
+
+class _PytestWrapper(object):
+    """Dummy wrapper around a function object for internal use only.
+
+    Used to correctly unwrap the underlying function object
+    when we are creating fixtures, because we wrap the function object ourselves with a decorator
+    to issue warnings when the fixture function is called directly.
+    """
+
+    def __init__(self, obj):
+        self.obj = obj
+
+
+def get_real_func(obj):
+    """ gets the real function object of the (possibly) wrapped object by
+    functools.wraps or functools.partial.
+    """
+    start_obj = obj
+    for i in range(100):
+        # __pytest_wrapped__ is set by @pytest.fixture when wrapping the fixture function
+        # to trigger a warning if it gets called directly instead of by pytest: we don't
+        # want to unwrap further than this otherwise we lose useful wrappings like @mock.patch (#3774)
+        new_obj = getattr(obj, "__pytest_wrapped__", None)
+        if isinstance(new_obj, _PytestWrapper):
+            obj = new_obj.obj
+            break
+        new_obj = getattr(obj, "__wrapped__", None)
+        if new_obj is None:
+            break
+        obj = new_obj
+    else:
+        raise ValueError(
+            ("could not find real function of {start}\nstopped at {current}").format(
+                start=py.io.saferepr(start_obj), current=py.io.saferepr(obj)
+            )
+        )
+    if isinstance(obj, functools.partial):
+        obj = obj.func
+    return obj
+
+
+def get_real_method(obj, holder):
+    """
+    Attempts to obtain the real function object that might be wrapping ``obj``, while at the same time
+    returning a bound method to ``holder`` if the original object was a bound method.
+    """
+    try:
+        is_method = hasattr(obj, "__func__")
+        obj = get_real_func(obj)
+    except Exception:
+        return obj
+    if is_method and hasattr(obj, "__get__") and callable(obj.__get__):
+        obj = obj.__get__(holder)
+    return obj
+
+
+def getfslineno(obj):
+    # xxx let decorators etc specify a sane ordering
+    obj = get_real_func(obj)
+    if hasattr(obj, "place_as"):
+        obj = obj.place_as
+    fslineno = _pytest._code.getfslineno(obj)
+    assert isinstance(fslineno[1], int), obj
+    return fslineno
+
+
+def getimfunc(func):
+    try:
+        return func.__func__
+    except AttributeError:
+        return func
+
+
+def safe_getattr(object, name, default):
+    """ Like getattr but return default upon any Exception or any OutcomeException.
+
+    Attribute access can potentially fail for 'evil' Python objects.
+    See issue #214.
+    It catches OutcomeException because of #2490 (issue #580), new outcomes are derived from BaseException
+    instead of Exception (for more details check #2707)
+    """
+    try:
+        return getattr(object, name, default)
+    except TEST_OUTCOME:
+        return default
+
+
+def safe_isclass(obj):
+    """Ignore any exception via isinstance on Python 3."""
+    try:
+        return isclass(obj)
+    except Exception:
+        return False
+
+
+def _is_unittest_unexpected_success_a_failure():
+    """Return if the test suite should fail if an @expectedFailure unittest test PASSES.
+
+    From https://docs.python.org/3/library/unittest.html?highlight=unittest#unittest.TestResult.wasSuccessful:
+        Changed in version 3.4: Returns False if there were any
+        unexpectedSuccesses from tests marked with the expectedFailure() decorator.
+    """
+    return sys.version_info >= (3, 4)
+
+
+if _PY3:
+
+    def safe_str(v):
+        """returns v as string"""
+        return str(v)
+
+
+else:
+
+    def safe_str(v):
+        """returns v as string, converting to ascii if necessary"""
+        try:
+            return str(v)
+        except UnicodeError:
+            if not isinstance(v, text_type):
+                v = text_type(v)
+            errors = "replace"
+            return v.encode("utf-8", errors)
+
+
+COLLECT_FAKEMODULE_ATTRIBUTES = (
+    "Collector",
+    "Module",
+    "Generator",
+    "Function",
+    "Instance",
+    "Session",
+    "Item",
+    "Class",
+    "File",
+    "_fillfuncargs",
+)
+
+
+def _setup_collect_fakemodule():
+    from types import ModuleType
+    import pytest
+
+    pytest.collect = ModuleType("pytest.collect")
+    pytest.collect.__all__ = []  # used for setns
+    for attr in COLLECT_FAKEMODULE_ATTRIBUTES:
+        setattr(pytest.collect, attr, getattr(pytest, attr))
+
+
+if _PY2:
+    # Without this the test_dupfile_on_textio will fail, otherwise CaptureIO could directly inherit from StringIO.
+    from py.io import TextIO
+
+    class CaptureIO(TextIO):
+        @property
+        def encoding(self):
+            return getattr(self, "_encoding", "UTF-8")
+
+
+else:
+    import io
+
+    class CaptureIO(io.TextIOWrapper):
+        def __init__(self):
+            super(CaptureIO, self).__init__(
+                io.BytesIO(), encoding="UTF-8", newline="", write_through=True
+            )
+
+        def getvalue(self):
+            return self.buffer.getvalue().decode("UTF-8")
+
+
+class FuncargnamesCompatAttr(object):
+    """ helper class so that Metafunc, Function and FixtureRequest
+    don't need to each define the "funcargnames" compatibility attribute.
+    """
+
+    @property
+    def funcargnames(self):
+        """ alias attribute for ``fixturenames`` for pre-2.3 compatibility"""
+        return self.fixturenames
+
+
+if six.PY2:
+
+    def lru_cache(*_, **__):
+        def dec(fn):
+            return fn
+
+        return dec
+
+
+else:
+    from functools import lru_cache  # noqa: F401
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/metadata.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/metadata.json	(date 1543190976303)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/metadata.json	(date 1543190976303)
@@ -0,0 +1,1 @@
+{"classifiers": ["Development Status :: 5 - Production/Stable", "Environment :: Console", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Operating System :: OS Independent", "Programming Language :: Python", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: Implementation :: CPython", "Programming Language :: Python :: Implementation :: PyPy", "Topic :: Terminals"], "extensions": {"python.details": {"contacts": [{"email": "tartley@tartley.com", "name": "Jonathan Hartley", "role": "author"}, {"name": "Arnon Yaari", "role": "maintainer"}], "document_names": {"description": "DESCRIPTION.rst", "license": "LICENSE.txt"}, "project_urls": {"Home": "https://github.com/tartley/colorama"}}}, "generator": "bdist_wheel (0.29.0)", "keywords": ["color", "colour", "terminal", "text", "ansi", "windows", "crossplatform", "xplatform"], "license": "BSD", "metadata_version": "2.0", "name": "colorama", "requires_python": ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*", "summary": "Cross-platform colored terminal text.", "version": "0.4.0"}
\ No newline at end of file
Index: venv/Lib/site-packages/colorama-0.4.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama-0.4.0.dist-info/WHEEL	(date 1543190976312)
+++ venv/Lib/site-packages/colorama-0.4.0.dist-info/WHEEL	(date 1543190976312)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.29.0)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/_pytest/stepwise.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/stepwise.py	(date 1543190976325)
+++ venv/Lib/site-packages/_pytest/stepwise.py	(date 1543190976325)
@@ -0,0 +1,102 @@
+import pytest
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group.addoption(
+        "--sw",
+        "--stepwise",
+        action="store_true",
+        dest="stepwise",
+        help="exit on test fail and continue from last failing test next time",
+    )
+    group.addoption(
+        "--stepwise-skip",
+        action="store_true",
+        dest="stepwise_skip",
+        help="ignore the first failing test but stop on the next failing test",
+    )
+
+
+@pytest.hookimpl
+def pytest_configure(config):
+    config.pluginmanager.register(StepwisePlugin(config), "stepwiseplugin")
+
+
+class StepwisePlugin:
+    def __init__(self, config):
+        self.config = config
+        self.active = config.getvalue("stepwise")
+        self.session = None
+
+        if self.active:
+            self.lastfailed = config.cache.get("cache/stepwise", None)
+            self.skip = config.getvalue("stepwise_skip")
+
+    def pytest_sessionstart(self, session):
+        self.session = session
+
+    def pytest_collection_modifyitems(self, session, config, items):
+        if not self.active or not self.lastfailed:
+            return
+
+        already_passed = []
+        found = False
+
+        # Make a list of all tests that have been run before the last failing one.
+        for item in items:
+            if item.nodeid == self.lastfailed:
+                found = True
+                break
+            else:
+                already_passed.append(item)
+
+        # If the previously failed test was not found among the test items,
+        # do not skip any tests.
+        if not found:
+            already_passed = []
+
+        for item in already_passed:
+            items.remove(item)
+
+        config.hook.pytest_deselected(items=already_passed)
+
+    def pytest_collectreport(self, report):
+        if self.active and report.failed:
+            self.session.shouldstop = (
+                "Error when collecting test, stopping test execution."
+            )
+
+    def pytest_runtest_logreport(self, report):
+        # Skip this hook if plugin is not active or the test is xfailed.
+        if not self.active or "xfail" in report.keywords:
+            return
+
+        if report.failed:
+            if self.skip:
+                # Remove test from the failed ones (if it exists) and unset the skip option
+                # to make sure the following tests will not be skipped.
+                if report.nodeid == self.lastfailed:
+                    self.lastfailed = None
+
+                self.skip = False
+            else:
+                # Mark test as the last failing and interrupt the test session.
+                self.lastfailed = report.nodeid
+                self.session.shouldstop = (
+                    "Test failed, continuing from this test next run."
+                )
+
+        else:
+            # If the test was actually run and did pass.
+            if report.when == "call":
+                # Remove test from the failed ones, if exists.
+                if report.nodeid == self.lastfailed:
+                    self.lastfailed = None
+
+    def pytest_sessionfinish(self, session):
+        if self.active:
+            self.config.cache.set("cache/stepwise", self.lastfailed)
+        else:
+            # Clear the list of failing tests if the plugin is not active.
+            self.config.cache.set("cache/stepwise", [])
Index: venv/Lib/site-packages/_pytest/setupplan.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/setupplan.py	(date 1543190976337)
+++ venv/Lib/site-packages/_pytest/setupplan.py	(date 1543190976337)
@@ -0,0 +1,31 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import pytest
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("debugconfig")
+    group.addoption(
+        "--setupplan",
+        "--setup-plan",
+        action="store_true",
+        help="show what fixtures and tests would be executed but "
+        "don't execute anything.",
+    )
+
+
+@pytest.hookimpl(tryfirst=True)
+def pytest_fixture_setup(fixturedef, request):
+    # Will return a dummy fixture if the setuponly option is provided.
+    if request.config.option.setupplan:
+        fixturedef.cached_result = (None, None, None)
+        return fixturedef.cached_result
+
+
+@pytest.hookimpl(tryfirst=True)
+def pytest_cmdline_main(config):
+    if config.option.setupplan:
+        config.option.setuponly = True
+        config.option.setupshow = True
Index: venv/Lib/site-packages/pytest.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pytest.py	(date 1543190976347)
+++ venv/Lib/site-packages/pytest.py	(date 1543190976347)
@@ -0,0 +1,96 @@
+# PYTHON_ARGCOMPLETE_OK
+"""
+pytest: unit and functional testing with Python.
+"""
+# else we are imported
+from _pytest import __version__
+from _pytest.assertion import register_assert_rewrite
+from _pytest.config import cmdline
+from _pytest.config import hookimpl
+from _pytest.config import hookspec
+from _pytest.config import main
+from _pytest.config import UsageError
+from _pytest.debugging import pytestPDB as __pytestPDB
+from _pytest.fixtures import fillfixtures as _fillfuncargs
+from _pytest.fixtures import fixture
+from _pytest.fixtures import yield_fixture
+from _pytest.freeze_support import freeze_includes
+from _pytest.main import Session
+from _pytest.mark import MARK_GEN as mark
+from _pytest.mark import param
+from _pytest.nodes import Collector
+from _pytest.nodes import File
+from _pytest.nodes import Item
+from _pytest.outcomes import exit
+from _pytest.outcomes import fail
+from _pytest.outcomes import importorskip
+from _pytest.outcomes import skip
+from _pytest.outcomes import xfail
+from _pytest.python import Class
+from _pytest.python import Function
+from _pytest.python import Generator
+from _pytest.python import Instance
+from _pytest.python import Module
+from _pytest.python import Package
+from _pytest.python_api import approx
+from _pytest.python_api import raises
+from _pytest.recwarn import deprecated_call
+from _pytest.recwarn import warns
+from _pytest.warning_types import PytestDeprecationWarning
+from _pytest.warning_types import PytestExperimentalApiWarning
+from _pytest.warning_types import PytestWarning
+from _pytest.warning_types import RemovedInPytest4Warning
+
+set_trace = __pytestPDB.set_trace
+
+__all__ = [
+    "__version__",
+    "_fillfuncargs",
+    "approx",
+    "Class",
+    "cmdline",
+    "Collector",
+    "deprecated_call",
+    "exit",
+    "fail",
+    "File",
+    "fixture",
+    "freeze_includes",
+    "Function",
+    "Generator",
+    "hookimpl",
+    "hookspec",
+    "importorskip",
+    "Instance",
+    "Item",
+    "main",
+    "mark",
+    "Module",
+    "Package",
+    "param",
+    "PytestDeprecationWarning",
+    "PytestExperimentalApiWarning",
+    "PytestWarning",
+    "raises",
+    "register_assert_rewrite",
+    "RemovedInPytest4Warning",
+    "Session",
+    "set_trace",
+    "skip",
+    "UsageError",
+    "warns",
+    "xfail",
+    "yield_fixture",
+]
+
+if __name__ == "__main__":
+    # if run as a script or by 'python -m pytest'
+    # we trigger the below "else" condition by the following import
+    import pytest
+
+    raise SystemExit(pytest.main())
+else:
+
+    from _pytest.compat import _setup_collect_fakemodule
+
+    _setup_collect_fakemodule()
Index: venv/Lib/site-packages/six.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six.py	(date 1543190976361)
+++ venv/Lib/site-packages/six.py	(date 1543190976361)
@@ -0,0 +1,891 @@
+# Copyright (c) 2010-2017 Benjamin Peterson
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all
+# copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+"""Utilities for writing code that runs on Python 2 and 3"""
+
+from __future__ import absolute_import
+
+import functools
+import itertools
+import operator
+import sys
+import types
+
+__author__ = "Benjamin Peterson <benjamin@python.org>"
+__version__ = "1.11.0"
+
+
+# Useful for very coarse version differentiation.
+PY2 = sys.version_info[0] == 2
+PY3 = sys.version_info[0] == 3
+PY34 = sys.version_info[0:2] >= (3, 4)
+
+if PY3:
+    string_types = str,
+    integer_types = int,
+    class_types = type,
+    text_type = str
+    binary_type = bytes
+
+    MAXSIZE = sys.maxsize
+else:
+    string_types = basestring,
+    integer_types = (int, long)
+    class_types = (type, types.ClassType)
+    text_type = unicode
+    binary_type = str
+
+    if sys.platform.startswith("java"):
+        # Jython always uses 32 bits.
+        MAXSIZE = int((1 << 31) - 1)
+    else:
+        # It's possible to have sizeof(long) != sizeof(Py_ssize_t).
+        class X(object):
+
+            def __len__(self):
+                return 1 << 31
+        try:
+            len(X())
+        except OverflowError:
+            # 32-bit
+            MAXSIZE = int((1 << 31) - 1)
+        else:
+            # 64-bit
+            MAXSIZE = int((1 << 63) - 1)
+        del X
+
+
+def _add_doc(func, doc):
+    """Add documentation to a function."""
+    func.__doc__ = doc
+
+
+def _import_module(name):
+    """Import module, returning the module after the last dot."""
+    __import__(name)
+    return sys.modules[name]
+
+
+class _LazyDescr(object):
+
+    def __init__(self, name):
+        self.name = name
+
+    def __get__(self, obj, tp):
+        result = self._resolve()
+        setattr(obj, self.name, result)  # Invokes __set__.
+        try:
+            # This is a bit ugly, but it avoids running this again by
+            # removing this descriptor.
+            delattr(obj.__class__, self.name)
+        except AttributeError:
+            pass
+        return result
+
+
+class MovedModule(_LazyDescr):
+
+    def __init__(self, name, old, new=None):
+        super(MovedModule, self).__init__(name)
+        if PY3:
+            if new is None:
+                new = name
+            self.mod = new
+        else:
+            self.mod = old
+
+    def _resolve(self):
+        return _import_module(self.mod)
+
+    def __getattr__(self, attr):
+        _module = self._resolve()
+        value = getattr(_module, attr)
+        setattr(self, attr, value)
+        return value
+
+
+class _LazyModule(types.ModuleType):
+
+    def __init__(self, name):
+        super(_LazyModule, self).__init__(name)
+        self.__doc__ = self.__class__.__doc__
+
+    def __dir__(self):
+        attrs = ["__doc__", "__name__"]
+        attrs += [attr.name for attr in self._moved_attributes]
+        return attrs
+
+    # Subclasses should override this
+    _moved_attributes = []
+
+
+class MovedAttribute(_LazyDescr):
+
+    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):
+        super(MovedAttribute, self).__init__(name)
+        if PY3:
+            if new_mod is None:
+                new_mod = name
+            self.mod = new_mod
+            if new_attr is None:
+                if old_attr is None:
+                    new_attr = name
+                else:
+                    new_attr = old_attr
+            self.attr = new_attr
+        else:
+            self.mod = old_mod
+            if old_attr is None:
+                old_attr = name
+            self.attr = old_attr
+
+    def _resolve(self):
+        module = _import_module(self.mod)
+        return getattr(module, self.attr)
+
+
+class _SixMetaPathImporter(object):
+
+    """
+    A meta path importer to import six.moves and its submodules.
+
+    This class implements a PEP302 finder and loader. It should be compatible
+    with Python 2.5 and all existing versions of Python3
+    """
+
+    def __init__(self, six_module_name):
+        self.name = six_module_name
+        self.known_modules = {}
+
+    def _add_module(self, mod, *fullnames):
+        for fullname in fullnames:
+            self.known_modules[self.name + "." + fullname] = mod
+
+    def _get_module(self, fullname):
+        return self.known_modules[self.name + "." + fullname]
+
+    def find_module(self, fullname, path=None):
+        if fullname in self.known_modules:
+            return self
+        return None
+
+    def __get_module(self, fullname):
+        try:
+            return self.known_modules[fullname]
+        except KeyError:
+            raise ImportError("This loader does not know module " + fullname)
+
+    def load_module(self, fullname):
+        try:
+            # in case of a reload
+            return sys.modules[fullname]
+        except KeyError:
+            pass
+        mod = self.__get_module(fullname)
+        if isinstance(mod, MovedModule):
+            mod = mod._resolve()
+        else:
+            mod.__loader__ = self
+        sys.modules[fullname] = mod
+        return mod
+
+    def is_package(self, fullname):
+        """
+        Return true, if the named module is a package.
+
+        We need this method to get correct spec objects with
+        Python 3.4 (see PEP451)
+        """
+        return hasattr(self.__get_module(fullname), "__path__")
+
+    def get_code(self, fullname):
+        """Return None
+
+        Required, if is_package is implemented"""
+        self.__get_module(fullname)  # eventually raises ImportError
+        return None
+    get_source = get_code  # same as get_code
+
+_importer = _SixMetaPathImporter(__name__)
+
+
+class _MovedItems(_LazyModule):
+
+    """Lazy loading of moved objects"""
+    __path__ = []  # mark as package
+
+
+_moved_attributes = [
+    MovedAttribute("cStringIO", "cStringIO", "io", "StringIO"),
+    MovedAttribute("filter", "itertools", "builtins", "ifilter", "filter"),
+    MovedAttribute("filterfalse", "itertools", "itertools", "ifilterfalse", "filterfalse"),
+    MovedAttribute("input", "__builtin__", "builtins", "raw_input", "input"),
+    MovedAttribute("intern", "__builtin__", "sys"),
+    MovedAttribute("map", "itertools", "builtins", "imap", "map"),
+    MovedAttribute("getcwd", "os", "os", "getcwdu", "getcwd"),
+    MovedAttribute("getcwdb", "os", "os", "getcwd", "getcwdb"),
+    MovedAttribute("getoutput", "commands", "subprocess"),
+    MovedAttribute("range", "__builtin__", "builtins", "xrange", "range"),
+    MovedAttribute("reload_module", "__builtin__", "importlib" if PY34 else "imp", "reload"),
+    MovedAttribute("reduce", "__builtin__", "functools"),
+    MovedAttribute("shlex_quote", "pipes", "shlex", "quote"),
+    MovedAttribute("StringIO", "StringIO", "io"),
+    MovedAttribute("UserDict", "UserDict", "collections"),
+    MovedAttribute("UserList", "UserList", "collections"),
+    MovedAttribute("UserString", "UserString", "collections"),
+    MovedAttribute("xrange", "__builtin__", "builtins", "xrange", "range"),
+    MovedAttribute("zip", "itertools", "builtins", "izip", "zip"),
+    MovedAttribute("zip_longest", "itertools", "itertools", "izip_longest", "zip_longest"),
+    MovedModule("builtins", "__builtin__"),
+    MovedModule("configparser", "ConfigParser"),
+    MovedModule("copyreg", "copy_reg"),
+    MovedModule("dbm_gnu", "gdbm", "dbm.gnu"),
+    MovedModule("_dummy_thread", "dummy_thread", "_dummy_thread"),
+    MovedModule("http_cookiejar", "cookielib", "http.cookiejar"),
+    MovedModule("http_cookies", "Cookie", "http.cookies"),
+    MovedModule("html_entities", "htmlentitydefs", "html.entities"),
+    MovedModule("html_parser", "HTMLParser", "html.parser"),
+    MovedModule("http_client", "httplib", "http.client"),
+    MovedModule("email_mime_base", "email.MIMEBase", "email.mime.base"),
+    MovedModule("email_mime_image", "email.MIMEImage", "email.mime.image"),
+    MovedModule("email_mime_multipart", "email.MIMEMultipart", "email.mime.multipart"),
+    MovedModule("email_mime_nonmultipart", "email.MIMENonMultipart", "email.mime.nonmultipart"),
+    MovedModule("email_mime_text", "email.MIMEText", "email.mime.text"),
+    MovedModule("BaseHTTPServer", "BaseHTTPServer", "http.server"),
+    MovedModule("CGIHTTPServer", "CGIHTTPServer", "http.server"),
+    MovedModule("SimpleHTTPServer", "SimpleHTTPServer", "http.server"),
+    MovedModule("cPickle", "cPickle", "pickle"),
+    MovedModule("queue", "Queue"),
+    MovedModule("reprlib", "repr"),
+    MovedModule("socketserver", "SocketServer"),
+    MovedModule("_thread", "thread", "_thread"),
+    MovedModule("tkinter", "Tkinter"),
+    MovedModule("tkinter_dialog", "Dialog", "tkinter.dialog"),
+    MovedModule("tkinter_filedialog", "FileDialog", "tkinter.filedialog"),
+    MovedModule("tkinter_scrolledtext", "ScrolledText", "tkinter.scrolledtext"),
+    MovedModule("tkinter_simpledialog", "SimpleDialog", "tkinter.simpledialog"),
+    MovedModule("tkinter_tix", "Tix", "tkinter.tix"),
+    MovedModule("tkinter_ttk", "ttk", "tkinter.ttk"),
+    MovedModule("tkinter_constants", "Tkconstants", "tkinter.constants"),
+    MovedModule("tkinter_dnd", "Tkdnd", "tkinter.dnd"),
+    MovedModule("tkinter_colorchooser", "tkColorChooser",
+                "tkinter.colorchooser"),
+    MovedModule("tkinter_commondialog", "tkCommonDialog",
+                "tkinter.commondialog"),
+    MovedModule("tkinter_tkfiledialog", "tkFileDialog", "tkinter.filedialog"),
+    MovedModule("tkinter_font", "tkFont", "tkinter.font"),
+    MovedModule("tkinter_messagebox", "tkMessageBox", "tkinter.messagebox"),
+    MovedModule("tkinter_tksimpledialog", "tkSimpleDialog",
+                "tkinter.simpledialog"),
+    MovedModule("urllib_parse", __name__ + ".moves.urllib_parse", "urllib.parse"),
+    MovedModule("urllib_error", __name__ + ".moves.urllib_error", "urllib.error"),
+    MovedModule("urllib", __name__ + ".moves.urllib", __name__ + ".moves.urllib"),
+    MovedModule("urllib_robotparser", "robotparser", "urllib.robotparser"),
+    MovedModule("xmlrpc_client", "xmlrpclib", "xmlrpc.client"),
+    MovedModule("xmlrpc_server", "SimpleXMLRPCServer", "xmlrpc.server"),
+]
+# Add windows specific modules.
+if sys.platform == "win32":
+    _moved_attributes += [
+        MovedModule("winreg", "_winreg"),
+    ]
+
+for attr in _moved_attributes:
+    setattr(_MovedItems, attr.name, attr)
+    if isinstance(attr, MovedModule):
+        _importer._add_module(attr, "moves." + attr.name)
+del attr
+
+_MovedItems._moved_attributes = _moved_attributes
+
+moves = _MovedItems(__name__ + ".moves")
+_importer._add_module(moves, "moves")
+
+
+class Module_six_moves_urllib_parse(_LazyModule):
+
+    """Lazy loading of moved objects in six.moves.urllib_parse"""
+
+
+_urllib_parse_moved_attributes = [
+    MovedAttribute("ParseResult", "urlparse", "urllib.parse"),
+    MovedAttribute("SplitResult", "urlparse", "urllib.parse"),
+    MovedAttribute("parse_qs", "urlparse", "urllib.parse"),
+    MovedAttribute("parse_qsl", "urlparse", "urllib.parse"),
+    MovedAttribute("urldefrag", "urlparse", "urllib.parse"),
+    MovedAttribute("urljoin", "urlparse", "urllib.parse"),
+    MovedAttribute("urlparse", "urlparse", "urllib.parse"),
+    MovedAttribute("urlsplit", "urlparse", "urllib.parse"),
+    MovedAttribute("urlunparse", "urlparse", "urllib.parse"),
+    MovedAttribute("urlunsplit", "urlparse", "urllib.parse"),
+    MovedAttribute("quote", "urllib", "urllib.parse"),
+    MovedAttribute("quote_plus", "urllib", "urllib.parse"),
+    MovedAttribute("unquote", "urllib", "urllib.parse"),
+    MovedAttribute("unquote_plus", "urllib", "urllib.parse"),
+    MovedAttribute("unquote_to_bytes", "urllib", "urllib.parse", "unquote", "unquote_to_bytes"),
+    MovedAttribute("urlencode", "urllib", "urllib.parse"),
+    MovedAttribute("splitquery", "urllib", "urllib.parse"),
+    MovedAttribute("splittag", "urllib", "urllib.parse"),
+    MovedAttribute("splituser", "urllib", "urllib.parse"),
+    MovedAttribute("splitvalue", "urllib", "urllib.parse"),
+    MovedAttribute("uses_fragment", "urlparse", "urllib.parse"),
+    MovedAttribute("uses_netloc", "urlparse", "urllib.parse"),
+    MovedAttribute("uses_params", "urlparse", "urllib.parse"),
+    MovedAttribute("uses_query", "urlparse", "urllib.parse"),
+    MovedAttribute("uses_relative", "urlparse", "urllib.parse"),
+]
+for attr in _urllib_parse_moved_attributes:
+    setattr(Module_six_moves_urllib_parse, attr.name, attr)
+del attr
+
+Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes
+
+_importer._add_module(Module_six_moves_urllib_parse(__name__ + ".moves.urllib_parse"),
+                      "moves.urllib_parse", "moves.urllib.parse")
+
+
+class Module_six_moves_urllib_error(_LazyModule):
+
+    """Lazy loading of moved objects in six.moves.urllib_error"""
+
+
+_urllib_error_moved_attributes = [
+    MovedAttribute("URLError", "urllib2", "urllib.error"),
+    MovedAttribute("HTTPError", "urllib2", "urllib.error"),
+    MovedAttribute("ContentTooShortError", "urllib", "urllib.error"),
+]
+for attr in _urllib_error_moved_attributes:
+    setattr(Module_six_moves_urllib_error, attr.name, attr)
+del attr
+
+Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes
+
+_importer._add_module(Module_six_moves_urllib_error(__name__ + ".moves.urllib.error"),
+                      "moves.urllib_error", "moves.urllib.error")
+
+
+class Module_six_moves_urllib_request(_LazyModule):
+
+    """Lazy loading of moved objects in six.moves.urllib_request"""
+
+
+_urllib_request_moved_attributes = [
+    MovedAttribute("urlopen", "urllib2", "urllib.request"),
+    MovedAttribute("install_opener", "urllib2", "urllib.request"),
+    MovedAttribute("build_opener", "urllib2", "urllib.request"),
+    MovedAttribute("pathname2url", "urllib", "urllib.request"),
+    MovedAttribute("url2pathname", "urllib", "urllib.request"),
+    MovedAttribute("getproxies", "urllib", "urllib.request"),
+    MovedAttribute("Request", "urllib2", "urllib.request"),
+    MovedAttribute("OpenerDirector", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPDefaultErrorHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPRedirectHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPCookieProcessor", "urllib2", "urllib.request"),
+    MovedAttribute("ProxyHandler", "urllib2", "urllib.request"),
+    MovedAttribute("BaseHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPPasswordMgr", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPPasswordMgrWithDefaultRealm", "urllib2", "urllib.request"),
+    MovedAttribute("AbstractBasicAuthHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPBasicAuthHandler", "urllib2", "urllib.request"),
+    MovedAttribute("ProxyBasicAuthHandler", "urllib2", "urllib.request"),
+    MovedAttribute("AbstractDigestAuthHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPDigestAuthHandler", "urllib2", "urllib.request"),
+    MovedAttribute("ProxyDigestAuthHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPSHandler", "urllib2", "urllib.request"),
+    MovedAttribute("FileHandler", "urllib2", "urllib.request"),
+    MovedAttribute("FTPHandler", "urllib2", "urllib.request"),
+    MovedAttribute("CacheFTPHandler", "urllib2", "urllib.request"),
+    MovedAttribute("UnknownHandler", "urllib2", "urllib.request"),
+    MovedAttribute("HTTPErrorProcessor", "urllib2", "urllib.request"),
+    MovedAttribute("urlretrieve", "urllib", "urllib.request"),
+    MovedAttribute("urlcleanup", "urllib", "urllib.request"),
+    MovedAttribute("URLopener", "urllib", "urllib.request"),
+    MovedAttribute("FancyURLopener", "urllib", "urllib.request"),
+    MovedAttribute("proxy_bypass", "urllib", "urllib.request"),
+    MovedAttribute("parse_http_list", "urllib2", "urllib.request"),
+    MovedAttribute("parse_keqv_list", "urllib2", "urllib.request"),
+]
+for attr in _urllib_request_moved_attributes:
+    setattr(Module_six_moves_urllib_request, attr.name, attr)
+del attr
+
+Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes
+
+_importer._add_module(Module_six_moves_urllib_request(__name__ + ".moves.urllib.request"),
+                      "moves.urllib_request", "moves.urllib.request")
+
+
+class Module_six_moves_urllib_response(_LazyModule):
+
+    """Lazy loading of moved objects in six.moves.urllib_response"""
+
+
+_urllib_response_moved_attributes = [
+    MovedAttribute("addbase", "urllib", "urllib.response"),
+    MovedAttribute("addclosehook", "urllib", "urllib.response"),
+    MovedAttribute("addinfo", "urllib", "urllib.response"),
+    MovedAttribute("addinfourl", "urllib", "urllib.response"),
+]
+for attr in _urllib_response_moved_attributes:
+    setattr(Module_six_moves_urllib_response, attr.name, attr)
+del attr
+
+Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes
+
+_importer._add_module(Module_six_moves_urllib_response(__name__ + ".moves.urllib.response"),
+                      "moves.urllib_response", "moves.urllib.response")
+
+
+class Module_six_moves_urllib_robotparser(_LazyModule):
+
+    """Lazy loading of moved objects in six.moves.urllib_robotparser"""
+
+
+_urllib_robotparser_moved_attributes = [
+    MovedAttribute("RobotFileParser", "robotparser", "urllib.robotparser"),
+]
+for attr in _urllib_robotparser_moved_attributes:
+    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)
+del attr
+
+Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes
+
+_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + ".moves.urllib.robotparser"),
+                      "moves.urllib_robotparser", "moves.urllib.robotparser")
+
+
+class Module_six_moves_urllib(types.ModuleType):
+
+    """Create a six.moves.urllib namespace that resembles the Python 3 namespace"""
+    __path__ = []  # mark as package
+    parse = _importer._get_module("moves.urllib_parse")
+    error = _importer._get_module("moves.urllib_error")
+    request = _importer._get_module("moves.urllib_request")
+    response = _importer._get_module("moves.urllib_response")
+    robotparser = _importer._get_module("moves.urllib_robotparser")
+
+    def __dir__(self):
+        return ['parse', 'error', 'request', 'response', 'robotparser']
+
+_importer._add_module(Module_six_moves_urllib(__name__ + ".moves.urllib"),
+                      "moves.urllib")
+
+
+def add_move(move):
+    """Add an item to six.moves."""
+    setattr(_MovedItems, move.name, move)
+
+
+def remove_move(name):
+    """Remove item from six.moves."""
+    try:
+        delattr(_MovedItems, name)
+    except AttributeError:
+        try:
+            del moves.__dict__[name]
+        except KeyError:
+            raise AttributeError("no such move, %r" % (name,))
+
+
+if PY3:
+    _meth_func = "__func__"
+    _meth_self = "__self__"
+
+    _func_closure = "__closure__"
+    _func_code = "__code__"
+    _func_defaults = "__defaults__"
+    _func_globals = "__globals__"
+else:
+    _meth_func = "im_func"
+    _meth_self = "im_self"
+
+    _func_closure = "func_closure"
+    _func_code = "func_code"
+    _func_defaults = "func_defaults"
+    _func_globals = "func_globals"
+
+
+try:
+    advance_iterator = next
+except NameError:
+    def advance_iterator(it):
+        return it.next()
+next = advance_iterator
+
+
+try:
+    callable = callable
+except NameError:
+    def callable(obj):
+        return any("__call__" in klass.__dict__ for klass in type(obj).__mro__)
+
+
+if PY3:
+    def get_unbound_function(unbound):
+        return unbound
+
+    create_bound_method = types.MethodType
+
+    def create_unbound_method(func, cls):
+        return func
+
+    Iterator = object
+else:
+    def get_unbound_function(unbound):
+        return unbound.im_func
+
+    def create_bound_method(func, obj):
+        return types.MethodType(func, obj, obj.__class__)
+
+    def create_unbound_method(func, cls):
+        return types.MethodType(func, None, cls)
+
+    class Iterator(object):
+
+        def next(self):
+            return type(self).__next__(self)
+
+    callable = callable
+_add_doc(get_unbound_function,
+         """Get the function out of a possibly unbound function""")
+
+
+get_method_function = operator.attrgetter(_meth_func)
+get_method_self = operator.attrgetter(_meth_self)
+get_function_closure = operator.attrgetter(_func_closure)
+get_function_code = operator.attrgetter(_func_code)
+get_function_defaults = operator.attrgetter(_func_defaults)
+get_function_globals = operator.attrgetter(_func_globals)
+
+
+if PY3:
+    def iterkeys(d, **kw):
+        return iter(d.keys(**kw))
+
+    def itervalues(d, **kw):
+        return iter(d.values(**kw))
+
+    def iteritems(d, **kw):
+        return iter(d.items(**kw))
+
+    def iterlists(d, **kw):
+        return iter(d.lists(**kw))
+
+    viewkeys = operator.methodcaller("keys")
+
+    viewvalues = operator.methodcaller("values")
+
+    viewitems = operator.methodcaller("items")
+else:
+    def iterkeys(d, **kw):
+        return d.iterkeys(**kw)
+
+    def itervalues(d, **kw):
+        return d.itervalues(**kw)
+
+    def iteritems(d, **kw):
+        return d.iteritems(**kw)
+
+    def iterlists(d, **kw):
+        return d.iterlists(**kw)
+
+    viewkeys = operator.methodcaller("viewkeys")
+
+    viewvalues = operator.methodcaller("viewvalues")
+
+    viewitems = operator.methodcaller("viewitems")
+
+_add_doc(iterkeys, "Return an iterator over the keys of a dictionary.")
+_add_doc(itervalues, "Return an iterator over the values of a dictionary.")
+_add_doc(iteritems,
+         "Return an iterator over the (key, value) pairs of a dictionary.")
+_add_doc(iterlists,
+         "Return an iterator over the (key, [values]) pairs of a dictionary.")
+
+
+if PY3:
+    def b(s):
+        return s.encode("latin-1")
+
+    def u(s):
+        return s
+    unichr = chr
+    import struct
+    int2byte = struct.Struct(">B").pack
+    del struct
+    byte2int = operator.itemgetter(0)
+    indexbytes = operator.getitem
+    iterbytes = iter
+    import io
+    StringIO = io.StringIO
+    BytesIO = io.BytesIO
+    _assertCountEqual = "assertCountEqual"
+    if sys.version_info[1] <= 1:
+        _assertRaisesRegex = "assertRaisesRegexp"
+        _assertRegex = "assertRegexpMatches"
+    else:
+        _assertRaisesRegex = "assertRaisesRegex"
+        _assertRegex = "assertRegex"
+else:
+    def b(s):
+        return s
+    # Workaround for standalone backslash
+
+    def u(s):
+        return unicode(s.replace(r'\\', r'\\\\'), "unicode_escape")
+    unichr = unichr
+    int2byte = chr
+
+    def byte2int(bs):
+        return ord(bs[0])
+
+    def indexbytes(buf, i):
+        return ord(buf[i])
+    iterbytes = functools.partial(itertools.imap, ord)
+    import StringIO
+    StringIO = BytesIO = StringIO.StringIO
+    _assertCountEqual = "assertItemsEqual"
+    _assertRaisesRegex = "assertRaisesRegexp"
+    _assertRegex = "assertRegexpMatches"
+_add_doc(b, """Byte literal""")
+_add_doc(u, """Text literal""")
+
+
+def assertCountEqual(self, *args, **kwargs):
+    return getattr(self, _assertCountEqual)(*args, **kwargs)
+
+
+def assertRaisesRegex(self, *args, **kwargs):
+    return getattr(self, _assertRaisesRegex)(*args, **kwargs)
+
+
+def assertRegex(self, *args, **kwargs):
+    return getattr(self, _assertRegex)(*args, **kwargs)
+
+
+if PY3:
+    exec_ = getattr(moves.builtins, "exec")
+
+    def reraise(tp, value, tb=None):
+        try:
+            if value is None:
+                value = tp()
+            if value.__traceback__ is not tb:
+                raise value.with_traceback(tb)
+            raise value
+        finally:
+            value = None
+            tb = None
+
+else:
+    def exec_(_code_, _globs_=None, _locs_=None):
+        """Execute code in a namespace."""
+        if _globs_ is None:
+            frame = sys._getframe(1)
+            _globs_ = frame.f_globals
+            if _locs_ is None:
+                _locs_ = frame.f_locals
+            del frame
+        elif _locs_ is None:
+            _locs_ = _globs_
+        exec("""exec _code_ in _globs_, _locs_""")
+
+    exec_("""def reraise(tp, value, tb=None):
+    try:
+        raise tp, value, tb
+    finally:
+        tb = None
+""")
+
+
+if sys.version_info[:2] == (3, 2):
+    exec_("""def raise_from(value, from_value):
+    try:
+        if from_value is None:
+            raise value
+        raise value from from_value
+    finally:
+        value = None
+""")
+elif sys.version_info[:2] > (3, 2):
+    exec_("""def raise_from(value, from_value):
+    try:
+        raise value from from_value
+    finally:
+        value = None
+""")
+else:
+    def raise_from(value, from_value):
+        raise value
+
+
+print_ = getattr(moves.builtins, "print", None)
+if print_ is None:
+    def print_(*args, **kwargs):
+        """The new-style print function for Python 2.4 and 2.5."""
+        fp = kwargs.pop("file", sys.stdout)
+        if fp is None:
+            return
+
+        def write(data):
+            if not isinstance(data, basestring):
+                data = str(data)
+            # If the file has an encoding, encode unicode with it.
+            if (isinstance(fp, file) and
+                    isinstance(data, unicode) and
+                    fp.encoding is not None):
+                errors = getattr(fp, "errors", None)
+                if errors is None:
+                    errors = "strict"
+                data = data.encode(fp.encoding, errors)
+            fp.write(data)
+        want_unicode = False
+        sep = kwargs.pop("sep", None)
+        if sep is not None:
+            if isinstance(sep, unicode):
+                want_unicode = True
+            elif not isinstance(sep, str):
+                raise TypeError("sep must be None or a string")
+        end = kwargs.pop("end", None)
+        if end is not None:
+            if isinstance(end, unicode):
+                want_unicode = True
+            elif not isinstance(end, str):
+                raise TypeError("end must be None or a string")
+        if kwargs:
+            raise TypeError("invalid keyword arguments to print()")
+        if not want_unicode:
+            for arg in args:
+                if isinstance(arg, unicode):
+                    want_unicode = True
+                    break
+        if want_unicode:
+            newline = unicode("\n")
+            space = unicode(" ")
+        else:
+            newline = "\n"
+            space = " "
+        if sep is None:
+            sep = space
+        if end is None:
+            end = newline
+        for i, arg in enumerate(args):
+            if i:
+                write(sep)
+            write(arg)
+        write(end)
+if sys.version_info[:2] < (3, 3):
+    _print = print_
+
+    def print_(*args, **kwargs):
+        fp = kwargs.get("file", sys.stdout)
+        flush = kwargs.pop("flush", False)
+        _print(*args, **kwargs)
+        if flush and fp is not None:
+            fp.flush()
+
+_add_doc(reraise, """Reraise an exception.""")
+
+if sys.version_info[0:2] < (3, 4):
+    def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,
+              updated=functools.WRAPPER_UPDATES):
+        def wrapper(f):
+            f = functools.wraps(wrapped, assigned, updated)(f)
+            f.__wrapped__ = wrapped
+            return f
+        return wrapper
+else:
+    wraps = functools.wraps
+
+
+def with_metaclass(meta, *bases):
+    """Create a base class with a metaclass."""
+    # This requires a bit of explanation: the basic idea is to make a dummy
+    # metaclass for one level of class instantiation that replaces itself with
+    # the actual metaclass.
+    class metaclass(type):
+
+        def __new__(cls, name, this_bases, d):
+            return meta(name, bases, d)
+
+        @classmethod
+        def __prepare__(cls, name, this_bases):
+            return meta.__prepare__(name, bases)
+    return type.__new__(metaclass, 'temporary_class', (), {})
+
+
+def add_metaclass(metaclass):
+    """Class decorator for creating a class with a metaclass."""
+    def wrapper(cls):
+        orig_vars = cls.__dict__.copy()
+        slots = orig_vars.get('__slots__')
+        if slots is not None:
+            if isinstance(slots, str):
+                slots = [slots]
+            for slots_var in slots:
+                orig_vars.pop(slots_var)
+        orig_vars.pop('__dict__', None)
+        orig_vars.pop('__weakref__', None)
+        return metaclass(cls.__name__, cls.__bases__, orig_vars)
+    return wrapper
+
+
+def python_2_unicode_compatible(klass):
+    """
+    A decorator that defines __unicode__ and __str__ methods under Python 2.
+    Under Python 3 it does nothing.
+
+    To support Python 2 and 3 with a single code base, define a __str__ method
+    returning text and apply this decorator to the class.
+    """
+    if PY2:
+        if '__str__' not in klass.__dict__:
+            raise ValueError("@python_2_unicode_compatible cannot be applied "
+                             "to %s because it doesn't define __str__()." %
+                             klass.__name__)
+        klass.__unicode__ = klass.__str__
+        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')
+    return klass
+
+
+# Complete the moves implementation.
+# This code is at the end of this module to speed up module loading.
+# Turn this module into a package.
+__path__ = []  # required for PEP 302 and PEP 451
+__package__ = __name__  # see PEP 366 @ReservedAssignment
+if globals().get("__spec__") is not None:
+    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable
+# Remove other six meta path importers, since they cause problems. This can
+# happen if six is removed from sys.modules and then reloaded. (Setuptools does
+# this for some reason.)
+if sys.meta_path:
+    for i, importer in enumerate(sys.meta_path):
+        # Here's some real nastiness: Another "instance" of the six module might
+        # be floating around. Therefore, we can't use isinstance() to check for
+        # the six meta path importer, since the other six instance will have
+        # inserted an importer with different class.
+        if (type(importer).__name__ == "_SixMetaPathImporter" and
+                importer.name == __name__):
+            del sys.meta_path[i]
+            break
+    del i, importer
+# Finally, add the importer to the meta path import hook.
+sys.meta_path.append(_importer)
Index: venv/Lib/site-packages/_pytest/capture.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/capture.py	(date 1543190976377)
+++ venv/Lib/site-packages/_pytest/capture.py	(date 1543190976377)
@@ -0,0 +1,786 @@
+"""
+per-test stdout/stderr capturing mechanism.
+
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import collections
+import contextlib
+import io
+import os
+import sys
+from io import UnsupportedOperation
+from tempfile import TemporaryFile
+
+import six
+
+import pytest
+from _pytest.compat import CaptureIO
+
+patchsysdict = {0: "stdin", 1: "stdout", 2: "stderr"}
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group._addoption(
+        "--capture",
+        action="store",
+        default="fd" if hasattr(os, "dup") else "sys",
+        metavar="method",
+        choices=["fd", "sys", "no"],
+        help="per-test capturing method: one of fd|sys|no.",
+    )
+    group._addoption(
+        "-s",
+        action="store_const",
+        const="no",
+        dest="capture",
+        help="shortcut for --capture=no.",
+    )
+
+
+@pytest.hookimpl(hookwrapper=True)
+def pytest_load_initial_conftests(early_config, parser, args):
+    ns = early_config.known_args_namespace
+    if ns.capture == "fd":
+        _py36_windowsconsoleio_workaround(sys.stdout)
+    _colorama_workaround()
+    _readline_workaround()
+    pluginmanager = early_config.pluginmanager
+    capman = CaptureManager(ns.capture)
+    pluginmanager.register(capman, "capturemanager")
+
+    # make sure that capturemanager is properly reset at final shutdown
+    early_config.add_cleanup(capman.stop_global_capturing)
+
+    # make sure logging does not raise exceptions at the end
+    def silence_logging_at_shutdown():
+        if "logging" in sys.modules:
+            sys.modules["logging"].raiseExceptions = False
+
+    early_config.add_cleanup(silence_logging_at_shutdown)
+
+    # finally trigger conftest loading but while capturing (issue93)
+    capman.start_global_capturing()
+    outcome = yield
+    capman.suspend_global_capture()
+    if outcome.excinfo is not None:
+        out, err = capman.read_global_capture()
+        sys.stdout.write(out)
+        sys.stderr.write(err)
+
+
+class CaptureManager(object):
+    """
+    Capture plugin, manages that the appropriate capture method is enabled/disabled during collection and each
+    test phase (setup, call, teardown). After each of those points, the captured output is obtained and
+    attached to the collection/runtest report.
+
+    There are two levels of capture:
+    * global: which is enabled by default and can be suppressed by the ``-s`` option. This is always enabled/disabled
+      during collection and each test phase.
+    * fixture: when a test function or one of its fixture depend on the ``capsys`` or ``capfd`` fixtures. In this
+      case special handling is needed to ensure the fixtures take precedence over the global capture.
+    """
+
+    def __init__(self, method):
+        self._method = method
+        self._global_capturing = None
+        self._current_item = None
+
+    def _getcapture(self, method):
+        if method == "fd":
+            return MultiCapture(out=True, err=True, Capture=FDCapture)
+        elif method == "sys":
+            return MultiCapture(out=True, err=True, Capture=SysCapture)
+        elif method == "no":
+            return MultiCapture(out=False, err=False, in_=False)
+        else:
+            raise ValueError("unknown capturing method: %r" % method)
+
+    # Global capturing control
+
+    def is_globally_capturing(self):
+        return self._method != "no"
+
+    def start_global_capturing(self):
+        assert self._global_capturing is None
+        self._global_capturing = self._getcapture(self._method)
+        self._global_capturing.start_capturing()
+
+    def stop_global_capturing(self):
+        if self._global_capturing is not None:
+            self._global_capturing.pop_outerr_to_orig()
+            self._global_capturing.stop_capturing()
+            self._global_capturing = None
+
+    def resume_global_capture(self):
+        self._global_capturing.resume_capturing()
+
+    def suspend_global_capture(self, in_=False):
+        cap = getattr(self, "_global_capturing", None)
+        if cap is not None:
+            cap.suspend_capturing(in_=in_)
+
+    def read_global_capture(self):
+        return self._global_capturing.readouterr()
+
+    # Fixture Control (it's just forwarding, think about removing this later)
+
+    def activate_fixture(self, item):
+        """If the current item is using ``capsys`` or ``capfd``, activate them so they take precedence over
+        the global capture.
+        """
+        fixture = getattr(item, "_capture_fixture", None)
+        if fixture is not None:
+            fixture._start()
+
+    def deactivate_fixture(self, item):
+        """Deactivates the ``capsys`` or ``capfd`` fixture of this item, if any."""
+        fixture = getattr(item, "_capture_fixture", None)
+        if fixture is not None:
+            fixture.close()
+
+    def suspend_fixture(self, item):
+        fixture = getattr(item, "_capture_fixture", None)
+        if fixture is not None:
+            fixture._suspend()
+
+    def resume_fixture(self, item):
+        fixture = getattr(item, "_capture_fixture", None)
+        if fixture is not None:
+            fixture._resume()
+
+    # Helper context managers
+
+    @contextlib.contextmanager
+    def global_and_fixture_disabled(self):
+        """Context manager to temporarily disables global and current fixture capturing."""
+        # Need to undo local capsys-et-al if exists before disabling global capture
+        self.suspend_fixture(self._current_item)
+        self.suspend_global_capture(in_=False)
+        try:
+            yield
+        finally:
+            self.resume_global_capture()
+            self.resume_fixture(self._current_item)
+
+    @contextlib.contextmanager
+    def item_capture(self, when, item):
+        self.resume_global_capture()
+        self.activate_fixture(item)
+        try:
+            yield
+        finally:
+            self.deactivate_fixture(item)
+            self.suspend_global_capture(in_=False)
+
+        out, err = self.read_global_capture()
+        item.add_report_section(when, "stdout", out)
+        item.add_report_section(when, "stderr", err)
+
+    # Hooks
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_make_collect_report(self, collector):
+        if isinstance(collector, pytest.File):
+            self.resume_global_capture()
+            outcome = yield
+            self.suspend_global_capture()
+            out, err = self.read_global_capture()
+            rep = outcome.get_result()
+            if out:
+                rep.sections.append(("Captured stdout", out))
+            if err:
+                rep.sections.append(("Captured stderr", err))
+        else:
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_protocol(self, item):
+        self._current_item = item
+        yield
+        self._current_item = None
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_setup(self, item):
+        with self.item_capture("setup", item):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_call(self, item):
+        with self.item_capture("call", item):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_teardown(self, item):
+        with self.item_capture("teardown", item):
+            yield
+
+    @pytest.hookimpl(tryfirst=True)
+    def pytest_keyboard_interrupt(self, excinfo):
+        self.stop_global_capturing()
+
+    @pytest.hookimpl(tryfirst=True)
+    def pytest_internalerror(self, excinfo):
+        self.stop_global_capturing()
+
+
+capture_fixtures = {"capfd", "capfdbinary", "capsys", "capsysbinary"}
+
+
+def _ensure_only_one_capture_fixture(request, name):
+    fixtures = set(request.fixturenames) & capture_fixtures - {name}
+    if fixtures:
+        fixtures = sorted(fixtures)
+        fixtures = fixtures[0] if len(fixtures) == 1 else fixtures
+        raise request.raiseerror(
+            "cannot use {} and {} at the same time".format(fixtures, name)
+        )
+
+
+@pytest.fixture
+def capsys(request):
+    """Enable capturing of writes to ``sys.stdout`` and ``sys.stderr`` and make
+    captured output available via ``capsys.readouterr()`` method calls
+    which return a ``(out, err)`` namedtuple.  ``out`` and ``err`` will be ``text``
+    objects.
+    """
+    _ensure_only_one_capture_fixture(request, "capsys")
+    with _install_capture_fixture_on_item(request, SysCapture) as fixture:
+        yield fixture
+
+
+@pytest.fixture
+def capsysbinary(request):
+    """Enable capturing of writes to ``sys.stdout`` and ``sys.stderr`` and make
+    captured output available via ``capsys.readouterr()`` method calls
+    which return a ``(out, err)`` tuple.  ``out`` and ``err`` will be ``bytes``
+    objects.
+    """
+    _ensure_only_one_capture_fixture(request, "capsysbinary")
+    # Currently, the implementation uses the python3 specific `.buffer`
+    # property of CaptureIO.
+    if sys.version_info < (3,):
+        raise request.raiseerror("capsysbinary is only supported on python 3")
+    with _install_capture_fixture_on_item(request, SysCaptureBinary) as fixture:
+        yield fixture
+
+
+@pytest.fixture
+def capfd(request):
+    """Enable capturing of writes to file descriptors ``1`` and ``2`` and make
+    captured output available via ``capfd.readouterr()`` method calls
+    which return a ``(out, err)`` tuple.  ``out`` and ``err`` will be ``text``
+    objects.
+    """
+    _ensure_only_one_capture_fixture(request, "capfd")
+    if not hasattr(os, "dup"):
+        pytest.skip(
+            "capfd fixture needs os.dup function which is not available in this system"
+        )
+    with _install_capture_fixture_on_item(request, FDCapture) as fixture:
+        yield fixture
+
+
+@pytest.fixture
+def capfdbinary(request):
+    """Enable capturing of write to file descriptors 1 and 2 and make
+    captured output available via ``capfdbinary.readouterr`` method calls
+    which return a ``(out, err)`` tuple.  ``out`` and ``err`` will be
+    ``bytes`` objects.
+    """
+    _ensure_only_one_capture_fixture(request, "capfdbinary")
+    if not hasattr(os, "dup"):
+        pytest.skip(
+            "capfdbinary fixture needs os.dup function which is not available in this system"
+        )
+    with _install_capture_fixture_on_item(request, FDCaptureBinary) as fixture:
+        yield fixture
+
+
+@contextlib.contextmanager
+def _install_capture_fixture_on_item(request, capture_class):
+    """
+    Context manager which creates a ``CaptureFixture`` instance and "installs" it on
+    the item/node of the given request. Used by ``capsys`` and ``capfd``.
+
+    The CaptureFixture is added as attribute of the item because it needs to accessed
+    by ``CaptureManager`` during its ``pytest_runtest_*`` hooks.
+    """
+    request.node._capture_fixture = fixture = CaptureFixture(capture_class, request)
+    capmanager = request.config.pluginmanager.getplugin("capturemanager")
+    # need to active this fixture right away in case it is being used by another fixture (setup phase)
+    # if this fixture is being used only by a test function (call phase), then we wouldn't need this
+    # activation, but it doesn't hurt
+    capmanager.activate_fixture(request.node)
+    yield fixture
+    fixture.close()
+    del request.node._capture_fixture
+
+
+class CaptureFixture(object):
+    """
+    Object returned by :py:func:`capsys`, :py:func:`capsysbinary`, :py:func:`capfd` and :py:func:`capfdbinary`
+    fixtures.
+    """
+
+    def __init__(self, captureclass, request):
+        self.captureclass = captureclass
+        self.request = request
+        self._capture = None
+        self._captured_out = self.captureclass.EMPTY_BUFFER
+        self._captured_err = self.captureclass.EMPTY_BUFFER
+
+    def _start(self):
+        # Start if not started yet
+        if getattr(self, "_capture", None) is None:
+            self._capture = MultiCapture(
+                out=True, err=True, in_=False, Capture=self.captureclass
+            )
+            self._capture.start_capturing()
+
+    def close(self):
+        if self._capture is not None:
+            out, err = self._capture.pop_outerr_to_orig()
+            self._captured_out += out
+            self._captured_err += err
+            self._capture.stop_capturing()
+            self._capture = None
+
+    def readouterr(self):
+        """Read and return the captured output so far, resetting the internal buffer.
+
+        :return: captured content as a namedtuple with  ``out`` and ``err`` string attributes
+        """
+        captured_out, captured_err = self._captured_out, self._captured_err
+        if self._capture is not None:
+            out, err = self._capture.readouterr()
+            captured_out += out
+            captured_err += err
+        self._captured_out = self.captureclass.EMPTY_BUFFER
+        self._captured_err = self.captureclass.EMPTY_BUFFER
+        return CaptureResult(captured_out, captured_err)
+
+    def _suspend(self):
+        """Suspends this fixture's own capturing temporarily."""
+        self._capture.suspend_capturing()
+
+    def _resume(self):
+        """Resumes this fixture's own capturing temporarily."""
+        self._capture.resume_capturing()
+
+    @contextlib.contextmanager
+    def disabled(self):
+        """Temporarily disables capture while inside the 'with' block."""
+        capmanager = self.request.config.pluginmanager.getplugin("capturemanager")
+        with capmanager.global_and_fixture_disabled():
+            yield
+
+
+def safe_text_dupfile(f, mode, default_encoding="UTF8"):
+    """ return an open text file object that's a duplicate of f on the
+        FD-level if possible.
+    """
+    encoding = getattr(f, "encoding", None)
+    try:
+        fd = f.fileno()
+    except Exception:
+        if "b" not in getattr(f, "mode", "") and hasattr(f, "encoding"):
+            # we seem to have a text stream, let's just use it
+            return f
+    else:
+        newfd = os.dup(fd)
+        if "b" not in mode:
+            mode += "b"
+        f = os.fdopen(newfd, mode, 0)  # no buffering
+    return EncodedFile(f, encoding or default_encoding)
+
+
+class EncodedFile(object):
+    errors = "strict"  # possibly needed by py3 code (issue555)
+
+    def __init__(self, buffer, encoding):
+        self.buffer = buffer
+        self.encoding = encoding
+
+    def write(self, obj):
+        if isinstance(obj, six.text_type):
+            obj = obj.encode(self.encoding, "replace")
+        self.buffer.write(obj)
+
+    def writelines(self, linelist):
+        data = "".join(linelist)
+        self.write(data)
+
+    @property
+    def name(self):
+        """Ensure that file.name is a string."""
+        return repr(self.buffer)
+
+    def __getattr__(self, name):
+        return getattr(object.__getattribute__(self, "buffer"), name)
+
+
+CaptureResult = collections.namedtuple("CaptureResult", ["out", "err"])
+
+
+class MultiCapture(object):
+    out = err = in_ = None
+
+    def __init__(self, out=True, err=True, in_=True, Capture=None):
+        if in_:
+            self.in_ = Capture(0)
+        if out:
+            self.out = Capture(1)
+        if err:
+            self.err = Capture(2)
+
+    def start_capturing(self):
+        if self.in_:
+            self.in_.start()
+        if self.out:
+            self.out.start()
+        if self.err:
+            self.err.start()
+
+    def pop_outerr_to_orig(self):
+        """ pop current snapshot out/err capture and flush to orig streams. """
+        out, err = self.readouterr()
+        if out:
+            self.out.writeorg(out)
+        if err:
+            self.err.writeorg(err)
+        return out, err
+
+    def suspend_capturing(self, in_=False):
+        if self.out:
+            self.out.suspend()
+        if self.err:
+            self.err.suspend()
+        if in_ and self.in_:
+            self.in_.suspend()
+            self._in_suspended = True
+
+    def resume_capturing(self):
+        if self.out:
+            self.out.resume()
+        if self.err:
+            self.err.resume()
+        if hasattr(self, "_in_suspended"):
+            self.in_.resume()
+            del self._in_suspended
+
+    def stop_capturing(self):
+        """ stop capturing and reset capturing streams """
+        if hasattr(self, "_reset"):
+            raise ValueError("was already stopped")
+        self._reset = True
+        if self.out:
+            self.out.done()
+        if self.err:
+            self.err.done()
+        if self.in_:
+            self.in_.done()
+
+    def readouterr(self):
+        """ return snapshot unicode value of stdout/stderr capturings. """
+        return CaptureResult(
+            self.out.snap() if self.out is not None else "",
+            self.err.snap() if self.err is not None else "",
+        )
+
+
+class NoCapture(object):
+    EMPTY_BUFFER = None
+    __init__ = start = done = suspend = resume = lambda *args: None
+
+
+class FDCaptureBinary(object):
+    """Capture IO to/from a given os-level filedescriptor.
+
+    snap() produces `bytes`
+    """
+
+    EMPTY_BUFFER = b""
+
+    def __init__(self, targetfd, tmpfile=None):
+        self.targetfd = targetfd
+        try:
+            self.targetfd_save = os.dup(self.targetfd)
+        except OSError:
+            self.start = lambda: None
+            self.done = lambda: None
+        else:
+            if targetfd == 0:
+                assert not tmpfile, "cannot set tmpfile with stdin"
+                tmpfile = open(os.devnull, "r")
+                self.syscapture = SysCapture(targetfd)
+            else:
+                if tmpfile is None:
+                    f = TemporaryFile()
+                    with f:
+                        tmpfile = safe_text_dupfile(f, mode="wb+")
+                if targetfd in patchsysdict:
+                    self.syscapture = SysCapture(targetfd, tmpfile)
+                else:
+                    self.syscapture = NoCapture()
+            self.tmpfile = tmpfile
+            self.tmpfile_fd = tmpfile.fileno()
+
+    def __repr__(self):
+        return "<FDCapture %s oldfd=%s>" % (self.targetfd, self.targetfd_save)
+
+    def start(self):
+        """ Start capturing on targetfd using memorized tmpfile. """
+        try:
+            os.fstat(self.targetfd_save)
+        except (AttributeError, OSError):
+            raise ValueError("saved filedescriptor not valid anymore")
+        os.dup2(self.tmpfile_fd, self.targetfd)
+        self.syscapture.start()
+
+    def snap(self):
+        self.tmpfile.seek(0)
+        res = self.tmpfile.read()
+        self.tmpfile.seek(0)
+        self.tmpfile.truncate()
+        return res
+
+    def done(self):
+        """ stop capturing, restore streams, return original capture file,
+        seeked to position zero. """
+        targetfd_save = self.__dict__.pop("targetfd_save")
+        os.dup2(targetfd_save, self.targetfd)
+        os.close(targetfd_save)
+        self.syscapture.done()
+        _attempt_to_close_capture_file(self.tmpfile)
+
+    def suspend(self):
+        self.syscapture.suspend()
+        os.dup2(self.targetfd_save, self.targetfd)
+
+    def resume(self):
+        self.syscapture.resume()
+        os.dup2(self.tmpfile_fd, self.targetfd)
+
+    def writeorg(self, data):
+        """ write to original file descriptor. """
+        if isinstance(data, six.text_type):
+            data = data.encode("utf8")  # XXX use encoding of original stream
+        os.write(self.targetfd_save, data)
+
+
+class FDCapture(FDCaptureBinary):
+    """Capture IO to/from a given os-level filedescriptor.
+
+    snap() produces text
+    """
+
+    EMPTY_BUFFER = str()
+
+    def snap(self):
+        res = FDCaptureBinary.snap(self)
+        enc = getattr(self.tmpfile, "encoding", None)
+        if enc and isinstance(res, bytes):
+            res = six.text_type(res, enc, "replace")
+        return res
+
+
+class SysCapture(object):
+
+    EMPTY_BUFFER = str()
+
+    def __init__(self, fd, tmpfile=None):
+        name = patchsysdict[fd]
+        self._old = getattr(sys, name)
+        self.name = name
+        if tmpfile is None:
+            if name == "stdin":
+                tmpfile = DontReadFromInput()
+            else:
+                tmpfile = CaptureIO()
+        self.tmpfile = tmpfile
+
+    def start(self):
+        setattr(sys, self.name, self.tmpfile)
+
+    def snap(self):
+        res = self.tmpfile.getvalue()
+        self.tmpfile.seek(0)
+        self.tmpfile.truncate()
+        return res
+
+    def done(self):
+        setattr(sys, self.name, self._old)
+        del self._old
+        _attempt_to_close_capture_file(self.tmpfile)
+
+    def suspend(self):
+        setattr(sys, self.name, self._old)
+
+    def resume(self):
+        setattr(sys, self.name, self.tmpfile)
+
+    def writeorg(self, data):
+        self._old.write(data)
+        self._old.flush()
+
+
+class SysCaptureBinary(SysCapture):
+    EMPTY_BUFFER = b""
+
+    def snap(self):
+        res = self.tmpfile.buffer.getvalue()
+        self.tmpfile.seek(0)
+        self.tmpfile.truncate()
+        return res
+
+
+class DontReadFromInput(six.Iterator):
+    """Temporary stub class.  Ideally when stdin is accessed, the
+    capturing should be turned off, with possibly all data captured
+    so far sent to the screen.  This should be configurable, though,
+    because in automated test runs it is better to crash than
+    hang indefinitely.
+    """
+
+    encoding = None
+
+    def read(self, *args):
+        raise IOError("reading from stdin while output is captured")
+
+    readline = read
+    readlines = read
+    __next__ = read
+
+    def __iter__(self):
+        return self
+
+    def fileno(self):
+        raise UnsupportedOperation("redirected stdin is pseudofile, has no fileno()")
+
+    def isatty(self):
+        return False
+
+    def close(self):
+        pass
+
+    @property
+    def buffer(self):
+        if sys.version_info >= (3, 0):
+            return self
+        else:
+            raise AttributeError("redirected stdin has no attribute buffer")
+
+
+def _colorama_workaround():
+    """
+    Ensure colorama is imported so that it attaches to the correct stdio
+    handles on Windows.
+
+    colorama uses the terminal on import time. So if something does the
+    first import of colorama while I/O capture is active, colorama will
+    fail in various ways.
+    """
+
+    if not sys.platform.startswith("win32"):
+        return
+    try:
+        import colorama  # noqa
+    except ImportError:
+        pass
+
+
+def _readline_workaround():
+    """
+    Ensure readline is imported so that it attaches to the correct stdio
+    handles on Windows.
+
+    Pdb uses readline support where available--when not running from the Python
+    prompt, the readline module is not imported until running the pdb REPL.  If
+    running pytest with the --pdb option this means the readline module is not
+    imported until after I/O capture has been started.
+
+    This is a problem for pyreadline, which is often used to implement readline
+    support on Windows, as it does not attach to the correct handles for stdout
+    and/or stdin if they have been redirected by the FDCapture mechanism.  This
+    workaround ensures that readline is imported before I/O capture is setup so
+    that it can attach to the actual stdin/out for the console.
+
+    See https://github.com/pytest-dev/pytest/pull/1281
+    """
+
+    if not sys.platform.startswith("win32"):
+        return
+    try:
+        import readline  # noqa
+    except ImportError:
+        pass
+
+
+def _py36_windowsconsoleio_workaround(stream):
+    """
+    Python 3.6 implemented unicode console handling for Windows. This works
+    by reading/writing to the raw console handle using
+    ``{Read,Write}ConsoleW``.
+
+    The problem is that we are going to ``dup2`` over the stdio file
+    descriptors when doing ``FDCapture`` and this will ``CloseHandle`` the
+    handles used by Python to write to the console. Though there is still some
+    weirdness and the console handle seems to only be closed randomly and not
+    on the first call to ``CloseHandle``, or maybe it gets reopened with the
+    same handle value when we suspend capturing.
+
+    The workaround in this case will reopen stdio with a different fd which
+    also means a different handle by replicating the logic in
+    "Py_lifecycle.c:initstdio/create_stdio".
+
+    :param stream: in practice ``sys.stdout`` or ``sys.stderr``, but given
+        here as parameter for unittesting purposes.
+
+    See https://github.com/pytest-dev/py/issues/103
+    """
+    if not sys.platform.startswith("win32") or sys.version_info[:2] < (3, 6):
+        return
+
+    # bail out if ``stream`` doesn't seem like a proper ``io`` stream (#2666)
+    if not hasattr(stream, "buffer"):
+        return
+
+    buffered = hasattr(stream.buffer, "raw")
+    raw_stdout = stream.buffer.raw if buffered else stream.buffer
+
+    if not isinstance(raw_stdout, io._WindowsConsoleIO):
+        return
+
+    def _reopen_stdio(f, mode):
+        if not buffered and mode[0] == "w":
+            buffering = 0
+        else:
+            buffering = -1
+
+        return io.TextIOWrapper(
+            open(os.dup(f.fileno()), mode, buffering),
+            f.encoding,
+            f.errors,
+            f.newlines,
+            f.line_buffering,
+        )
+
+    sys.__stdin__ = sys.stdin = _reopen_stdio(sys.stdin, "rb")
+    sys.__stdout__ = sys.stdout = _reopen_stdio(sys.stdout, "wb")
+    sys.__stderr__ = sys.stderr = _reopen_stdio(sys.stderr, "wb")
+
+
+def _attempt_to_close_capture_file(f):
+    """Suppress IOError when closing the temporary file used for capturing streams in py27 (#2370)"""
+    if six.PY2:
+        try:
+            f.close()
+        except IOError:
+            pass
+    else:
+        f.close()
Index: venv/Lib/site-packages/_pytest/logging.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/logging.py	(date 1543190976390)
+++ venv/Lib/site-packages/_pytest/logging.py	(date 1543190976390)
@@ -0,0 +1,625 @@
+""" Access and control log capturing. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import logging
+import re
+from contextlib import contextmanager
+
+import py
+import six
+
+import pytest
+from _pytest.compat import dummy_context_manager
+from _pytest.config import create_terminal_writer
+
+
+DEFAULT_LOG_FORMAT = "%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s"
+DEFAULT_LOG_DATE_FORMAT = "%H:%M:%S"
+
+
+class ColoredLevelFormatter(logging.Formatter):
+    """
+    Colorize the %(levelname)..s part of the log format passed to __init__.
+    """
+
+    LOGLEVEL_COLOROPTS = {
+        logging.CRITICAL: {"red"},
+        logging.ERROR: {"red", "bold"},
+        logging.WARNING: {"yellow"},
+        logging.WARN: {"yellow"},
+        logging.INFO: {"green"},
+        logging.DEBUG: {"purple"},
+        logging.NOTSET: set(),
+    }
+    LEVELNAME_FMT_REGEX = re.compile(r"%\(levelname\)([+-]?\d*s)")
+
+    def __init__(self, terminalwriter, *args, **kwargs):
+        super(ColoredLevelFormatter, self).__init__(*args, **kwargs)
+        if six.PY2:
+            self._original_fmt = self._fmt
+        else:
+            self._original_fmt = self._style._fmt
+        self._level_to_fmt_mapping = {}
+
+        levelname_fmt_match = self.LEVELNAME_FMT_REGEX.search(self._fmt)
+        if not levelname_fmt_match:
+            return
+        levelname_fmt = levelname_fmt_match.group()
+
+        for level, color_opts in self.LOGLEVEL_COLOROPTS.items():
+            formatted_levelname = levelname_fmt % {
+                "levelname": logging.getLevelName(level)
+            }
+
+            # add ANSI escape sequences around the formatted levelname
+            color_kwargs = {name: True for name in color_opts}
+            colorized_formatted_levelname = terminalwriter.markup(
+                formatted_levelname, **color_kwargs
+            )
+            self._level_to_fmt_mapping[level] = self.LEVELNAME_FMT_REGEX.sub(
+                colorized_formatted_levelname, self._fmt
+            )
+
+    def format(self, record):
+        fmt = self._level_to_fmt_mapping.get(record.levelno, self._original_fmt)
+        if six.PY2:
+            self._fmt = fmt
+        else:
+            self._style._fmt = fmt
+        return super(ColoredLevelFormatter, self).format(record)
+
+
+def get_option_ini(config, *names):
+    for name in names:
+        ret = config.getoption(name)  # 'default' arg won't work as expected
+        if ret is None:
+            ret = config.getini(name)
+        if ret:
+            return ret
+
+
+def pytest_addoption(parser):
+    """Add options to control log capturing."""
+    group = parser.getgroup("logging")
+
+    def add_option_ini(option, dest, default=None, type=None, **kwargs):
+        parser.addini(
+            dest, default=default, type=type, help="default value for " + option
+        )
+        group.addoption(option, dest=dest, **kwargs)
+
+    add_option_ini(
+        "--no-print-logs",
+        dest="log_print",
+        action="store_const",
+        const=False,
+        default=True,
+        type="bool",
+        help="disable printing caught logs on failed tests.",
+    )
+    add_option_ini(
+        "--log-level",
+        dest="log_level",
+        default=None,
+        help="logging level used by the logging module",
+    )
+    add_option_ini(
+        "--log-format",
+        dest="log_format",
+        default=DEFAULT_LOG_FORMAT,
+        help="log format as used by the logging module.",
+    )
+    add_option_ini(
+        "--log-date-format",
+        dest="log_date_format",
+        default=DEFAULT_LOG_DATE_FORMAT,
+        help="log date format as used by the logging module.",
+    )
+    parser.addini(
+        "log_cli",
+        default=False,
+        type="bool",
+        help='enable log display during test run (also known as "live logging").',
+    )
+    add_option_ini(
+        "--log-cli-level", dest="log_cli_level", default=None, help="cli logging level."
+    )
+    add_option_ini(
+        "--log-cli-format",
+        dest="log_cli_format",
+        default=None,
+        help="log format as used by the logging module.",
+    )
+    add_option_ini(
+        "--log-cli-date-format",
+        dest="log_cli_date_format",
+        default=None,
+        help="log date format as used by the logging module.",
+    )
+    add_option_ini(
+        "--log-file",
+        dest="log_file",
+        default=None,
+        help="path to a file when logging will be written to.",
+    )
+    add_option_ini(
+        "--log-file-level",
+        dest="log_file_level",
+        default=None,
+        help="log file logging level.",
+    )
+    add_option_ini(
+        "--log-file-format",
+        dest="log_file_format",
+        default=DEFAULT_LOG_FORMAT,
+        help="log format as used by the logging module.",
+    )
+    add_option_ini(
+        "--log-file-date-format",
+        dest="log_file_date_format",
+        default=DEFAULT_LOG_DATE_FORMAT,
+        help="log date format as used by the logging module.",
+    )
+
+
+@contextmanager
+def catching_logs(handler, formatter=None, level=None):
+    """Context manager that prepares the whole logging machinery properly."""
+    root_logger = logging.getLogger()
+
+    if formatter is not None:
+        handler.setFormatter(formatter)
+    if level is not None:
+        handler.setLevel(level)
+
+    # Adding the same handler twice would confuse logging system.
+    # Just don't do that.
+    add_new_handler = handler not in root_logger.handlers
+
+    if add_new_handler:
+        root_logger.addHandler(handler)
+    if level is not None:
+        orig_level = root_logger.level
+        root_logger.setLevel(min(orig_level, level))
+    try:
+        yield handler
+    finally:
+        if level is not None:
+            root_logger.setLevel(orig_level)
+        if add_new_handler:
+            root_logger.removeHandler(handler)
+
+
+class LogCaptureHandler(logging.StreamHandler):
+    """A logging handler that stores log records and the log text."""
+
+    def __init__(self):
+        """Creates a new log handler."""
+        logging.StreamHandler.__init__(self, py.io.TextIO())
+        self.records = []
+
+    def emit(self, record):
+        """Keep the log records in a list in addition to the log text."""
+        self.records.append(record)
+        logging.StreamHandler.emit(self, record)
+
+    def reset(self):
+        self.records = []
+        self.stream = py.io.TextIO()
+
+
+class LogCaptureFixture(object):
+    """Provides access and control of log capturing."""
+
+    def __init__(self, item):
+        """Creates a new funcarg."""
+        self._item = item
+        # dict of log name -> log level
+        self._initial_log_levels = {}  # type: Dict[str, int]
+
+    def _finalize(self):
+        """Finalizes the fixture.
+
+        This restores the log levels changed by :meth:`set_level`.
+        """
+        # restore log levels
+        for logger_name, level in self._initial_log_levels.items():
+            logger = logging.getLogger(logger_name)
+            logger.setLevel(level)
+
+    @property
+    def handler(self):
+        """
+        :rtype: LogCaptureHandler
+        """
+        return self._item.catch_log_handler
+
+    def get_records(self, when):
+        """
+        Get the logging records for one of the possible test phases.
+
+        :param str when:
+            Which test phase to obtain the records from. Valid values are: "setup", "call" and "teardown".
+
+        :rtype: List[logging.LogRecord]
+        :return: the list of captured records at the given stage
+
+        .. versionadded:: 3.4
+        """
+        handler = self._item.catch_log_handlers.get(when)
+        if handler:
+            return handler.records
+        else:
+            return []
+
+    @property
+    def text(self):
+        """Returns the log text."""
+        return self.handler.stream.getvalue()
+
+    @property
+    def records(self):
+        """Returns the list of log records."""
+        return self.handler.records
+
+    @property
+    def record_tuples(self):
+        """Returns a list of a stripped down version of log records intended
+        for use in assertion comparison.
+
+        The format of the tuple is:
+
+            (logger_name, log_level, message)
+        """
+        return [(r.name, r.levelno, r.getMessage()) for r in self.records]
+
+    @property
+    def messages(self):
+        """Returns a list of format-interpolated log messages.
+
+        Unlike 'records', which contains the format string and parameters for interpolation, log messages in this list
+        are all interpolated.
+        Unlike 'text', which contains the output from the handler, log messages in this list are unadorned with
+        levels, timestamps, etc, making exact comparisons more reliable.
+
+        Note that traceback or stack info (from :func:`logging.exception` or the `exc_info` or `stack_info` arguments
+        to the logging functions) is not included, as this is added by the formatter in the handler.
+
+        .. versionadded:: 3.7
+        """
+        return [r.getMessage() for r in self.records]
+
+    def clear(self):
+        """Reset the list of log records and the captured log text."""
+        self.handler.reset()
+
+    def set_level(self, level, logger=None):
+        """Sets the level for capturing of logs. The level will be restored to its previous value at the end of
+        the test.
+
+        :param int level: the logger to level.
+        :param str logger: the logger to update the level. If not given, the root logger level is updated.
+
+        .. versionchanged:: 3.4
+            The levels of the loggers changed by this function will be restored to their initial values at the
+            end of the test.
+        """
+        logger_name = logger
+        logger = logging.getLogger(logger_name)
+        # save the original log-level to restore it during teardown
+        self._initial_log_levels.setdefault(logger_name, logger.level)
+        logger.setLevel(level)
+
+    @contextmanager
+    def at_level(self, level, logger=None):
+        """Context manager that sets the level for capturing of logs. After the end of the 'with' statement the
+        level is restored to its original value.
+
+        :param int level: the logger to level.
+        :param str logger: the logger to update the level. If not given, the root logger level is updated.
+        """
+        logger = logging.getLogger(logger)
+        orig_level = logger.level
+        logger.setLevel(level)
+        try:
+            yield
+        finally:
+            logger.setLevel(orig_level)
+
+
+@pytest.fixture
+def caplog(request):
+    """Access and control log capturing.
+
+    Captured logs are available through the following properties/methods::
+
+    * caplog.text            -> string containing formatted log output
+    * caplog.records         -> list of logging.LogRecord instances
+    * caplog.record_tuples   -> list of (logger_name, level, message) tuples
+    * caplog.clear()         -> clear captured records and formatted log output string
+    """
+    result = LogCaptureFixture(request.node)
+    yield result
+    result._finalize()
+
+
+def get_actual_log_level(config, *setting_names):
+    """Return the actual logging level."""
+
+    for setting_name in setting_names:
+        log_level = config.getoption(setting_name)
+        if log_level is None:
+            log_level = config.getini(setting_name)
+        if log_level:
+            break
+    else:
+        return
+
+    if isinstance(log_level, six.string_types):
+        log_level = log_level.upper()
+    try:
+        return int(getattr(logging, log_level, log_level))
+    except ValueError:
+        # Python logging does not recognise this as a logging level
+        raise pytest.UsageError(
+            "'{}' is not recognized as a logging level name for "
+            "'{}'. Please consider passing the "
+            "logging level num instead.".format(log_level, setting_name)
+        )
+
+
+def pytest_configure(config):
+    config.pluginmanager.register(LoggingPlugin(config), "logging-plugin")
+
+
+class LoggingPlugin(object):
+    """Attaches to the logging module and captures log messages for each test.
+    """
+
+    def __init__(self, config):
+        """Creates a new plugin to capture log messages.
+
+        The formatter can be safely shared across all handlers so
+        create a single one for the entire test session here.
+        """
+        self._config = config
+
+        # enable verbose output automatically if live logging is enabled
+        if self._log_cli_enabled() and not config.getoption("verbose"):
+            # sanity check: terminal reporter should not have been loaded at this point
+            assert self._config.pluginmanager.get_plugin("terminalreporter") is None
+            config.option.verbose = 1
+
+        self.print_logs = get_option_ini(config, "log_print")
+        self.formatter = logging.Formatter(
+            get_option_ini(config, "log_format"),
+            get_option_ini(config, "log_date_format"),
+        )
+        self.log_level = get_actual_log_level(config, "log_level")
+
+        log_file = get_option_ini(config, "log_file")
+        if log_file:
+            self.log_file_level = get_actual_log_level(config, "log_file_level")
+
+            log_file_format = get_option_ini(config, "log_file_format", "log_format")
+            log_file_date_format = get_option_ini(
+                config, "log_file_date_format", "log_date_format"
+            )
+            # Each pytest runtests session will write to a clean logfile
+            self.log_file_handler = logging.FileHandler(
+                log_file, mode="w", encoding="UTF-8"
+            )
+            log_file_formatter = logging.Formatter(
+                log_file_format, datefmt=log_file_date_format
+            )
+            self.log_file_handler.setFormatter(log_file_formatter)
+        else:
+            self.log_file_handler = None
+
+        self.log_cli_handler = None
+
+    def _log_cli_enabled(self):
+        """Return True if log_cli should be considered enabled, either explicitly
+        or because --log-cli-level was given in the command-line.
+        """
+        return self._config.getoption(
+            "--log-cli-level"
+        ) is not None or self._config.getini("log_cli")
+
+    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    def pytest_collection(self):
+        # This has to be called before the first log message is logged,
+        # so we can access the terminal reporter plugin.
+        self._setup_cli_logging()
+
+        with self.live_logs_context():
+            if self.log_cli_handler:
+                self.log_cli_handler.set_when("collection")
+
+            if self.log_file_handler is not None:
+                with catching_logs(self.log_file_handler, level=self.log_file_level):
+                    yield
+            else:
+                yield
+
+    @contextmanager
+    def _runtest_for(self, item, when):
+        """Implements the internals of pytest_runtest_xxx() hook."""
+        with catching_logs(
+            LogCaptureHandler(), formatter=self.formatter, level=self.log_level
+        ) as log_handler:
+            if self.log_cli_handler:
+                self.log_cli_handler.set_when(when)
+
+            if item is None:
+                yield  # run the test
+                return
+
+            if not hasattr(item, "catch_log_handlers"):
+                item.catch_log_handlers = {}
+            item.catch_log_handlers[when] = log_handler
+            item.catch_log_handler = log_handler
+            try:
+                yield  # run test
+            finally:
+                if when == "teardown":
+                    del item.catch_log_handler
+                    del item.catch_log_handlers
+
+            if self.print_logs:
+                # Add a captured log section to the report.
+                log = log_handler.stream.getvalue().strip()
+                item.add_report_section(when, "log", log)
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_setup(self, item):
+        with self._runtest_for(item, "setup"):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_call(self, item):
+        with self._runtest_for(item, "call"):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_teardown(self, item):
+        with self._runtest_for(item, "teardown"):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_logstart(self):
+        if self.log_cli_handler:
+            self.log_cli_handler.reset()
+        with self._runtest_for(None, "start"):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtest_logfinish(self):
+        with self._runtest_for(None, "finish"):
+            yield
+
+    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    def pytest_sessionfinish(self):
+        with self.live_logs_context():
+            if self.log_cli_handler:
+                self.log_cli_handler.set_when("sessionfinish")
+            if self.log_file_handler is not None:
+                with catching_logs(self.log_file_handler, level=self.log_file_level):
+                    yield
+            else:
+                yield
+
+    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    def pytest_sessionstart(self):
+        self._setup_cli_logging()
+        with self.live_logs_context():
+            if self.log_cli_handler:
+                self.log_cli_handler.set_when("sessionstart")
+            if self.log_file_handler is not None:
+                with catching_logs(self.log_file_handler, level=self.log_file_level):
+                    yield
+            else:
+                yield
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_runtestloop(self, session):
+        """Runs all collected test items."""
+        with self.live_logs_context():
+            if self.log_file_handler is not None:
+                with catching_logs(self.log_file_handler, level=self.log_file_level):
+                    yield  # run all the tests
+            else:
+                yield  # run all the tests
+
+    def _setup_cli_logging(self):
+        """Sets up the handler and logger for the Live Logs feature, if enabled."""
+        terminal_reporter = self._config.pluginmanager.get_plugin("terminalreporter")
+        if self._log_cli_enabled() and terminal_reporter is not None:
+            capture_manager = self._config.pluginmanager.get_plugin("capturemanager")
+            log_cli_handler = _LiveLoggingStreamHandler(
+                terminal_reporter, capture_manager
+            )
+            log_cli_format = get_option_ini(
+                self._config, "log_cli_format", "log_format"
+            )
+            log_cli_date_format = get_option_ini(
+                self._config, "log_cli_date_format", "log_date_format"
+            )
+            if (
+                self._config.option.color != "no"
+                and ColoredLevelFormatter.LEVELNAME_FMT_REGEX.search(log_cli_format)
+            ):
+                log_cli_formatter = ColoredLevelFormatter(
+                    create_terminal_writer(self._config),
+                    log_cli_format,
+                    datefmt=log_cli_date_format,
+                )
+            else:
+                log_cli_formatter = logging.Formatter(
+                    log_cli_format, datefmt=log_cli_date_format
+                )
+            log_cli_level = get_actual_log_level(
+                self._config, "log_cli_level", "log_level"
+            )
+            self.log_cli_handler = log_cli_handler
+            self.live_logs_context = lambda: catching_logs(
+                log_cli_handler, formatter=log_cli_formatter, level=log_cli_level
+            )
+        else:
+            self.live_logs_context = lambda: dummy_context_manager()
+        # Note that the lambda for the live_logs_context is needed because
+        # live_logs_context can otherwise not be entered multiple times due
+        # to limitations of contextlib.contextmanager
+
+
+class _LiveLoggingStreamHandler(logging.StreamHandler):
+    """
+    Custom StreamHandler used by the live logging feature: it will write a newline before the first log message
+    in each test.
+
+    During live logging we must also explicitly disable stdout/stderr capturing otherwise it will get captured
+    and won't appear in the terminal.
+    """
+
+    def __init__(self, terminal_reporter, capture_manager):
+        """
+        :param _pytest.terminal.TerminalReporter terminal_reporter:
+        :param _pytest.capture.CaptureManager capture_manager:
+        """
+        logging.StreamHandler.__init__(self, stream=terminal_reporter)
+        self.capture_manager = capture_manager
+        self.reset()
+        self.set_when(None)
+        self._test_outcome_written = False
+
+    def reset(self):
+        """Reset the handler; should be called before the start of each test"""
+        self._first_record_emitted = False
+
+    def set_when(self, when):
+        """Prepares for the given test phase (setup/call/teardown)"""
+        self._when = when
+        self._section_name_shown = False
+        if when == "start":
+            self._test_outcome_written = False
+
+    def emit(self, record):
+        ctx_manager = (
+            self.capture_manager.global_and_fixture_disabled()
+            if self.capture_manager
+            else dummy_context_manager()
+        )
+        with ctx_manager:
+            if not self._first_record_emitted:
+                self.stream.write("\n")
+                self._first_record_emitted = True
+            elif self._when in ("teardown", "finish"):
+                if not self._test_outcome_written:
+                    self._test_outcome_written = True
+                    self.stream.write("\n")
+            if not self._section_name_shown and self._when:
+                self.stream.section("live log " + self._when, sep="-", bold=True)
+                self._section_name_shown = True
+            logging.StreamHandler.emit(self, record)
Index: venv/Lib/site-packages/_pytest/warning_types.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/warning_types.py	(date 1543190976401)
+++ venv/Lib/site-packages/_pytest/warning_types.py	(date 1543190976401)
@@ -0,0 +1,60 @@
+import attr
+
+
+class PytestWarning(UserWarning):
+    """
+    Bases: :class:`UserWarning`.
+
+    Base class for all warnings emitted by pytest.
+    """
+
+
+class PytestDeprecationWarning(PytestWarning, DeprecationWarning):
+    """
+    Bases: :class:`pytest.PytestWarning`, :class:`DeprecationWarning`.
+
+    Warning class for features that will be removed in a future version.
+    """
+
+
+class RemovedInPytest4Warning(PytestDeprecationWarning):
+    """
+    Bases: :class:`pytest.PytestDeprecationWarning`.
+
+    Warning class for features scheduled to be removed in pytest 4.0.
+    """
+
+
+class PytestExperimentalApiWarning(PytestWarning, FutureWarning):
+    """
+    Bases: :class:`pytest.PytestWarning`, :class:`FutureWarning`.
+
+    Warning category used to denote experiments in pytest. Use sparingly as the API might change or even be
+    removed completely in future version
+    """
+
+    @classmethod
+    def simple(cls, apiname):
+        return cls(
+            "{apiname} is an experimental api that may change over time".format(
+                apiname=apiname
+            )
+        )
+
+
+@attr.s
+class UnformattedWarning(object):
+    """Used to hold warnings that need to format their message at runtime, as opposed to a direct message.
+
+    Using this class avoids to keep all the warning types and messages in this module, avoiding misuse.
+    """
+
+    category = attr.ib()
+    template = attr.ib()
+
+    def format(self, **kwargs):
+        """Returns an instance of the warning category, formatted with given kwargs"""
+        return self.category(self.template.format(**kwargs))
+
+
+PYTESTER_COPY_EXAMPLE = PytestExperimentalApiWarning.simple("testdir.copy_example")
Index: venv/Lib/site-packages/_pytest/reports.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/reports.py	(date 1543190976414)
+++ venv/Lib/site-packages/_pytest/reports.py	(date 1543190976414)
@@ -0,0 +1,197 @@
+import py
+
+from _pytest._code.code import TerminalRepr
+
+
+def getslaveinfoline(node):
+    try:
+        return node._slaveinfocache
+    except AttributeError:
+        d = node.slaveinfo
+        ver = "%s.%s.%s" % d["version_info"][:3]
+        node._slaveinfocache = s = "[%s] %s -- Python %s %s" % (
+            d["id"],
+            d["sysplatform"],
+            ver,
+            d["executable"],
+        )
+        return s
+
+
+class BaseReport(object):
+    def __init__(self, **kw):
+        self.__dict__.update(kw)
+
+    def toterminal(self, out):
+        if hasattr(self, "node"):
+            out.line(getslaveinfoline(self.node))
+
+        longrepr = self.longrepr
+        if longrepr is None:
+            return
+
+        if hasattr(longrepr, "toterminal"):
+            longrepr.toterminal(out)
+        else:
+            try:
+                out.line(longrepr)
+            except UnicodeEncodeError:
+                out.line("<unprintable longrepr>")
+
+    def get_sections(self, prefix):
+        for name, content in self.sections:
+            if name.startswith(prefix):
+                yield prefix, content
+
+    @property
+    def longreprtext(self):
+        """
+        Read-only property that returns the full string representation
+        of ``longrepr``.
+
+        .. versionadded:: 3.0
+        """
+        tw = py.io.TerminalWriter(stringio=True)
+        tw.hasmarkup = False
+        self.toterminal(tw)
+        exc = tw.stringio.getvalue()
+        return exc.strip()
+
+    @property
+    def caplog(self):
+        """Return captured log lines, if log capturing is enabled
+
+        .. versionadded:: 3.5
+        """
+        return "\n".join(
+            content for (prefix, content) in self.get_sections("Captured log")
+        )
+
+    @property
+    def capstdout(self):
+        """Return captured text from stdout, if capturing is enabled
+
+        .. versionadded:: 3.0
+        """
+        return "".join(
+            content for (prefix, content) in self.get_sections("Captured stdout")
+        )
+
+    @property
+    def capstderr(self):
+        """Return captured text from stderr, if capturing is enabled
+
+        .. versionadded:: 3.0
+        """
+        return "".join(
+            content for (prefix, content) in self.get_sections("Captured stderr")
+        )
+
+    passed = property(lambda x: x.outcome == "passed")
+    failed = property(lambda x: x.outcome == "failed")
+    skipped = property(lambda x: x.outcome == "skipped")
+
+    @property
+    def fspath(self):
+        return self.nodeid.split("::")[0]
+
+
+class TestReport(BaseReport):
+    """ Basic test report object (also used for setup and teardown calls if
+    they fail).
+    """
+
+    def __init__(
+        self,
+        nodeid,
+        location,
+        keywords,
+        outcome,
+        longrepr,
+        when,
+        sections=(),
+        duration=0,
+        user_properties=None,
+        **extra
+    ):
+        #: normalized collection node id
+        self.nodeid = nodeid
+
+        #: a (filesystempath, lineno, domaininfo) tuple indicating the
+        #: actual location of a test item - it might be different from the
+        #: collected one e.g. if a method is inherited from a different module.
+        self.location = location
+
+        #: a name -> value dictionary containing all keywords and
+        #: markers associated with a test invocation.
+        self.keywords = keywords
+
+        #: test outcome, always one of "passed", "failed", "skipped".
+        self.outcome = outcome
+
+        #: None or a failure representation.
+        self.longrepr = longrepr
+
+        #: one of 'setup', 'call', 'teardown' to indicate runtest phase.
+        self.when = when
+
+        #: user properties is a list of tuples (name, value) that holds user
+        #: defined properties of the test
+        self.user_properties = list(user_properties or [])
+
+        #: list of pairs ``(str, str)`` of extra information which needs to
+        #: marshallable. Used by pytest to add captured text
+        #: from ``stdout`` and ``stderr``, but may be used by other plugins
+        #: to add arbitrary information to reports.
+        self.sections = list(sections)
+
+        #: time it took to run just the test
+        self.duration = duration
+
+        self.__dict__.update(extra)
+
+    def __repr__(self):
+        return "<TestReport %r when=%r outcome=%r>" % (
+            self.nodeid,
+            self.when,
+            self.outcome,
+        )
+
+
+class TeardownErrorReport(BaseReport):
+    outcome = "failed"
+    when = "teardown"
+
+    def __init__(self, longrepr, **extra):
+        self.longrepr = longrepr
+        self.sections = []
+        self.__dict__.update(extra)
+
+
+class CollectReport(BaseReport):
+    def __init__(self, nodeid, outcome, longrepr, result, sections=(), **extra):
+        self.nodeid = nodeid
+        self.outcome = outcome
+        self.longrepr = longrepr
+        self.result = result or []
+        self.sections = list(sections)
+        self.__dict__.update(extra)
+
+    @property
+    def location(self):
+        return (self.fspath, None, self.fspath)
+
+    def __repr__(self):
+        return "<CollectReport %r lenresult=%s outcome=%r>" % (
+            self.nodeid,
+            len(self.result),
+            self.outcome,
+        )
+
+
+class CollectErrorRepr(TerminalRepr):
+    def __init__(self, msg):
+        self.longrepr = msg
+
+    def toterminal(self, out):
+        out.line(self.longrepr, red=True)
Index: venv/Lib/site-packages/_pytest/freeze_support.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/freeze_support.py	(date 1543190976425)
+++ venv/Lib/site-packages/_pytest/freeze_support.py	(date 1543190976425)
@@ -0,0 +1,47 @@
+"""
+Provides a function to report all internal modules for using freezing tools
+pytest
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+
+def freeze_includes():
+    """
+    Returns a list of module names used by pytest that should be
+    included by cx_freeze.
+    """
+    import py
+    import _pytest
+
+    result = list(_iter_all_modules(py))
+    result += list(_iter_all_modules(_pytest))
+    return result
+
+
+def _iter_all_modules(package, prefix=""):
+    """
+    Iterates over the names of all modules that can be found in the given
+    package, recursively.
+    Example:
+        _iter_all_modules(_pytest) ->
+            ['_pytest.assertion.newinterpret',
+             '_pytest.capture',
+             '_pytest.core',
+             ...
+            ]
+    """
+    import os
+    import pkgutil
+
+    if type(package) is not str:
+        path, prefix = package.__path__[0], package.__name__ + "."
+    else:
+        path = package
+    for _, name, is_package in pkgutil.iter_modules([path]):
+        if is_package:
+            for m in _iter_all_modules(os.path.join(path, name), prefix=name + "."):
+                yield prefix + m
+        else:
+            yield prefix + name
Index: venv/Lib/site-packages/_pytest/pytester.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/pytester.py	(date 1543190976440)
+++ venv/Lib/site-packages/_pytest/pytester.py	(date 1543190976440)
@@ -0,0 +1,1386 @@
+"""(disabled by default) support for testing pytest and pytest plugins."""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import codecs
+import gc
+import os
+import platform
+import re
+import subprocess
+import sys
+import time
+import traceback
+from fnmatch import fnmatch
+from weakref import WeakKeyDictionary
+
+import py
+import six
+
+import pytest
+from _pytest._code import Source
+from _pytest.assertion.rewrite import AssertionRewritingHook
+from _pytest.capture import MultiCapture
+from _pytest.capture import SysCapture
+from _pytest.compat import safe_str
+from _pytest.main import EXIT_INTERRUPTED
+from _pytest.main import EXIT_OK
+from _pytest.main import Session
+from _pytest.pathlib import Path
+
+IGNORE_PAM = [  # filenames added when obtaining details about the current user
+    u"/var/lib/sss/mc/passwd"
+]
+
+
+def pytest_addoption(parser):
+    parser.addoption(
+        "--lsof",
+        action="store_true",
+        dest="lsof",
+        default=False,
+        help="run FD checks if lsof is available",
+    )
+
+    parser.addoption(
+        "--runpytest",
+        default="inprocess",
+        dest="runpytest",
+        choices=("inprocess", "subprocess"),
+        help=(
+            "run pytest sub runs in tests using an 'inprocess' "
+            "or 'subprocess' (python -m main) method"
+        ),
+    )
+
+    parser.addini(
+        "pytester_example_dir", help="directory to take the pytester example files from"
+    )
+
+
+def pytest_configure(config):
+    if config.getvalue("lsof"):
+        checker = LsofFdLeakChecker()
+        if checker.matching_platform():
+            config.pluginmanager.register(checker)
+
+
+def raise_on_kwargs(kwargs):
+    if kwargs:
+        raise TypeError("Unexpected arguments: {}".format(", ".join(sorted(kwargs))))
+
+
+class LsofFdLeakChecker(object):
+    def get_open_files(self):
+        out = self._exec_lsof()
+        open_files = self._parse_lsof_output(out)
+        return open_files
+
+    def _exec_lsof(self):
+        pid = os.getpid()
+        return py.process.cmdexec("lsof -Ffn0 -p %d" % pid)
+
+    def _parse_lsof_output(self, out):
+        def isopen(line):
+            return line.startswith("f") and (
+                "deleted" not in line
+                and "mem" not in line
+                and "txt" not in line
+                and "cwd" not in line
+            )
+
+        open_files = []
+
+        for line in out.split("\n"):
+            if isopen(line):
+                fields = line.split("\0")
+                fd = fields[0][1:]
+                filename = fields[1][1:]
+                if filename in IGNORE_PAM:
+                    continue
+                if filename.startswith("/"):
+                    open_files.append((fd, filename))
+
+        return open_files
+
+    def matching_platform(self):
+        try:
+            py.process.cmdexec("lsof -v")
+        except (py.process.cmdexec.Error, UnicodeDecodeError):
+            # cmdexec may raise UnicodeDecodeError on Windows systems with
+            # locale other than English:
+            # https://bitbucket.org/pytest-dev/py/issues/66
+            return False
+        else:
+            return True
+
+    @pytest.hookimpl(hookwrapper=True, tryfirst=True)
+    def pytest_runtest_protocol(self, item):
+        lines1 = self.get_open_files()
+        yield
+        if hasattr(sys, "pypy_version_info"):
+            gc.collect()
+        lines2 = self.get_open_files()
+
+        new_fds = {t[0] for t in lines2} - {t[0] for t in lines1}
+        leaked_files = [t for t in lines2 if t[0] in new_fds]
+        if leaked_files:
+            error = []
+            error.append("***** %s FD leakage detected" % len(leaked_files))
+            error.extend([str(f) for f in leaked_files])
+            error.append("*** Before:")
+            error.extend([str(f) for f in lines1])
+            error.append("*** After:")
+            error.extend([str(f) for f in lines2])
+            error.append(error[0])
+            error.append("*** function %s:%s: %s " % item.location)
+            error.append("See issue #2366")
+            item.warn(pytest.PytestWarning("\n".join(error)))
+
+
+# XXX copied from execnet's conftest.py - needs to be merged
+winpymap = {
+    "python2.7": r"C:\Python27\python.exe",
+    "python3.4": r"C:\Python34\python.exe",
+    "python3.5": r"C:\Python35\python.exe",
+    "python3.6": r"C:\Python36\python.exe",
+}
+
+
+def getexecutable(name, cache={}):
+    try:
+        return cache[name]
+    except KeyError:
+        executable = py.path.local.sysfind(name)
+        if executable:
+            import subprocess
+
+            popen = subprocess.Popen(
+                [str(executable), "--version"],
+                universal_newlines=True,
+                stderr=subprocess.PIPE,
+            )
+            out, err = popen.communicate()
+            if name == "jython":
+                if not err or "2.5" not in err:
+                    executable = None
+                if "2.5.2" in err:
+                    executable = None  # http://bugs.jython.org/issue1790
+            elif popen.returncode != 0:
+                # handle pyenv's 127
+                executable = None
+        cache[name] = executable
+        return executable
+
+
+@pytest.fixture(params=["python2.7", "python3.4", "pypy", "pypy3"])
+def anypython(request):
+    name = request.param
+    executable = getexecutable(name)
+    if executable is None:
+        if sys.platform == "win32":
+            executable = winpymap.get(name, None)
+            if executable:
+                executable = py.path.local(executable)
+                if executable.check():
+                    return executable
+        pytest.skip("no suitable %s found" % (name,))
+    return executable
+
+
+# used at least by pytest-xdist plugin
+
+
+@pytest.fixture
+def _pytest(request):
+    """Return a helper which offers a gethookrecorder(hook) method which
+    returns a HookRecorder instance which helps to make assertions about called
+    hooks.
+
+    """
+    return PytestArg(request)
+
+
+class PytestArg(object):
+    def __init__(self, request):
+        self.request = request
+
+    def gethookrecorder(self, hook):
+        hookrecorder = HookRecorder(hook._pm)
+        self.request.addfinalizer(hookrecorder.finish_recording)
+        return hookrecorder
+
+
+def get_public_names(values):
+    """Only return names from iterator values without a leading underscore."""
+    return [x for x in values if x[0] != "_"]
+
+
+class ParsedCall(object):
+    def __init__(self, name, kwargs):
+        self.__dict__.update(kwargs)
+        self._name = name
+
+    def __repr__(self):
+        d = self.__dict__.copy()
+        del d["_name"]
+        return "<ParsedCall %r(**%r)>" % (self._name, d)
+
+
+class HookRecorder(object):
+    """Record all hooks called in a plugin manager.
+
+    This wraps all the hook calls in the plugin manager, recording each call
+    before propagating the normal calls.
+
+    """
+
+    def __init__(self, pluginmanager):
+        self._pluginmanager = pluginmanager
+        self.calls = []
+
+        def before(hook_name, hook_impls, kwargs):
+            self.calls.append(ParsedCall(hook_name, kwargs))
+
+        def after(outcome, hook_name, hook_impls, kwargs):
+            pass
+
+        self._undo_wrapping = pluginmanager.add_hookcall_monitoring(before, after)
+
+    def finish_recording(self):
+        self._undo_wrapping()
+
+    def getcalls(self, names):
+        if isinstance(names, str):
+            names = names.split()
+        return [call for call in self.calls if call._name in names]
+
+    def assert_contains(self, entries):
+        __tracebackhide__ = True
+        i = 0
+        entries = list(entries)
+        backlocals = sys._getframe(1).f_locals
+        while entries:
+            name, check = entries.pop(0)
+            for ind, call in enumerate(self.calls[i:]):
+                if call._name == name:
+                    print("NAMEMATCH", name, call)
+                    if eval(check, backlocals, call.__dict__):
+                        print("CHECKERMATCH", repr(check), "->", call)
+                    else:
+                        print("NOCHECKERMATCH", repr(check), "-", call)
+                        continue
+                    i += ind + 1
+                    break
+                print("NONAMEMATCH", name, "with", call)
+            else:
+                pytest.fail("could not find %r check %r" % (name, check))
+
+    def popcall(self, name):
+        __tracebackhide__ = True
+        for i, call in enumerate(self.calls):
+            if call._name == name:
+                del self.calls[i]
+                return call
+        lines = ["could not find call %r, in:" % (name,)]
+        lines.extend(["  %s" % x for x in self.calls])
+        pytest.fail("\n".join(lines))
+
+    def getcall(self, name):
+        values = self.getcalls(name)
+        assert len(values) == 1, (name, values)
+        return values[0]
+
+    # functionality for test reports
+
+    def getreports(self, names="pytest_runtest_logreport pytest_collectreport"):
+        return [x.report for x in self.getcalls(names)]
+
+    def matchreport(
+        self,
+        inamepart="",
+        names="pytest_runtest_logreport pytest_collectreport",
+        when=None,
+    ):
+        """return a testreport whose dotted import path matches"""
+        values = []
+        for rep in self.getreports(names=names):
+            try:
+                if not when and rep.when != "call" and rep.passed:
+                    # setup/teardown passing reports - let's ignore those
+                    continue
+            except AttributeError:
+                pass
+            if when and getattr(rep, "when", None) != when:
+                continue
+            if not inamepart or inamepart in rep.nodeid.split("::"):
+                values.append(rep)
+        if not values:
+            raise ValueError(
+                "could not find test report matching %r: "
+                "no test reports at all!" % (inamepart,)
+            )
+        if len(values) > 1:
+            raise ValueError(
+                "found 2 or more testreports matching %r: %s" % (inamepart, values)
+            )
+        return values[0]
+
+    def getfailures(self, names="pytest_runtest_logreport pytest_collectreport"):
+        return [rep for rep in self.getreports(names) if rep.failed]
+
+    def getfailedcollections(self):
+        return self.getfailures("pytest_collectreport")
+
+    def listoutcomes(self):
+        passed = []
+        skipped = []
+        failed = []
+        for rep in self.getreports("pytest_collectreport pytest_runtest_logreport"):
+            if rep.passed:
+                if getattr(rep, "when", None) == "call":
+                    passed.append(rep)
+            elif rep.skipped:
+                skipped.append(rep)
+            elif rep.failed:
+                failed.append(rep)
+        return passed, skipped, failed
+
+    def countoutcomes(self):
+        return [len(x) for x in self.listoutcomes()]
+
+    def assertoutcome(self, passed=0, skipped=0, failed=0):
+        realpassed, realskipped, realfailed = self.listoutcomes()
+        assert passed == len(realpassed)
+        assert skipped == len(realskipped)
+        assert failed == len(realfailed)
+
+    def clear(self):
+        self.calls[:] = []
+
+
+@pytest.fixture
+def linecomp(request):
+    return LineComp()
+
+
+@pytest.fixture(name="LineMatcher")
+def LineMatcher_fixture(request):
+    return LineMatcher
+
+
+@pytest.fixture
+def testdir(request, tmpdir_factory):
+    return Testdir(request, tmpdir_factory)
+
+
+rex_outcome = re.compile(r"(\d+) ([\w-]+)")
+
+
+class RunResult(object):
+    """The result of running a command.
+
+    Attributes:
+
+    :ret: the return value
+    :outlines: list of lines captured from stdout
+    :errlines: list of lines captures from stderr
+    :stdout: :py:class:`LineMatcher` of stdout, use ``stdout.str()`` to
+       reconstruct stdout or the commonly used ``stdout.fnmatch_lines()``
+       method
+    :stderr: :py:class:`LineMatcher` of stderr
+    :duration: duration in seconds
+
+    """
+
+    def __init__(self, ret, outlines, errlines, duration):
+        self.ret = ret
+        self.outlines = outlines
+        self.errlines = errlines
+        self.stdout = LineMatcher(outlines)
+        self.stderr = LineMatcher(errlines)
+        self.duration = duration
+
+    def parseoutcomes(self):
+        """Return a dictionary of outcomestring->num from parsing the terminal
+        output that the test process produced.
+
+        """
+        for line in reversed(self.outlines):
+            if "seconds" in line:
+                outcomes = rex_outcome.findall(line)
+                if outcomes:
+                    d = {}
+                    for num, cat in outcomes:
+                        d[cat] = int(num)
+                    return d
+        raise ValueError("Pytest terminal report not found")
+
+    def assert_outcomes(
+        self, passed=0, skipped=0, failed=0, error=0, xpassed=0, xfailed=0
+    ):
+        """Assert that the specified outcomes appear with the respective
+        numbers (0 means it didn't occur) in the text output from a test run.
+
+        """
+        d = self.parseoutcomes()
+        obtained = {
+            "passed": d.get("passed", 0),
+            "skipped": d.get("skipped", 0),
+            "failed": d.get("failed", 0),
+            "error": d.get("error", 0),
+            "xpassed": d.get("xpassed", 0),
+            "xfailed": d.get("xfailed", 0),
+        }
+        expected = {
+            "passed": passed,
+            "skipped": skipped,
+            "failed": failed,
+            "error": error,
+            "xpassed": xpassed,
+            "xfailed": xfailed,
+        }
+        assert obtained == expected
+
+
+class CwdSnapshot(object):
+    def __init__(self):
+        self.__saved = os.getcwd()
+
+    def restore(self):
+        os.chdir(self.__saved)
+
+
+class SysModulesSnapshot(object):
+    def __init__(self, preserve=None):
+        self.__preserve = preserve
+        self.__saved = dict(sys.modules)
+
+    def restore(self):
+        if self.__preserve:
+            self.__saved.update(
+                (k, m) for k, m in sys.modules.items() if self.__preserve(k)
+            )
+        sys.modules.clear()
+        sys.modules.update(self.__saved)
+
+
+class SysPathsSnapshot(object):
+    def __init__(self):
+        self.__saved = list(sys.path), list(sys.meta_path)
+
+    def restore(self):
+        sys.path[:], sys.meta_path[:] = self.__saved
+
+
+class Testdir(object):
+    """Temporary test directory with tools to test/run pytest itself.
+
+    This is based on the ``tmpdir`` fixture but provides a number of methods
+    which aid with testing pytest itself.  Unless :py:meth:`chdir` is used all
+    methods will use :py:attr:`tmpdir` as their current working directory.
+
+    Attributes:
+
+    :tmpdir: The :py:class:`py.path.local` instance of the temporary directory.
+
+    :plugins: A list of plugins to use with :py:meth:`parseconfig` and
+       :py:meth:`runpytest`.  Initially this is an empty list but plugins can
+       be added to the list.  The type of items to add to the list depends on
+       the method using them so refer to them for details.
+
+    """
+
+    class TimeoutExpired(Exception):
+        pass
+
+    def __init__(self, request, tmpdir_factory):
+        self.request = request
+        self._mod_collections = WeakKeyDictionary()
+        name = request.function.__name__
+        self.tmpdir = tmpdir_factory.mktemp(name, numbered=True)
+        self.test_tmproot = tmpdir_factory.mktemp("tmp-" + name, numbered=True)
+        os.environ["PYTEST_DEBUG_TEMPROOT"] = str(self.test_tmproot)
+        os.environ.pop("TOX_ENV_DIR", None)  # Ensure that it is not used for caching.
+        self.plugins = []
+        self._cwd_snapshot = CwdSnapshot()
+        self._sys_path_snapshot = SysPathsSnapshot()
+        self._sys_modules_snapshot = self.__take_sys_modules_snapshot()
+        self.chdir()
+        self.request.addfinalizer(self.finalize)
+        method = self.request.config.getoption("--runpytest")
+        if method == "inprocess":
+            self._runpytest_method = self.runpytest_inprocess
+        elif method == "subprocess":
+            self._runpytest_method = self.runpytest_subprocess
+
+    def __repr__(self):
+        return "<Testdir %r>" % (self.tmpdir,)
+
+    def finalize(self):
+        """Clean up global state artifacts.
+
+        Some methods modify the global interpreter state and this tries to
+        clean this up.  It does not remove the temporary directory however so
+        it can be looked at after the test run has finished.
+
+        """
+        self._sys_modules_snapshot.restore()
+        self._sys_path_snapshot.restore()
+        self._cwd_snapshot.restore()
+        os.environ.pop("PYTEST_DEBUG_TEMPROOT", None)
+
+    def __take_sys_modules_snapshot(self):
+        # some zope modules used by twisted-related tests keep internal state
+        # and can't be deleted; we had some trouble in the past with
+        # `zope.interface` for example
+        def preserve_module(name):
+            return name.startswith("zope")
+
+        return SysModulesSnapshot(preserve=preserve_module)
+
+    def make_hook_recorder(self, pluginmanager):
+        """Create a new :py:class:`HookRecorder` for a PluginManager."""
+        pluginmanager.reprec = reprec = HookRecorder(pluginmanager)
+        self.request.addfinalizer(reprec.finish_recording)
+        return reprec
+
+    def chdir(self):
+        """Cd into the temporary directory.
+
+        This is done automatically upon instantiation.
+
+        """
+        self.tmpdir.chdir()
+
+    def _makefile(self, ext, args, kwargs, encoding="utf-8"):
+        items = list(kwargs.items())
+
+        def to_text(s):
+            return s.decode(encoding) if isinstance(s, bytes) else six.text_type(s)
+
+        if args:
+            source = u"\n".join(to_text(x) for x in args)
+            basename = self.request.function.__name__
+            items.insert(0, (basename, source))
+
+        ret = None
+        for basename, value in items:
+            p = self.tmpdir.join(basename).new(ext=ext)
+            p.dirpath().ensure_dir()
+            source = Source(value)
+            source = u"\n".join(to_text(line) for line in source.lines)
+            p.write(source.strip().encode(encoding), "wb")
+            if ret is None:
+                ret = p
+        return ret
+
+    def makefile(self, ext, *args, **kwargs):
+        r"""Create new file(s) in the testdir.
+
+        :param str ext: The extension the file(s) should use, including the dot, e.g. `.py`.
+        :param list[str] args: All args will be treated as strings and joined using newlines.
+           The result will be written as contents to the file.  The name of the
+           file will be based on the test function requesting this fixture.
+        :param kwargs: Each keyword is the name of a file, while the value of it will
+           be written as contents of the file.
+
+        Examples:
+
+        .. code-block:: python
+
+            testdir.makefile(".txt", "line1", "line2")
+
+            testdir.makefile(".ini", pytest="[pytest]\naddopts=-rs\n")
+
+        """
+        return self._makefile(ext, args, kwargs)
+
+    def makeconftest(self, source):
+        """Write a contest.py file with 'source' as contents."""
+        return self.makepyfile(conftest=source)
+
+    def makeini(self, source):
+        """Write a tox.ini file with 'source' as contents."""
+        return self.makefile(".ini", tox=source)
+
+    def getinicfg(self, source):
+        """Return the pytest section from the tox.ini config file."""
+        p = self.makeini(source)
+        return py.iniconfig.IniConfig(p)["pytest"]
+
+    def makepyfile(self, *args, **kwargs):
+        """Shortcut for .makefile() with a .py extension."""
+        return self._makefile(".py", args, kwargs)
+
+    def maketxtfile(self, *args, **kwargs):
+        """Shortcut for .makefile() with a .txt extension."""
+        return self._makefile(".txt", args, kwargs)
+
+    def syspathinsert(self, path=None):
+        """Prepend a directory to sys.path, defaults to :py:attr:`tmpdir`.
+
+        This is undone automatically when this object dies at the end of each
+        test.
+
+        """
+        if path is None:
+            path = self.tmpdir
+        sys.path.insert(0, str(path))
+        # a call to syspathinsert() usually means that the caller wants to
+        # import some dynamically created files, thus with python3 we
+        # invalidate its import caches
+        self._possibly_invalidate_import_caches()
+
+    def _possibly_invalidate_import_caches(self):
+        # invalidate caches if we can (py33 and above)
+        try:
+            import importlib
+        except ImportError:
+            pass
+        else:
+            if hasattr(importlib, "invalidate_caches"):
+                importlib.invalidate_caches()
+
+    def mkdir(self, name):
+        """Create a new (sub)directory."""
+        return self.tmpdir.mkdir(name)
+
+    def mkpydir(self, name):
+        """Create a new python package.
+
+        This creates a (sub)directory with an empty ``__init__.py`` file so it
+        gets recognised as a python package.
+
+        """
+        p = self.mkdir(name)
+        p.ensure("__init__.py")
+        return p
+
+    def copy_example(self, name=None):
+        import warnings
+        from _pytest.warning_types import PYTESTER_COPY_EXAMPLE
+
+        warnings.warn(PYTESTER_COPY_EXAMPLE, stacklevel=2)
+        example_dir = self.request.config.getini("pytester_example_dir")
+        if example_dir is None:
+            raise ValueError("pytester_example_dir is unset, can't copy examples")
+        example_dir = self.request.config.rootdir.join(example_dir)
+
+        for extra_element in self.request.node.iter_markers("pytester_example_path"):
+            assert extra_element.args
+            example_dir = example_dir.join(*extra_element.args)
+
+        if name is None:
+            func_name = self.request.function.__name__
+            maybe_dir = example_dir / func_name
+            maybe_file = example_dir / (func_name + ".py")
+
+            if maybe_dir.isdir():
+                example_path = maybe_dir
+            elif maybe_file.isfile():
+                example_path = maybe_file
+            else:
+                raise LookupError(
+                    "{} cant be found as module or package in {}".format(
+                        func_name, example_dir.bestrelpath(self.request.confg.rootdir)
+                    )
+                )
+        else:
+            example_path = example_dir.join(name)
+
+        if example_path.isdir() and not example_path.join("__init__.py").isfile():
+            example_path.copy(self.tmpdir)
+            return self.tmpdir
+        elif example_path.isfile():
+            result = self.tmpdir.join(example_path.basename)
+            example_path.copy(result)
+            return result
+        else:
+            raise LookupError(
+                'example "{}" is not found as a file or directory'.format(example_path)
+            )
+
+    Session = Session
+
+    def getnode(self, config, arg):
+        """Return the collection node of a file.
+
+        :param config: :py:class:`_pytest.config.Config` instance, see
+           :py:meth:`parseconfig` and :py:meth:`parseconfigure` to create the
+           configuration
+
+        :param arg: a :py:class:`py.path.local` instance of the file
+
+        """
+        session = Session(config)
+        assert "::" not in str(arg)
+        p = py.path.local(arg)
+        config.hook.pytest_sessionstart(session=session)
+        res = session.perform_collect([str(p)], genitems=False)[0]
+        config.hook.pytest_sessionfinish(session=session, exitstatus=EXIT_OK)
+        return res
+
+    def getpathnode(self, path):
+        """Return the collection node of a file.
+
+        This is like :py:meth:`getnode` but uses :py:meth:`parseconfigure` to
+        create the (configured) pytest Config instance.
+
+        :param path: a :py:class:`py.path.local` instance of the file
+
+        """
+        config = self.parseconfigure(path)
+        session = Session(config)
+        x = session.fspath.bestrelpath(path)
+        config.hook.pytest_sessionstart(session=session)
+        res = session.perform_collect([x], genitems=False)[0]
+        config.hook.pytest_sessionfinish(session=session, exitstatus=EXIT_OK)
+        return res
+
+    def genitems(self, colitems):
+        """Generate all test items from a collection node.
+
+        This recurses into the collection node and returns a list of all the
+        test items contained within.
+
+        """
+        session = colitems[0].session
+        result = []
+        for colitem in colitems:
+            result.extend(session.genitems(colitem))
+        return result
+
+    def runitem(self, source):
+        """Run the "test_func" Item.
+
+        The calling test instance (class containing the test method) must
+        provide a ``.getrunner()`` method which should return a runner which
+        can run the test protocol for a single item, e.g.
+        :py:func:`_pytest.runner.runtestprotocol`.
+
+        """
+        # used from runner functional tests
+        item = self.getitem(source)
+        # the test class where we are called from wants to provide the runner
+        testclassinstance = self.request.instance
+        runner = testclassinstance.getrunner()
+        return runner(item)
+
+    def inline_runsource(self, source, *cmdlineargs):
+        """Run a test module in process using ``pytest.main()``.
+
+        This run writes "source" into a temporary file and runs
+        ``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance
+        for the result.
+
+        :param source: the source code of the test module
+
+        :param cmdlineargs: any extra command line arguments to use
+
+        :return: :py:class:`HookRecorder` instance of the result
+
+        """
+        p = self.makepyfile(source)
+        values = list(cmdlineargs) + [p]
+        return self.inline_run(*values)
+
+    def inline_genitems(self, *args):
+        """Run ``pytest.main(['--collectonly'])`` in-process.
+
+        Runs the :py:func:`pytest.main` function to run all of pytest inside
+        the test process itself like :py:meth:`inline_run`, but returns a
+        tuple of the collected items and a :py:class:`HookRecorder` instance.
+
+        """
+        rec = self.inline_run("--collect-only", *args)
+        items = [x.item for x in rec.getcalls("pytest_itemcollected")]
+        return items, rec
+
+    def inline_run(self, *args, **kwargs):
+        """Run ``pytest.main()`` in-process, returning a HookRecorder.
+
+        Runs the :py:func:`pytest.main` function to run all of pytest inside
+        the test process itself.  This means it can return a
+        :py:class:`HookRecorder` instance which gives more detailed results
+        from that run than can be done by matching stdout/stderr from
+        :py:meth:`runpytest`.
+
+        :param args: command line arguments to pass to :py:func:`pytest.main`
+
+        :param plugin: (keyword-only) extra plugin instances the
+           ``pytest.main()`` instance should use
+
+        :return: a :py:class:`HookRecorder` instance
+
+        """
+        finalizers = []
+        try:
+            # When running pytest inline any plugins active in the main test
+            # process are already imported.  So this disables the warning which
+            # will trigger to say they can no longer be rewritten, which is
+            # fine as they have already been rewritten.
+            orig_warn = AssertionRewritingHook._warn_already_imported
+
+            def revert_warn_already_imported():
+                AssertionRewritingHook._warn_already_imported = orig_warn
+
+            finalizers.append(revert_warn_already_imported)
+            AssertionRewritingHook._warn_already_imported = lambda *a: None
+
+            # Any sys.module or sys.path changes done while running pytest
+            # inline should be reverted after the test run completes to avoid
+            # clashing with later inline tests run within the same pytest test,
+            # e.g. just because they use matching test module names.
+            finalizers.append(self.__take_sys_modules_snapshot().restore)
+            finalizers.append(SysPathsSnapshot().restore)
+
+            # Important note:
+            # - our tests should not leave any other references/registrations
+            #   laying around other than possibly loaded test modules
+            #   referenced from sys.modules, as nothing will clean those up
+            #   automatically
+
+            rec = []
+
+            class Collect(object):
+                def pytest_configure(x, config):
+                    rec.append(self.make_hook_recorder(config.pluginmanager))
+
+            plugins = kwargs.get("plugins") or []
+            plugins.append(Collect())
+            ret = pytest.main(list(args), plugins=plugins)
+            if len(rec) == 1:
+                reprec = rec.pop()
+            else:
+
+                class reprec(object):
+                    pass
+
+            reprec.ret = ret
+
+            # typically we reraise keyboard interrupts from the child run
+            # because it's our user requesting interruption of the testing
+            if ret == EXIT_INTERRUPTED and not kwargs.get("no_reraise_ctrlc"):
+                calls = reprec.getcalls("pytest_keyboard_interrupt")
+                if calls and calls[-1].excinfo.type == KeyboardInterrupt:
+                    raise KeyboardInterrupt()
+            return reprec
+        finally:
+            for finalizer in finalizers:
+                finalizer()
+
+    def runpytest_inprocess(self, *args, **kwargs):
+        """Return result of running pytest in-process, providing a similar
+        interface to what self.runpytest() provides.
+
+        """
+        if kwargs.get("syspathinsert"):
+            self.syspathinsert()
+        now = time.time()
+        capture = MultiCapture(Capture=SysCapture)
+        capture.start_capturing()
+        try:
+            try:
+                reprec = self.inline_run(*args, **kwargs)
+            except SystemExit as e:
+
+                class reprec(object):
+                    ret = e.args[0]
+
+            except Exception:
+                traceback.print_exc()
+
+                class reprec(object):
+                    ret = 3
+
+        finally:
+            out, err = capture.readouterr()
+            capture.stop_capturing()
+            sys.stdout.write(out)
+            sys.stderr.write(err)
+
+        res = RunResult(reprec.ret, out.split("\n"), err.split("\n"), time.time() - now)
+        res.reprec = reprec
+        return res
+
+    def runpytest(self, *args, **kwargs):
+        """Run pytest inline or in a subprocess, depending on the command line
+        option "--runpytest" and return a :py:class:`RunResult`.
+
+        """
+        args = self._ensure_basetemp(args)
+        return self._runpytest_method(*args, **kwargs)
+
+    def _ensure_basetemp(self, args):
+        args = list(args)
+        for x in args:
+            if safe_str(x).startswith("--basetemp"):
+                break
+        else:
+            args.append("--basetemp=%s" % self.tmpdir.dirpath("basetemp"))
+        return args
+
+    def parseconfig(self, *args):
+        """Return a new pytest Config instance from given commandline args.
+
+        This invokes the pytest bootstrapping code in _pytest.config to create
+        a new :py:class:`_pytest.core.PluginManager` and call the
+        pytest_cmdline_parse hook to create a new
+        :py:class:`_pytest.config.Config` instance.
+
+        If :py:attr:`plugins` has been populated they should be plugin modules
+        to be registered with the PluginManager.
+
+        """
+        args = self._ensure_basetemp(args)
+
+        import _pytest.config
+
+        config = _pytest.config._prepareconfig(args, self.plugins)
+        # we don't know what the test will do with this half-setup config
+        # object and thus we make sure it gets unconfigured properly in any
+        # case (otherwise capturing could still be active, for example)
+        self.request.addfinalizer(config._ensure_unconfigure)
+        return config
+
+    def parseconfigure(self, *args):
+        """Return a new pytest configured Config instance.
+
+        This returns a new :py:class:`_pytest.config.Config` instance like
+        :py:meth:`parseconfig`, but also calls the pytest_configure hook.
+
+        """
+        config = self.parseconfig(*args)
+        config._do_configure()
+        self.request.addfinalizer(config._ensure_unconfigure)
+        return config
+
+    def getitem(self, source, funcname="test_func"):
+        """Return the test item for a test function.
+
+        This writes the source to a python file and runs pytest's collection on
+        the resulting module, returning the test item for the requested
+        function name.
+
+        :param source: the module source
+
+        :param funcname: the name of the test function for which to return a
+            test item
+
+        """
+        items = self.getitems(source)
+        for item in items:
+            if item.name == funcname:
+                return item
+        assert 0, "%r item not found in module:\n%s\nitems: %s" % (
+            funcname,
+            source,
+            items,
+        )
+
+    def getitems(self, source):
+        """Return all test items collected from the module.
+
+        This writes the source to a python file and runs pytest's collection on
+        the resulting module, returning all test items contained within.
+
+        """
+        modcol = self.getmodulecol(source)
+        return self.genitems([modcol])
+
+    def getmodulecol(self, source, configargs=(), withinit=False):
+        """Return the module collection node for ``source``.
+
+        This writes ``source`` to a file using :py:meth:`makepyfile` and then
+        runs the pytest collection on it, returning the collection node for the
+        test module.
+
+        :param source: the source code of the module to collect
+
+        :param configargs: any extra arguments to pass to
+            :py:meth:`parseconfigure`
+
+        :param withinit: whether to also write an ``__init__.py`` file to the
+            same directory to ensure it is a package
+
+        """
+        if isinstance(source, Path):
+            path = self.tmpdir.join(str(source))
+            assert not withinit, "not supported for paths"
+        else:
+            kw = {self.request.function.__name__: Source(source).strip()}
+            path = self.makepyfile(**kw)
+        if withinit:
+            self.makepyfile(__init__="#")
+        self.config = config = self.parseconfigure(path, *configargs)
+        return self.getnode(config, path)
+
+    def collect_by_name(self, modcol, name):
+        """Return the collection node for name from the module collection.
+
+        This will search a module collection node for a collection node
+        matching the given name.
+
+        :param modcol: a module collection node; see :py:meth:`getmodulecol`
+
+        :param name: the name of the node to return
+
+        """
+        if modcol not in self._mod_collections:
+            self._mod_collections[modcol] = list(modcol.collect())
+        for colitem in self._mod_collections[modcol]:
+            if colitem.name == name:
+                return colitem
+
+    def popen(self, cmdargs, stdout, stderr, **kw):
+        """Invoke subprocess.Popen.
+
+        This calls subprocess.Popen making sure the current working directory
+        is in the PYTHONPATH.
+
+        You probably want to use :py:meth:`run` instead.
+
+        """
+        env = os.environ.copy()
+        env["PYTHONPATH"] = os.pathsep.join(
+            filter(None, [os.getcwd(), env.get("PYTHONPATH", "")])
+        )
+        kw["env"] = env
+
+        popen = subprocess.Popen(
+            cmdargs, stdin=subprocess.PIPE, stdout=stdout, stderr=stderr, **kw
+        )
+        popen.stdin.close()
+
+        return popen
+
+    def run(self, *cmdargs, **kwargs):
+        """Run a command with arguments.
+
+        Run a process using subprocess.Popen saving the stdout and stderr.
+
+        :param args: the sequence of arguments to pass to `subprocess.Popen()`
+        :param timeout: the period in seconds after which to timeout and raise
+            :py:class:`Testdir.TimeoutExpired`
+
+        Returns a :py:class:`RunResult`.
+
+        """
+        __tracebackhide__ = True
+
+        timeout = kwargs.pop("timeout", None)
+        raise_on_kwargs(kwargs)
+
+        cmdargs = [
+            str(arg) if isinstance(arg, py.path.local) else arg for arg in cmdargs
+        ]
+        p1 = self.tmpdir.join("stdout")
+        p2 = self.tmpdir.join("stderr")
+        print("running:", *cmdargs)
+        print("     in:", py.path.local())
+        f1 = codecs.open(str(p1), "w", encoding="utf8")
+        f2 = codecs.open(str(p2), "w", encoding="utf8")
+        try:
+            now = time.time()
+            popen = self.popen(
+                cmdargs, stdout=f1, stderr=f2, close_fds=(sys.platform != "win32")
+            )
+
+            def handle_timeout():
+                __tracebackhide__ = True
+
+                timeout_message = (
+                    "{seconds} second timeout expired running:"
+                    " {command}".format(seconds=timeout, command=cmdargs)
+                )
+
+                popen.kill()
+                popen.wait()
+                raise self.TimeoutExpired(timeout_message)
+
+            if timeout is None:
+                ret = popen.wait()
+            elif six.PY3:
+                try:
+                    ret = popen.wait(timeout)
+                except subprocess.TimeoutExpired:
+                    handle_timeout()
+            else:
+                end = time.time() + timeout
+
+                resolution = min(0.1, timeout / 10)
+
+                while True:
+                    ret = popen.poll()
+                    if ret is not None:
+                        break
+
+                    if time.time() > end:
+                        handle_timeout()
+
+                    time.sleep(resolution)
+        finally:
+            f1.close()
+            f2.close()
+        f1 = codecs.open(str(p1), "r", encoding="utf8")
+        f2 = codecs.open(str(p2), "r", encoding="utf8")
+        try:
+            out = f1.read().splitlines()
+            err = f2.read().splitlines()
+        finally:
+            f1.close()
+            f2.close()
+        self._dump_lines(out, sys.stdout)
+        self._dump_lines(err, sys.stderr)
+        return RunResult(ret, out, err, time.time() - now)
+
+    def _dump_lines(self, lines, fp):
+        try:
+            for line in lines:
+                print(line, file=fp)
+        except UnicodeEncodeError:
+            print("couldn't print to %s because of encoding" % (fp,))
+
+    def _getpytestargs(self):
+        return sys.executable, "-mpytest"
+
+    def runpython(self, script):
+        """Run a python script using sys.executable as interpreter.
+
+        Returns a :py:class:`RunResult`.
+
+        """
+        return self.run(sys.executable, script)
+
+    def runpython_c(self, command):
+        """Run python -c "command", return a :py:class:`RunResult`."""
+        return self.run(sys.executable, "-c", command)
+
+    def runpytest_subprocess(self, *args, **kwargs):
+        """Run pytest as a subprocess with given arguments.
+
+        Any plugins added to the :py:attr:`plugins` list will be added using the
+        ``-p`` command line option.  Additionally ``--basetemp`` is used to put
+        any temporary files and directories in a numbered directory prefixed
+        with "runpytest-" to not conflict with the normal numbered pytest
+        location for temporary files and directories.
+
+        :param args: the sequence of arguments to pass to the pytest subprocess
+        :param timeout: the period in seconds after which to timeout and raise
+            :py:class:`Testdir.TimeoutExpired`
+
+        Returns a :py:class:`RunResult`.
+
+        """
+        __tracebackhide__ = True
+
+        p = py.path.local.make_numbered_dir(
+            prefix="runpytest-", keep=None, rootdir=self.tmpdir
+        )
+        args = ("--basetemp=%s" % p,) + args
+        plugins = [x for x in self.plugins if isinstance(x, str)]
+        if plugins:
+            args = ("-p", plugins[0]) + args
+        args = self._getpytestargs() + args
+        return self.run(*args, timeout=kwargs.get("timeout"))
+
+    def spawn_pytest(self, string, expect_timeout=10.0):
+        """Run pytest using pexpect.
+
+        This makes sure to use the right pytest and sets up the temporary
+        directory locations.
+
+        The pexpect child is returned.
+
+        """
+        basetemp = self.tmpdir.mkdir("temp-pexpect")
+        invoke = " ".join(map(str, self._getpytestargs()))
+        cmd = "%s --basetemp=%s %s" % (invoke, basetemp, string)
+        return self.spawn(cmd, expect_timeout=expect_timeout)
+
+    def spawn(self, cmd, expect_timeout=10.0):
+        """Run a command using pexpect.
+
+        The pexpect child is returned.
+
+        """
+        pexpect = pytest.importorskip("pexpect", "3.0")
+        if hasattr(sys, "pypy_version_info") and "64" in platform.machine():
+            pytest.skip("pypy-64 bit not supported")
+        if sys.platform.startswith("freebsd"):
+            pytest.xfail("pexpect does not work reliably on freebsd")
+        logfile = self.tmpdir.join("spawn.out").open("wb")
+        child = pexpect.spawn(cmd, logfile=logfile)
+        self.request.addfinalizer(logfile.close)
+        child.timeout = expect_timeout
+        return child
+
+
+def getdecoded(out):
+    try:
+        return out.decode("utf-8")
+    except UnicodeDecodeError:
+        return "INTERNAL not-utf8-decodeable, truncated string:\n%s" % (
+            py.io.saferepr(out),
+        )
+
+
+class LineComp(object):
+    def __init__(self):
+        self.stringio = py.io.TextIO()
+
+    def assert_contains_lines(self, lines2):
+        """Assert that lines2 are contained (linearly) in lines1.
+
+        Return a list of extralines found.
+
+        """
+        __tracebackhide__ = True
+        val = self.stringio.getvalue()
+        self.stringio.truncate(0)
+        self.stringio.seek(0)
+        lines1 = val.split("\n")
+        return LineMatcher(lines1).fnmatch_lines(lines2)
+
+
+class LineMatcher(object):
+    """Flexible matching of text.
+
+    This is a convenience class to test large texts like the output of
+    commands.
+
+    The constructor takes a list of lines without their trailing newlines, i.e.
+    ``text.splitlines()``.
+
+    """
+
+    def __init__(self, lines):
+        self.lines = lines
+        self._log_output = []
+
+    def str(self):
+        """Return the entire original text."""
+        return "\n".join(self.lines)
+
+    def _getlines(self, lines2):
+        if isinstance(lines2, str):
+            lines2 = Source(lines2)
+        if isinstance(lines2, Source):
+            lines2 = lines2.strip().lines
+        return lines2
+
+    def fnmatch_lines_random(self, lines2):
+        """Check lines exist in the output using in any order.
+
+        Lines are checked using ``fnmatch.fnmatch``. The argument is a list of
+        lines which have to occur in the output, in any order.
+
+        """
+        self._match_lines_random(lines2, fnmatch)
+
+    def re_match_lines_random(self, lines2):
+        """Check lines exist in the output using ``re.match``, in any order.
+
+        The argument is a list of lines which have to occur in the output, in
+        any order.
+
+        """
+        self._match_lines_random(lines2, lambda name, pat: re.match(pat, name))
+
+    def _match_lines_random(self, lines2, match_func):
+        """Check lines exist in the output.
+
+        The argument is a list of lines which have to occur in the output, in
+        any order.  Each line can contain glob whildcards.
+
+        """
+        lines2 = self._getlines(lines2)
+        for line in lines2:
+            for x in self.lines:
+                if line == x or match_func(x, line):
+                    self._log("matched: ", repr(line))
+                    break
+            else:
+                self._log("line %r not found in output" % line)
+                raise ValueError(self._log_text)
+
+    def get_lines_after(self, fnline):
+        """Return all lines following the given line in the text.
+
+        The given line can contain glob wildcards.
+
+        """
+        for i, line in enumerate(self.lines):
+            if fnline == line or fnmatch(line, fnline):
+                return self.lines[i + 1 :]
+        raise ValueError("line %r not found in output" % fnline)
+
+    def _log(self, *args):
+        self._log_output.append(" ".join((str(x) for x in args)))
+
+    @property
+    def _log_text(self):
+        return "\n".join(self._log_output)
+
+    def fnmatch_lines(self, lines2):
+        """Search captured text for matching lines using ``fnmatch.fnmatch``.
+
+        The argument is a list of lines which have to match and can use glob
+        wildcards.  If they do not match a pytest.fail() is called.  The
+        matches and non-matches are also printed on stdout.
+
+        """
+        __tracebackhide__ = True
+        self._match_lines(lines2, fnmatch, "fnmatch")
+
+    def re_match_lines(self, lines2):
+        """Search captured text for matching lines using ``re.match``.
+
+        The argument is a list of lines which have to match using ``re.match``.
+        If they do not match a pytest.fail() is called.
+
+        The matches and non-matches are also printed on stdout.
+
+        """
+        __tracebackhide__ = True
+        self._match_lines(lines2, lambda name, pat: re.match(pat, name), "re.match")
+
+    def _match_lines(self, lines2, match_func, match_nickname):
+        """Underlying implementation of ``fnmatch_lines`` and ``re_match_lines``.
+
+        :param list[str] lines2: list of string patterns to match. The actual
+            format depends on ``match_func``
+        :param match_func: a callable ``match_func(line, pattern)`` where line
+            is the captured line from stdout/stderr and pattern is the matching
+            pattern
+        :param str match_nickname: the nickname for the match function that
+            will be logged to stdout when a match occurs
+
+        """
+        lines2 = self._getlines(lines2)
+        lines1 = self.lines[:]
+        nextline = None
+        extralines = []
+        __tracebackhide__ = True
+        for line in lines2:
+            nomatchprinted = False
+            while lines1:
+                nextline = lines1.pop(0)
+                if line == nextline:
+                    self._log("exact match:", repr(line))
+                    break
+                elif match_func(nextline, line):
+                    self._log("%s:" % match_nickname, repr(line))
+                    self._log("   with:", repr(nextline))
+                    break
+                else:
+                    if not nomatchprinted:
+                        self._log("nomatch:", repr(line))
+                        nomatchprinted = True
+                    self._log("    and:", repr(nextline))
+                extralines.append(nextline)
+            else:
+                self._log("remains unmatched: %r" % (line,))
+                pytest.fail(self._log_text)
Index: venv/Lib/site-packages/py/_io/capture.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_io/capture.py	(date 1543190976452)
+++ venv/Lib/site-packages/py/_io/capture.py	(date 1543190976452)
@@ -0,0 +1,371 @@
+import os
+import sys
+import py
+import tempfile
+
+try:
+    from io import StringIO
+except ImportError:
+    from StringIO import StringIO
+
+if sys.version_info < (3,0):
+    class TextIO(StringIO):
+        def write(self, data):
+            if not isinstance(data, unicode):
+                data = unicode(data, getattr(self, '_encoding', 'UTF-8'), 'replace')
+            StringIO.write(self, data)
+else:
+    TextIO = StringIO
+
+try:
+    from io import BytesIO
+except ImportError:
+    class BytesIO(StringIO):
+        def write(self, data):
+            if isinstance(data, unicode):
+                raise TypeError("not a byte value: %r" %(data,))
+            StringIO.write(self, data)
+
+patchsysdict = {0: 'stdin', 1: 'stdout', 2: 'stderr'}
+
+class FDCapture:
+    """ Capture IO to/from a given os-level filedescriptor. """
+
+    def __init__(self, targetfd, tmpfile=None, now=True, patchsys=False):
+        """ save targetfd descriptor, and open a new
+            temporary file there.  If no tmpfile is
+            specified a tempfile.Tempfile() will be opened
+            in text mode.
+        """
+        self.targetfd = targetfd
+        if tmpfile is None and targetfd != 0:
+            f = tempfile.TemporaryFile('wb+')
+            tmpfile = dupfile(f, encoding="UTF-8")
+            f.close()
+        self.tmpfile = tmpfile
+        self._savefd = os.dup(self.targetfd)
+        if patchsys:
+            self._oldsys = getattr(sys, patchsysdict[targetfd])
+        if now:
+            self.start()
+
+    def start(self):
+        try:
+            os.fstat(self._savefd)
+        except OSError:
+            raise ValueError("saved filedescriptor not valid, "
+                "did you call start() twice?")
+        if self.targetfd == 0 and not self.tmpfile:
+            fd = os.open(devnullpath, os.O_RDONLY)
+            os.dup2(fd, 0)
+            os.close(fd)
+            if hasattr(self, '_oldsys'):
+                setattr(sys, patchsysdict[self.targetfd], DontReadFromInput())
+        else:
+            os.dup2(self.tmpfile.fileno(), self.targetfd)
+            if hasattr(self, '_oldsys'):
+                setattr(sys, patchsysdict[self.targetfd], self.tmpfile)
+
+    def done(self):
+        """ unpatch and clean up, returns the self.tmpfile (file object)
+        """
+        os.dup2(self._savefd, self.targetfd)
+        os.close(self._savefd)
+        if self.targetfd != 0:
+            self.tmpfile.seek(0)
+        if hasattr(self, '_oldsys'):
+            setattr(sys, patchsysdict[self.targetfd], self._oldsys)
+        return self.tmpfile
+
+    def writeorg(self, data):
+        """ write a string to the original file descriptor
+        """
+        tempfp = tempfile.TemporaryFile()
+        try:
+            os.dup2(self._savefd, tempfp.fileno())
+            tempfp.write(data)
+        finally:
+            tempfp.close()
+
+
+def dupfile(f, mode=None, buffering=0, raising=False, encoding=None):
+    """ return a new open file object that's a duplicate of f
+
+        mode is duplicated if not given, 'buffering' controls
+        buffer size (defaulting to no buffering) and 'raising'
+        defines whether an exception is raised when an incompatible
+        file object is passed in (if raising is False, the file
+        object itself will be returned)
+    """
+    try:
+        fd = f.fileno()
+        mode = mode or f.mode
+    except AttributeError:
+        if raising:
+            raise
+        return f
+    newfd = os.dup(fd)
+    if sys.version_info >= (3,0):
+        if encoding is not None:
+            mode = mode.replace("b", "")
+            buffering = True
+        return os.fdopen(newfd, mode, buffering, encoding, closefd=True)
+    else:
+        f = os.fdopen(newfd, mode, buffering)
+        if encoding is not None:
+            return EncodedFile(f, encoding)
+        return f
+
+class EncodedFile(object):
+    def __init__(self, _stream, encoding):
+        self._stream = _stream
+        self.encoding = encoding
+
+    def write(self, obj):
+        if isinstance(obj, unicode):
+            obj = obj.encode(self.encoding)
+        elif isinstance(obj, str):
+            pass
+        else:
+            obj = str(obj)
+        self._stream.write(obj)
+
+    def writelines(self, linelist):
+        data = ''.join(linelist)
+        self.write(data)
+
+    def __getattr__(self, name):
+        return getattr(self._stream, name)
+
+class Capture(object):
+    def call(cls, func, *args, **kwargs):
+        """ return a (res, out, err) tuple where
+            out and err represent the output/error output
+            during function execution.
+            call the given function with args/kwargs
+            and capture output/error during its execution.
+        """
+        so = cls()
+        try:
+            res = func(*args, **kwargs)
+        finally:
+            out, err = so.reset()
+        return res, out, err
+    call = classmethod(call)
+
+    def reset(self):
+        """ reset sys.stdout/stderr and return captured output as strings. """
+        if hasattr(self, '_reset'):
+            raise ValueError("was already reset")
+        self._reset = True
+        outfile, errfile = self.done(save=False)
+        out, err = "", ""
+        if outfile and not outfile.closed:
+            out = outfile.read()
+            outfile.close()
+        if errfile and errfile != outfile and not errfile.closed:
+            err = errfile.read()
+            errfile.close()
+        return out, err
+
+    def suspend(self):
+        """ return current snapshot captures, memorize tempfiles. """
+        outerr = self.readouterr()
+        outfile, errfile = self.done()
+        return outerr
+
+
+class StdCaptureFD(Capture):
+    """ This class allows to capture writes to FD1 and FD2
+        and may connect a NULL file to FD0 (and prevent
+        reads from sys.stdin).  If any of the 0,1,2 file descriptors
+        is invalid it will not be captured.
+    """
+    def __init__(self, out=True, err=True, mixed=False,
+        in_=True, patchsys=True, now=True):
+        self._options = {
+            "out": out,
+            "err": err,
+            "mixed": mixed,
+            "in_": in_,
+            "patchsys": patchsys,
+            "now": now,
+        }
+        self._save()
+        if now:
+            self.startall()
+
+    def _save(self):
+        in_ = self._options['in_']
+        out = self._options['out']
+        err = self._options['err']
+        mixed = self._options['mixed']
+        patchsys = self._options['patchsys']
+        if in_:
+            try:
+                self.in_ = FDCapture(0, tmpfile=None, now=False,
+                    patchsys=patchsys)
+            except OSError:
+                pass
+        if out:
+            tmpfile = None
+            if hasattr(out, 'write'):
+                tmpfile = out
+            try:
+                self.out = FDCapture(1, tmpfile=tmpfile,
+                           now=False, patchsys=patchsys)
+                self._options['out'] = self.out.tmpfile
+            except OSError:
+                pass
+        if err:
+            if out and mixed:
+                tmpfile = self.out.tmpfile
+            elif hasattr(err, 'write'):
+                tmpfile = err
+            else:
+                tmpfile = None
+            try:
+                self.err = FDCapture(2, tmpfile=tmpfile,
+                           now=False, patchsys=patchsys)
+                self._options['err'] = self.err.tmpfile
+            except OSError:
+                pass
+
+    def startall(self):
+        if hasattr(self, 'in_'):
+            self.in_.start()
+        if hasattr(self, 'out'):
+            self.out.start()
+        if hasattr(self, 'err'):
+            self.err.start()
+
+    def resume(self):
+        """ resume capturing with original temp files. """
+        self.startall()
+
+    def done(self, save=True):
+        """ return (outfile, errfile) and stop capturing. """
+        outfile = errfile = None
+        if hasattr(self, 'out') and not self.out.tmpfile.closed:
+            outfile = self.out.done()
+        if hasattr(self, 'err') and not self.err.tmpfile.closed:
+            errfile = self.err.done()
+        if hasattr(self, 'in_'):
+            tmpfile = self.in_.done()
+        if save:
+            self._save()
+        return outfile, errfile
+
+    def readouterr(self):
+        """ return snapshot value of stdout/stderr capturings. """
+        if hasattr(self, "out"):
+            out = self._readsnapshot(self.out.tmpfile)
+        else:
+            out = ""
+        if hasattr(self, "err"):
+            err = self._readsnapshot(self.err.tmpfile)
+        else:
+            err = ""
+        return [out, err]
+
+    def _readsnapshot(self, f):
+        f.seek(0)
+        res = f.read()
+        enc = getattr(f, "encoding", None)
+        if enc:
+            res = py.builtin._totext(res, enc, "replace")
+        f.truncate(0)
+        f.seek(0)
+        return res
+
+
+class StdCapture(Capture):
+    """ This class allows to capture writes to sys.stdout|stderr "in-memory"
+        and will raise errors on tries to read from sys.stdin. It only
+        modifies sys.stdout|stderr|stdin attributes and does not
+        touch underlying File Descriptors (use StdCaptureFD for that).
+    """
+    def __init__(self, out=True, err=True, in_=True, mixed=False, now=True):
+        self._oldout = sys.stdout
+        self._olderr = sys.stderr
+        self._oldin  = sys.stdin
+        if out and not hasattr(out, 'file'):
+            out = TextIO()
+        self.out = out
+        if err:
+            if mixed:
+                err = out
+            elif not hasattr(err, 'write'):
+                err = TextIO()
+        self.err = err
+        self.in_ = in_
+        if now:
+            self.startall()
+
+    def startall(self):
+        if self.out:
+            sys.stdout = self.out
+        if self.err:
+            sys.stderr = self.err
+        if self.in_:
+            sys.stdin  = self.in_  = DontReadFromInput()
+
+    def done(self, save=True):
+        """ return (outfile, errfile) and stop capturing. """
+        outfile = errfile = None
+        if self.out and not self.out.closed:
+            sys.stdout = self._oldout
+            outfile = self.out
+            outfile.seek(0)
+        if self.err and not self.err.closed:
+            sys.stderr = self._olderr
+            errfile = self.err
+            errfile.seek(0)
+        if self.in_:
+            sys.stdin = self._oldin
+        return outfile, errfile
+
+    def resume(self):
+        """ resume capturing with original temp files. """
+        self.startall()
+
+    def readouterr(self):
+        """ return snapshot value of stdout/stderr capturings. """
+        out = err = ""
+        if self.out:
+            out = self.out.getvalue()
+            self.out.truncate(0)
+            self.out.seek(0)
+        if self.err:
+            err = self.err.getvalue()
+            self.err.truncate(0)
+            self.err.seek(0)
+        return out, err
+
+class DontReadFromInput:
+    """Temporary stub class.  Ideally when stdin is accessed, the
+    capturing should be turned off, with possibly all data captured
+    so far sent to the screen.  This should be configurable, though,
+    because in automated test runs it is better to crash than
+    hang indefinitely.
+    """
+    def read(self, *args):
+        raise IOError("reading from stdin while output is captured")
+    readline = read
+    readlines = read
+    __iter__ = read
+
+    def fileno(self):
+        raise ValueError("redirected Stdin is pseudofile, has no fileno()")
+    def isatty(self):
+        return False
+    def close(self):
+        pass
+
+try:
+    devnullpath = os.devnull
+except AttributeError:
+    if os.name == 'nt':
+        devnullpath = 'NUL'
+    else:
+        devnullpath = '/dev/null'
Index: venv/Lib/site-packages/py/_io/terminalwriter.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_io/terminalwriter.py	(date 1543190976463)
+++ venv/Lib/site-packages/py/_io/terminalwriter.py	(date 1543190976463)
@@ -0,0 +1,421 @@
+"""
+
+Helper functions for writing to terminals and files.
+
+"""
+
+
+import sys, os, unicodedata
+import py
+py3k = sys.version_info[0] >= 3
+py33 = sys.version_info >= (3, 3)
+from py.builtin import text, bytes
+
+win32_and_ctypes = False
+colorama = None
+if sys.platform == "win32":
+    try:
+        import colorama
+    except ImportError:
+        try:
+            import ctypes
+            win32_and_ctypes = True
+        except ImportError:
+            pass
+
+
+def _getdimensions():
+    if py33:
+        import shutil
+        size = shutil.get_terminal_size()
+        return size.lines, size.columns
+    else:
+        import termios, fcntl, struct
+        call = fcntl.ioctl(1, termios.TIOCGWINSZ, "\000" * 8)
+        height, width = struct.unpack("hhhh", call)[:2]
+        return height, width
+
+
+def get_terminal_width():
+    width = 0
+    try:
+        _, width = _getdimensions()
+    except py.builtin._sysex:
+        raise
+    except:
+        # pass to fallback below
+        pass
+
+    if width == 0:
+        # FALLBACK:
+        # * some exception happened
+        # * or this is emacs terminal which reports (0,0)
+        width = int(os.environ.get('COLUMNS', 80))
+
+    # XXX the windows getdimensions may be bogus, let's sanify a bit
+    if width < 40:
+        width = 80
+    return width
+
+terminal_width = get_terminal_width()
+
+char_width = {
+    'A': 1,   # "Ambiguous"
+    'F': 2,   # Fullwidth
+    'H': 1,   # Halfwidth
+    'N': 1,   # Neutral
+    'Na': 1,  # Narrow
+    'W': 2,   # Wide
+}
+
+
+def get_line_width(text):
+    text = unicodedata.normalize('NFC', text)
+    return sum(char_width.get(unicodedata.east_asian_width(c), 1) for c in text)
+
+
+# XXX unify with _escaped func below
+def ansi_print(text, esc, file=None, newline=True, flush=False):
+    if file is None:
+        file = sys.stderr
+    text = text.rstrip()
+    if esc and not isinstance(esc, tuple):
+        esc = (esc,)
+    if esc and sys.platform != "win32" and file.isatty():
+        text = (''.join(['\x1b[%sm' % cod for cod in esc])  +
+                text +
+                '\x1b[0m')     # ANSI color code "reset"
+    if newline:
+        text += '\n'
+
+    if esc and win32_and_ctypes and file.isatty():
+        if 1 in esc:
+            bold = True
+            esc = tuple([x for x in esc if x != 1])
+        else:
+            bold = False
+        esctable = {()   : FOREGROUND_WHITE,                 # normal
+                    (31,): FOREGROUND_RED,                   # red
+                    (32,): FOREGROUND_GREEN,                 # green
+                    (33,): FOREGROUND_GREEN|FOREGROUND_RED,  # yellow
+                    (34,): FOREGROUND_BLUE,                  # blue
+                    (35,): FOREGROUND_BLUE|FOREGROUND_RED,   # purple
+                    (36,): FOREGROUND_BLUE|FOREGROUND_GREEN, # cyan
+                    (37,): FOREGROUND_WHITE,                 # white
+                    (39,): FOREGROUND_WHITE,                 # reset
+                    }
+        attr = esctable.get(esc, FOREGROUND_WHITE)
+        if bold:
+            attr |= FOREGROUND_INTENSITY
+        STD_OUTPUT_HANDLE = -11
+        STD_ERROR_HANDLE = -12
+        if file is sys.stderr:
+            handle = GetStdHandle(STD_ERROR_HANDLE)
+        else:
+            handle = GetStdHandle(STD_OUTPUT_HANDLE)
+        oldcolors = GetConsoleInfo(handle).wAttributes
+        attr |= (oldcolors & 0x0f0)
+        SetConsoleTextAttribute(handle, attr)
+        while len(text) > 32768:
+            file.write(text[:32768])
+            text = text[32768:]
+        if text:
+            file.write(text)
+        SetConsoleTextAttribute(handle, oldcolors)
+    else:
+        file.write(text)
+
+    if flush:
+        file.flush()
+
+def should_do_markup(file):
+    if os.environ.get('PY_COLORS') == '1':
+        return True
+    if os.environ.get('PY_COLORS') == '0':
+        return False
+    return hasattr(file, 'isatty') and file.isatty() \
+           and os.environ.get('TERM') != 'dumb' \
+           and not (sys.platform.startswith('java') and os._name == 'nt')
+
+class TerminalWriter(object):
+    _esctable = dict(black=30, red=31, green=32, yellow=33,
+                     blue=34, purple=35, cyan=36, white=37,
+                     Black=40, Red=41, Green=42, Yellow=43,
+                     Blue=44, Purple=45, Cyan=46, White=47,
+                     bold=1, light=2, blink=5, invert=7)
+
+    # XXX deprecate stringio argument
+    def __init__(self, file=None, stringio=False, encoding=None):
+        if file is None:
+            if stringio:
+                self.stringio = file = py.io.TextIO()
+            else:
+                from sys import stdout as file
+        elif py.builtin.callable(file) and not (
+             hasattr(file, "write") and hasattr(file, "flush")):
+            file = WriteFile(file, encoding=encoding)
+        if hasattr(file, "isatty") and file.isatty() and colorama:
+            file = colorama.AnsiToWin32(file).stream
+        self.encoding = encoding or getattr(file, 'encoding', "utf-8")
+        self._file = file
+        self.hasmarkup = should_do_markup(file)
+        self._lastlen = 0
+        self._chars_on_current_line = 0
+        self._width_of_current_line = 0
+
+    @property
+    def fullwidth(self):
+        if hasattr(self, '_terminal_width'):
+            return self._terminal_width
+        return get_terminal_width()
+
+    @fullwidth.setter
+    def fullwidth(self, value):
+        self._terminal_width = value
+
+    @property
+    def chars_on_current_line(self):
+        """Return the number of characters written so far in the current line.
+
+        Please note that this count does not produce correct results after a reline() call,
+        see #164.
+
+        .. versionadded:: 1.5.0
+
+        :rtype: int
+        """
+        return self._chars_on_current_line
+
+    @property
+    def width_of_current_line(self):
+        """Return an estimate of the width so far in the current line.
+
+        .. versionadded:: 1.6.0
+
+        :rtype: int
+        """
+        return self._width_of_current_line
+
+    def _escaped(self, text, esc):
+        if esc and self.hasmarkup:
+            text = (''.join(['\x1b[%sm' % cod for cod in esc])  +
+                text +'\x1b[0m')
+        return text
+
+    def markup(self, text, **kw):
+        esc = []
+        for name in kw:
+            if name not in self._esctable:
+                raise ValueError("unknown markup: %r" %(name,))
+            if kw[name]:
+                esc.append(self._esctable[name])
+        return self._escaped(text, tuple(esc))
+
+    def sep(self, sepchar, title=None, fullwidth=None, **kw):
+        if fullwidth is None:
+            fullwidth = self.fullwidth
+        # the goal is to have the line be as long as possible
+        # under the condition that len(line) <= fullwidth
+        if sys.platform == "win32":
+            # if we print in the last column on windows we are on a
+            # new line but there is no way to verify/neutralize this
+            # (we may not know the exact line width)
+            # so let's be defensive to avoid empty lines in the output
+            fullwidth -= 1
+        if title is not None:
+            # we want 2 + 2*len(fill) + len(title) <= fullwidth
+            # i.e.    2 + 2*len(sepchar)*N + len(title) <= fullwidth
+            #         2*len(sepchar)*N <= fullwidth - len(title) - 2
+            #         N <= (fullwidth - len(title) - 2) // (2*len(sepchar))
+            N = (fullwidth - len(title) - 2) // (2*len(sepchar))
+            fill = sepchar * N
+            line = "%s %s %s" % (fill, title, fill)
+        else:
+            # we want len(sepchar)*N <= fullwidth
+            # i.e.    N <= fullwidth // len(sepchar)
+            line = sepchar * (fullwidth // len(sepchar))
+        # in some situations there is room for an extra sepchar at the right,
+        # in particular if we consider that with a sepchar like "_ " the
+        # trailing space is not important at the end of the line
+        if len(line) + len(sepchar.rstrip()) <= fullwidth:
+            line += sepchar.rstrip()
+
+        self.line(line, **kw)
+
+    def write(self, msg, **kw):
+        if msg:
+            if not isinstance(msg, (bytes, text)):
+                msg = text(msg)
+
+            self._update_chars_on_current_line(msg)
+
+            if self.hasmarkup and kw:
+                markupmsg = self.markup(msg, **kw)
+            else:
+                markupmsg = msg
+            write_out(self._file, markupmsg)
+
+    def _update_chars_on_current_line(self, text_or_bytes):
+        newline = b'\n' if isinstance(text_or_bytes, bytes) else '\n'
+        current_line = text_or_bytes.rsplit(newline, 1)[-1]
+        if isinstance(current_line, bytes):
+            current_line = current_line.decode('utf-8', errors='replace')
+        if newline in text_or_bytes:
+            self._chars_on_current_line = len(current_line)
+            self._width_of_current_line = get_line_width(current_line)
+        else:
+            self._chars_on_current_line += len(current_line)
+            self._width_of_current_line += get_line_width(current_line)
+
+    def line(self, s='', **kw):
+        self.write(s, **kw)
+        self._checkfill(s)
+        self.write('\n')
+
+    def reline(self, line, **kw):
+        if not self.hasmarkup:
+            raise ValueError("cannot use rewrite-line without terminal")
+        self.write(line, **kw)
+        self._checkfill(line)
+        self.write('\r')
+        self._lastlen = len(line)
+
+    def _checkfill(self, line):
+        diff2last = self._lastlen - len(line)
+        if diff2last > 0:
+            self.write(" " * diff2last)
+
+class Win32ConsoleWriter(TerminalWriter):
+    def write(self, msg, **kw):
+        if msg:
+            if not isinstance(msg, (bytes, text)):
+                msg = text(msg)
+
+            self._update_chars_on_current_line(msg)
+
+            oldcolors = None
+            if self.hasmarkup and kw:
+                handle = GetStdHandle(STD_OUTPUT_HANDLE)
+                oldcolors = GetConsoleInfo(handle).wAttributes
+                default_bg = oldcolors & 0x00F0
+                attr = default_bg
+                if kw.pop('bold', False):
+                    attr |= FOREGROUND_INTENSITY
+
+                if kw.pop('red', False):
+                    attr |= FOREGROUND_RED
+                elif kw.pop('blue', False):
+                    attr |= FOREGROUND_BLUE
+                elif kw.pop('green', False):
+                    attr |= FOREGROUND_GREEN
+                elif kw.pop('yellow', False):
+                    attr |= FOREGROUND_GREEN|FOREGROUND_RED
+                else:
+                    attr |= oldcolors & 0x0007
+
+                SetConsoleTextAttribute(handle, attr)
+            write_out(self._file, msg)
+            if oldcolors:
+                SetConsoleTextAttribute(handle, oldcolors)
+
+class WriteFile(object):
+    def __init__(self, writemethod, encoding=None):
+        self.encoding = encoding
+        self._writemethod = writemethod
+
+    def write(self, data):
+        if self.encoding:
+            data = data.encode(self.encoding, "replace")
+        self._writemethod(data)
+
+    def flush(self):
+        return
+
+
+if win32_and_ctypes:
+    TerminalWriter = Win32ConsoleWriter
+    import ctypes
+    from ctypes import wintypes
+
+    # ctypes access to the Windows console
+    STD_OUTPUT_HANDLE = -11
+    STD_ERROR_HANDLE  = -12
+    FOREGROUND_BLACK     = 0x0000 # black text
+    FOREGROUND_BLUE      = 0x0001 # text color contains blue.
+    FOREGROUND_GREEN     = 0x0002 # text color contains green.
+    FOREGROUND_RED       = 0x0004 # text color contains red.
+    FOREGROUND_WHITE     = 0x0007
+    FOREGROUND_INTENSITY = 0x0008 # text color is intensified.
+    BACKGROUND_BLACK     = 0x0000 # background color black
+    BACKGROUND_BLUE      = 0x0010 # background color contains blue.
+    BACKGROUND_GREEN     = 0x0020 # background color contains green.
+    BACKGROUND_RED       = 0x0040 # background color contains red.
+    BACKGROUND_WHITE     = 0x0070
+    BACKGROUND_INTENSITY = 0x0080 # background color is intensified.
+
+    SHORT = ctypes.c_short
+    class COORD(ctypes.Structure):
+        _fields_ = [('X', SHORT),
+                    ('Y', SHORT)]
+    class SMALL_RECT(ctypes.Structure):
+        _fields_ = [('Left', SHORT),
+                    ('Top', SHORT),
+                    ('Right', SHORT),
+                    ('Bottom', SHORT)]
+    class CONSOLE_SCREEN_BUFFER_INFO(ctypes.Structure):
+        _fields_ = [('dwSize', COORD),
+                    ('dwCursorPosition', COORD),
+                    ('wAttributes', wintypes.WORD),
+                    ('srWindow', SMALL_RECT),
+                    ('dwMaximumWindowSize', COORD)]
+
+    _GetStdHandle = ctypes.windll.kernel32.GetStdHandle
+    _GetStdHandle.argtypes = [wintypes.DWORD]
+    _GetStdHandle.restype = wintypes.HANDLE
+    def GetStdHandle(kind):
+        return _GetStdHandle(kind)
+
+    SetConsoleTextAttribute = ctypes.windll.kernel32.SetConsoleTextAttribute
+    SetConsoleTextAttribute.argtypes = [wintypes.HANDLE, wintypes.WORD]
+    SetConsoleTextAttribute.restype = wintypes.BOOL
+
+    _GetConsoleScreenBufferInfo = \
+        ctypes.windll.kernel32.GetConsoleScreenBufferInfo
+    _GetConsoleScreenBufferInfo.argtypes = [wintypes.HANDLE,
+                                ctypes.POINTER(CONSOLE_SCREEN_BUFFER_INFO)]
+    _GetConsoleScreenBufferInfo.restype = wintypes.BOOL
+    def GetConsoleInfo(handle):
+        info = CONSOLE_SCREEN_BUFFER_INFO()
+        _GetConsoleScreenBufferInfo(handle, ctypes.byref(info))
+        return info
+
+    def _getdimensions():
+        handle = GetStdHandle(STD_OUTPUT_HANDLE)
+        info = GetConsoleInfo(handle)
+        # Substract one from the width, otherwise the cursor wraps
+        # and the ending \n causes an empty line to display.
+        return info.dwSize.Y, info.dwSize.X - 1
+
+def write_out(fil, msg):
+    # XXX sometimes "msg" is of type bytes, sometimes text which
+    # complicates the situation.  Should we try to enforce unicode?
+    try:
+        # on py27 and above writing out to sys.stdout with an encoding
+        # should usually work for unicode messages (if the encoding is
+        # capable of it)
+        fil.write(msg)
+    except UnicodeEncodeError:
+        # on py26 it might not work because stdout expects bytes
+        if fil.encoding:
+            try:
+                fil.write(msg.encode(fil.encoding))
+            except UnicodeEncodeError:
+                # it might still fail if the encoding is not capable
+                pass
+            else:
+                fil.flush()
+                return
+        # fallback: escape all unicode characters
+        msg = msg.encode("unicode-escape").decode("ascii")
+        fil.write(msg)
+    fil.flush()
Index: venv/Lib/site-packages/py/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/__init__.py	(date 1543190976475)
+++ venv/Lib/site-packages/py/__init__.py	(date 1543190976475)
@@ -0,0 +1,156 @@
+"""
+pylib: rapid testing and development utils
+
+this module uses apipkg.py for lazy-loading sub modules
+and classes.  The initpkg-dictionary  below specifies
+name->value mappings where value can be another namespace
+dictionary or an import path.
+
+(c) Holger Krekel and others, 2004-2014
+"""
+from py._error import error
+
+try:
+    from py._vendored_packages import apipkg
+    lib_not_mangled_by_packagers = True
+    vendor_prefix = '._vendored_packages.'
+except ImportError:
+    import apipkg
+    lib_not_mangled_by_packagers = False
+    vendor_prefix = ''
+
+try:
+    from ._version import version as __version__
+except ImportError:
+    # broken installation, we don't even try
+    __version__ = "unknown"
+
+
+apipkg.initpkg(__name__, attr={'_apipkg': apipkg, 'error': error}, exportdefs={
+    # access to all standard lib modules
+    'std': '._std:std',
+
+    '_pydir' : '.__metainfo:pydir',
+    'version': 'py:__version__', # backward compatibility
+
+    # pytest-2.0 has a flat namespace, we use alias modules
+    # to keep old references compatible
+    'test' : 'pytest',
+
+    # hook into the top-level standard library
+    'process' : {
+        '__doc__'        : '._process:__doc__',
+        'cmdexec'        : '._process.cmdexec:cmdexec',
+        'kill'           : '._process.killproc:kill',
+        'ForkedFunc'     : '._process.forkedfunc:ForkedFunc',
+    },
+
+    'apipkg' : {
+        'initpkg'   : vendor_prefix + 'apipkg:initpkg',
+        'ApiModule' : vendor_prefix + 'apipkg:ApiModule',
+    },
+
+    'iniconfig' : {
+        'IniConfig'      : vendor_prefix + 'iniconfig:IniConfig',
+        'ParseError'     : vendor_prefix + 'iniconfig:ParseError',
+    },
+
+    'path' : {
+        '__doc__'        : '._path:__doc__',
+        'svnwc'          : '._path.svnwc:SvnWCCommandPath',
+        'svnurl'         : '._path.svnurl:SvnCommandPath',
+        'local'          : '._path.local:LocalPath',
+        'SvnAuth'        : '._path.svnwc:SvnAuth',
+    },
+
+    # python inspection/code-generation API
+    'code' : {
+        '__doc__'           : '._code:__doc__',
+        'compile'           : '._code.source:compile_',
+        'Source'            : '._code.source:Source',
+        'Code'              : '._code.code:Code',
+        'Frame'             : '._code.code:Frame',
+        'ExceptionInfo'     : '._code.code:ExceptionInfo',
+        'Traceback'         : '._code.code:Traceback',
+        'getfslineno'       : '._code.source:getfslineno',
+        'getrawcode'        : '._code.code:getrawcode',
+        'patch_builtins'    : '._code.code:patch_builtins',
+        'unpatch_builtins'  : '._code.code:unpatch_builtins',
+        '_AssertionError'   : '._code.assertion:AssertionError',
+        '_reinterpret_old'  : '._code.assertion:reinterpret_old',
+        '_reinterpret'      : '._code.assertion:reinterpret',
+        '_reprcompare'      : '._code.assertion:_reprcompare',
+        '_format_explanation' : '._code.assertion:_format_explanation',
+    },
+
+    # backports and additions of builtins
+    'builtin' : {
+        '__doc__'        : '._builtin:__doc__',
+        'enumerate'      : '._builtin:enumerate',
+        'reversed'       : '._builtin:reversed',
+        'sorted'         : '._builtin:sorted',
+        'any'            : '._builtin:any',
+        'all'            : '._builtin:all',
+        'set'            : '._builtin:set',
+        'frozenset'      : '._builtin:frozenset',
+        'BaseException'  : '._builtin:BaseException',
+        'GeneratorExit'  : '._builtin:GeneratorExit',
+        '_sysex'         : '._builtin:_sysex',
+        'print_'         : '._builtin:print_',
+        '_reraise'       : '._builtin:_reraise',
+        '_tryimport'     : '._builtin:_tryimport',
+        'exec_'          : '._builtin:exec_',
+        '_basestring'    : '._builtin:_basestring',
+        '_totext'        : '._builtin:_totext',
+        '_isbytes'       : '._builtin:_isbytes',
+        '_istext'        : '._builtin:_istext',
+        '_getimself'     : '._builtin:_getimself',
+        '_getfuncdict'   : '._builtin:_getfuncdict',
+        '_getcode'       : '._builtin:_getcode',
+        'builtins'       : '._builtin:builtins',
+        'execfile'       : '._builtin:execfile',
+        'callable'       : '._builtin:callable',
+        'bytes'       : '._builtin:bytes',
+        'text'       : '._builtin:text',
+    },
+
+    # input-output helping
+    'io' : {
+        '__doc__'             : '._io:__doc__',
+        'dupfile'             : '._io.capture:dupfile',
+        'TextIO'              : '._io.capture:TextIO',
+        'BytesIO'             : '._io.capture:BytesIO',
+        'FDCapture'           : '._io.capture:FDCapture',
+        'StdCapture'          : '._io.capture:StdCapture',
+        'StdCaptureFD'        : '._io.capture:StdCaptureFD',
+        'TerminalWriter'      : '._io.terminalwriter:TerminalWriter',
+        'ansi_print'          : '._io.terminalwriter:ansi_print',
+        'get_terminal_width'  : '._io.terminalwriter:get_terminal_width',
+        'saferepr'            : '._io.saferepr:saferepr',
+    },
+
+    # small and mean xml/html generation
+    'xml' : {
+        '__doc__'            : '._xmlgen:__doc__',
+        'html'               : '._xmlgen:html',
+        'Tag'                : '._xmlgen:Tag',
+        'raw'                : '._xmlgen:raw',
+        'Namespace'          : '._xmlgen:Namespace',
+        'escape'             : '._xmlgen:escape',
+    },
+
+    'log' : {
+        # logging API ('producers' and 'consumers' connected via keywords)
+        '__doc__'            : '._log:__doc__',
+        '_apiwarn'           : '._log.warning:_apiwarn',
+        'Producer'           : '._log.log:Producer',
+        'setconsumer'        : '._log.log:setconsumer',
+        '_setstate'          : '._log.log:setstate',
+        '_getstate'          : '._log.log:getstate',
+        'Path'               : '._log.log:Path',
+        'STDOUT'             : '._log.log:STDOUT',
+        'STDERR'             : '._log.log:STDERR',
+        'Syslog'             : '._log.log:Syslog',
+    },
+
+})
Index: venv/Lib/site-packages/py/_version.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_version.py	(date 1543190976484)
+++ venv/Lib/site-packages/py/_version.py	(date 1543190976484)
@@ -0,0 +1,4 @@
+# coding: utf-8
+# file generated by setuptools_scm
+# don't change, don't track in version control
+version = '1.7.0'
Index: venv/Lib/site-packages/py/_builtin.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_builtin.py	(date 1543190976495)
+++ venv/Lib/site-packages/py/_builtin.py	(date 1543190976495)
@@ -0,0 +1,248 @@
+import sys
+
+try:
+    reversed = reversed
+except NameError:
+    def reversed(sequence):
+        """reversed(sequence) -> reverse iterator over values of the sequence
+
+        Return a reverse iterator
+        """
+        if hasattr(sequence, '__reversed__'):
+            return sequence.__reversed__()
+        if not hasattr(sequence, '__getitem__'):
+            raise TypeError("argument to reversed() must be a sequence")
+        return reversed_iterator(sequence)
+
+    class reversed_iterator(object):
+
+        def __init__(self, seq):
+            self.seq = seq
+            self.remaining = len(seq)
+
+        def __iter__(self):
+            return self
+
+        def next(self):
+            i = self.remaining
+            if i > 0:
+                i -= 1
+                item = self.seq[i]
+                self.remaining = i
+                return item
+            raise StopIteration
+
+        def __length_hint__(self):
+            return self.remaining
+
+try:
+    any = any
+except NameError:
+    def any(iterable):
+        for x in iterable:
+            if x:
+                return True
+        return False
+
+try:
+    all = all
+except NameError:
+    def all(iterable):
+        for x in iterable:
+            if not x:
+                return False
+        return True
+
+try:
+    sorted = sorted
+except NameError:
+    builtin_cmp = cmp # need to use cmp as keyword arg
+
+    def sorted(iterable, cmp=None, key=None, reverse=0):
+        use_cmp = None
+        if key is not None:
+            if cmp is None:
+                def use_cmp(x, y):
+                    return builtin_cmp(x[0], y[0])
+            else:
+                def use_cmp(x, y):
+                    return cmp(x[0], y[0])
+            l = [(key(element), element) for element in iterable]
+        else:
+            if cmp is not None:
+                use_cmp = cmp
+            l = list(iterable)
+        if use_cmp is not None:
+            l.sort(use_cmp)
+        else:
+            l.sort()
+        if reverse:
+            l.reverse()
+        if key is not None:
+            return [element for (_, element) in l]
+        return l
+
+try:
+    set, frozenset = set, frozenset
+except NameError:
+    from sets import set, frozenset
+
+# pass through
+enumerate = enumerate
+
+try:
+    BaseException = BaseException
+except NameError:
+    BaseException = Exception
+
+try:
+    GeneratorExit = GeneratorExit
+except NameError:
+    class GeneratorExit(Exception):
+        """ This exception is never raised, it is there to make it possible to
+        write code compatible with CPython 2.5 even in lower CPython
+        versions."""
+        pass
+    GeneratorExit.__module__ = 'exceptions'
+
+_sysex = (KeyboardInterrupt, SystemExit, MemoryError, GeneratorExit)
+
+try:
+    callable = callable
+except NameError:
+    def callable(obj):
+        return hasattr(obj, "__call__")
+
+if sys.version_info >= (3, 0):
+    exec ("print_ = print ; exec_=exec")
+    import builtins
+
+    # some backward compatibility helpers
+    _basestring = str
+    def _totext(obj, encoding=None, errors=None):
+        if isinstance(obj, bytes):
+            if errors is None:
+                obj = obj.decode(encoding)
+            else:
+                obj = obj.decode(encoding, errors)
+        elif not isinstance(obj, str):
+            obj = str(obj)
+        return obj
+
+    def _isbytes(x):
+        return isinstance(x, bytes)
+    def _istext(x):
+        return isinstance(x, str)
+
+    text = str
+    bytes = bytes
+
+
+    def _getimself(function):
+        return getattr(function, '__self__', None)
+
+    def _getfuncdict(function):
+        return getattr(function, "__dict__", None)
+
+    def _getcode(function):
+        return getattr(function, "__code__", None)
+
+    def execfile(fn, globs=None, locs=None):
+        if globs is None:
+            back = sys._getframe(1)
+            globs = back.f_globals
+            locs = back.f_locals
+            del back
+        elif locs is None:
+            locs = globs
+        fp = open(fn, "r")
+        try:
+            source = fp.read()
+        finally:
+            fp.close()
+        co = compile(source, fn, "exec", dont_inherit=True)
+        exec_(co, globs, locs)
+
+else:
+    import __builtin__ as builtins
+    _totext = unicode
+    _basestring = basestring
+    text = unicode
+    bytes = str
+    execfile = execfile
+    callable = callable
+    def _isbytes(x):
+        return isinstance(x, str)
+    def _istext(x):
+        return isinstance(x, unicode)
+
+    def _getimself(function):
+        return getattr(function, 'im_self', None)
+
+    def _getfuncdict(function):
+        return getattr(function, "__dict__", None)
+
+    def _getcode(function):
+        try:
+            return getattr(function, "__code__")
+        except AttributeError:
+            return getattr(function, "func_code", None)
+
+    def print_(*args, **kwargs):
+        """ minimal backport of py3k print statement. """
+        sep = ' '
+        if 'sep' in kwargs:
+            sep = kwargs.pop('sep')
+        end = '\n'
+        if 'end' in kwargs:
+            end = kwargs.pop('end')
+        file = 'file' in kwargs and kwargs.pop('file') or sys.stdout
+        if kwargs:
+            args = ", ".join([str(x) for x in kwargs])
+            raise TypeError("invalid keyword arguments: %s" % args)
+        at_start = True
+        for x in args:
+            if not at_start:
+                file.write(sep)
+            file.write(str(x))
+            at_start = False
+        file.write(end)
+
+    def exec_(obj, globals=None, locals=None):
+        """ minimal backport of py3k exec statement. """
+        __tracebackhide__ = True
+        if globals is None:
+            frame = sys._getframe(1)
+            globals = frame.f_globals
+            if locals is None:
+                locals = frame.f_locals
+        elif locals is None:
+            locals = globals
+        exec2(obj, globals, locals)
+
+if sys.version_info >= (3, 0):
+    def _reraise(cls, val, tb):
+        __tracebackhide__ = True
+        assert hasattr(val, '__traceback__')
+        raise cls.with_traceback(val, tb)
+else:
+    exec ("""
+def _reraise(cls, val, tb):
+    __tracebackhide__ = True
+    raise cls, val, tb
+def exec2(obj, globals, locals):
+    __tracebackhide__ = True
+    exec obj in globals, locals
+""")
+
+def _tryimport(*names):
+    """ return the first successfully imported module. """
+    assert names
+    for name in names:
+        try:
+            __import__(name)
+        except ImportError:
+            excinfo = sys.exc_info()
+        else:
+            return sys.modules[name]
+    _reraise(*excinfo)
Index: venv/Lib/site-packages/py/_error.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_error.py	(date 1543190976505)
+++ venv/Lib/site-packages/py/_error.py	(date 1543190976505)
@@ -0,0 +1,91 @@
+"""
+create errno-specific classes for IO or os calls.
+
+"""
+from types import ModuleType
+import sys, os, errno
+
+class Error(EnvironmentError):
+    def __repr__(self):
+        return "%s.%s %r: %s " %(self.__class__.__module__,
+                               self.__class__.__name__,
+                               self.__class__.__doc__,
+                               " ".join(map(str, self.args)),
+                               #repr(self.args)
+                                )
+
+    def __str__(self):
+        s = "[%s]: %s" %(self.__class__.__doc__,
+                          " ".join(map(str, self.args)),
+                          )
+        return s
+
+_winerrnomap = {
+    2: errno.ENOENT,
+    3: errno.ENOENT,
+    17: errno.EEXIST,
+    18: errno.EXDEV,
+    13: errno.EBUSY, # empty cd drive, but ENOMEDIUM seems unavailiable
+    22: errno.ENOTDIR,
+    20: errno.ENOTDIR,
+    267: errno.ENOTDIR,
+    5: errno.EACCES,  # anything better?
+}
+
+class ErrorMaker(ModuleType):
+    """ lazily provides Exception classes for each possible POSIX errno
+        (as defined per the 'errno' module).  All such instances
+        subclass EnvironmentError.
+    """
+    Error = Error
+    _errno2class = {}
+
+    def __getattr__(self, name):
+        if name[0] == "_":
+            raise AttributeError(name)
+        eno = getattr(errno, name)
+        cls = self._geterrnoclass(eno)
+        setattr(self, name, cls)
+        return cls
+
+    def _geterrnoclass(self, eno):
+        try:
+            return self._errno2class[eno]
+        except KeyError:
+            clsname = errno.errorcode.get(eno, "UnknownErrno%d" %(eno,))
+            errorcls = type(Error)(clsname, (Error,),
+                    {'__module__':'py.error',
+                     '__doc__': os.strerror(eno)})
+            self._errno2class[eno] = errorcls
+            return errorcls
+
+    def checked_call(self, func, *args, **kwargs):
+        """ call a function and raise an errno-exception if applicable. """
+        __tracebackhide__ = True
+        try:
+            return func(*args, **kwargs)
+        except self.Error:
+            raise
+        except (OSError, EnvironmentError):
+            cls, value, tb = sys.exc_info()
+            if not hasattr(value, 'errno'):
+                raise
+            __tracebackhide__ = False
+            errno = value.errno
+            try:
+                if not isinstance(value, WindowsError):
+                    raise NameError
+            except NameError:
+                # we are not on Windows, or we got a proper OSError
+                cls = self._geterrnoclass(errno)
+            else:
+                try:
+                    cls = self._geterrnoclass(_winerrnomap[errno])
+                except KeyError:
+                    raise value
+            raise cls("%s%r" % (func.__name__, args))
+            __tracebackhide__ = True
+            
+
+error = ErrorMaker('py.error')
+sys.modules[error.__name__] = error
\ No newline at end of file
Index: venv/Lib/site-packages/six-1.11.0.dist-info/DESCRIPTION.rst
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six-1.11.0.dist-info/DESCRIPTION.rst	(date 1543190976515)
+++ venv/Lib/site-packages/six-1.11.0.dist-info/DESCRIPTION.rst	(date 1543190976515)
@@ -0,0 +1,27 @@
+.. image:: http://img.shields.io/pypi/v/six.svg
+   :target: https://pypi.python.org/pypi/six
+
+.. image:: https://travis-ci.org/benjaminp/six.svg?branch=master
+    :target: https://travis-ci.org/benjaminp/six
+
+.. image:: http://img.shields.io/badge/license-MIT-green.svg
+   :target: https://github.com/benjaminp/six/blob/master/LICENSE
+
+Six is a Python 2 and 3 compatibility library.  It provides utility functions
+for smoothing over the differences between the Python versions with the goal of
+writing Python code that is compatible on both Python versions.  See the
+documentation for more information on what is provided.
+
+Six supports every Python version since 2.6.  It is contained in only one Python
+file, so it can be easily copied into your project. (The copyright and license
+notice must be retained.)
+
+Online documentation is at http://six.rtfd.org.
+
+Bugs can be reported to https://github.com/benjaminp/six.  The code can also
+be found there.
+
+For questions about six or porting in general, email the python-porting mailing
+list: https://mail.python.org/mailman/listinfo/python-porting
+
+
Index: venv/Lib/site-packages/py/test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/test.py	(date 1543190976524)
+++ venv/Lib/site-packages/py/test.py	(date 1543190976524)
@@ -0,0 +1,10 @@
+import sys
+if __name__ == '__main__':
+    import pytest
+    sys.exit(pytest.main())
+else:
+    import sys, pytest
+    sys.modules['py.test'] = pytest
+
+# for more API entry points see the 'tests' definition
+# in __init__.py
Index: venv/Lib/site-packages/py/_std.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_std.py	(date 1543190976544)
+++ venv/Lib/site-packages/py/_std.py	(date 1543190976544)
@@ -0,0 +1,26 @@
+import sys
+import warnings
+
+
+class PyStdIsDeprecatedWarning(DeprecationWarning):
+    pass
+
+
+class Std(object):
+    """ makes top-level python modules available as an attribute,
+        importing them on first access.
+    """
+
+    def __init__(self):
+        self.__dict__ = sys.modules
+
+    def __getattr__(self, name):
+        warnings.warn("py.std is deprecated, plase import %s directly" % name,
+                      category=PyStdIsDeprecatedWarning)
+        try:
+            m = __import__(name)
+        except ImportError:
+            raise AttributeError("py.std: could not import %s" % name)
+        return m
+
+std = Std()
Index: venv/Lib/site-packages/_pytest/config/exceptions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/config/exceptions.py	(date 1543190976557)
+++ venv/Lib/site-packages/_pytest/config/exceptions.py	(date 1543190976557)
@@ -0,0 +1,9 @@
+class UsageError(Exception):
+    """ error in pytest usage or invocation"""
+
+
+class PrintHelp(Exception):
+    """Raised when pytest should print it's help to skip the rest of the
+    argument parsing and validation."""
+
+    pass
Index: venv/Lib/site-packages/py/__metainfo.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/__metainfo.py	(date 1543190976567)
+++ venv/Lib/site-packages/py/__metainfo.py	(date 1543190976567)
@@ -0,0 +1,2 @@
+import py
+pydir = py.path.local(py.__file__).dirpath()
Index: venv/Lib/site-packages/_pytest/helpconfig.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/helpconfig.py	(date 1543190976579)
+++ venv/Lib/site-packages/_pytest/helpconfig.py	(date 1543190976579)
@@ -0,0 +1,217 @@
+""" version info, help messages, tracing configuration.  """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import sys
+from argparse import Action
+
+import py
+
+import pytest
+from _pytest.config import PrintHelp
+
+
+class HelpAction(Action):
+    """This is an argparse Action that will raise an exception in
+    order to skip the rest of the argument parsing when --help is passed.
+    This prevents argparse from quitting due to missing required arguments
+    when any are defined, for example by ``pytest_addoption``.
+    This is similar to the way that the builtin argparse --help option is
+    implemented by raising SystemExit.
+    """
+
+    def __init__(self, option_strings, dest=None, default=False, help=None):
+        super(HelpAction, self).__init__(
+            option_strings=option_strings,
+            dest=dest,
+            const=True,
+            default=default,
+            nargs=0,
+            help=help,
+        )
+
+    def __call__(self, parser, namespace, values, option_string=None):
+        setattr(namespace, self.dest, self.const)
+
+        # We should only skip the rest of the parsing after preparse is done
+        if getattr(parser._parser, "after_preparse", False):
+            raise PrintHelp
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("debugconfig")
+    group.addoption(
+        "--version",
+        action="store_true",
+        help="display pytest lib version and import information.",
+    )
+    group._addoption(
+        "-h",
+        "--help",
+        action=HelpAction,
+        dest="help",
+        help="show help message and configuration info",
+    )
+    group._addoption(
+        "-p",
+        action="append",
+        dest="plugins",
+        default=[],
+        metavar="name",
+        help="early-load given plugin (multi-allowed). "
+        "To avoid loading of plugins, use the `no:` prefix, e.g. "
+        "`no:doctest`.",
+    )
+    group.addoption(
+        "--traceconfig",
+        "--trace-config",
+        action="store_true",
+        default=False,
+        help="trace considerations of conftest.py files.",
+    ),
+    group.addoption(
+        "--debug",
+        action="store_true",
+        dest="debug",
+        default=False,
+        help="store internal tracing debug information in 'pytestdebug.log'.",
+    )
+    group._addoption(
+        "-o",
+        "--override-ini",
+        dest="override_ini",
+        action="append",
+        help='override ini option with "option=value" style, e.g. `-o xfail_strict=True -o cache_dir=cache`.',
+    )
+
+
+@pytest.hookimpl(hookwrapper=True)
+def pytest_cmdline_parse():
+    outcome = yield
+    config = outcome.get_result()
+    if config.option.debug:
+        path = os.path.abspath("pytestdebug.log")
+        debugfile = open(path, "w")
+        debugfile.write(
+            "versions pytest-%s, py-%s, "
+            "python-%s\ncwd=%s\nargs=%s\n\n"
+            % (
+                pytest.__version__,
+                py.__version__,
+                ".".join(map(str, sys.version_info)),
+                os.getcwd(),
+                config._origargs,
+            )
+        )
+        config.trace.root.setwriter(debugfile.write)
+        undo_tracing = config.pluginmanager.enable_tracing()
+        sys.stderr.write("writing pytestdebug information to %s\n" % path)
+
+        def unset_tracing():
+            debugfile.close()
+            sys.stderr.write("wrote pytestdebug information to %s\n" % debugfile.name)
+            config.trace.root.setwriter(None)
+            undo_tracing()
+
+        config.add_cleanup(unset_tracing)
+
+
+def pytest_cmdline_main(config):
+    if config.option.version:
+        p = py.path.local(pytest.__file__)
+        sys.stderr.write(
+            "This is pytest version %s, imported from %s\n" % (pytest.__version__, p)
+        )
+        plugininfo = getpluginversioninfo(config)
+        if plugininfo:
+            for line in plugininfo:
+                sys.stderr.write(line + "\n")
+        return 0
+    elif config.option.help:
+        config._do_configure()
+        showhelp(config)
+        config._ensure_unconfigure()
+        return 0
+
+
+def showhelp(config):
+    reporter = config.pluginmanager.get_plugin("terminalreporter")
+    tw = reporter._tw
+    tw.write(config._parser.optparser.format_help())
+    tw.line()
+    tw.line()
+    tw.line(
+        "[pytest] ini-options in the first pytest.ini|tox.ini|setup.cfg file found:"
+    )
+    tw.line()
+
+    for name in config._parser._ininames:
+        help, type, default = config._parser._inidict[name]
+        if type is None:
+            type = "string"
+        spec = "%s (%s)" % (name, type)
+        line = "  %-24s %s" % (spec, help)
+        tw.line(line[: tw.fullwidth])
+
+    tw.line()
+    tw.line("environment variables:")
+    vars = [
+        ("PYTEST_ADDOPTS", "extra command line options"),
+        ("PYTEST_PLUGINS", "comma-separated plugins to load during startup"),
+        ("PYTEST_DISABLE_PLUGIN_AUTOLOAD", "set to disable plugin auto-loading"),
+        ("PYTEST_DEBUG", "set to enable debug tracing of pytest's internals"),
+    ]
+    for name, help in vars:
+        tw.line("  %-24s %s" % (name, help))
+    tw.line()
+    tw.line()
+
+    tw.line("to see available markers type: pytest --markers")
+    tw.line("to see available fixtures type: pytest --fixtures")
+    tw.line(
+        "(shown according to specified file_or_dir or current dir "
+        "if not specified; fixtures with leading '_' are only shown "
+        "with the '-v' option"
+    )
+
+    for warningreport in reporter.stats.get("warnings", []):
+        tw.line("warning : " + warningreport.message, red=True)
+    return
+
+
+conftest_options = [("pytest_plugins", "list of plugin names to load")]
+
+
+def getpluginversioninfo(config):
+    lines = []
+    plugininfo = config.pluginmanager.list_plugin_distinfo()
+    if plugininfo:
+        lines.append("setuptools registered plugins:")
+        for plugin, dist in plugininfo:
+            loc = getattr(plugin, "__file__", repr(plugin))
+            content = "%s-%s at %s" % (dist.project_name, dist.version, loc)
+            lines.append("  " + content)
+    return lines
+
+
+def pytest_report_header(config):
+    lines = []
+    if config.option.debug or config.option.traceconfig:
+        lines.append("using: pytest-%s pylib-%s" % (pytest.__version__, py.__version__))
+
+        verinfo = getpluginversioninfo(config)
+        if verinfo:
+            lines.extend(verinfo)
+
+    if config.option.traceconfig:
+        lines.append("active plugins:")
+        items = config.pluginmanager.list_name_plugin()
+        for name, plugin in items:
+            if hasattr(plugin, "__file__"):
+                r = plugin.__file__
+            else:
+                r = repr(plugin)
+            lines.append("    %-20s: %s" % (name, r))
+    return lines
Index: venv/Lib/site-packages/_pytest/recwarn.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/recwarn.py	(date 1543190976591)
+++ venv/Lib/site-packages/_pytest/recwarn.py	(date 1543190976591)
@@ -0,0 +1,241 @@
+""" recording warnings during test function execution. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import inspect
+import re
+import sys
+import warnings
+
+import six
+
+import _pytest._code
+from _pytest.fixtures import yield_fixture
+from _pytest.outcomes import fail
+
+
+@yield_fixture
+def recwarn():
+    """Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.
+
+    See http://docs.python.org/library/warnings.html for information
+    on warning categories.
+    """
+    wrec = WarningsRecorder()
+    with wrec:
+        warnings.simplefilter("default")
+        yield wrec
+
+
+def deprecated_call(func=None, *args, **kwargs):
+    """context manager that can be used to ensure a block of code triggers a
+    ``DeprecationWarning`` or ``PendingDeprecationWarning``::
+
+        >>> import warnings
+        >>> def api_call_v2():
+        ...     warnings.warn('use v3 of this api', DeprecationWarning)
+        ...     return 200
+
+        >>> with deprecated_call():
+        ...    assert api_call_v2() == 200
+
+    ``deprecated_call`` can also be used by passing a function and ``*args`` and ``*kwargs``,
+    in which case it will ensure calling ``func(*args, **kwargs)`` produces one of the warnings
+    types above.
+    """
+    __tracebackhide__ = True
+    if func is not None:
+        args = (func,) + args
+    return warns((DeprecationWarning, PendingDeprecationWarning), *args, **kwargs)
+
+
+def warns(expected_warning, *args, **kwargs):
+    r"""Assert that code raises a particular class of warning.
+
+    Specifically, the parameter ``expected_warning`` can be a warning class or
+    sequence of warning classes, and the inside the ``with`` block must issue a warning of that class or
+    classes.
+
+    This helper produces a list of :class:`warnings.WarningMessage` objects,
+    one for each warning raised.
+
+    This function can be used as a context manager, or any of the other ways
+    ``pytest.raises`` can be used::
+
+        >>> with warns(RuntimeWarning):
+        ...    warnings.warn("my warning", RuntimeWarning)
+
+    In the context manager form you may use the keyword argument ``match`` to assert
+    that the exception matches a text or regex::
+
+        >>> with warns(UserWarning, match='must be 0 or None'):
+        ...     warnings.warn("value must be 0 or None", UserWarning)
+
+        >>> with warns(UserWarning, match=r'must be \d+$'):
+        ...     warnings.warn("value must be 42", UserWarning)
+
+        >>> with warns(UserWarning, match=r'must be \d+$'):
+        ...     warnings.warn("this is not here", UserWarning)
+        Traceback (most recent call last):
+          ...
+        Failed: DID NOT WARN. No warnings of type ...UserWarning... was emitted...
+
+    """
+    __tracebackhide__ = True
+    match_expr = None
+    if not args:
+        if "match" in kwargs:
+            match_expr = kwargs.pop("match")
+        return WarningsChecker(expected_warning, match_expr=match_expr)
+    elif isinstance(args[0], str):
+        code, = args
+        assert isinstance(code, str)
+        frame = sys._getframe(1)
+        loc = frame.f_locals.copy()
+        loc.update(kwargs)
+
+        with WarningsChecker(expected_warning, match_expr=match_expr):
+            code = _pytest._code.Source(code).compile()
+            six.exec_(code, frame.f_globals, loc)
+    else:
+        func = args[0]
+        with WarningsChecker(expected_warning, match_expr=match_expr):
+            return func(*args[1:], **kwargs)
+
+
+class WarningsRecorder(warnings.catch_warnings):
+    """A context manager to record raised warnings.
+
+    Adapted from `warnings.catch_warnings`.
+    """
+
+    def __init__(self):
+        super(WarningsRecorder, self).__init__(record=True)
+        self._entered = False
+        self._list = []
+
+    @property
+    def list(self):
+        """The list of recorded warnings."""
+        return self._list
+
+    def __getitem__(self, i):
+        """Get a recorded warning by index."""
+        return self._list[i]
+
+    def __iter__(self):
+        """Iterate through the recorded warnings."""
+        return iter(self._list)
+
+    def __len__(self):
+        """The number of recorded warnings."""
+        return len(self._list)
+
+    def pop(self, cls=Warning):
+        """Pop the first recorded warning, raise exception if not exists."""
+        for i, w in enumerate(self._list):
+            if issubclass(w.category, cls):
+                return self._list.pop(i)
+        __tracebackhide__ = True
+        raise AssertionError("%r not found in warning list" % cls)
+
+    def clear(self):
+        """Clear the list of recorded warnings."""
+        self._list[:] = []
+
+    def __enter__(self):
+        if self._entered:
+            __tracebackhide__ = True
+            raise RuntimeError("Cannot enter %r twice" % self)
+        self._list = super(WarningsRecorder, self).__enter__()
+        warnings.simplefilter("always")
+        # python3 keeps track of a "filter version", when the filters are
+        # updated previously seen warnings can be re-warned.  python2 has no
+        # concept of this so we must reset the warnings registry manually.
+        # trivial patching of `warnings.warn` seems to be enough somehow?
+        if six.PY2:
+
+            def warn(message, category=None, stacklevel=1):
+                # duplicate the stdlib logic due to
+                # bad handing in the c version of warnings
+                if isinstance(message, Warning):
+                    category = message.__class__
+                # Check category argument
+                if category is None:
+                    category = UserWarning
+                assert issubclass(category, Warning)
+
+                # emulate resetting the warn registry
+                f_globals = sys._getframe(stacklevel).f_globals
+                if "__warningregistry__" in f_globals:
+                    orig = f_globals["__warningregistry__"]
+                    f_globals["__warningregistry__"] = None
+                    try:
+                        return self._saved_warn(message, category, stacklevel + 1)
+                    finally:
+                        f_globals["__warningregistry__"] = orig
+                else:
+                    return self._saved_warn(message, category, stacklevel + 1)
+
+            warnings.warn, self._saved_warn = warn, warnings.warn
+        return self
+
+    def __exit__(self, *exc_info):
+        if not self._entered:
+            __tracebackhide__ = True
+            raise RuntimeError("Cannot exit %r without entering first" % self)
+        # see above where `self._saved_warn` is assigned
+        if six.PY2:
+            warnings.warn = self._saved_warn
+        super(WarningsRecorder, self).__exit__(*exc_info)
+
+
+class WarningsChecker(WarningsRecorder):
+    def __init__(self, expected_warning=None, match_expr=None):
+        super(WarningsChecker, self).__init__()
+
+        msg = "exceptions must be old-style classes or derived from Warning, not %s"
+        if isinstance(expected_warning, tuple):
+            for exc in expected_warning:
+                if not inspect.isclass(exc):
+                    raise TypeError(msg % type(exc))
+        elif inspect.isclass(expected_warning):
+            expected_warning = (expected_warning,)
+        elif expected_warning is not None:
+            raise TypeError(msg % type(expected_warning))
+
+        self.expected_warning = expected_warning
+        self.match_expr = match_expr
+
+    def __exit__(self, *exc_info):
+        super(WarningsChecker, self).__exit__(*exc_info)
+
+        __tracebackhide__ = True
+
+        # only check if we're not currently handling an exception
+        if all(a is None for a in exc_info):
+            if self.expected_warning is not None:
+                if not any(issubclass(r.category, self.expected_warning) for r in self):
+                    __tracebackhide__ = True
+                    fail(
+                        "DID NOT WARN. No warnings of type {} was emitted. "
+                        "The list of emitted warnings is: {}.".format(
+                            self.expected_warning, [each.message for each in self]
+                        )
+                    )
+                elif self.match_expr is not None:
+                    for r in self:
+                        if issubclass(r.category, self.expected_warning):
+                            if re.compile(self.match_expr).search(str(r.message)):
+                                break
+                    else:
+                        fail(
+                            "DID NOT WARN. No warnings of type {} matching"
+                            " ('{}') was emitted. The list of emitted warnings"
+                            " is: {}.".format(
+                                self.expected_warning,
+                                self.match_expr,
+                                [each.message for each in self],
+                            )
+                        )
Index: venv/Lib/site-packages/_pytest/setuponly.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/setuponly.py	(date 1543190976601)
+++ venv/Lib/site-packages/_pytest/setuponly.py	(date 1543190976601)
@@ -0,0 +1,88 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+
+import pytest
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("debugconfig")
+    group.addoption(
+        "--setuponly",
+        "--setup-only",
+        action="store_true",
+        help="only setup fixtures, do not execute tests.",
+    )
+    group.addoption(
+        "--setupshow",
+        "--setup-show",
+        action="store_true",
+        help="show setup of fixtures while executing tests.",
+    )
+
+
+@pytest.hookimpl(hookwrapper=True)
+def pytest_fixture_setup(fixturedef, request):
+    yield
+    config = request.config
+    if config.option.setupshow:
+        if hasattr(request, "param"):
+            # Save the fixture parameter so ._show_fixture_action() can
+            # display it now and during the teardown (in .finish()).
+            if fixturedef.ids:
+                if callable(fixturedef.ids):
+                    fixturedef.cached_param = fixturedef.ids(request.param)
+                else:
+                    fixturedef.cached_param = fixturedef.ids[request.param_index]
+            else:
+                fixturedef.cached_param = request.param
+        _show_fixture_action(fixturedef, "SETUP")
+
+
+def pytest_fixture_post_finalizer(fixturedef):
+    if hasattr(fixturedef, "cached_result"):
+        config = fixturedef._fixturemanager.config
+        if config.option.setupshow:
+            _show_fixture_action(fixturedef, "TEARDOWN")
+            if hasattr(fixturedef, "cached_param"):
+                del fixturedef.cached_param
+
+
+def _show_fixture_action(fixturedef, msg):
+    config = fixturedef._fixturemanager.config
+    capman = config.pluginmanager.getplugin("capturemanager")
+    if capman:
+        capman.suspend_global_capture()
+        out, err = capman.read_global_capture()
+
+    tw = config.get_terminal_writer()
+    tw.line()
+    tw.write(" " * 2 * fixturedef.scopenum)
+    tw.write(
+        "{step} {scope} {fixture}".format(
+            step=msg.ljust(8),  # align the output to TEARDOWN
+            scope=fixturedef.scope[0].upper(),
+            fixture=fixturedef.argname,
+        )
+    )
+
+    if msg == "SETUP":
+        deps = sorted(arg for arg in fixturedef.argnames if arg != "request")
+        if deps:
+            tw.write(" (fixtures used: {})".format(", ".join(deps)))
+
+    if hasattr(fixturedef, "cached_param"):
+        tw.write("[{}]".format(fixturedef.cached_param))
+
+    if capman:
+        capman.resume_global_capture()
+        sys.stdout.write(out)
+        sys.stderr.write(err)
+
+
+@pytest.hookimpl(tryfirst=True)
+def pytest_cmdline_main(config):
+    if config.option.setuponly:
+        config.option.setupshow = True
Index: venv/Lib/site-packages/_pytest/_argcomplete.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/_argcomplete.py	(date 1543190976611)
+++ venv/Lib/site-packages/_pytest/_argcomplete.py	(date 1543190976611)
@@ -0,0 +1,109 @@
+"""allow bash-completion for argparse with argcomplete if installed
+needs argcomplete>=0.5.6 for python 3.2/3.3 (older versions fail
+to find the magic string, so _ARGCOMPLETE env. var is never set, and
+this does not need special code.
+
+Function try_argcomplete(parser) should be called directly before
+the call to ArgumentParser.parse_args().
+
+The filescompleter is what you normally would use on the positional
+arguments specification, in order to get "dirname/" after "dirn<TAB>"
+instead of the default "dirname ":
+
+   optparser.add_argument(Config._file_or_dir, nargs='*'
+                               ).completer=filescompleter
+
+Other, application specific, completers should go in the file
+doing the add_argument calls as they need to be specified as .completer
+attributes as well. (If argcomplete is not installed, the function the
+attribute points to will not be used).
+
+SPEEDUP
+=======
+The generic argcomplete script for bash-completion
+(/etc/bash_completion.d/python-argcomplete.sh )
+uses a python program to determine startup script generated by pip.
+You can speed up completion somewhat by changing this script to include
+  # PYTHON_ARGCOMPLETE_OK
+so the the python-argcomplete-check-easy-install-script does not
+need to be called to find the entry point of the code and see if that is
+marked  with PYTHON_ARGCOMPLETE_OK
+
+INSTALL/DEBUGGING
+=================
+To include this support in another application that has setup.py generated
+scripts:
+- add the line:
+    # PYTHON_ARGCOMPLETE_OK
+  near the top of the main python entry point
+- include in the file calling parse_args():
+    from _argcomplete import try_argcomplete, filescompleter
+   , call try_argcomplete just before parse_args(), and optionally add
+   filescompleter to the positional arguments' add_argument()
+If things do not work right away:
+- switch on argcomplete debugging with (also helpful when doing custom
+  completers):
+    export _ARC_DEBUG=1
+- run:
+    python-argcomplete-check-easy-install-script $(which appname)
+    echo $?
+  will echo 0 if the magic line has been found, 1 if not
+- sometimes it helps to find early on errors using:
+    _ARGCOMPLETE=1 _ARC_DEBUG=1 appname
+  which should throw a KeyError: 'COMPLINE' (which is properly set by the
+  global argcomplete script).
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import sys
+from glob import glob
+
+
+class FastFilesCompleter(object):
+    "Fast file completer class"
+
+    def __init__(self, directories=True):
+        self.directories = directories
+
+    def __call__(self, prefix, **kwargs):
+        """only called on non option completions"""
+        if os.path.sep in prefix[1:]:
+            prefix_dir = len(os.path.dirname(prefix) + os.path.sep)
+        else:
+            prefix_dir = 0
+        completion = []
+        globbed = []
+        if "*" not in prefix and "?" not in prefix:
+            # we are on unix, otherwise no bash
+            if not prefix or prefix[-1] == os.path.sep:
+                globbed.extend(glob(prefix + ".*"))
+            prefix += "*"
+        globbed.extend(glob(prefix))
+        for x in sorted(globbed):
+            if os.path.isdir(x):
+                x += "/"
+            # append stripping the prefix (like bash, not like compgen)
+            completion.append(x[prefix_dir:])
+        return completion
+
+
+if os.environ.get("_ARGCOMPLETE"):
+    try:
+        import argcomplete.completers
+    except ImportError:
+        sys.exit(-1)
+    filescompleter = FastFilesCompleter()
+
+    def try_argcomplete(parser):
+        argcomplete.autocomplete(parser, always_complete_options=False)
+
+
+else:
+
+    def try_argcomplete(parser):
+        pass
+
+    filescompleter = None
Index: venv/Lib/site-packages/_pytest/python.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/python.py	(date 1543190976631)
+++ venv/Lib/site-packages/_pytest/python.py	(date 1543190976631)
@@ -0,0 +1,1454 @@
+""" Python test discovery, setup and run of test functions. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import collections
+import fnmatch
+import inspect
+import os
+import sys
+import warnings
+from textwrap import dedent
+
+import py
+import six
+
+import _pytest
+from _pytest import deprecated
+from _pytest import fixtures
+from _pytest import nodes
+from _pytest._code import filter_traceback
+from _pytest.compat import ascii_escaped
+from _pytest.compat import enum
+from _pytest.compat import get_default_arg_names
+from _pytest.compat import get_real_func
+from _pytest.compat import getfslineno
+from _pytest.compat import getimfunc
+from _pytest.compat import getlocation
+from _pytest.compat import is_generator
+from _pytest.compat import isclass
+from _pytest.compat import isfunction
+from _pytest.compat import NoneType
+from _pytest.compat import NOTSET
+from _pytest.compat import REGEX_TYPE
+from _pytest.compat import safe_getattr
+from _pytest.compat import safe_isclass
+from _pytest.compat import safe_str
+from _pytest.compat import STRING_TYPES
+from _pytest.config import hookimpl
+from _pytest.main import FSHookProxy
+from _pytest.mark.structures import get_unpacked_marks
+from _pytest.mark.structures import normalize_mark_list
+from _pytest.mark.structures import transfer_markers
+from _pytest.outcomes import fail
+from _pytest.pathlib import parts
+from _pytest.warning_types import PytestWarning
+from _pytest.warning_types import RemovedInPytest4Warning
+
+
+def pyobj_property(name):
+    def get(self):
+        node = self.getparent(getattr(__import__("pytest"), name))
+        if node is not None:
+            return node.obj
+
+    doc = "python %s object this node was collected from (can be None)." % (
+        name.lower(),
+    )
+    return property(get, None, None, doc)
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group.addoption(
+        "--fixtures",
+        "--funcargs",
+        action="store_true",
+        dest="showfixtures",
+        default=False,
+        help="show available fixtures, sorted by plugin appearance "
+        "(fixtures with leading '_' are only shown with '-v')",
+    )
+    group.addoption(
+        "--fixtures-per-test",
+        action="store_true",
+        dest="show_fixtures_per_test",
+        default=False,
+        help="show fixtures per test",
+    )
+    parser.addini(
+        "usefixtures",
+        type="args",
+        default=[],
+        help="list of default fixtures to be used with this project",
+    )
+    parser.addini(
+        "python_files",
+        type="args",
+        default=["test_*.py", "*_test.py"],
+        help="glob-style file patterns for Python test module discovery",
+    )
+    parser.addini(
+        "python_classes",
+        type="args",
+        default=["Test"],
+        help="prefixes or glob names for Python test class discovery",
+    )
+    parser.addini(
+        "python_functions",
+        type="args",
+        default=["test"],
+        help="prefixes or glob names for Python test function and method discovery",
+    )
+
+    group.addoption(
+        "--import-mode",
+        default="prepend",
+        choices=["prepend", "append"],
+        dest="importmode",
+        help="prepend/append to sys.path when importing test modules, "
+        "default is to prepend.",
+    )
+
+
+def pytest_cmdline_main(config):
+    if config.option.showfixtures:
+        showfixtures(config)
+        return 0
+    if config.option.show_fixtures_per_test:
+        show_fixtures_per_test(config)
+        return 0
+
+
+def pytest_generate_tests(metafunc):
+    # those alternative spellings are common - raise a specific error to alert
+    # the user
+    alt_spellings = ["parameterize", "parametrise", "parameterise"]
+    for attr in alt_spellings:
+        if hasattr(metafunc.function, attr):
+            msg = "{0} has '{1}' mark, spelling should be 'parametrize'"
+            fail(msg.format(metafunc.function.__name__, attr), pytrace=False)
+    for marker in metafunc.definition.iter_markers(name="parametrize"):
+        metafunc.parametrize(*marker.args, **marker.kwargs)
+
+
+def pytest_configure(config):
+    config.addinivalue_line(
+        "markers",
+        "parametrize(argnames, argvalues): call a test function multiple "
+        "times passing in different arguments in turn. argvalues generally "
+        "needs to be a list of values if argnames specifies only one name "
+        "or a list of tuples of values if argnames specifies multiple names. "
+        "Example: @parametrize('arg1', [1,2]) would lead to two calls of the "
+        "decorated test function, one with arg1=1 and another with arg1=2."
+        "see https://docs.pytest.org/en/latest/parametrize.html for more info "
+        "and examples.",
+    )
+    config.addinivalue_line(
+        "markers",
+        "usefixtures(fixturename1, fixturename2, ...): mark tests as needing "
+        "all of the specified fixtures. see "
+        "https://docs.pytest.org/en/latest/fixture.html#usefixtures ",
+    )
+
+
+@hookimpl(trylast=True)
+def pytest_pyfunc_call(pyfuncitem):
+    testfunction = pyfuncitem.obj
+    if pyfuncitem._isyieldedfunction():
+        testfunction(*pyfuncitem._args)
+    else:
+        funcargs = pyfuncitem.funcargs
+        testargs = {}
+        for arg in pyfuncitem._fixtureinfo.argnames:
+            testargs[arg] = funcargs[arg]
+        testfunction(**testargs)
+    return True
+
+
+def pytest_collect_file(path, parent):
+    ext = path.ext
+    if ext == ".py":
+        if not parent.session.isinitpath(path):
+            if not path_matches_patterns(
+                path, parent.config.getini("python_files") + ["__init__.py"]
+            ):
+                return
+        ihook = parent.session.gethookproxy(path)
+        return ihook.pytest_pycollect_makemodule(path=path, parent=parent)
+
+
+def path_matches_patterns(path, patterns):
+    """Returns True if the given py.path.local matches one of the patterns in the list of globs given"""
+    return any(path.fnmatch(pattern) for pattern in patterns)
+
+
+def pytest_pycollect_makemodule(path, parent):
+    if path.basename == "__init__.py":
+        return Package(path, parent)
+    return Module(path, parent)
+
+
+@hookimpl(hookwrapper=True)
+def pytest_pycollect_makeitem(collector, name, obj):
+    outcome = yield
+    res = outcome.get_result()
+    if res is not None:
+        return
+    # nothing was collected elsewhere, let's do it here
+    if safe_isclass(obj):
+        if collector.istestclass(obj, name):
+            Class = collector._getcustomclass("Class")
+            outcome.force_result(Class(name, parent=collector))
+    elif collector.istestfunction(obj, name):
+        # mock seems to store unbound methods (issue473), normalize it
+        obj = getattr(obj, "__func__", obj)
+        # We need to try and unwrap the function if it's a functools.partial
+        # or a funtools.wrapped.
+        # We musn't if it's been wrapped with mock.patch (python 2 only)
+        if not (isfunction(obj) or isfunction(get_real_func(obj))):
+            filename, lineno = getfslineno(obj)
+            warnings.warn_explicit(
+                message=PytestWarning(
+                    "cannot collect %r because it is not a function." % name
+                ),
+                category=None,
+                filename=str(filename),
+                lineno=lineno + 1,
+            )
+        elif getattr(obj, "__test__", True):
+            if is_generator(obj):
+                res = Generator(name, parent=collector)
+            else:
+                res = list(collector._genfunctions(name, obj))
+            outcome.force_result(res)
+
+
+def pytest_make_parametrize_id(config, val, argname=None):
+    return None
+
+
+class PyobjContext(object):
+    module = pyobj_property("Module")
+    cls = pyobj_property("Class")
+    instance = pyobj_property("Instance")
+
+
+class PyobjMixin(PyobjContext):
+    _ALLOW_MARKERS = True
+
+    def __init__(self, *k, **kw):
+        super(PyobjMixin, self).__init__(*k, **kw)
+
+    def obj():
+        def fget(self):
+            obj = getattr(self, "_obj", None)
+            if obj is None:
+                self._obj = obj = self._getobj()
+                # XXX evil hack
+                # used to avoid Instance collector marker duplication
+                if self._ALLOW_MARKERS:
+                    self.own_markers.extend(get_unpacked_marks(self.obj))
+            return obj
+
+        def fset(self, value):
+            self._obj = value
+
+        return property(fget, fset, None, "underlying python object")
+
+    obj = obj()
+
+    def _getobj(self):
+        return getattr(self.parent.obj, self.name)
+
+    def getmodpath(self, stopatmodule=True, includemodule=False):
+        """ return python path relative to the containing module. """
+        chain = self.listchain()
+        chain.reverse()
+        parts = []
+        for node in chain:
+            if isinstance(node, Instance):
+                continue
+            name = node.name
+            if isinstance(node, Module):
+                name = os.path.splitext(name)[0]
+                if stopatmodule:
+                    if includemodule:
+                        parts.append(name)
+                    break
+            parts.append(name)
+        parts.reverse()
+        s = ".".join(parts)
+        return s.replace(".[", "[")
+
+    def _getfslineno(self):
+        return getfslineno(self.obj)
+
+    def reportinfo(self):
+        # XXX caching?
+        obj = self.obj
+        compat_co_firstlineno = getattr(obj, "compat_co_firstlineno", None)
+        if isinstance(compat_co_firstlineno, int):
+            # nose compatibility
+            fspath = sys.modules[obj.__module__].__file__
+            if fspath.endswith(".pyc"):
+                fspath = fspath[:-1]
+            lineno = compat_co_firstlineno
+        else:
+            fspath, lineno = getfslineno(obj)
+        modpath = self.getmodpath()
+        assert isinstance(lineno, int)
+        return fspath, lineno, modpath
+
+
+class PyCollector(PyobjMixin, nodes.Collector):
+    def funcnamefilter(self, name):
+        return self._matches_prefix_or_glob_option("python_functions", name)
+
+    def isnosetest(self, obj):
+        """ Look for the __test__ attribute, which is applied by the
+        @nose.tools.istest decorator
+        """
+        # We explicitly check for "is True" here to not mistakenly treat
+        # classes with a custom __getattr__ returning something truthy (like a
+        # function) as test classes.
+        return safe_getattr(obj, "__test__", False) is True
+
+    def classnamefilter(self, name):
+        return self._matches_prefix_or_glob_option("python_classes", name)
+
+    def istestfunction(self, obj, name):
+        if self.funcnamefilter(name) or self.isnosetest(obj):
+            if isinstance(obj, staticmethod):
+                # static methods need to be unwrapped
+                obj = safe_getattr(obj, "__func__", False)
+            return (
+                safe_getattr(obj, "__call__", False)
+                and fixtures.getfixturemarker(obj) is None
+            )
+        else:
+            return False
+
+    def istestclass(self, obj, name):
+        return self.classnamefilter(name) or self.isnosetest(obj)
+
+    def _matches_prefix_or_glob_option(self, option_name, name):
+        """
+        checks if the given name matches the prefix or glob-pattern defined
+        in ini configuration.
+        """
+        for option in self.config.getini(option_name):
+            if name.startswith(option):
+                return True
+            # check that name looks like a glob-string before calling fnmatch
+            # because this is called for every name in each collected module,
+            # and fnmatch is somewhat expensive to call
+            elif ("*" in option or "?" in option or "[" in option) and fnmatch.fnmatch(
+                name, option
+            ):
+                return True
+        return False
+
+    def collect(self):
+        if not getattr(self.obj, "__test__", True):
+            return []
+
+        # NB. we avoid random getattrs and peek in the __dict__ instead
+        # (XXX originally introduced from a PyPy need, still true?)
+        dicts = [getattr(self.obj, "__dict__", {})]
+        for basecls in inspect.getmro(self.obj.__class__):
+            dicts.append(basecls.__dict__)
+        seen = {}
+        values = []
+        for dic in dicts:
+            for name, obj in list(dic.items()):
+                if name in seen:
+                    continue
+                seen[name] = True
+                res = self._makeitem(name, obj)
+                if res is None:
+                    continue
+                if not isinstance(res, list):
+                    res = [res]
+                values.extend(res)
+        values.sort(key=lambda item: item.reportinfo()[:2])
+        return values
+
+    def makeitem(self, name, obj):
+        warnings.warn(deprecated.COLLECTOR_MAKEITEM, stacklevel=2)
+        self._makeitem(name, obj)
+
+    def _makeitem(self, name, obj):
+        # assert self.ihook.fspath == self.fspath, self
+        return self.ihook.pytest_pycollect_makeitem(collector=self, name=name, obj=obj)
+
+    def _genfunctions(self, name, funcobj):
+        module = self.getparent(Module).obj
+        clscol = self.getparent(Class)
+        cls = clscol and clscol.obj or None
+        transfer_markers(funcobj, cls, module)
+        fm = self.session._fixturemanager
+
+        definition = FunctionDefinition(name=name, parent=self, callobj=funcobj)
+        fixtureinfo = fm.getfixtureinfo(definition, funcobj, cls)
+
+        metafunc = Metafunc(
+            definition, fixtureinfo, self.config, cls=cls, module=module
+        )
+        methods = []
+        if hasattr(module, "pytest_generate_tests"):
+            methods.append(module.pytest_generate_tests)
+        if hasattr(cls, "pytest_generate_tests"):
+            methods.append(cls().pytest_generate_tests)
+        if methods:
+            self.ihook.pytest_generate_tests.call_extra(
+                methods, dict(metafunc=metafunc)
+            )
+        else:
+            self.ihook.pytest_generate_tests(metafunc=metafunc)
+
+        Function = self._getcustomclass("Function")
+        if not metafunc._calls:
+            yield Function(name, parent=self, fixtureinfo=fixtureinfo)
+        else:
+            # add funcargs() as fixturedefs to fixtureinfo.arg2fixturedefs
+            fixtures.add_funcarg_pseudo_fixture_def(self, metafunc, fm)
+
+            # add_funcarg_pseudo_fixture_def may have shadowed some fixtures
+            # with direct parametrization, so make sure we update what the
+            # function really needs.
+            fixtureinfo.prune_dependency_tree()
+
+            for callspec in metafunc._calls:
+                subname = "%s[%s]" % (name, callspec.id)
+                yield Function(
+                    name=subname,
+                    parent=self,
+                    callspec=callspec,
+                    callobj=funcobj,
+                    fixtureinfo=fixtureinfo,
+                    keywords={callspec.id: True},
+                    originalname=name,
+                )
+
+
+class Module(nodes.File, PyCollector):
+    """ Collector for test classes and functions. """
+
+    def _getobj(self):
+        return self._importtestmodule()
+
+    def collect(self):
+        self.session._fixturemanager.parsefactories(self)
+        return super(Module, self).collect()
+
+    def _importtestmodule(self):
+        # we assume we are only called once per module
+        importmode = self.config.getoption("--import-mode")
+        try:
+            mod = self.fspath.pyimport(ensuresyspath=importmode)
+        except SyntaxError:
+            raise self.CollectError(
+                _pytest._code.ExceptionInfo().getrepr(style="short")
+            )
+        except self.fspath.ImportMismatchError:
+            e = sys.exc_info()[1]
+            raise self.CollectError(
+                "import file mismatch:\n"
+                "imported module %r has this __file__ attribute:\n"
+                "  %s\n"
+                "which is not the same as the test file we want to collect:\n"
+                "  %s\n"
+                "HINT: remove __pycache__ / .pyc files and/or use a "
+                "unique basename for your test file modules" % e.args
+            )
+        except ImportError:
+            from _pytest._code.code import ExceptionInfo
+
+            exc_info = ExceptionInfo()
+            if self.config.getoption("verbose") < 2:
+                exc_info.traceback = exc_info.traceback.filter(filter_traceback)
+            exc_repr = (
+                exc_info.getrepr(style="short")
+                if exc_info.traceback
+                else exc_info.exconly()
+            )
+            formatted_tb = safe_str(exc_repr)
+            raise self.CollectError(
+                "ImportError while importing test module '{fspath}'.\n"
+                "Hint: make sure your test modules/packages have valid Python names.\n"
+                "Traceback:\n"
+                "{traceback}".format(fspath=self.fspath, traceback=formatted_tb)
+            )
+        except _pytest.runner.Skipped as e:
+            if e.allow_module_level:
+                raise
+            raise self.CollectError(
+                "Using pytest.skip outside of a test is not allowed. "
+                "To decorate a test function, use the @pytest.mark.skip "
+                "or @pytest.mark.skipif decorators instead, and to skip a "
+                "module use `pytestmark = pytest.mark.{skip,skipif}."
+            )
+        self.config.pluginmanager.consider_module(mod)
+        return mod
+
+    def setup(self):
+        setup_module = _get_xunit_setup_teardown(self.obj, "setUpModule")
+        if setup_module is None:
+            setup_module = _get_xunit_setup_teardown(self.obj, "setup_module")
+        if setup_module is not None:
+            setup_module()
+
+        teardown_module = _get_xunit_setup_teardown(self.obj, "tearDownModule")
+        if teardown_module is None:
+            teardown_module = _get_xunit_setup_teardown(self.obj, "teardown_module")
+        if teardown_module is not None:
+            self.addfinalizer(teardown_module)
+
+
+class Package(Module):
+    def __init__(self, fspath, parent=None, config=None, session=None, nodeid=None):
+        session = parent.session
+        nodes.FSCollector.__init__(
+            self, fspath, parent=parent, config=config, session=session, nodeid=nodeid
+        )
+        self.name = fspath.dirname
+        self.trace = session.trace
+        self._norecursepatterns = session._norecursepatterns
+        self.fspath = fspath
+
+    def _recurse(self, dirpath):
+        if dirpath.basename == "__pycache__":
+            return False
+        ihook = self.gethookproxy(dirpath.dirpath())
+        if ihook.pytest_ignore_collect(path=dirpath, config=self.config):
+            return
+        for pat in self._norecursepatterns:
+            if dirpath.check(fnmatch=pat):
+                return False
+        ihook = self.gethookproxy(dirpath)
+        ihook.pytest_collect_directory(path=dirpath, parent=self)
+        return True
+
+    def gethookproxy(self, fspath):
+        # check if we have the common case of running
+        # hooks with all conftest.py filesall conftest.py
+        pm = self.config.pluginmanager
+        my_conftestmodules = pm._getconftestmodules(fspath)
+        remove_mods = pm._conftest_plugins.difference(my_conftestmodules)
+        if remove_mods:
+            # one or more conftests are not in use at this fspath
+            proxy = FSHookProxy(fspath, pm, remove_mods)
+        else:
+            # all plugis are active for this fspath
+            proxy = self.config.hook
+        return proxy
+
+    def _collectfile(self, path, handle_dupes=True):
+        ihook = self.gethookproxy(path)
+        if not self.isinitpath(path):
+            if ihook.pytest_ignore_collect(path=path, config=self.config):
+                return ()
+
+        if handle_dupes:
+            keepduplicates = self.config.getoption("keepduplicates")
+            if not keepduplicates:
+                duplicate_paths = self.config.pluginmanager._duplicatepaths
+                if path in duplicate_paths:
+                    return ()
+                else:
+                    duplicate_paths.add(path)
+
+        if self.fspath == path:  # __init__.py
+            return [self]
+
+        return ihook.pytest_collect_file(path=path, parent=self)
+
+    def isinitpath(self, path):
+        return path in self.session._initialpaths
+
+    def collect(self):
+        this_path = self.fspath.dirpath()
+        init_module = this_path.join("__init__.py")
+        if init_module.check(file=1) and path_matches_patterns(
+            init_module, self.config.getini("python_files")
+        ):
+            yield Module(init_module, self)
+        pkg_prefixes = set()
+        for path in this_path.visit(rec=self._recurse, bf=True, sort=True):
+            # We will visit our own __init__.py file, in which case we skip it.
+            if path.isfile():
+                if path.basename == "__init__.py" and path.dirpath() == this_path:
+                    continue
+
+            parts_ = parts(path.strpath)
+            if any(
+                pkg_prefix in parts_ and pkg_prefix.join("__init__.py") != path
+                for pkg_prefix in pkg_prefixes
+            ):
+                continue
+
+            if path.isdir() and path.join("__init__.py").check(file=1):
+                pkg_prefixes.add(path)
+
+            for x in self._collectfile(path):
+                yield x
+
+
+def _get_xunit_setup_teardown(holder, attr_name, param_obj=None):
+    """
+    Return a callable to perform xunit-style setup or teardown if
+    the function exists in the ``holder`` object.
+    The ``param_obj`` parameter is the parameter which will be passed to the function
+    when the callable is called without arguments, defaults to the ``holder`` object.
+    Return ``None`` if a suitable callable is not found.
+    """
+    param_obj = param_obj if param_obj is not None else holder
+    result = _get_xunit_func(holder, attr_name)
+    if result is not None:
+        arg_count = result.__code__.co_argcount
+        if inspect.ismethod(result):
+            arg_count -= 1
+        if arg_count:
+            return lambda: result(param_obj)
+        else:
+            return result
+
+
+def _get_xunit_func(obj, name):
+    """Return the attribute from the given object to be used as a setup/teardown
+    xunit-style function, but only if not marked as a fixture to
+    avoid calling it twice.
+    """
+    meth = getattr(obj, name, None)
+    if fixtures.getfixturemarker(meth) is None:
+        return meth
+
+
+class Class(PyCollector):
+    """ Collector for test methods. """
+
+    def collect(self):
+        if not safe_getattr(self.obj, "__test__", True):
+            return []
+        if hasinit(self.obj):
+            self.warn(
+                PytestWarning(
+                    "cannot collect test class %r because it has a "
+                    "__init__ constructor" % self.obj.__name__
+                )
+            )
+            return []
+        elif hasnew(self.obj):
+            self.warn(
+                PytestWarning(
+                    "cannot collect test class %r because it has a "
+                    "__new__ constructor" % self.obj.__name__
+                )
+            )
+            return []
+        return [self._getcustomclass("Instance")(name="()", parent=self)]
+
+    def setup(self):
+        setup_class = _get_xunit_func(self.obj, "setup_class")
+        if setup_class is not None:
+            setup_class = getimfunc(setup_class)
+            setup_class(self.obj)
+
+        fin_class = getattr(self.obj, "teardown_class", None)
+        if fin_class is not None:
+            fin_class = getimfunc(fin_class)
+            self.addfinalizer(lambda: fin_class(self.obj))
+
+
+class Instance(PyCollector):
+    _ALLOW_MARKERS = False  # hack, destroy later
+    # instances share the object with their parents in a way
+    # that duplicates markers instances if not taken out
+    # can be removed at node structure reorganization time
+
+    def _getobj(self):
+        return self.parent.obj()
+
+    def collect(self):
+        self.session._fixturemanager.parsefactories(self)
+        return super(Instance, self).collect()
+
+    def newinstance(self):
+        self.obj = self._getobj()
+        return self.obj
+
+
+class FunctionMixin(PyobjMixin):
+    """ mixin for the code common to Function and Generator.
+    """
+
+    def setup(self):
+        """ perform setup for this test function. """
+        if hasattr(self, "_preservedparent"):
+            obj = self._preservedparent
+        elif isinstance(self.parent, Instance):
+            obj = self.parent.newinstance()
+            self.obj = self._getobj()
+        else:
+            obj = self.parent.obj
+        if inspect.ismethod(self.obj):
+            setup_name = "setup_method"
+            teardown_name = "teardown_method"
+        else:
+            setup_name = "setup_function"
+            teardown_name = "teardown_function"
+        setup_func_or_method = _get_xunit_setup_teardown(
+            obj, setup_name, param_obj=self.obj
+        )
+        if setup_func_or_method is not None:
+            setup_func_or_method()
+        teardown_func_or_method = _get_xunit_setup_teardown(
+            obj, teardown_name, param_obj=self.obj
+        )
+        if teardown_func_or_method is not None:
+            self.addfinalizer(teardown_func_or_method)
+
+    def _prunetraceback(self, excinfo):
+        if hasattr(self, "_obj") and not self.config.option.fulltrace:
+            code = _pytest._code.Code(get_real_func(self.obj))
+            path, firstlineno = code.path, code.firstlineno
+            traceback = excinfo.traceback
+            ntraceback = traceback.cut(path=path, firstlineno=firstlineno)
+            if ntraceback == traceback:
+                ntraceback = ntraceback.cut(path=path)
+                if ntraceback == traceback:
+                    ntraceback = ntraceback.filter(filter_traceback)
+                    if not ntraceback:
+                        ntraceback = traceback
+
+            excinfo.traceback = ntraceback.filter()
+            # issue364: mark all but first and last frames to
+            # only show a single-line message for each frame
+            if self.config.option.tbstyle == "auto":
+                if len(excinfo.traceback) > 2:
+                    for entry in excinfo.traceback[1:-1]:
+                        entry.set_repr_style("short")
+
+    def repr_failure(self, excinfo, outerr=None):
+        assert outerr is None, "XXX outerr usage is deprecated"
+        style = self.config.option.tbstyle
+        if style == "auto":
+            style = "long"
+        return self._repr_failure_py(excinfo, style=style)
+
+
+class Generator(FunctionMixin, PyCollector):
+    def collect(self):
+        # test generators are seen as collectors but they also
+        # invoke setup/teardown on popular request
+        # (induced by the common "test_*" naming shared with normal tests)
+        from _pytest import deprecated
+
+        self.session._setupstate.prepare(self)
+        # see FunctionMixin.setup and test_setupstate_is_preserved_134
+        self._preservedparent = self.parent.obj
+        values = []
+        seen = {}
+        for i, x in enumerate(self.obj()):
+            name, call, args = self.getcallargs(x)
+            if not callable(call):
+                raise TypeError("%r yielded non callable test %r" % (self.obj, call))
+            if name is None:
+                name = "[%d]" % i
+            else:
+                name = "['%s']" % name
+            if name in seen:
+                raise ValueError(
+                    "%r generated tests with non-unique name %r" % (self, name)
+                )
+            seen[name] = True
+            with warnings.catch_warnings():
+                # ignore our own deprecation warning
+                function_class = self.Function
+            values.append(function_class(name, self, args=args, callobj=call))
+        self.warn(deprecated.YIELD_TESTS)
+        return values
+
+    def getcallargs(self, obj):
+        if not isinstance(obj, (tuple, list)):
+            obj = (obj,)
+        # explicit naming
+        if isinstance(obj[0], six.string_types):
+            name = obj[0]
+            obj = obj[1:]
+        else:
+            name = None
+        call, args = obj[0], obj[1:]
+        return name, call, args
+
+
+def hasinit(obj):
+    init = getattr(obj, "__init__", None)
+    if init:
+        return init != object.__init__
+
+
+def hasnew(obj):
+    new = getattr(obj, "__new__", None)
+    if new:
+        return new != object.__new__
+
+
+class CallSpec2(object):
+    def __init__(self, metafunc):
+        self.metafunc = metafunc
+        self.funcargs = {}
+        self._idlist = []
+        self.params = {}
+        self._globalid = NOTSET
+        self._globalparam = NOTSET
+        self._arg2scopenum = {}  # used for sorting parametrized resources
+        self.marks = []
+        self.indices = {}
+
+    def copy(self):
+        cs = CallSpec2(self.metafunc)
+        cs.funcargs.update(self.funcargs)
+        cs.params.update(self.params)
+        cs.marks.extend(self.marks)
+        cs.indices.update(self.indices)
+        cs._arg2scopenum.update(self._arg2scopenum)
+        cs._idlist = list(self._idlist)
+        cs._globalid = self._globalid
+        cs._globalparam = self._globalparam
+        return cs
+
+    def _checkargnotcontained(self, arg):
+        if arg in self.params or arg in self.funcargs:
+            raise ValueError("duplicate %r" % (arg,))
+
+    def getparam(self, name):
+        try:
+            return self.params[name]
+        except KeyError:
+            if self._globalparam is NOTSET:
+                raise ValueError(name)
+            return self._globalparam
+
+    @property
+    def id(self):
+        return "-".join(map(str, filter(None, self._idlist)))
+
+    def setmulti2(self, valtypes, argnames, valset, id, marks, scopenum, param_index):
+        for arg, val in zip(argnames, valset):
+            self._checkargnotcontained(arg)
+            valtype_for_arg = valtypes[arg]
+            getattr(self, valtype_for_arg)[arg] = val
+            self.indices[arg] = param_index
+            self._arg2scopenum[arg] = scopenum
+        self._idlist.append(id)
+        self.marks.extend(normalize_mark_list(marks))
+
+    def setall(self, funcargs, id, param):
+        for x in funcargs:
+            self._checkargnotcontained(x)
+        self.funcargs.update(funcargs)
+        if id is not NOTSET:
+            self._idlist.append(id)
+        if param is not NOTSET:
+            assert self._globalparam is NOTSET
+            self._globalparam = param
+        for arg in funcargs:
+            self._arg2scopenum[arg] = fixtures.scopenum_function
+
+
+class Metafunc(fixtures.FuncargnamesCompatAttr):
+    """
+    Metafunc objects are passed to the :func:`pytest_generate_tests <_pytest.hookspec.pytest_generate_tests>` hook.
+    They help to inspect a test function and to generate tests according to
+    test configuration or values specified in the class or module where a
+    test function is defined.
+    """
+
+    def __init__(self, definition, fixtureinfo, config, cls=None, module=None):
+        assert (
+            isinstance(definition, FunctionDefinition)
+            or type(definition).__name__ == "DefinitionMock"
+        )
+        self.definition = definition
+
+        #: access to the :class:`_pytest.config.Config` object for the test session
+        self.config = config
+
+        #: the module object where the test function is defined in.
+        self.module = module
+
+        #: underlying python test function
+        self.function = definition.obj
+
+        #: set of fixture names required by the test function
+        self.fixturenames = fixtureinfo.names_closure
+
+        #: class object where the test function is defined in or ``None``.
+        self.cls = cls
+
+        self._calls = []
+        self._ids = set()
+        self._arg2fixturedefs = fixtureinfo.name2fixturedefs
+
+    def parametrize(self, argnames, argvalues, indirect=False, ids=None, scope=None):
+        """ Add new invocations to the underlying test function using the list
+        of argvalues for the given argnames.  Parametrization is performed
+        during the collection phase.  If you need to setup expensive resources
+        see about setting indirect to do it rather at test setup time.
+
+        :arg argnames: a comma-separated string denoting one or more argument
+                       names, or a list/tuple of argument strings.
+
+        :arg argvalues: The list of argvalues determines how often a
+            test is invoked with different argument values.  If only one
+            argname was specified argvalues is a list of values.  If N
+            argnames were specified, argvalues must be a list of N-tuples,
+            where each tuple-element specifies a value for its respective
+            argname.
+
+        :arg indirect: The list of argnames or boolean. A list of arguments'
+            names (subset of argnames). If True the list contains all names from
+            the argnames. Each argvalue corresponding to an argname in this list will
+            be passed as request.param to its respective argname fixture
+            function so that it can perform more expensive setups during the
+            setup phase of a test rather than at collection time.
+
+        :arg ids: list of string ids, or a callable.
+            If strings, each is corresponding to the argvalues so that they are
+            part of the test id. If None is given as id of specific test, the
+            automatically generated id for that argument will be used.
+            If callable, it should take one argument (a single argvalue) and return
+            a string or return None. If None, the automatically generated id for that
+            argument will be used.
+            If no ids are provided they will be generated automatically from
+            the argvalues.
+
+        :arg scope: if specified it denotes the scope of the parameters.
+            The scope is used for grouping tests by parameter instances.
+            It will also override any fixture-function defined scope, allowing
+            to set a dynamic scope using test context or configuration.
+        """
+        from _pytest.fixtures import scope2index
+        from _pytest.mark import ParameterSet
+
+        argnames, parameters = ParameterSet._for_parametrize(
+            argnames,
+            argvalues,
+            self.function,
+            self.config,
+            function_definition=self.definition,
+        )
+        del argvalues
+
+        if scope is None:
+            scope = _find_parametrized_scope(argnames, self._arg2fixturedefs, indirect)
+
+        self._validate_if_using_arg_names(argnames, indirect)
+
+        arg_values_types = self._resolve_arg_value_types(argnames, indirect)
+
+        ids = self._resolve_arg_ids(argnames, ids, parameters, item=self.definition)
+
+        scopenum = scope2index(
+            scope, descr="parametrize() call in {}".format(self.function.__name__)
+        )
+
+        # create the new calls: if we are parametrize() multiple times (by applying the decorator
+        # more than once) then we accumulate those calls generating the cartesian product
+        # of all calls
+        newcalls = []
+        for callspec in self._calls or [CallSpec2(self)]:
+            for param_index, (param_id, param_set) in enumerate(zip(ids, parameters)):
+                newcallspec = callspec.copy()
+                newcallspec.setmulti2(
+                    arg_values_types,
+                    argnames,
+                    param_set.values,
+                    param_id,
+                    param_set.marks,
+                    scopenum,
+                    param_index,
+                )
+                newcalls.append(newcallspec)
+        self._calls = newcalls
+
+    def _resolve_arg_ids(self, argnames, ids, parameters, item):
+        """Resolves the actual ids for the given argnames, based on the ``ids`` parameter given
+        to ``parametrize``.
+
+        :param List[str] argnames: list of argument names passed to ``parametrize()``.
+        :param ids: the ids parameter of the parametrized call (see docs).
+        :param List[ParameterSet] parameters: the list of parameter values, same size as ``argnames``.
+        :param Item item: the item that generated this parametrized call.
+        :rtype: List[str]
+        :return: the list of ids for each argname given
+        """
+        from py.io import saferepr
+
+        idfn = None
+        if callable(ids):
+            idfn = ids
+            ids = None
+        if ids:
+            func_name = self.function.__name__
+            if len(ids) != len(parameters):
+                msg = "In {}: {} parameter sets specified, with different number of ids: {}"
+                fail(msg.format(func_name, len(parameters), len(ids)), pytrace=False)
+            for id_value in ids:
+                if id_value is not None and not isinstance(id_value, six.string_types):
+                    msg = "In {}: ids must be list of strings, found: {} (type: {!r})"
+                    fail(
+                        msg.format(func_name, saferepr(id_value), type(id_value)),
+                        pytrace=False,
+                    )
+        ids = idmaker(argnames, parameters, idfn, ids, self.config, item=item)
+        return ids
+
+    def _resolve_arg_value_types(self, argnames, indirect):
+        """Resolves if each parametrized argument must be considered a parameter to a fixture or a "funcarg"
+        to the function, based on the ``indirect`` parameter of the parametrized() call.
+
+        :param List[str] argnames: list of argument names passed to ``parametrize()``.
+        :param indirect: same ``indirect`` parameter of ``parametrize()``.
+        :rtype: Dict[str, str]
+            A dict mapping each arg name to either:
+            * "params" if the argname should be the parameter of a fixture of the same name.
+            * "funcargs" if the argname should be a parameter to the parametrized test function.
+        """
+        valtypes = {}
+        if indirect is True:
+            valtypes = dict.fromkeys(argnames, "params")
+        elif indirect is False:
+            valtypes = dict.fromkeys(argnames, "funcargs")
+        elif isinstance(indirect, (tuple, list)):
+            valtypes = dict.fromkeys(argnames, "funcargs")
+            for arg in indirect:
+                if arg not in argnames:
+                    fail(
+                        "In {}: indirect fixture '{}' doesn't exist".format(
+                            self.function.__name__, arg
+                        ),
+                        pytrace=False,
+                    )
+                valtypes[arg] = "params"
+        return valtypes
+
+    def _validate_if_using_arg_names(self, argnames, indirect):
+        """
+        Check if all argnames are being used, by default values, or directly/indirectly.
+
+        :param List[str] argnames: list of argument names passed to ``parametrize()``.
+        :param indirect: same ``indirect`` parameter of ``parametrize()``.
+        :raise ValueError: if validation fails.
+        """
+        default_arg_names = set(get_default_arg_names(self.function))
+        func_name = self.function.__name__
+        for arg in argnames:
+            if arg not in self.fixturenames:
+                if arg in default_arg_names:
+                    fail(
+                        "In {}: function already takes an argument '{}' with a default value".format(
+                            func_name, arg
+                        ),
+                        pytrace=False,
+                    )
+                else:
+                    if isinstance(indirect, (tuple, list)):
+                        name = "fixture" if arg in indirect else "argument"
+                    else:
+                        name = "fixture" if indirect else "argument"
+                    fail(
+                        "In {}: function uses no {} '{}'".format(func_name, name, arg),
+                        pytrace=False,
+                    )
+
+    def addcall(self, funcargs=None, id=NOTSET, param=NOTSET):
+        """ Add a new call to the underlying test function during the collection phase of a test run.
+
+        .. deprecated:: 3.3
+
+            Use :meth:`parametrize` instead.
+
+        Note that request.addcall() is called during the test collection phase prior and
+        independently to actual test execution.  You should only use addcall()
+        if you need to specify multiple arguments of a test function.
+
+        :arg funcargs: argument keyword dictionary used when invoking
+            the test function.
+
+        :arg id: used for reporting and identification purposes.  If you
+            don't supply an `id` an automatic unique id will be generated.
+
+        :arg param: a parameter which will be exposed to a later fixture function
+            invocation through the ``request.param`` attribute.
+        """
+        warnings.warn(deprecated.METAFUNC_ADD_CALL, stacklevel=2)
+
+        assert funcargs is None or isinstance(funcargs, dict)
+        if funcargs is not None:
+            for name in funcargs:
+                if name not in self.fixturenames:
+                    fail("funcarg %r not used in this function." % name)
+        else:
+            funcargs = {}
+        if id is None:
+            raise ValueError("id=None not allowed")
+        if id is NOTSET:
+            id = len(self._calls)
+        id = str(id)
+        if id in self._ids:
+            raise ValueError("duplicate id %r" % id)
+        self._ids.add(id)
+
+        cs = CallSpec2(self)
+        cs.setall(funcargs, id, param)
+        self._calls.append(cs)
+
+
+def _find_parametrized_scope(argnames, arg2fixturedefs, indirect):
+    """Find the most appropriate scope for a parametrized call based on its arguments.
+
+    When there's at least one direct argument, always use "function" scope.
+
+    When a test function is parametrized and all its arguments are indirect
+    (e.g. fixtures), return the most narrow scope based on the fixtures used.
+
+    Related to issue #1832, based on code posted by @Kingdread.
+    """
+    from _pytest.fixtures import scopes
+
+    if isinstance(indirect, (list, tuple)):
+        all_arguments_are_fixtures = len(indirect) == len(argnames)
+    else:
+        all_arguments_are_fixtures = bool(indirect)
+
+    if all_arguments_are_fixtures:
+        fixturedefs = arg2fixturedefs or {}
+        used_scopes = [
+            fixturedef[0].scope
+            for name, fixturedef in fixturedefs.items()
+            if name in argnames
+        ]
+        if used_scopes:
+            # Takes the most narrow scope from used fixtures
+            for scope in reversed(scopes):
+                if scope in used_scopes:
+                    return scope
+
+    return "function"
+
+
+def _idval(val, argname, idx, idfn, item, config):
+    if idfn:
+        s = None
+        try:
+            s = idfn(val)
+        except Exception as e:
+            # See issue https://github.com/pytest-dev/pytest/issues/2169
+            msg = (
+                "While trying to determine id of parameter {} at position "
+                "{} the following exception was raised:\n".format(argname, idx)
+            )
+            msg += "  {}: {}\n".format(type(e).__name__, e)
+            msg += "This warning will be an error error in pytest-4.0."
+            item.warn(RemovedInPytest4Warning(msg))
+        if s:
+            return ascii_escaped(s)
+
+    if config:
+        hook_id = config.hook.pytest_make_parametrize_id(
+            config=config, val=val, argname=argname
+        )
+        if hook_id:
+            return hook_id
+
+    if isinstance(val, STRING_TYPES):
+        return ascii_escaped(val)
+    elif isinstance(val, (float, int, bool, NoneType)):
+        return str(val)
+    elif isinstance(val, REGEX_TYPE):
+        return ascii_escaped(val.pattern)
+    elif enum is not None and isinstance(val, enum.Enum):
+        return str(val)
+    elif (isclass(val) or isfunction(val)) and hasattr(val, "__name__"):
+        return val.__name__
+    return str(argname) + str(idx)
+
+
+def _idvalset(idx, parameterset, argnames, idfn, ids, item, config):
+    if parameterset.id is not None:
+        return parameterset.id
+    if ids is None or (idx >= len(ids) or ids[idx] is None):
+        this_id = [
+            _idval(val, argname, idx, idfn, item=item, config=config)
+            for val, argname in zip(parameterset.values, argnames)
+        ]
+        return "-".join(this_id)
+    else:
+        return ascii_escaped(ids[idx])
+
+
+def idmaker(argnames, parametersets, idfn=None, ids=None, config=None, item=None):
+    ids = [
+        _idvalset(valindex, parameterset, argnames, idfn, ids, config=config, item=item)
+        for valindex, parameterset in enumerate(parametersets)
+    ]
+    if len(set(ids)) != len(ids):
+        # The ids are not unique
+        duplicates = [testid for testid in ids if ids.count(testid) > 1]
+        counters = collections.defaultdict(lambda: 0)
+        for index, testid in enumerate(ids):
+            if testid in duplicates:
+                ids[index] = testid + str(counters[testid])
+                counters[testid] += 1
+    return ids
+
+
+def show_fixtures_per_test(config):
+    from _pytest.main import wrap_session
+
+    return wrap_session(config, _show_fixtures_per_test)
+
+
+def _show_fixtures_per_test(config, session):
+    import _pytest.config
+
+    session.perform_collect()
+    curdir = py.path.local()
+    tw = _pytest.config.create_terminal_writer(config)
+    verbose = config.getvalue("verbose")
+
+    def get_best_relpath(func):
+        loc = getlocation(func, curdir)
+        return curdir.bestrelpath(loc)
+
+    def write_fixture(fixture_def):
+        argname = fixture_def.argname
+        if verbose <= 0 and argname.startswith("_"):
+            return
+        if verbose > 0:
+            bestrel = get_best_relpath(fixture_def.func)
+            funcargspec = "{} -- {}".format(argname, bestrel)
+        else:
+            funcargspec = argname
+        tw.line(funcargspec, green=True)
+        fixture_doc = fixture_def.func.__doc__
+        if fixture_doc:
+            write_docstring(tw, fixture_doc)
+        else:
+            tw.line("    no docstring available", red=True)
+
+    def write_item(item):
+        try:
+            info = item._fixtureinfo
+        except AttributeError:
+            # doctests items have no _fixtureinfo attribute
+            return
+        if not info.name2fixturedefs:
+            # this test item does not use any fixtures
+            return
+        tw.line()
+        tw.sep("-", "fixtures used by {}".format(item.name))
+        tw.sep("-", "({})".format(get_best_relpath(item.function)))
+        # dict key not used in loop but needed for sorting
+        for _, fixturedefs in sorted(info.name2fixturedefs.items()):
+            assert fixturedefs is not None
+            if not fixturedefs:
+                continue
+            # last item is expected to be the one used by the test item
+            write_fixture(fixturedefs[-1])
+
+    for session_item in session.items:
+        write_item(session_item)
+
+
+def showfixtures(config):
+    from _pytest.main import wrap_session
+
+    return wrap_session(config, _showfixtures_main)
+
+
+def _showfixtures_main(config, session):
+    import _pytest.config
+
+    session.perform_collect()
+    curdir = py.path.local()
+    tw = _pytest.config.create_terminal_writer(config)
+    verbose = config.getvalue("verbose")
+
+    fm = session._fixturemanager
+
+    available = []
+    seen = set()
+
+    for argname, fixturedefs in fm._arg2fixturedefs.items():
+        assert fixturedefs is not None
+        if not fixturedefs:
+            continue
+        for fixturedef in fixturedefs:
+            loc = getlocation(fixturedef.func, curdir)
+            if (fixturedef.argname, loc) in seen:
+                continue
+            seen.add((fixturedef.argname, loc))
+            available.append(
+                (
+                    len(fixturedef.baseid),
+                    fixturedef.func.__module__,
+                    curdir.bestrelpath(loc),
+                    fixturedef.argname,
+                    fixturedef,
+                )
+            )
+
+    available.sort()
+    currentmodule = None
+    for baseid, module, bestrel, argname, fixturedef in available:
+        if currentmodule != module:
+            if not module.startswith("_pytest."):
+                tw.line()
+                tw.sep("-", "fixtures defined from %s" % (module,))
+                currentmodule = module
+        if verbose <= 0 and argname[0] == "_":
+            continue
+        if verbose > 0:
+            funcargspec = "%s -- %s" % (argname, bestrel)
+        else:
+            funcargspec = argname
+        tw.line(funcargspec, green=True)
+        loc = getlocation(fixturedef.func, curdir)
+        doc = fixturedef.func.__doc__ or ""
+        if doc:
+            write_docstring(tw, doc)
+        else:
+            tw.line("    %s: no docstring available" % (loc,), red=True)
+
+
+def write_docstring(tw, doc):
+    INDENT = "    "
+    doc = doc.rstrip()
+    if "\n" in doc:
+        firstline, rest = doc.split("\n", 1)
+    else:
+        firstline, rest = doc, ""
+
+    if firstline.strip():
+        tw.line(INDENT + firstline.strip())
+
+    if rest:
+        for line in dedent(rest).split("\n"):
+            tw.write(INDENT + line + "\n")
+
+
+class Function(FunctionMixin, nodes.Item, fixtures.FuncargnamesCompatAttr):
+    """ a Function Item is responsible for setting up and executing a
+    Python test function.
+    """
+
+    _genid = None
+    # disable since functions handle it themselves
+    _ALLOW_MARKERS = False
+
+    def __init__(
+        self,
+        name,
+        parent,
+        args=None,
+        config=None,
+        callspec=None,
+        callobj=NOTSET,
+        keywords=None,
+        session=None,
+        fixtureinfo=None,
+        originalname=None,
+    ):
+        super(Function, self).__init__(name, parent, config=config, session=session)
+        self._args = args
+        if callobj is not NOTSET:
+            self.obj = callobj
+
+        self.keywords.update(self.obj.__dict__)
+        self.own_markers.extend(get_unpacked_marks(self.obj))
+        if callspec:
+            self.callspec = callspec
+            # this is total hostile and a mess
+            # keywords are broken by design by now
+            # this will be redeemed later
+            for mark in callspec.marks:
+                # feel free to cry, this was broken for years before
+                # and keywords cant fix it per design
+                self.keywords[mark.name] = mark
+            self.own_markers.extend(normalize_mark_list(callspec.marks))
+        if keywords:
+            self.keywords.update(keywords)
+
+        if fixtureinfo is None:
+            fixtureinfo = self.session._fixturemanager.getfixtureinfo(
+                self, self.obj, self.cls, funcargs=not self._isyieldedfunction()
+            )
+        self._fixtureinfo = fixtureinfo
+        self.fixturenames = fixtureinfo.names_closure
+        self._initrequest()
+
+        #: original function name, without any decorations (for example
+        #: parametrization adds a ``"[...]"`` suffix to function names).
+        #:
+        #: .. versionadded:: 3.0
+        self.originalname = originalname
+
+    def _initrequest(self):
+        self.funcargs = {}
+        if self._isyieldedfunction():
+            assert not hasattr(
+                self, "callspec"
+            ), "yielded functions (deprecated) cannot have funcargs"
+        else:
+            if hasattr(self, "callspec"):
+                callspec = self.callspec
+                assert not callspec.funcargs
+                self._genid = callspec.id
+                if hasattr(callspec, "param"):
+                    self.param = callspec.param
+        self._request = fixtures.FixtureRequest(self)
+
+    @property
+    def function(self):
+        "underlying python 'function' object"
+        return getimfunc(self.obj)
+
+    def _getobj(self):
+        name = self.name
+        i = name.find("[")  # parametrization
+        if i != -1:
+            name = name[:i]
+        return getattr(self.parent.obj, name)
+
+    @property
+    def _pyfuncitem(self):
+        "(compatonly) for code expecting pytest-2.2 style request objects"
+        return self
+
+    def _isyieldedfunction(self):
+        return getattr(self, "_args", None) is not None
+
+    def runtest(self):
+        """ execute the underlying test function. """
+        self.ihook.pytest_pyfunc_call(pyfuncitem=self)
+
+    def setup(self):
+        super(Function, self).setup()
+        fixtures.fillfixtures(self)
+
+
+class FunctionDefinition(Function):
+    """
+    internal hack until we get actual definition nodes instead of the
+    crappy metafunc hack
+    """
+
+    def runtest(self):
+        raise RuntimeError("function definitions are not supposed to be used")
+
+    setup = runtest
Index: venv/Lib/site-packages/_pytest/deprecated.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/deprecated.py	(date 1543190976641)
+++ venv/Lib/site-packages/_pytest/deprecated.py	(date 1543190976641)
@@ -0,0 +1,123 @@
+"""
+This module contains deprecation messages and bits of code used elsewhere in the codebase
+that is planned to be removed in the next pytest release.
+
+Keeping it in a central location makes it easy to track what is deprecated and should
+be removed when the time comes.
+
+All constants defined in this module should be either PytestWarning instances or UnformattedWarning
+in case of warnings which need to format their messages.
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+from _pytest.warning_types import PytestDeprecationWarning
+from _pytest.warning_types import RemovedInPytest4Warning
+from _pytest.warning_types import UnformattedWarning
+
+
+MAIN_STR_ARGS = RemovedInPytest4Warning(
+    "passing a string to pytest.main() is deprecated, "
+    "pass a list of arguments instead."
+)
+
+YIELD_TESTS = RemovedInPytest4Warning(
+    "yield tests are deprecated, and scheduled to be removed in pytest 4.0"
+)
+
+CACHED_SETUP = RemovedInPytest4Warning(
+    "cached_setup is deprecated and will be removed in a future release. "
+    "Use standard fixture functions instead."
+)
+
+COMPAT_PROPERTY = UnformattedWarning(
+    RemovedInPytest4Warning,
+    "usage of {owner}.{name} is deprecated, please use pytest.{name} instead",
+)
+
+CUSTOM_CLASS = UnformattedWarning(
+    RemovedInPytest4Warning,
+    'use of special named "{name}" objects in collectors of type "{type_name}" to '
+    "customize the created nodes is deprecated. "
+    "Use pytest_pycollect_makeitem(...) to create custom "
+    "collection nodes instead.",
+)
+
+FUNCARG_PREFIX = UnformattedWarning(
+    RemovedInPytest4Warning,
+    '{name}: declaring fixtures using "pytest_funcarg__" prefix is deprecated '
+    "and scheduled to be removed in pytest 4.0.  "
+    "Please remove the prefix and use the @pytest.fixture decorator instead.",
+)
+
+FIXTURE_FUNCTION_CALL = UnformattedWarning(
+    RemovedInPytest4Warning,
+    'Fixture "{name}" called directly. Fixtures are not meant to be called directly, '
+    "are created automatically when test functions request them as parameters. "
+    "See https://docs.pytest.org/en/latest/fixture.html for more information.",
+)
+
+FIXTURE_NAMED_REQUEST = PytestDeprecationWarning(
+    "'request' is a reserved name for fixtures and will raise an error in future versions"
+)
+
+CFG_PYTEST_SECTION = UnformattedWarning(
+    RemovedInPytest4Warning,
+    "[pytest] section in {filename} files is deprecated, use [tool:pytest] instead.",
+)
+
+GETFUNCARGVALUE = RemovedInPytest4Warning(
+    "getfuncargvalue is deprecated, use getfixturevalue"
+)
+
+RESULT_LOG = RemovedInPytest4Warning(
+    "--result-log is deprecated and scheduled for removal in pytest 4.0.\n"
+    "See https://docs.pytest.org/en/latest/usage.html#creating-resultlog-format-files for more information."
+)
+
+MARK_INFO_ATTRIBUTE = RemovedInPytest4Warning(
+    "MarkInfo objects are deprecated as they contain merged marks which are hard to deal with correctly.\n"
+    "Please use node.get_closest_marker(name) or node.iter_markers(name).\n"
+    "Docs: https://docs.pytest.org/en/latest/mark.html#updating-code"
+)
+
+MARK_PARAMETERSET_UNPACKING = RemovedInPytest4Warning(
+    "Applying marks directly to parameters is deprecated,"
+    " please use pytest.param(..., marks=...) instead.\n"
+    "For more details, see: https://docs.pytest.org/en/latest/parametrize.html"
+)
+
+NODE_WARN = RemovedInPytest4Warning(
+    "Node.warn(code, message) form has been deprecated, use Node.warn(warning_instance) instead."
+)
+
+RECORD_XML_PROPERTY = RemovedInPytest4Warning(
+    'Fixture renamed from "record_xml_property" to "record_property" as user '
+    "properties are now available to all reporters.\n"
+    '"record_xml_property" is now deprecated.'
+)
+
+COLLECTOR_MAKEITEM = RemovedInPytest4Warning(
+    "pycollector makeitem was removed as it is an accidentially leaked internal api"
+)
+
+METAFUNC_ADD_CALL = RemovedInPytest4Warning(
+    "Metafunc.addcall is deprecated and scheduled to be removed in pytest 4.0.\n"
+    "Please use Metafunc.parametrize instead."
+)
+
+PYTEST_PLUGINS_FROM_NON_TOP_LEVEL_CONFTEST = RemovedInPytest4Warning(
+    "Defining pytest_plugins in a non-top-level conftest is deprecated, "
+    "because it affects the entire directory tree in a non-explicit way.\n"
+    "Please move it to the top level conftest file instead."
+)
+
+PYTEST_NAMESPACE = RemovedInPytest4Warning(
+    "pytest_namespace is deprecated and will be removed soon"
+)
+
+PYTEST_ENSURETEMP = RemovedInPytest4Warning(
+    "pytest/tmpdir_factory.ensuretemp is deprecated, \n"
+    "please use the tmp_path fixture or tmp_path_factory.mktemp"
+)
Index: venv/Lib/site-packages/_pytest/warnings.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/warnings.py	(date 1543190976652)
+++ venv/Lib/site-packages/_pytest/warnings.py	(date 1543190976652)
@@ -0,0 +1,177 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+import warnings
+from contextlib import contextmanager
+
+import pytest
+from _pytest import compat
+
+SHOW_PYTEST_WARNINGS_ARG = "-Walways::pytest.RemovedInPytest4Warning"
+
+
+def _setoption(wmod, arg):
+    """
+    Copy of the warning._setoption function but does not escape arguments.
+    """
+    parts = arg.split(":")
+    if len(parts) > 5:
+        raise wmod._OptionError("too many fields (max 5): %r" % (arg,))
+    while len(parts) < 5:
+        parts.append("")
+    action, message, category, module, lineno = [s.strip() for s in parts]
+    action = wmod._getaction(action)
+    category = wmod._getcategory(category)
+    if lineno:
+        try:
+            lineno = int(lineno)
+            if lineno < 0:
+                raise ValueError
+        except (ValueError, OverflowError):
+            raise wmod._OptionError("invalid lineno %r" % (lineno,))
+    else:
+        lineno = 0
+    wmod.filterwarnings(action, message, category, module, lineno)
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("pytest-warnings")
+    group.addoption(
+        "-W",
+        "--pythonwarnings",
+        action="append",
+        help="set which warnings to report, see -W option of python itself.",
+    )
+    parser.addini(
+        "filterwarnings",
+        type="linelist",
+        help="Each line specifies a pattern for "
+        "warnings.filterwarnings. "
+        "Processed after -W and --pythonwarnings.",
+    )
+
+
+def pytest_configure(config):
+    config.addinivalue_line(
+        "markers",
+        "filterwarnings(warning): add a warning filter to the given test. "
+        "see https://docs.pytest.org/en/latest/warnings.html#pytest-mark-filterwarnings ",
+    )
+
+
+@contextmanager
+def catch_warnings_for_item(config, ihook, when, item):
+    """
+    Context manager that catches warnings generated in the contained execution block.
+
+    ``item`` can be None if we are not in the context of an item execution.
+
+    Each warning captured triggers the ``pytest_warning_captured`` hook.
+    """
+    cmdline_filters = config.getoption("pythonwarnings") or []
+    inifilters = config.getini("filterwarnings")
+    with warnings.catch_warnings(record=True) as log:
+
+        if not sys.warnoptions:
+            # if user is not explicitly configuring warning filters, show deprecation warnings by default (#2908)
+            warnings.filterwarnings("always", category=DeprecationWarning)
+            warnings.filterwarnings("always", category=PendingDeprecationWarning)
+
+        warnings.filterwarnings("error", category=pytest.RemovedInPytest4Warning)
+
+        # filters should have this precedence: mark, cmdline options, ini
+        # filters should be applied in the inverse order of precedence
+        for arg in inifilters:
+            _setoption(warnings, arg)
+
+        for arg in cmdline_filters:
+            warnings._setoption(arg)
+
+        if item is not None:
+            for mark in item.iter_markers(name="filterwarnings"):
+                for arg in mark.args:
+                    _setoption(warnings, arg)
+
+        yield
+
+        for warning_message in log:
+            ihook.pytest_warning_captured.call_historic(
+                kwargs=dict(warning_message=warning_message, when=when, item=item)
+            )
+
+
+def warning_record_to_str(warning_message):
+    """Convert a warnings.WarningMessage to a string, taking in account a lot of unicode shenaningans in Python 2.
+
+    When Python 2 support is dropped this function can be greatly simplified.
+    """
+    warn_msg = warning_message.message
+    unicode_warning = False
+    if compat._PY2 and any(isinstance(m, compat.UNICODE_TYPES) for m in warn_msg.args):
+        new_args = []
+        for m in warn_msg.args:
+            new_args.append(
+                compat.ascii_escaped(m) if isinstance(m, compat.UNICODE_TYPES) else m
+            )
+        unicode_warning = list(warn_msg.args) != new_args
+        warn_msg.args = new_args
+
+    msg = warnings.formatwarning(
+        warn_msg,
+        warning_message.category,
+        warning_message.filename,
+        warning_message.lineno,
+        warning_message.line,
+    )
+    if unicode_warning:
+        warnings.warn(
+            "Warning is using unicode non convertible to ascii, "
+            "converting to a safe representation:\n  {!r}".format(compat.safe_str(msg)),
+            UnicodeWarning,
+        )
+    return msg
+
+
+@pytest.hookimpl(hookwrapper=True, tryfirst=True)
+def pytest_runtest_protocol(item):
+    with catch_warnings_for_item(
+        config=item.config, ihook=item.ihook, when="runtest", item=item
+    ):
+        yield
+
+
+@pytest.hookimpl(hookwrapper=True, tryfirst=True)
+def pytest_collection(session):
+    config = session.config
+    with catch_warnings_for_item(
+        config=config, ihook=config.hook, when="collect", item=None
+    ):
+        yield
+
+
+@pytest.hookimpl(hookwrapper=True)
+def pytest_terminal_summary(terminalreporter):
+    config = terminalreporter.config
+    with catch_warnings_for_item(
+        config=config, ihook=config.hook, when="config", item=None
+    ):
+        yield
+
+
+def _issue_config_warning(warning, config):
+    """
+    This function should be used instead of calling ``warnings.warn`` directly when we are in the "configure" stage:
+    at this point the actual options might not have been set, so we manually trigger the pytest_warning_captured
+    hook so we can display this warnings in the terminal. This is a hack until we can sort out #2891.
+
+    :param warning: the warning instance.
+    :param config:
+    """
+    with warnings.catch_warnings(record=True) as records:
+        warnings.simplefilter("always", type(warning))
+        warnings.warn(warning, stacklevel=2)
+    config.hook.pytest_warning_captured.call_historic(
+        kwargs=dict(warning_message=records[0], when="config", item=None)
+    )
Index: venv/Lib/site-packages/_pytest/debugging.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/debugging.py	(date 1543190976662)
+++ venv/Lib/site-packages/_pytest/debugging.py	(date 1543190976662)
@@ -0,0 +1,237 @@
+""" interactive debugging with PDB, the Python Debugger. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import pdb
+import sys
+from doctest import UnexpectedException
+
+from _pytest import outcomes
+from _pytest.config import hookimpl
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group._addoption(
+        "--pdb",
+        dest="usepdb",
+        action="store_true",
+        help="start the interactive Python debugger on errors or KeyboardInterrupt.",
+    )
+    group._addoption(
+        "--pdbcls",
+        dest="usepdb_cls",
+        metavar="modulename:classname",
+        help="start a custom interactive Python debugger on errors. "
+        "For example: --pdbcls=IPython.terminal.debugger:TerminalPdb",
+    )
+    group._addoption(
+        "--trace",
+        dest="trace",
+        action="store_true",
+        help="Immediately break when running each test.",
+    )
+
+
+def pytest_configure(config):
+    if config.getvalue("usepdb_cls"):
+        modname, classname = config.getvalue("usepdb_cls").split(":")
+        __import__(modname)
+        pdb_cls = getattr(sys.modules[modname], classname)
+    else:
+        pdb_cls = pdb.Pdb
+
+    if config.getvalue("trace"):
+        config.pluginmanager.register(PdbTrace(), "pdbtrace")
+    if config.getvalue("usepdb"):
+        config.pluginmanager.register(PdbInvoke(), "pdbinvoke")
+
+    pytestPDB._saved.append(
+        (pdb.set_trace, pytestPDB._pluginmanager, pytestPDB._config, pytestPDB._pdb_cls)
+    )
+    pdb.set_trace = pytestPDB.set_trace
+    pytestPDB._pluginmanager = config.pluginmanager
+    pytestPDB._config = config
+    pytestPDB._pdb_cls = pdb_cls
+
+    # NOTE: not using pytest_unconfigure, since it might get called although
+    #       pytest_configure was not (if another plugin raises UsageError).
+    def fin():
+        (
+            pdb.set_trace,
+            pytestPDB._pluginmanager,
+            pytestPDB._config,
+            pytestPDB._pdb_cls,
+        ) = pytestPDB._saved.pop()
+
+    config._cleanup.append(fin)
+
+
+class pytestPDB(object):
+    """ Pseudo PDB that defers to the real pdb. """
+
+    _pluginmanager = None
+    _config = None
+    _pdb_cls = pdb.Pdb
+    _saved = []
+
+    @classmethod
+    def set_trace(cls, set_break=True):
+        """ invoke PDB set_trace debugging, dropping any IO capturing. """
+        import _pytest.config
+
+        frame = sys._getframe().f_back
+        if cls._pluginmanager is not None:
+            capman = cls._pluginmanager.getplugin("capturemanager")
+            if capman:
+                capman.suspend_global_capture(in_=True)
+            tw = _pytest.config.create_terminal_writer(cls._config)
+            tw.line()
+            if capman and capman.is_globally_capturing():
+                tw.sep(">", "PDB set_trace (IO-capturing turned off)")
+            else:
+                tw.sep(">", "PDB set_trace")
+
+            class _PdbWrapper(cls._pdb_cls, object):
+                _pytest_capman = capman
+                _continued = False
+
+                def do_continue(self, arg):
+                    ret = super(_PdbWrapper, self).do_continue(arg)
+                    if self._pytest_capman:
+                        tw = _pytest.config.create_terminal_writer(cls._config)
+                        tw.line()
+                        if self._pytest_capman.is_globally_capturing():
+                            tw.sep(">", "PDB continue (IO-capturing resumed)")
+                        else:
+                            tw.sep(">", "PDB continue")
+                        self._pytest_capman.resume_global_capture()
+                    cls._pluginmanager.hook.pytest_leave_pdb(
+                        config=cls._config, pdb=self
+                    )
+                    self._continued = True
+                    return ret
+
+                do_c = do_cont = do_continue
+
+                def setup(self, f, tb):
+                    """Suspend on setup().
+
+                    Needed after do_continue resumed, and entering another
+                    breakpoint again.
+                    """
+                    ret = super(_PdbWrapper, self).setup(f, tb)
+                    if not ret and self._continued:
+                        # pdb.setup() returns True if the command wants to exit
+                        # from the interaction: do not suspend capturing then.
+                        if self._pytest_capman:
+                            self._pytest_capman.suspend_global_capture(in_=True)
+                    return ret
+
+            _pdb = _PdbWrapper()
+            cls._pluginmanager.hook.pytest_enter_pdb(config=cls._config, pdb=_pdb)
+        else:
+            _pdb = cls._pdb_cls()
+
+        if set_break:
+            _pdb.set_trace(frame)
+
+
+class PdbInvoke(object):
+    def pytest_exception_interact(self, node, call, report):
+        capman = node.config.pluginmanager.getplugin("capturemanager")
+        if capman:
+            capman.suspend_global_capture(in_=True)
+            out, err = capman.read_global_capture()
+            sys.stdout.write(out)
+            sys.stdout.write(err)
+        _enter_pdb(node, call.excinfo, report)
+
+    def pytest_internalerror(self, excrepr, excinfo):
+        tb = _postmortem_traceback(excinfo)
+        post_mortem(tb)
+
+
+class PdbTrace(object):
+    @hookimpl(hookwrapper=True)
+    def pytest_pyfunc_call(self, pyfuncitem):
+        _test_pytest_function(pyfuncitem)
+        yield
+
+
+def _test_pytest_function(pyfuncitem):
+    pytestPDB.set_trace(set_break=False)
+    testfunction = pyfuncitem.obj
+    pyfuncitem.obj = pdb.runcall
+    if pyfuncitem._isyieldedfunction():
+        arg_list = list(pyfuncitem._args)
+        arg_list.insert(0, testfunction)
+        pyfuncitem._args = tuple(arg_list)
+    else:
+        if "func" in pyfuncitem._fixtureinfo.argnames:
+            raise ValueError("--trace can't be used with a fixture named func!")
+        pyfuncitem.funcargs["func"] = testfunction
+        new_list = list(pyfuncitem._fixtureinfo.argnames)
+        new_list.append("func")
+        pyfuncitem._fixtureinfo.argnames = tuple(new_list)
+
+
+def _enter_pdb(node, excinfo, rep):
+    # XXX we re-use the TerminalReporter's terminalwriter
+    # because this seems to avoid some encoding related troubles
+    # for not completely clear reasons.
+    tw = node.config.pluginmanager.getplugin("terminalreporter")._tw
+    tw.line()
+
+    showcapture = node.config.option.showcapture
+
+    for sectionname, content in (
+        ("stdout", rep.capstdout),
+        ("stderr", rep.capstderr),
+        ("log", rep.caplog),
+    ):
+        if showcapture in (sectionname, "all") and content:
+            tw.sep(">", "captured " + sectionname)
+            if content[-1:] == "\n":
+                content = content[:-1]
+            tw.line(content)
+
+    tw.sep(">", "traceback")
+    rep.toterminal(tw)
+    tw.sep(">", "entering PDB")
+    tb = _postmortem_traceback(excinfo)
+    rep._pdbshown = True
+    if post_mortem(tb):
+        outcomes.exit("Quitting debugger")
+    return rep
+
+
+def _postmortem_traceback(excinfo):
+    if isinstance(excinfo.value, UnexpectedException):
+        # A doctest.UnexpectedException is not useful for post_mortem.
+        # Use the underlying exception instead:
+        return excinfo.value.exc_info[2]
+    else:
+        return excinfo._excinfo[2]
+
+
+def _find_last_non_hidden_frame(stack):
+    i = max(0, len(stack) - 1)
+    while i and stack[i][0].f_locals.get("__tracebackhide__", False):
+        i -= 1
+    return i
+
+
+def post_mortem(t):
+    class Pdb(pytestPDB._pdb_cls):
+        def get_stack(self, f, t):
+            stack, i = pdb.Pdb.get_stack(self, f, t)
+            if f is None:
+                i = _find_last_non_hidden_frame(stack)
+            return stack, i
+
+    p = Pdb()
+    p.reset()
+    p.interaction(None, t)
+    return p.quitting
Index: venv/Lib/site-packages/_pytest/python_api.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/python_api.py	(date 1543190976677)
+++ venv/Lib/site-packages/_pytest/python_api.py	(date 1543190976677)
@@ -0,0 +1,721 @@
+import math
+import pprint
+import sys
+from decimal import Decimal
+from numbers import Number
+
+import six
+from more_itertools.more import always_iterable
+from six.moves import filterfalse
+from six.moves import zip
+
+import _pytest._code
+from _pytest.compat import isclass
+from _pytest.compat import Mapping
+from _pytest.compat import Sequence
+from _pytest.compat import STRING_TYPES
+from _pytest.outcomes import fail
+
+BASE_TYPE = (type, STRING_TYPES)
+
+
+def _cmp_raises_type_error(self, other):
+    """__cmp__ implementation which raises TypeError. Used
+    by Approx base classes to implement only == and != and raise a
+    TypeError for other comparisons.
+
+    Needed in Python 2 only, Python 3 all it takes is not implementing the
+    other operators at all.
+    """
+    __tracebackhide__ = True
+    raise TypeError(
+        "Comparison operators other than == and != not supported by approx objects"
+    )
+
+
+def _non_numeric_type_error(value, at):
+    at_str = " at {}".format(at) if at else ""
+    return TypeError(
+        "cannot make approximate comparisons to non-numeric values: {!r} {}".format(
+            value, at_str
+        )
+    )
+
+
+# builtin pytest.approx helper
+
+
+class ApproxBase(object):
+    """
+    Provide shared utilities for making approximate comparisons between numbers
+    or sequences of numbers.
+    """
+
+    # Tell numpy to use our `__eq__` operator instead of its.
+    __array_ufunc__ = None
+    __array_priority__ = 100
+
+    def __init__(self, expected, rel=None, abs=None, nan_ok=False):
+        __tracebackhide__ = True
+        self.expected = expected
+        self.abs = abs
+        self.rel = rel
+        self.nan_ok = nan_ok
+        self._check_type()
+
+    def __repr__(self):
+        raise NotImplementedError
+
+    def __eq__(self, actual):
+        return all(
+            a == self._approx_scalar(x) for a, x in self._yield_comparisons(actual)
+        )
+
+    __hash__ = None
+
+    def __ne__(self, actual):
+        return not (actual == self)
+
+    if sys.version_info[0] == 2:
+        __cmp__ = _cmp_raises_type_error
+
+    def _approx_scalar(self, x):
+        return ApproxScalar(x, rel=self.rel, abs=self.abs, nan_ok=self.nan_ok)
+
+    def _yield_comparisons(self, actual):
+        """
+        Yield all the pairs of numbers to be compared.  This is used to
+        implement the `__eq__` method.
+        """
+        raise NotImplementedError
+
+    def _check_type(self):
+        """
+        Raise a TypeError if the expected value is not a valid type.
+        """
+        # This is only a concern if the expected value is a sequence.  In every
+        # other case, the approx() function ensures that the expected value has
+        # a numeric type.  For this reason, the default is to do nothing.  The
+        # classes that deal with sequences should reimplement this method to
+        # raise if there are any non-numeric elements in the sequence.
+        pass
+
+
+def _recursive_list_map(f, x):
+    if isinstance(x, list):
+        return list(_recursive_list_map(f, xi) for xi in x)
+    else:
+        return f(x)
+
+
+class ApproxNumpy(ApproxBase):
+    """
+    Perform approximate comparisons where the expected value is numpy array.
+    """
+
+    def __repr__(self):
+        list_scalars = _recursive_list_map(self._approx_scalar, self.expected.tolist())
+        return "approx({!r})".format(list_scalars)
+
+    if sys.version_info[0] == 2:
+        __cmp__ = _cmp_raises_type_error
+
+    def __eq__(self, actual):
+        import numpy as np
+
+        # self.expected is supposed to always be an array here
+
+        if not np.isscalar(actual):
+            try:
+                actual = np.asarray(actual)
+            except:  # noqa
+                raise TypeError("cannot compare '{}' to numpy.ndarray".format(actual))
+
+        if not np.isscalar(actual) and actual.shape != self.expected.shape:
+            return False
+
+        return ApproxBase.__eq__(self, actual)
+
+    def _yield_comparisons(self, actual):
+        import numpy as np
+
+        # `actual` can either be a numpy array or a scalar, it is treated in
+        # `__eq__` before being passed to `ApproxBase.__eq__`, which is the
+        # only method that calls this one.
+
+        if np.isscalar(actual):
+            for i in np.ndindex(self.expected.shape):
+                yield actual, np.asscalar(self.expected[i])
+        else:
+            for i in np.ndindex(self.expected.shape):
+                yield np.asscalar(actual[i]), np.asscalar(self.expected[i])
+
+
+class ApproxMapping(ApproxBase):
+    """
+    Perform approximate comparisons where the expected value is a mapping with
+    numeric values (the keys can be anything).
+    """
+
+    def __repr__(self):
+        return "approx({!r})".format(
+            {k: self._approx_scalar(v) for k, v in self.expected.items()}
+        )
+
+    def __eq__(self, actual):
+        if set(actual.keys()) != set(self.expected.keys()):
+            return False
+
+        return ApproxBase.__eq__(self, actual)
+
+    def _yield_comparisons(self, actual):
+        for k in self.expected.keys():
+            yield actual[k], self.expected[k]
+
+    def _check_type(self):
+        __tracebackhide__ = True
+        for key, value in self.expected.items():
+            if isinstance(value, type(self.expected)):
+                msg = "pytest.approx() does not support nested dictionaries: key={!r} value={!r}\n  full mapping={}"
+                raise TypeError(msg.format(key, value, pprint.pformat(self.expected)))
+            elif not isinstance(value, Number):
+                raise _non_numeric_type_error(self.expected, at="key={!r}".format(key))
+
+
+class ApproxSequence(ApproxBase):
+    """
+    Perform approximate comparisons where the expected value is a sequence of
+    numbers.
+    """
+
+    def __repr__(self):
+        seq_type = type(self.expected)
+        if seq_type not in (tuple, list, set):
+            seq_type = list
+        return "approx({!r})".format(
+            seq_type(self._approx_scalar(x) for x in self.expected)
+        )
+
+    def __eq__(self, actual):
+        if len(actual) != len(self.expected):
+            return False
+        return ApproxBase.__eq__(self, actual)
+
+    def _yield_comparisons(self, actual):
+        return zip(actual, self.expected)
+
+    def _check_type(self):
+        __tracebackhide__ = True
+        for index, x in enumerate(self.expected):
+            if isinstance(x, type(self.expected)):
+                msg = "pytest.approx() does not support nested data structures: {!r} at index {}\n  full sequence: {}"
+                raise TypeError(msg.format(x, index, pprint.pformat(self.expected)))
+            elif not isinstance(x, Number):
+                raise _non_numeric_type_error(
+                    self.expected, at="index {}".format(index)
+                )
+
+
+class ApproxScalar(ApproxBase):
+    """
+    Perform approximate comparisons where the expected value is a single number.
+    """
+
+    DEFAULT_ABSOLUTE_TOLERANCE = 1e-12
+    DEFAULT_RELATIVE_TOLERANCE = 1e-6
+
+    def __repr__(self):
+        """
+        Return a string communicating both the expected value and the tolerance
+        for the comparison being made, e.g. '1.0 +- 1e-6'.  Use the unicode
+        plus/minus symbol if this is python3 (it's too hard to get right for
+        python2).
+        """
+        if isinstance(self.expected, complex):
+            return str(self.expected)
+
+        # Infinities aren't compared using tolerances, so don't show a
+        # tolerance.
+        if math.isinf(self.expected):
+            return str(self.expected)
+
+        # If a sensible tolerance can't be calculated, self.tolerance will
+        # raise a ValueError.  In this case, display '???'.
+        try:
+            vetted_tolerance = "{:.1e}".format(self.tolerance)
+        except ValueError:
+            vetted_tolerance = "???"
+
+        if sys.version_info[0] == 2:
+            return "{} +- {}".format(self.expected, vetted_tolerance)
+        else:
+            return u"{} \u00b1 {}".format(self.expected, vetted_tolerance)
+
+    def __eq__(self, actual):
+        """
+        Return true if the given value is equal to the expected value within
+        the pre-specified tolerance.
+        """
+        if _is_numpy_array(actual):
+            # Call ``__eq__()`` manually to prevent infinite-recursion with
+            # numpy<1.13.  See #3748.
+            return all(self.__eq__(a) for a in actual.flat)
+
+        # Short-circuit exact equality.
+        if actual == self.expected:
+            return True
+
+        # Allow the user to control whether NaNs are considered equal to each
+        # other or not.  The abs() calls are for compatibility with complex
+        # numbers.
+        if math.isnan(abs(self.expected)):
+            return self.nan_ok and math.isnan(abs(actual))
+
+        # Infinity shouldn't be approximately equal to anything but itself, but
+        # if there's a relative tolerance, it will be infinite and infinity
+        # will seem approximately equal to everything.  The equal-to-itself
+        # case would have been short circuited above, so here we can just
+        # return false if the expected value is infinite.  The abs() call is
+        # for compatibility with complex numbers.
+        if math.isinf(abs(self.expected)):
+            return False
+
+        # Return true if the two numbers are within the tolerance.
+        return abs(self.expected - actual) <= self.tolerance
+
+    __hash__ = None
+
+    @property
+    def tolerance(self):
+        """
+        Return the tolerance for the comparison.  This could be either an
+        absolute tolerance or a relative tolerance, depending on what the user
+        specified or which would be larger.
+        """
+
+        def set_default(x, default):
+            return x if x is not None else default
+
+        # Figure out what the absolute tolerance should be.  ``self.abs`` is
+        # either None or a value specified by the user.
+        absolute_tolerance = set_default(self.abs, self.DEFAULT_ABSOLUTE_TOLERANCE)
+
+        if absolute_tolerance < 0:
+            raise ValueError(
+                "absolute tolerance can't be negative: {}".format(absolute_tolerance)
+            )
+        if math.isnan(absolute_tolerance):
+            raise ValueError("absolute tolerance can't be NaN.")
+
+        # If the user specified an absolute tolerance but not a relative one,
+        # just return the absolute tolerance.
+        if self.rel is None:
+            if self.abs is not None:
+                return absolute_tolerance
+
+        # Figure out what the relative tolerance should be.  ``self.rel`` is
+        # either None or a value specified by the user.  This is done after
+        # we've made sure the user didn't ask for an absolute tolerance only,
+        # because we don't want to raise errors about the relative tolerance if
+        # we aren't even going to use it.
+        relative_tolerance = set_default(
+            self.rel, self.DEFAULT_RELATIVE_TOLERANCE
+        ) * abs(self.expected)
+
+        if relative_tolerance < 0:
+            raise ValueError(
+                "relative tolerance can't be negative: {}".format(absolute_tolerance)
+            )
+        if math.isnan(relative_tolerance):
+            raise ValueError("relative tolerance can't be NaN.")
+
+        # Return the larger of the relative and absolute tolerances.
+        return max(relative_tolerance, absolute_tolerance)
+
+
+class ApproxDecimal(ApproxScalar):
+    """
+    Perform approximate comparisons where the expected value is a decimal.
+    """
+
+    DEFAULT_ABSOLUTE_TOLERANCE = Decimal("1e-12")
+    DEFAULT_RELATIVE_TOLERANCE = Decimal("1e-6")
+
+
+def approx(expected, rel=None, abs=None, nan_ok=False):
+    """
+    Assert that two numbers (or two sets of numbers) are equal to each other
+    within some tolerance.
+
+    Due to the `intricacies of floating-point arithmetic`__, numbers that we
+    would intuitively expect to be equal are not always so::
+
+        >>> 0.1 + 0.2 == 0.3
+        False
+
+    __ https://docs.python.org/3/tutorial/floatingpoint.html
+
+    This problem is commonly encountered when writing tests, e.g. when making
+    sure that floating-point values are what you expect them to be.  One way to
+    deal with this problem is to assert that two floating-point numbers are
+    equal to within some appropriate tolerance::
+
+        >>> abs((0.1 + 0.2) - 0.3) < 1e-6
+        True
+
+    However, comparisons like this are tedious to write and difficult to
+    understand.  Furthermore, absolute comparisons like the one above are
+    usually discouraged because there's no tolerance that works well for all
+    situations.  ``1e-6`` is good for numbers around ``1``, but too small for
+    very big numbers and too big for very small ones.  It's better to express
+    the tolerance as a fraction of the expected value, but relative comparisons
+    like that are even more difficult to write correctly and concisely.
+
+    The ``approx`` class performs floating-point comparisons using a syntax
+    that's as intuitive as possible::
+
+        >>> from pytest import approx
+        >>> 0.1 + 0.2 == approx(0.3)
+        True
+
+    The same syntax also works for sequences of numbers::
+
+        >>> (0.1 + 0.2, 0.2 + 0.4) == approx((0.3, 0.6))
+        True
+
+    Dictionary *values*::
+
+        >>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})
+        True
+
+    ``numpy`` arrays::
+
+        >>> import numpy as np                                                          # doctest: +SKIP
+        >>> np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == approx(np.array([0.3, 0.6])) # doctest: +SKIP
+        True
+
+    And for a ``numpy`` array against a scalar::
+
+        >>> import numpy as np                                         # doctest: +SKIP
+        >>> np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3) # doctest: +SKIP
+        True
+
+    By default, ``approx`` considers numbers within a relative tolerance of
+    ``1e-6`` (i.e. one part in a million) of its expected value to be equal.
+    This treatment would lead to surprising results if the expected value was
+    ``0.0``, because nothing but ``0.0`` itself is relatively close to ``0.0``.
+    To handle this case less surprisingly, ``approx`` also considers numbers
+    within an absolute tolerance of ``1e-12`` of its expected value to be
+    equal.  Infinity and NaN are special cases.  Infinity is only considered
+    equal to itself, regardless of the relative tolerance.  NaN is not
+    considered equal to anything by default, but you can make it be equal to
+    itself by setting the ``nan_ok`` argument to True.  (This is meant to
+    facilitate comparing arrays that use NaN to mean "no data".)
+
+    Both the relative and absolute tolerances can be changed by passing
+    arguments to the ``approx`` constructor::
+
+        >>> 1.0001 == approx(1)
+        False
+        >>> 1.0001 == approx(1, rel=1e-3)
+        True
+        >>> 1.0001 == approx(1, abs=1e-3)
+        True
+
+    If you specify ``abs`` but not ``rel``, the comparison will not consider
+    the relative tolerance at all.  In other words, two numbers that are within
+    the default relative tolerance of ``1e-6`` will still be considered unequal
+    if they exceed the specified absolute tolerance.  If you specify both
+    ``abs`` and ``rel``, the numbers will be considered equal if either
+    tolerance is met::
+
+        >>> 1 + 1e-8 == approx(1)
+        True
+        >>> 1 + 1e-8 == approx(1, abs=1e-12)
+        False
+        >>> 1 + 1e-8 == approx(1, rel=1e-6, abs=1e-12)
+        True
+
+    If you're thinking about using ``approx``, then you might want to know how
+    it compares to other good ways of comparing floating-point numbers.  All of
+    these algorithms are based on relative and absolute tolerances and should
+    agree for the most part, but they do have meaningful differences:
+
+    - ``math.isclose(a, b, rel_tol=1e-9, abs_tol=0.0)``:  True if the relative
+      tolerance is met w.r.t. either ``a`` or ``b`` or if the absolute
+      tolerance is met.  Because the relative tolerance is calculated w.r.t.
+      both ``a`` and ``b``, this test is symmetric (i.e.  neither ``a`` nor
+      ``b`` is a "reference value").  You have to specify an absolute tolerance
+      if you want to compare to ``0.0`` because there is no tolerance by
+      default.  Only available in python>=3.5.  `More information...`__
+
+      __ https://docs.python.org/3/library/math.html#math.isclose
+
+    - ``numpy.isclose(a, b, rtol=1e-5, atol=1e-8)``: True if the difference
+      between ``a`` and ``b`` is less that the sum of the relative tolerance
+      w.r.t. ``b`` and the absolute tolerance.  Because the relative tolerance
+      is only calculated w.r.t. ``b``, this test is asymmetric and you can
+      think of ``b`` as the reference value.  Support for comparing sequences
+      is provided by ``numpy.allclose``.  `More information...`__
+
+      __ http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.isclose.html
+
+    - ``unittest.TestCase.assertAlmostEqual(a, b)``: True if ``a`` and ``b``
+      are within an absolute tolerance of ``1e-7``.  No relative tolerance is
+      considered and the absolute tolerance cannot be changed, so this function
+      is not appropriate for very large or very small numbers.  Also, it's only
+      available in subclasses of ``unittest.TestCase`` and it's ugly because it
+      doesn't follow PEP8.  `More information...`__
+
+      __ https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertAlmostEqual
+
+    - ``a == pytest.approx(b, rel=1e-6, abs=1e-12)``: True if the relative
+      tolerance is met w.r.t. ``b`` or if the absolute tolerance is met.
+      Because the relative tolerance is only calculated w.r.t. ``b``, this test
+      is asymmetric and you can think of ``b`` as the reference value.  In the
+      special case that you explicitly specify an absolute tolerance but not a
+      relative tolerance, only the absolute tolerance is considered.
+
+    .. warning::
+
+       .. versionchanged:: 3.2
+
+       In order to avoid inconsistent behavior, ``TypeError`` is
+       raised for ``>``, ``>=``, ``<`` and ``<=`` comparisons.
+       The example below illustrates the problem::
+
+           assert approx(0.1) > 0.1 + 1e-10  # calls approx(0.1).__gt__(0.1 + 1e-10)
+           assert 0.1 + 1e-10 > approx(0.1)  # calls approx(0.1).__lt__(0.1 + 1e-10)
+
+       In the second example one expects ``approx(0.1).__le__(0.1 + 1e-10)``
+       to be called. But instead, ``approx(0.1).__lt__(0.1 + 1e-10)`` is used to
+       comparison. This is because the call hierarchy of rich comparisons
+       follows a fixed behavior. `More information...`__
+
+       __ https://docs.python.org/3/reference/datamodel.html#object.__ge__
+    """
+
+    # Delegate the comparison to a class that knows how to deal with the type
+    # of the expected value (e.g. int, float, list, dict, numpy.array, etc).
+    #
+    # The primary responsibility of these classes is to implement ``__eq__()``
+    # and ``__repr__()``.  The former is used to actually check if some
+    # "actual" value is equivalent to the given expected value within the
+    # allowed tolerance.  The latter is used to show the user the expected
+    # value and tolerance, in the case that a test failed.
+    #
+    # The actual logic for making approximate comparisons can be found in
+    # ApproxScalar, which is used to compare individual numbers.  All of the
+    # other Approx classes eventually delegate to this class.  The ApproxBase
+    # class provides some convenient methods and overloads, but isn't really
+    # essential.
+
+    __tracebackhide__ = True
+
+    if isinstance(expected, Decimal):
+        cls = ApproxDecimal
+    elif isinstance(expected, Number):
+        cls = ApproxScalar
+    elif isinstance(expected, Mapping):
+        cls = ApproxMapping
+    elif isinstance(expected, Sequence) and not isinstance(expected, STRING_TYPES):
+        cls = ApproxSequence
+    elif _is_numpy_array(expected):
+        cls = ApproxNumpy
+    else:
+        raise _non_numeric_type_error(expected, at=None)
+
+    return cls(expected, rel, abs, nan_ok)
+
+
+def _is_numpy_array(obj):
+    """
+    Return true if the given object is a numpy array.  Make a special effort to
+    avoid importing numpy unless it's really necessary.
+    """
+    import sys
+
+    np = sys.modules.get("numpy")
+    if np is not None:
+        return isinstance(obj, np.ndarray)
+    return False
+
+
+# builtin pytest.raises helper
+
+
+def raises(expected_exception, *args, **kwargs):
+    r"""
+    Assert that a code block/function call raises ``expected_exception``
+    and raise a failure exception otherwise.
+
+    :arg message: if specified, provides a custom failure message if the
+        exception is not raised
+    :arg match: if specified, asserts that the exception matches a text or regex
+
+    This helper produces a ``ExceptionInfo()`` object (see below).
+
+    You may use this function as a context manager::
+
+        >>> with raises(ZeroDivisionError):
+        ...    1/0
+
+    .. versionchanged:: 2.10
+
+    In the context manager form you may use the keyword argument
+    ``message`` to specify a custom failure message::
+
+        >>> with raises(ZeroDivisionError, message="Expecting ZeroDivisionError"):
+        ...    pass
+        Traceback (most recent call last):
+          ...
+        Failed: Expecting ZeroDivisionError
+
+    .. note::
+
+       When using ``pytest.raises`` as a context manager, it's worthwhile to
+       note that normal context manager rules apply and that the exception
+       raised *must* be the final line in the scope of the context manager.
+       Lines of code after that, within the scope of the context manager will
+       not be executed. For example::
+
+           >>> value = 15
+           >>> with raises(ValueError) as exc_info:
+           ...     if value > 10:
+           ...         raise ValueError("value must be <= 10")
+           ...     assert exc_info.type == ValueError  # this will not execute
+
+       Instead, the following approach must be taken (note the difference in
+       scope)::
+
+           >>> with raises(ValueError) as exc_info:
+           ...     if value > 10:
+           ...         raise ValueError("value must be <= 10")
+           ...
+           >>> assert exc_info.type == ValueError
+
+
+    Since version ``3.1`` you can use the keyword argument ``match`` to assert that the
+    exception matches a text or regex::
+
+        >>> with raises(ValueError, match='must be 0 or None'):
+        ...     raise ValueError("value must be 0 or None")
+
+        >>> with raises(ValueError, match=r'must be \d+$'):
+        ...     raise ValueError("value must be 42")
+
+    **Legacy forms**
+
+    The forms below are fully supported but are discouraged for new code because the
+    context manager form is regarded as more readable and less error-prone.
+
+    It is possible to specify a callable by passing a to-be-called lambda::
+
+        >>> raises(ZeroDivisionError, lambda: 1/0)
+        <ExceptionInfo ...>
+
+    or you can specify an arbitrary callable with arguments::
+
+        >>> def f(x): return 1/x
+        ...
+        >>> raises(ZeroDivisionError, f, 0)
+        <ExceptionInfo ...>
+        >>> raises(ZeroDivisionError, f, x=0)
+        <ExceptionInfo ...>
+
+    It is also possible to pass a string to be evaluated at runtime::
+
+        >>> raises(ZeroDivisionError, "f(0)")
+        <ExceptionInfo ...>
+
+    The string will be evaluated using the same ``locals()`` and ``globals()``
+    at the moment of the ``raises`` call.
+
+    .. currentmodule:: _pytest._code
+
+    Consult the API of ``excinfo`` objects: :class:`ExceptionInfo`.
+
+    .. note::
+        Similar to caught exception objects in Python, explicitly clearing
+        local references to returned ``ExceptionInfo`` objects can
+        help the Python interpreter speed up its garbage collection.
+
+        Clearing those references breaks a reference cycle
+        (``ExceptionInfo`` --> caught exception --> frame stack raising
+        the exception --> current frame stack --> local variables -->
+        ``ExceptionInfo``) which makes Python keep all objects referenced
+        from that cycle (including all local variables in the current
+        frame) alive until the next cyclic garbage collection run. See the
+        official Python ``try`` statement documentation for more detailed
+        information.
+
+    """
+    __tracebackhide__ = True
+    for exc in filterfalse(isclass, always_iterable(expected_exception, BASE_TYPE)):
+        msg = (
+            "exceptions must be old-style classes or"
+            " derived from BaseException, not %s"
+        )
+        raise TypeError(msg % type(exc))
+
+    message = "DID NOT RAISE {}".format(expected_exception)
+    match_expr = None
+
+    if not args:
+        if "message" in kwargs:
+            message = kwargs.pop("message")
+        if "match" in kwargs:
+            match_expr = kwargs.pop("match")
+        if kwargs:
+            msg = "Unexpected keyword arguments passed to pytest.raises: "
+            msg += ", ".join(kwargs.keys())
+            raise TypeError(msg)
+        return RaisesContext(expected_exception, message, match_expr)
+    elif isinstance(args[0], str):
+        code, = args
+        assert isinstance(code, str)
+        frame = sys._getframe(1)
+        loc = frame.f_locals.copy()
+        loc.update(kwargs)
+        # print "raises frame scope: %r" % frame.f_locals
+        try:
+            code = _pytest._code.Source(code).compile()
+            six.exec_(code, frame.f_globals, loc)
+            # XXX didn't mean f_globals == f_locals something special?
+            #     this is destroyed here ...
+        except expected_exception:
+            return _pytest._code.ExceptionInfo()
+    else:
+        func = args[0]
+        try:
+            func(*args[1:], **kwargs)
+        except expected_exception:
+            return _pytest._code.ExceptionInfo()
+    fail(message)
+
+
+raises.Exception = fail.Exception
+
+
+class RaisesContext(object):
+    def __init__(self, expected_exception, message, match_expr):
+        self.expected_exception = expected_exception
+        self.message = message
+        self.match_expr = match_expr
+        self.excinfo = None
+
+    def __enter__(self):
+        self.excinfo = object.__new__(_pytest._code.ExceptionInfo)
+        return self.excinfo
+
+    def __exit__(self, *tp):
+        __tracebackhide__ = True
+        if tp[0] is None:
+            fail(self.message)
+        self.excinfo.__init__(tp)
+        suppress_exception = issubclass(self.excinfo.type, self.expected_exception)
+        if sys.version_info[0] == 2 and suppress_exception:
+            sys.exc_clear()
+        if self.match_expr and suppress_exception:
+            self.excinfo.match(self.match_expr)
+        return suppress_exception
Index: venv/Lib/site-packages/_pytest/outcomes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/outcomes.py	(date 1543190976687)
+++ venv/Lib/site-packages/_pytest/outcomes.py	(date 1543190976687)
@@ -0,0 +1,182 @@
+"""
+exception classes and constants handling test outcomes
+as well as functions creating them
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+
+
+class OutcomeException(BaseException):
+    """ OutcomeException and its subclass instances indicate and
+        contain info about test and collection outcomes.
+    """
+
+    def __init__(self, msg=None, pytrace=True):
+        BaseException.__init__(self, msg)
+        self.msg = msg
+        self.pytrace = pytrace
+
+    def __repr__(self):
+        if self.msg:
+            val = self.msg
+            if isinstance(val, bytes):
+                val = val.decode("UTF-8", errors="replace")
+            return val
+        return "<%s instance>" % (self.__class__.__name__,)
+
+    __str__ = __repr__
+
+
+TEST_OUTCOME = (OutcomeException, Exception)
+
+
+class Skipped(OutcomeException):
+    # XXX hackish: on 3k we fake to live in the builtins
+    # in order to have Skipped exception printing shorter/nicer
+    __module__ = "builtins"
+
+    def __init__(self, msg=None, pytrace=True, allow_module_level=False):
+        OutcomeException.__init__(self, msg=msg, pytrace=pytrace)
+        self.allow_module_level = allow_module_level
+
+
+class Failed(OutcomeException):
+    """ raised from an explicit call to pytest.fail() """
+
+    __module__ = "builtins"
+
+
+class Exit(KeyboardInterrupt):
+    """ raised for immediate program exits (no tracebacks/summaries)"""
+
+    def __init__(self, msg="unknown reason", returncode=None):
+        self.msg = msg
+        self.returncode = returncode
+        KeyboardInterrupt.__init__(self, msg)
+
+
+# exposed helper methods
+
+
+def exit(msg, returncode=None):
+    """
+    Exit testing process as if KeyboardInterrupt was triggered.
+
+    :param str msg: message to display upon exit.
+    :param int returncode: return code to be used when exiting pytest.
+    """
+    __tracebackhide__ = True
+    raise Exit(msg, returncode)
+
+
+exit.Exception = Exit
+
+
+def skip(msg="", **kwargs):
+    """
+    Skip an executing test with the given message.
+
+    This function should be called only during testing (setup, call or teardown) or
+    during collection by using the ``allow_module_level`` flag.
+
+    :kwarg bool allow_module_level: allows this function to be called at
+        module level, skipping the rest of the module. Default to False.
+
+    .. note::
+        It is better to use the :ref:`pytest.mark.skipif ref` marker when possible to declare a test to be
+        skipped under certain conditions like mismatching platforms or
+        dependencies.
+    """
+    __tracebackhide__ = True
+    allow_module_level = kwargs.pop("allow_module_level", False)
+    if kwargs:
+        keys = [k for k in kwargs.keys()]
+        raise TypeError("unexpected keyword arguments: {}".format(keys))
+    raise Skipped(msg=msg, allow_module_level=allow_module_level)
+
+
+skip.Exception = Skipped
+
+
+def fail(msg="", pytrace=True):
+    """
+    Explicitly fail an executing test with the given message.
+
+    :param str msg: the message to show the user as reason for the failure.
+    :param bool pytrace: if false the msg represents the full failure information and no
+        python traceback will be reported.
+    """
+    __tracebackhide__ = True
+    raise Failed(msg=msg, pytrace=pytrace)
+
+
+fail.Exception = Failed
+
+
+class XFailed(fail.Exception):
+    """ raised from an explicit call to pytest.xfail() """
+
+
+def xfail(reason=""):
+    """
+    Imperatively xfail an executing test or setup functions with the given reason.
+
+    This function should be called only during testing (setup, call or teardown).
+
+    .. note::
+        It is better to use the :ref:`pytest.mark.xfail ref` marker when possible to declare a test to be
+        xfailed under certain conditions like known bugs or missing features.
+    """
+    __tracebackhide__ = True
+    raise XFailed(reason)
+
+
+xfail.Exception = XFailed
+
+
+def importorskip(modname, minversion=None):
+    """ return imported module if it has at least "minversion" as its
+    __version__ attribute.  If no minversion is specified the a skip
+    is only triggered if the module can not be imported.
+    """
+    import warnings
+
+    __tracebackhide__ = True
+    compile(modname, "", "eval")  # to catch syntaxerrors
+    should_skip = False
+
+    with warnings.catch_warnings():
+        # make sure to ignore ImportWarnings that might happen because
+        # of existing directories with the same name we're trying to
+        # import but without a __init__.py file
+        warnings.simplefilter("ignore")
+        try:
+            __import__(modname)
+        except ImportError:
+            # Do not raise chained exception here(#1485)
+            should_skip = True
+    if should_skip:
+        raise Skipped("could not import %r" % (modname,), allow_module_level=True)
+    mod = sys.modules[modname]
+    if minversion is None:
+        return mod
+    verattr = getattr(mod, "__version__", None)
+    if minversion is not None:
+        try:
+            from pkg_resources import parse_version as pv
+        except ImportError:
+            raise Skipped(
+                "we have a required version for %r but can not import "
+                "pkg_resources to parse version strings." % (modname,),
+                allow_module_level=True,
+            )
+        if verattr is None or pv(verattr) < pv(minversion):
+            raise Skipped(
+                "module %r has __version__ %r, required is: %r"
+                % (modname, verattr, minversion),
+                allow_module_level=True,
+            )
+    return mod
Index: venv/Lib/site-packages/_pytest/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/__init__.py	(date 1543190976695)
+++ venv/Lib/site-packages/_pytest/__init__.py	(date 1543190976695)
@@ -0,0 +1,8 @@
+__all__ = ["__version__"]
+
+try:
+    from ._version import version as __version__
+except ImportError:
+    # broken installation, we don't even try
+    # unknown only works because we do poor mans version compare
+    __version__ = "unknown"
Index: venv/Lib/site-packages/_pytest/nose.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/nose.py	(date 1543190976706)
+++ venv/Lib/site-packages/_pytest/nose.py	(date 1543190976706)
@@ -0,0 +1,76 @@
+""" run test suites written for nose. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+
+from _pytest import python
+from _pytest import runner
+from _pytest import unittest
+from _pytest.config import hookimpl
+
+
+def get_skip_exceptions():
+    skip_classes = set()
+    for module_name in ("unittest", "unittest2", "nose"):
+        mod = sys.modules.get(module_name)
+        if hasattr(mod, "SkipTest"):
+            skip_classes.add(mod.SkipTest)
+    return tuple(skip_classes)
+
+
+def pytest_runtest_makereport(item, call):
+    if call.excinfo and call.excinfo.errisinstance(get_skip_exceptions()):
+        # let's substitute the excinfo with a pytest.skip one
+        call2 = call.__class__(lambda: runner.skip(str(call.excinfo.value)), call.when)
+        call.excinfo = call2.excinfo
+
+
+@hookimpl(trylast=True)
+def pytest_runtest_setup(item):
+    if is_potential_nosetest(item):
+        if isinstance(item.parent, python.Generator):
+            gen = item.parent
+            if not hasattr(gen, "_nosegensetup"):
+                call_optional(gen.obj, "setup")
+                if isinstance(gen.parent, python.Instance):
+                    call_optional(gen.parent.obj, "setup")
+                gen._nosegensetup = True
+        if not call_optional(item.obj, "setup"):
+            # call module level setup if there is no object level one
+            call_optional(item.parent.obj, "setup")
+        # XXX this implies we only call teardown when setup worked
+        item.session._setupstate.addfinalizer((lambda: teardown_nose(item)), item)
+
+
+def teardown_nose(item):
+    if is_potential_nosetest(item):
+        if not call_optional(item.obj, "teardown"):
+            call_optional(item.parent.obj, "teardown")
+        # if hasattr(item.parent, '_nosegensetup'):
+        #    #call_optional(item._nosegensetup, 'teardown')
+        #    del item.parent._nosegensetup
+
+
+def pytest_make_collect_report(collector):
+    if isinstance(collector, python.Generator):
+        call_optional(collector.obj, "setup")
+
+
+def is_potential_nosetest(item):
+    # extra check needed since we do not do nose style setup/teardown
+    # on direct unittest style classes
+    return isinstance(item, python.Function) and not isinstance(
+        item, unittest.TestCaseFunction
+    )
+
+
+def call_optional(obj, name):
+    method = getattr(obj, name, None)
+    isfixture = hasattr(method, "_pytestfixturefunction")
+    if method is not None and not isfixture and callable(method):
+        # If there's any problems allow the exception to raise rather than
+        # silently ignoring them
+        method()
+        return True
Index: venv/Lib/site-packages/_pytest/tmpdir.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/tmpdir.py	(date 1543190976717)
+++ venv/Lib/site-packages/_pytest/tmpdir.py	(date 1543190976717)
@@ -0,0 +1,187 @@
+""" support for providing temporary directories to test functions.  """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import re
+import tempfile
+import warnings
+
+import attr
+import py
+
+import pytest
+from .pathlib import ensure_reset_dir
+from .pathlib import LOCK_TIMEOUT
+from .pathlib import make_numbered_dir
+from .pathlib import make_numbered_dir_with_cleanup
+from .pathlib import Path
+from _pytest.monkeypatch import MonkeyPatch
+
+
+@attr.s
+class TempPathFactory(object):
+    """Factory for temporary directories under the common base temp directory.
+
+    The base directory can be configured using the ``--basetemp`` option."""
+
+    _given_basetemp = attr.ib()
+    _trace = attr.ib()
+    _basetemp = attr.ib(default=None)
+
+    @classmethod
+    def from_config(cls, config):
+        """
+        :param config: a pytest configuration
+        """
+        return cls(
+            given_basetemp=config.option.basetemp, trace=config.trace.get("tmpdir")
+        )
+
+    def mktemp(self, basename, numbered=True):
+        """makes a temporary directory managed by the factory"""
+        if not numbered:
+            p = self.getbasetemp().joinpath(basename)
+            p.mkdir()
+        else:
+            p = make_numbered_dir(root=self.getbasetemp(), prefix=basename)
+            self._trace("mktemp", p)
+        return p
+
+    def getbasetemp(self):
+        """ return base temporary directory. """
+        if self._basetemp is None:
+            if self._given_basetemp is not None:
+                basetemp = Path(self._given_basetemp)
+                ensure_reset_dir(basetemp)
+            else:
+                from_env = os.environ.get("PYTEST_DEBUG_TEMPROOT")
+                temproot = Path(from_env or tempfile.gettempdir())
+                user = get_user() or "unknown"
+                # use a sub-directory in the temproot to speed-up
+                # make_numbered_dir() call
+                rootdir = temproot.joinpath("pytest-of-{}".format(user))
+                rootdir.mkdir(exist_ok=True)
+                basetemp = make_numbered_dir_with_cleanup(
+                    prefix="pytest-", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT
+                )
+            assert basetemp is not None
+            self._basetemp = t = basetemp
+            self._trace("new basetemp", t)
+            return t
+        else:
+            return self._basetemp
+
+
+@attr.s
+class TempdirFactory(object):
+    """
+    backward comptibility wrapper that implements
+    :class:``py.path.local`` for :class:``TempPathFactory``
+    """
+
+    _tmppath_factory = attr.ib()
+
+    def ensuretemp(self, string, dir=1):
+        """ (deprecated) return temporary directory path with
+            the given string as the trailing part.  It is usually
+            better to use the 'tmpdir' function argument which
+            provides an empty unique-per-test-invocation directory
+            and is guaranteed to be empty.
+        """
+        # py.log._apiwarn(">1.1", "use tmpdir function argument")
+        from .deprecated import PYTEST_ENSURETEMP
+
+        warnings.warn(PYTEST_ENSURETEMP, stacklevel=2)
+        return self.getbasetemp().ensure(string, dir=dir)
+
+    def mktemp(self, basename, numbered=True):
+        """Create a subdirectory of the base temporary directory and return it.
+        If ``numbered``, ensure the directory is unique by adding a number
+        prefix greater than any existing one.
+        """
+        return py.path.local(self._tmppath_factory.mktemp(basename, numbered).resolve())
+
+    def getbasetemp(self):
+        """backward compat wrapper for ``_tmppath_factory.getbasetemp``"""
+        return py.path.local(self._tmppath_factory.getbasetemp().resolve())
+
+
+def get_user():
+    """Return the current user name, or None if getuser() does not work
+    in the current environment (see #1010).
+    """
+    import getpass
+
+    try:
+        return getpass.getuser()
+    except (ImportError, KeyError):
+        return None
+
+
+def pytest_configure(config):
+    """Create a TempdirFactory and attach it to the config object.
+
+    This is to comply with existing plugins which expect the handler to be
+    available at pytest_configure time, but ideally should be moved entirely
+    to the tmpdir_factory session fixture.
+    """
+    mp = MonkeyPatch()
+    tmppath_handler = TempPathFactory.from_config(config)
+    t = TempdirFactory(tmppath_handler)
+    config._cleanup.append(mp.undo)
+    mp.setattr(config, "_tmp_path_factory", tmppath_handler, raising=False)
+    mp.setattr(config, "_tmpdirhandler", t, raising=False)
+    mp.setattr(pytest, "ensuretemp", t.ensuretemp, raising=False)
+
+
+@pytest.fixture(scope="session")
+def tmpdir_factory(request):
+    """Return a :class:`_pytest.tmpdir.TempdirFactory` instance for the test session.
+    """
+    return request.config._tmpdirhandler
+
+
+@pytest.fixture(scope="session")
+def tmp_path_factory(request):
+    """Return a :class:`_pytest.tmpdir.TempPathFactory` instance for the test session.
+    """
+    return request.config._tmp_path_factory
+
+
+def _mk_tmp(request, factory):
+    name = request.node.name
+    name = re.sub(r"[\W]", "_", name)
+    MAXVAL = 30
+    name = name[:MAXVAL]
+    return factory.mktemp(name, numbered=True)
+
+
+@pytest.fixture
+def tmpdir(request, tmpdir_factory):
+    """Return a temporary directory path object
+    which is unique to each test function invocation,
+    created as a sub directory of the base temporary
+    directory.  The returned object is a `py.path.local`_
+    path object.
+
+    .. _`py.path.local`: https://py.readthedocs.io/en/latest/path.html
+    """
+    return _mk_tmp(request, tmpdir_factory)
+
+
+@pytest.fixture
+def tmp_path(request, tmp_path_factory):
+    """Return a temporary directory path object
+    which is unique to each test function invocation,
+    created as a sub directory of the base temporary
+    directory.  The returned object is a :class:`pathlib.Path`
+    object.
+
+    .. note::
+
+        in python < 3.6 this is a pathlib2.Path
+    """
+
+    return _mk_tmp(request, tmp_path_factory)
Index: venv/Lib/site-packages/_pytest/terminal.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/terminal.py	(date 1543190976733)
+++ venv/Lib/site-packages/_pytest/terminal.py	(date 1543190976733)
@@ -0,0 +1,891 @@
+""" terminal reporting of the full testing process.
+
+This is a good source for looking at the various reporting hooks.
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import argparse
+import itertools
+import platform
+import sys
+import time
+
+import attr
+import pluggy
+import py
+import six
+from more_itertools import collapse
+
+import pytest
+from _pytest import nodes
+from _pytest.main import EXIT_INTERRUPTED
+from _pytest.main import EXIT_NOTESTSCOLLECTED
+from _pytest.main import EXIT_OK
+from _pytest.main import EXIT_TESTSFAILED
+from _pytest.main import EXIT_USAGEERROR
+
+
+class MoreQuietAction(argparse.Action):
+    """
+    a modified copy of the argparse count action which counts down and updates
+    the legacy quiet attribute at the same time
+
+    used to unify verbosity handling
+    """
+
+    def __init__(self, option_strings, dest, default=None, required=False, help=None):
+        super(MoreQuietAction, self).__init__(
+            option_strings=option_strings,
+            dest=dest,
+            nargs=0,
+            default=default,
+            required=required,
+            help=help,
+        )
+
+    def __call__(self, parser, namespace, values, option_string=None):
+        new_count = getattr(namespace, self.dest, 0) - 1
+        setattr(namespace, self.dest, new_count)
+        # todo Deprecate config.quiet
+        namespace.quiet = getattr(namespace, "quiet", 0) + 1
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("terminal reporting", "reporting", after="general")
+    group._addoption(
+        "-v",
+        "--verbose",
+        action="count",
+        default=0,
+        dest="verbose",
+        help="increase verbosity.",
+    ),
+    group._addoption(
+        "-q",
+        "--quiet",
+        action=MoreQuietAction,
+        default=0,
+        dest="verbose",
+        help="decrease verbosity.",
+    ),
+    group._addoption(
+        "--verbosity", dest="verbose", type=int, default=0, help="set verbosity"
+    )
+    group._addoption(
+        "-r",
+        action="store",
+        dest="reportchars",
+        default="",
+        metavar="chars",
+        help="show extra test summary info as specified by chars (f)ailed, "
+        "(E)error, (s)skipped, (x)failed, (X)passed, "
+        "(p)passed, (P)passed with output, (a)all except pP. "
+        "Warnings are displayed at all times except when "
+        "--disable-warnings is set",
+    )
+    group._addoption(
+        "--disable-warnings",
+        "--disable-pytest-warnings",
+        default=False,
+        dest="disable_warnings",
+        action="store_true",
+        help="disable warnings summary",
+    )
+    group._addoption(
+        "-l",
+        "--showlocals",
+        action="store_true",
+        dest="showlocals",
+        default=False,
+        help="show locals in tracebacks (disabled by default).",
+    )
+    group._addoption(
+        "--tb",
+        metavar="style",
+        action="store",
+        dest="tbstyle",
+        default="auto",
+        choices=["auto", "long", "short", "no", "line", "native"],
+        help="traceback print mode (auto/long/short/line/native/no).",
+    )
+    group._addoption(
+        "--show-capture",
+        action="store",
+        dest="showcapture",
+        choices=["no", "stdout", "stderr", "log", "all"],
+        default="all",
+        help="Controls how captured stdout/stderr/log is shown on failed tests. "
+        "Default is 'all'.",
+    )
+    group._addoption(
+        "--fulltrace",
+        "--full-trace",
+        action="store_true",
+        default=False,
+        help="don't cut any tracebacks (default is to cut).",
+    )
+    group._addoption(
+        "--color",
+        metavar="color",
+        action="store",
+        dest="color",
+        default="auto",
+        choices=["yes", "no", "auto"],
+        help="color terminal output (yes/no/auto).",
+    )
+
+    parser.addini(
+        "console_output_style",
+        help="console output: classic or with additional progress information (classic|progress).",
+        default="progress",
+    )
+
+
+def pytest_configure(config):
+    reporter = TerminalReporter(config, sys.stdout)
+    config.pluginmanager.register(reporter, "terminalreporter")
+    if config.option.debug or config.option.traceconfig:
+
+        def mywriter(tags, args):
+            msg = " ".join(map(str, args))
+            reporter.write_line("[traceconfig] " + msg)
+
+        config.trace.root.setprocessor("pytest:config", mywriter)
+
+
+def getreportopt(config):
+    reportopts = ""
+    reportchars = config.option.reportchars
+    if not config.option.disable_warnings and "w" not in reportchars:
+        reportchars += "w"
+    elif config.option.disable_warnings and "w" in reportchars:
+        reportchars = reportchars.replace("w", "")
+    if reportchars:
+        for char in reportchars:
+            if char not in reportopts and char != "a":
+                reportopts += char
+            elif char == "a":
+                reportopts = "fEsxXw"
+    return reportopts
+
+
+def pytest_report_teststatus(report):
+    if report.passed:
+        letter = "."
+    elif report.skipped:
+        letter = "s"
+    elif report.failed:
+        letter = "F"
+        if report.when != "call":
+            letter = "f"
+    return report.outcome, letter, report.outcome.upper()
+
+
+@attr.s
+class WarningReport(object):
+    """
+    Simple structure to hold warnings information captured by ``pytest_logwarning`` and ``pytest_warning_captured``.
+
+    :ivar str message: user friendly message about the warning
+    :ivar str|None nodeid: node id that generated the warning (see ``get_location``).
+    :ivar tuple|py.path.local fslocation:
+        file system location of the source of the warning (see ``get_location``).
+
+    :ivar bool legacy: if this warning report was generated from the deprecated ``pytest_logwarning`` hook.
+    """
+
+    message = attr.ib()
+    nodeid = attr.ib(default=None)
+    fslocation = attr.ib(default=None)
+    legacy = attr.ib(default=False)
+
+    def get_location(self, config):
+        """
+        Returns the more user-friendly information about the location
+        of a warning, or None.
+        """
+        if self.nodeid:
+            return self.nodeid
+        if self.fslocation:
+            if isinstance(self.fslocation, tuple) and len(self.fslocation) >= 2:
+                filename, linenum = self.fslocation[:2]
+                relpath = py.path.local(filename).relto(config.invocation_dir)
+                if not relpath:
+                    relpath = str(filename)
+                return "%s:%s" % (relpath, linenum)
+            else:
+                return str(self.fslocation)
+        return None
+
+
+class TerminalReporter(object):
+    def __init__(self, config, file=None):
+        import _pytest.config
+
+        self.config = config
+        self.verbosity = self.config.option.verbose
+        self.showheader = self.verbosity >= 0
+        self.showfspath = self.verbosity >= 0
+        self.showlongtestinfo = self.verbosity > 0
+        self._numcollected = 0
+        self._session = None
+
+        self.stats = {}
+        self.startdir = py.path.local()
+        if file is None:
+            file = sys.stdout
+        self._tw = _pytest.config.create_terminal_writer(config, file)
+        # self.writer will be deprecated in pytest-3.4
+        self.writer = self._tw
+        self._screen_width = self._tw.fullwidth
+        self.currentfspath = None
+        self.reportchars = getreportopt(config)
+        self.hasmarkup = self._tw.hasmarkup
+        self.isatty = file.isatty()
+        self._progress_nodeids_reported = set()
+        self._show_progress_info = self._determine_show_progress_info()
+        self._collect_report_last_write = None
+
+    def _determine_show_progress_info(self):
+        """Return True if we should display progress information based on the current config"""
+        # do not show progress if we are not capturing output (#3038)
+        if self.config.getoption("capture") == "no":
+            return False
+        # do not show progress if we are showing fixture setup/teardown
+        if self.config.getoption("setupshow"):
+            return False
+        return self.config.getini("console_output_style") in ("progress", "count")
+
+    def hasopt(self, char):
+        char = {"xfailed": "x", "skipped": "s"}.get(char, char)
+        return char in self.reportchars
+
+    def write_fspath_result(self, nodeid, res, **markup):
+        fspath = self.config.rootdir.join(nodeid.split("::")[0])
+        if fspath != self.currentfspath:
+            if self.currentfspath is not None and self._show_progress_info:
+                self._write_progress_information_filling_space()
+            self.currentfspath = fspath
+            fspath = self.startdir.bestrelpath(fspath)
+            self._tw.line()
+            self._tw.write(fspath + " ")
+        self._tw.write(res, **markup)
+
+    def write_ensure_prefix(self, prefix, extra="", **kwargs):
+        if self.currentfspath != prefix:
+            self._tw.line()
+            self.currentfspath = prefix
+            self._tw.write(prefix)
+        if extra:
+            self._tw.write(extra, **kwargs)
+            self.currentfspath = -2
+
+    def ensure_newline(self):
+        if self.currentfspath:
+            self._tw.line()
+            self.currentfspath = None
+
+    def write(self, content, **markup):
+        self._tw.write(content, **markup)
+
+    def write_line(self, line, **markup):
+        if not isinstance(line, six.text_type):
+            line = six.text_type(line, errors="replace")
+        self.ensure_newline()
+        self._tw.line(line, **markup)
+
+    def rewrite(self, line, **markup):
+        """
+        Rewinds the terminal cursor to the beginning and writes the given line.
+
+        :kwarg erase: if True, will also add spaces until the full terminal width to ensure
+            previous lines are properly erased.
+
+        The rest of the keyword arguments are markup instructions.
+        """
+        erase = markup.pop("erase", False)
+        if erase:
+            fill_count = self._tw.fullwidth - len(line) - 1
+            fill = " " * fill_count
+        else:
+            fill = ""
+        line = str(line)
+        self._tw.write("\r" + line + fill, **markup)
+
+    def write_sep(self, sep, title=None, **markup):
+        self.ensure_newline()
+        self._tw.sep(sep, title, **markup)
+
+    def section(self, title, sep="=", **kw):
+        self._tw.sep(sep, title, **kw)
+
+    def line(self, msg, **kw):
+        self._tw.line(msg, **kw)
+
+    def pytest_internalerror(self, excrepr):
+        for line in six.text_type(excrepr).split("\n"):
+            self.write_line("INTERNALERROR> " + line)
+        return 1
+
+    def pytest_logwarning(self, fslocation, message, nodeid):
+        warnings = self.stats.setdefault("warnings", [])
+        warning = WarningReport(
+            fslocation=fslocation, message=message, nodeid=nodeid, legacy=True
+        )
+        warnings.append(warning)
+
+    def pytest_warning_captured(self, warning_message, item):
+        # from _pytest.nodes import get_fslocation_from_item
+        from _pytest.warnings import warning_record_to_str
+
+        warnings = self.stats.setdefault("warnings", [])
+        fslocation = warning_message.filename, warning_message.lineno
+        message = warning_record_to_str(warning_message)
+
+        nodeid = item.nodeid if item is not None else ""
+        warning_report = WarningReport(
+            fslocation=fslocation, message=message, nodeid=nodeid
+        )
+        warnings.append(warning_report)
+
+    def pytest_plugin_registered(self, plugin):
+        if self.config.option.traceconfig:
+            msg = "PLUGIN registered: %s" % (plugin,)
+            # XXX this event may happen during setup/teardown time
+            #     which unfortunately captures our output here
+            #     which garbles our output if we use self.write_line
+            self.write_line(msg)
+
+    def pytest_deselected(self, items):
+        self.stats.setdefault("deselected", []).extend(items)
+
+    def pytest_runtest_logstart(self, nodeid, location):
+        # ensure that the path is printed before the
+        # 1st test of a module starts running
+        if self.showlongtestinfo:
+            line = self._locationline(nodeid, *location)
+            self.write_ensure_prefix(line, "")
+        elif self.showfspath:
+            fsid = nodeid.split("::")[0]
+            self.write_fspath_result(fsid, "")
+
+    def pytest_runtest_logreport(self, report):
+        rep = report
+        res = self.config.hook.pytest_report_teststatus(report=rep)
+        category, letter, word = res
+        if isinstance(word, tuple):
+            word, markup = word
+        else:
+            markup = None
+        self.stats.setdefault(category, []).append(rep)
+        self._tests_ran = True
+        if not letter and not word:
+            # probably passed setup/teardown
+            return
+        running_xdist = hasattr(rep, "node")
+        if markup is None:
+            if rep.passed:
+                markup = {"green": True}
+            elif rep.failed:
+                markup = {"red": True}
+            elif rep.skipped:
+                markup = {"yellow": True}
+            else:
+                markup = {}
+        if self.verbosity <= 0:
+            if not running_xdist and self.showfspath:
+                self.write_fspath_result(rep.nodeid, letter, **markup)
+            else:
+                self._tw.write(letter, **markup)
+        else:
+            self._progress_nodeids_reported.add(rep.nodeid)
+            line = self._locationline(rep.nodeid, *rep.location)
+            if not running_xdist:
+                self.write_ensure_prefix(line, word, **markup)
+                if self._show_progress_info:
+                    self._write_progress_information_filling_space()
+            else:
+                self.ensure_newline()
+                self._tw.write("[%s]" % rep.node.gateway.id)
+                if self._show_progress_info:
+                    self._tw.write(
+                        self._get_progress_information_message() + " ", cyan=True
+                    )
+                else:
+                    self._tw.write(" ")
+                self._tw.write(word, **markup)
+                self._tw.write(" " + line)
+                self.currentfspath = -2
+
+    def pytest_runtest_logfinish(self, nodeid):
+        if self.config.getini("console_output_style") == "count":
+            num_tests = self._session.testscollected
+            progress_length = len(" [{}/{}]".format(str(num_tests), str(num_tests)))
+        else:
+            progress_length = len(" [100%]")
+
+        if self.verbosity <= 0 and self._show_progress_info:
+            self._progress_nodeids_reported.add(nodeid)
+            last_item = (
+                len(self._progress_nodeids_reported) == self._session.testscollected
+            )
+            if last_item:
+                self._write_progress_information_filling_space()
+            else:
+                w = self._width_of_current_line
+                past_edge = w + progress_length + 1 >= self._screen_width
+                if past_edge:
+                    msg = self._get_progress_information_message()
+                    self._tw.write(msg + "\n", cyan=True)
+
+    def _get_progress_information_message(self):
+        if self.config.getoption("capture") == "no":
+            return ""
+        collected = self._session.testscollected
+        if self.config.getini("console_output_style") == "count":
+            if collected:
+                progress = self._progress_nodeids_reported
+                counter_format = "{{:{}d}}".format(len(str(collected)))
+                format_string = " [{}/{{}}]".format(counter_format)
+                return format_string.format(len(progress), collected)
+            return " [ {} / {} ]".format(collected, collected)
+        else:
+            if collected:
+                progress = len(self._progress_nodeids_reported) * 100 // collected
+                return " [{:3d}%]".format(progress)
+            return " [100%]"
+
+    def _write_progress_information_filling_space(self):
+        msg = self._get_progress_information_message()
+        w = self._width_of_current_line
+        fill = self._tw.fullwidth - w - 1
+        self.write(msg.rjust(fill), cyan=True)
+
+    @property
+    def _width_of_current_line(self):
+        """Return the width of current line, using the superior implementation of py-1.6 when available"""
+        try:
+            return self._tw.width_of_current_line
+        except AttributeError:
+            # py < 1.6.0
+            return self._tw.chars_on_current_line
+
+    def pytest_collection(self):
+        if self.isatty:
+            if self.config.option.verbose >= 0:
+                self.write("collecting ... ", bold=True)
+                self._collect_report_last_write = time.time()
+        elif self.config.option.verbose >= 1:
+            self.write("collecting ... ", bold=True)
+
+    def pytest_collectreport(self, report):
+        if report.failed:
+            self.stats.setdefault("error", []).append(report)
+        elif report.skipped:
+            self.stats.setdefault("skipped", []).append(report)
+        items = [x for x in report.result if isinstance(x, pytest.Item)]
+        self._numcollected += len(items)
+        if self.isatty:
+            self.report_collect()
+
+    def report_collect(self, final=False):
+        if self.config.option.verbose < 0:
+            return
+
+        if not final:
+            # Only write "collecting" report every 0.5s.
+            t = time.time()
+            if (
+                self._collect_report_last_write is not None
+                and self._collect_report_last_write > t - 0.5
+            ):
+                return
+            self._collect_report_last_write = t
+
+        errors = len(self.stats.get("error", []))
+        skipped = len(self.stats.get("skipped", []))
+        deselected = len(self.stats.get("deselected", []))
+        if final:
+            line = "collected "
+        else:
+            line = "collecting "
+        line += (
+            str(self._numcollected) + " item" + ("" if self._numcollected == 1 else "s")
+        )
+        if errors:
+            line += " / %d errors" % errors
+        if deselected:
+            line += " / %d deselected" % deselected
+        if skipped:
+            line += " / %d skipped" % skipped
+        if self.isatty:
+            self.rewrite(line, bold=True, erase=True)
+            if final:
+                self.write("\n")
+        else:
+            self.write_line(line)
+
+    @pytest.hookimpl(trylast=True)
+    def pytest_collection_modifyitems(self):
+        self.report_collect(True)
+
+    @pytest.hookimpl(trylast=True)
+    def pytest_sessionstart(self, session):
+        self._session = session
+        self._sessionstarttime = time.time()
+        if not self.showheader:
+            return
+        self.write_sep("=", "test session starts", bold=True)
+        verinfo = platform.python_version()
+        msg = "platform %s -- Python %s" % (sys.platform, verinfo)
+        if hasattr(sys, "pypy_version_info"):
+            verinfo = ".".join(map(str, sys.pypy_version_info[:3]))
+            msg += "[pypy-%s-%s]" % (verinfo, sys.pypy_version_info[3])
+        msg += ", pytest-%s, py-%s, pluggy-%s" % (
+            pytest.__version__,
+            py.__version__,
+            pluggy.__version__,
+        )
+        if (
+            self.verbosity > 0
+            or self.config.option.debug
+            or getattr(self.config.option, "pastebin", None)
+        ):
+            msg += " -- " + str(sys.executable)
+        self.write_line(msg)
+        lines = self.config.hook.pytest_report_header(
+            config=self.config, startdir=self.startdir
+        )
+        self._write_report_lines_from_hooks(lines)
+
+    def _write_report_lines_from_hooks(self, lines):
+        lines.reverse()
+        for line in collapse(lines):
+            self.write_line(line)
+
+    def pytest_report_header(self, config):
+        inifile = ""
+        if config.inifile:
+            inifile = " " + config.rootdir.bestrelpath(config.inifile)
+        lines = ["rootdir: %s, inifile:%s" % (config.rootdir, inifile)]
+
+        plugininfo = config.pluginmanager.list_plugin_distinfo()
+        if plugininfo:
+
+            lines.append("plugins: %s" % ", ".join(_plugin_nameversions(plugininfo)))
+        return lines
+
+    def pytest_collection_finish(self, session):
+        if self.config.option.collectonly:
+            self._printcollecteditems(session.items)
+            if self.stats.get("failed"):
+                self._tw.sep("!", "collection failures")
+                for rep in self.stats.get("failed"):
+                    rep.toterminal(self._tw)
+                return 1
+            return 0
+        lines = self.config.hook.pytest_report_collectionfinish(
+            config=self.config, startdir=self.startdir, items=session.items
+        )
+        self._write_report_lines_from_hooks(lines)
+
+    def _printcollecteditems(self, items):
+        # to print out items and their parent collectors
+        # we take care to leave out Instances aka ()
+        # because later versions are going to get rid of them anyway
+        if self.config.option.verbose < 0:
+            if self.config.option.verbose < -1:
+                counts = {}
+                for item in items:
+                    name = item.nodeid.split("::", 1)[0]
+                    counts[name] = counts.get(name, 0) + 1
+                for name, count in sorted(counts.items()):
+                    self._tw.line("%s: %d" % (name, count))
+            else:
+                for item in items:
+                    self._tw.line(item.nodeid)
+            return
+        stack = []
+        indent = ""
+        for item in items:
+            needed_collectors = item.listchain()[1:]  # strip root node
+            while stack:
+                if stack == needed_collectors[: len(stack)]:
+                    break
+                stack.pop()
+            for col in needed_collectors[len(stack) :]:
+                stack.append(col)
+                if col.name == "()":  # Skip Instances.
+                    continue
+                indent = (len(stack) - 1) * "  "
+                self._tw.line("%s%s" % (indent, col))
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_sessionfinish(self, exitstatus):
+        outcome = yield
+        outcome.get_result()
+        self._tw.line("")
+        summary_exit_codes = (
+            EXIT_OK,
+            EXIT_TESTSFAILED,
+            EXIT_INTERRUPTED,
+            EXIT_USAGEERROR,
+            EXIT_NOTESTSCOLLECTED,
+        )
+        if exitstatus in summary_exit_codes:
+            self.config.hook.pytest_terminal_summary(
+                terminalreporter=self, exitstatus=exitstatus
+            )
+        if exitstatus == EXIT_INTERRUPTED:
+            self._report_keyboardinterrupt()
+            del self._keyboardinterrupt_memo
+        self.summary_stats()
+
+    @pytest.hookimpl(hookwrapper=True)
+    def pytest_terminal_summary(self):
+        self.summary_errors()
+        self.summary_failures()
+        yield
+        self.summary_warnings()
+        self.summary_passes()
+
+    def pytest_keyboard_interrupt(self, excinfo):
+        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)
+
+    def pytest_unconfigure(self):
+        if hasattr(self, "_keyboardinterrupt_memo"):
+            self._report_keyboardinterrupt()
+
+    def _report_keyboardinterrupt(self):
+        excrepr = self._keyboardinterrupt_memo
+        msg = excrepr.reprcrash.message
+        self.write_sep("!", msg)
+        if "KeyboardInterrupt" in msg:
+            if self.config.option.fulltrace:
+                excrepr.toterminal(self._tw)
+            else:
+                excrepr.reprcrash.toterminal(self._tw)
+                self._tw.line(
+                    "(to show a full traceback on KeyboardInterrupt use --fulltrace)",
+                    yellow=True,
+                )
+
+    def _locationline(self, nodeid, fspath, lineno, domain):
+        def mkrel(nodeid):
+            line = self.config.cwd_relative_nodeid(nodeid)
+            if domain and line.endswith(domain):
+                line = line[: -len(domain)]
+                values = domain.split("[")
+                values[0] = values[0].replace(".", "::")  # don't replace '.' in params
+                line += "[".join(values)
+            return line
+
+        # collect_fspath comes from testid which has a "/"-normalized path
+
+        if fspath:
+            res = mkrel(nodeid)
+            if self.verbosity >= 2 and nodeid.split("::")[0] != fspath.replace(
+                "\\", nodes.SEP
+            ):
+                res += " <- " + self.startdir.bestrelpath(fspath)
+        else:
+            res = "[location]"
+        return res + " "
+
+    def _getfailureheadline(self, rep):
+        if hasattr(rep, "location"):
+            fspath, lineno, domain = rep.location
+            return domain
+        else:
+            return "test session"  # XXX?
+
+    def _getcrashline(self, rep):
+        try:
+            return str(rep.longrepr.reprcrash)
+        except AttributeError:
+            try:
+                return str(rep.longrepr)[:50]
+            except AttributeError:
+                return ""
+
+    #
+    # summaries for sessionfinish
+    #
+    def getreports(self, name):
+        values = []
+        for x in self.stats.get(name, []):
+            if not hasattr(x, "_pdbshown"):
+                values.append(x)
+        return values
+
+    def summary_warnings(self):
+        if self.hasopt("w"):
+            all_warnings = self.stats.get("warnings")
+            if not all_warnings:
+                return
+
+            grouped = itertools.groupby(
+                all_warnings, key=lambda wr: wr.get_location(self.config)
+            )
+
+            self.write_sep("=", "warnings summary", yellow=True, bold=False)
+            for location, warning_records in grouped:
+                # legacy warnings show their location explicitly, while standard warnings look better without
+                # it because the location is already formatted into the message
+                warning_records = list(warning_records)
+                if location:
+                    self._tw.line(str(location))
+                for w in warning_records:
+                    if location:
+                        lines = w.message.splitlines()
+                        indented = "\n".join("  " + x for x in lines)
+                        message = indented.rstrip()
+                    else:
+                        message = w.message.rstrip()
+                    self._tw.line(message)
+                self._tw.line()
+            self._tw.line("-- Docs: https://docs.pytest.org/en/latest/warnings.html")
+
+    def summary_passes(self):
+        if self.config.option.tbstyle != "no":
+            if self.hasopt("P"):
+                reports = self.getreports("passed")
+                if not reports:
+                    return
+                self.write_sep("=", "PASSES")
+                for rep in reports:
+                    if rep.sections:
+                        msg = self._getfailureheadline(rep)
+                        self.write_sep("_", msg)
+                        self._outrep_summary(rep)
+
+    def print_teardown_sections(self, rep):
+        showcapture = self.config.option.showcapture
+        if showcapture == "no":
+            return
+        for secname, content in rep.sections:
+            if showcapture != "all" and showcapture not in secname:
+                continue
+            if "teardown" in secname:
+                self._tw.sep("-", secname)
+                if content[-1:] == "\n":
+                    content = content[:-1]
+                self._tw.line(content)
+
+    def summary_failures(self):
+        if self.config.option.tbstyle != "no":
+            reports = self.getreports("failed")
+            if not reports:
+                return
+            self.write_sep("=", "FAILURES")
+            for rep in reports:
+                if self.config.option.tbstyle == "line":
+                    line = self._getcrashline(rep)
+                    self.write_line(line)
+                else:
+                    msg = self._getfailureheadline(rep)
+                    markup = {"red": True, "bold": True}
+                    self.write_sep("_", msg, **markup)
+                    self._outrep_summary(rep)
+                    for report in self.getreports(""):
+                        if report.nodeid == rep.nodeid and report.when == "teardown":
+                            self.print_teardown_sections(report)
+
+    def summary_errors(self):
+        if self.config.option.tbstyle != "no":
+            reports = self.getreports("error")
+            if not reports:
+                return
+            self.write_sep("=", "ERRORS")
+            for rep in self.stats["error"]:
+                msg = self._getfailureheadline(rep)
+                if not hasattr(rep, "when"):
+                    # collect
+                    msg = "ERROR collecting " + msg
+                elif rep.when == "setup":
+                    msg = "ERROR at setup of " + msg
+                elif rep.when == "teardown":
+                    msg = "ERROR at teardown of " + msg
+                self.write_sep("_", msg)
+                self._outrep_summary(rep)
+
+    def _outrep_summary(self, rep):
+        rep.toterminal(self._tw)
+        showcapture = self.config.option.showcapture
+        if showcapture == "no":
+            return
+        for secname, content in rep.sections:
+            if showcapture != "all" and showcapture not in secname:
+                continue
+            self._tw.sep("-", secname)
+            if content[-1:] == "\n":
+                content = content[:-1]
+            self._tw.line(content)
+
+    def summary_stats(self):
+        session_duration = time.time() - self._sessionstarttime
+        (line, color) = build_summary_stats_line(self.stats)
+        msg = "%s in %.2f seconds" % (line, session_duration)
+        markup = {color: True, "bold": True}
+
+        if self.verbosity >= 0:
+            self.write_sep("=", msg, **markup)
+        if self.verbosity == -1:
+            self.write_line(msg, **markup)
+
+
+def repr_pythonversion(v=None):
+    if v is None:
+        v = sys.version_info
+    try:
+        return "%s.%s.%s-%s-%s" % v
+    except (TypeError, ValueError):
+        return str(v)
+
+
+def build_summary_stats_line(stats):
+    keys = ("failed passed skipped deselected xfailed xpassed warnings error").split()
+    unknown_key_seen = False
+    for key in stats.keys():
+        if key not in keys:
+            if key:  # setup/teardown reports have an empty key, ignore them
+                keys.append(key)
+                unknown_key_seen = True
+    parts = []
+    for key in keys:
+        val = stats.get(key, None)
+        if val:
+            parts.append("%d %s" % (len(val), key))
+
+    if parts:
+        line = ", ".join(parts)
+    else:
+        line = "no tests ran"
+
+    if "failed" in stats or "error" in stats:
+        color = "red"
+    elif "warnings" in stats or unknown_key_seen:
+        color = "yellow"
+    elif "passed" in stats:
+        color = "green"
+    else:
+        color = "yellow"
+
+    return (line, color)
+
+
+def _plugin_nameversions(plugininfo):
+    values = []
+    for plugin, dist in plugininfo:
+        # gets us name and version!
+        name = "{dist.project_name}-{dist.version}".format(dist=dist)
+        # questionable convenience, but it keeps things short
+        if name.startswith("pytest-"):
+            name = name[7:]
+        # we decided to print python package names
+        # they can have more than one plugin
+        if name not in values:
+            values.append(name)
+    return values
Index: venv/Lib/site-packages/_pytest/nodes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/nodes.py	(date 1543190976744)
+++ venv/Lib/site-packages/_pytest/nodes.py	(date 1543190976744)
@@ -0,0 +1,531 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import warnings
+
+import attr
+import py
+import six
+
+import _pytest._code
+from _pytest.compat import getfslineno
+from _pytest.mark.structures import MarkInfo
+from _pytest.mark.structures import NodeKeywords
+from _pytest.outcomes import fail
+
+SEP = "/"
+
+tracebackcutdir = py.path.local(_pytest.__file__).dirpath()
+
+
+def _splitnode(nodeid):
+    """Split a nodeid into constituent 'parts'.
+
+    Node IDs are strings, and can be things like:
+        ''
+        'testing/code'
+        'testing/code/test_excinfo.py'
+        'testing/code/test_excinfo.py::TestFormattedExcinfo'
+
+    Return values are lists e.g.
+        []
+        ['testing', 'code']
+        ['testing', 'code', 'test_excinfo.py']
+        ['testing', 'code', 'test_excinfo.py', 'TestFormattedExcinfo', '()']
+    """
+    if nodeid == "":
+        # If there is no root node at all, return an empty list so the caller's logic can remain sane
+        return []
+    parts = nodeid.split(SEP)
+    # Replace single last element 'test_foo.py::Bar' with multiple elements 'test_foo.py', 'Bar'
+    parts[-1:] = parts[-1].split("::")
+    return parts
+
+
+def ischildnode(baseid, nodeid):
+    """Return True if the nodeid is a child node of the baseid.
+
+    E.g. 'foo/bar::Baz' is a child of 'foo', 'foo/bar' and 'foo/bar::Baz', but not of 'foo/blorp'
+    """
+    base_parts = _splitnode(baseid)
+    node_parts = _splitnode(nodeid)
+    if len(node_parts) < len(base_parts):
+        return False
+    return node_parts[: len(base_parts)] == base_parts
+
+
+@attr.s
+class _CompatProperty(object):
+    name = attr.ib()
+
+    def __get__(self, obj, owner):
+        if obj is None:
+            return self
+
+        from _pytest.deprecated import COMPAT_PROPERTY
+
+        warnings.warn(
+            COMPAT_PROPERTY.format(name=self.name, owner=owner.__name__), stacklevel=2
+        )
+        return getattr(__import__("pytest"), self.name)
+
+
+class Node(object):
+    """ base class for Collector and Item the test collection tree.
+    Collector subclasses have children, Items are terminal nodes."""
+
+    def __init__(
+        self, name, parent=None, config=None, session=None, fspath=None, nodeid=None
+    ):
+        #: a unique name within the scope of the parent node
+        self.name = name
+
+        #: the parent collector node.
+        self.parent = parent
+
+        #: the pytest config object
+        self.config = config or parent.config
+
+        #: the session this node is part of
+        self.session = session or parent.session
+
+        #: filesystem path where this node was collected from (can be None)
+        self.fspath = fspath or getattr(parent, "fspath", None)
+
+        #: keywords/markers collected from all scopes
+        self.keywords = NodeKeywords(self)
+
+        #: the marker objects belonging to this node
+        self.own_markers = []
+
+        #: allow adding of extra keywords to use for matching
+        self.extra_keyword_matches = set()
+
+        # used for storing artificial fixturedefs for direct parametrization
+        self._name2pseudofixturedef = {}
+
+        if nodeid is not None:
+            assert "::()" not in nodeid
+            self._nodeid = nodeid
+        else:
+            self._nodeid = self.parent.nodeid
+            if self.name != "()":
+                self._nodeid += "::" + self.name
+
+    @property
+    def ihook(self):
+        """ fspath sensitive hook proxy used to call pytest hooks"""
+        return self.session.gethookproxy(self.fspath)
+
+    Module = _CompatProperty("Module")
+    Class = _CompatProperty("Class")
+    Instance = _CompatProperty("Instance")
+    Function = _CompatProperty("Function")
+    File = _CompatProperty("File")
+    Item = _CompatProperty("Item")
+
+    def _getcustomclass(self, name):
+        maybe_compatprop = getattr(type(self), name)
+        if isinstance(maybe_compatprop, _CompatProperty):
+            return getattr(__import__("pytest"), name)
+        else:
+            from _pytest.deprecated import CUSTOM_CLASS
+
+            cls = getattr(self, name)
+            self.warn(CUSTOM_CLASS.format(name=name, type_name=type(self).__name__))
+        return cls
+
+    def __repr__(self):
+        return "<%s %r>" % (self.__class__.__name__, getattr(self, "name", None))
+
+    def warn(self, _code_or_warning=None, message=None, code=None):
+        """Issue a warning for this item.
+
+        Warnings will be displayed after the test session, unless explicitly suppressed.
+
+        This can be called in two forms:
+
+        **Warning instance**
+
+        This was introduced in pytest 3.8 and uses the standard warning mechanism to issue warnings.
+
+        .. code-block:: python
+
+            node.warn(PytestWarning("some message"))
+
+        The warning instance must be a subclass of :class:`pytest.PytestWarning`.
+
+        **code/message (deprecated)**
+
+        This form was used in pytest prior to 3.8 and is considered deprecated. Using this form will emit another
+        warning about the deprecation:
+
+        .. code-block:: python
+
+            node.warn("CI", "some message")
+
+        :param Union[Warning,str] _code_or_warning:
+            warning instance or warning code (legacy). This parameter receives an underscore for backward
+            compatibility with the legacy code/message form, and will be replaced for something
+            more usual when the legacy form is removed.
+
+        :param Union[str,None] message: message to display when called in the legacy form.
+        :param str code: code for the warning, in legacy form when using keyword arguments.
+        :return:
+        """
+        if message is None:
+            if _code_or_warning is None:
+                raise ValueError("code_or_warning must be given")
+            self._std_warn(_code_or_warning)
+        else:
+            if _code_or_warning and code:
+                raise ValueError(
+                    "code_or_warning and code cannot both be passed to this function"
+                )
+            code = _code_or_warning or code
+            self._legacy_warn(code, message)
+
+    def _legacy_warn(self, code, message):
+        """
+        .. deprecated:: 3.8
+
+            Use :meth:`Node.std_warn <_pytest.nodes.Node.std_warn>` instead.
+
+        Generate a warning with the given code and message for this item.
+        """
+        from _pytest.deprecated import NODE_WARN
+
+        self._std_warn(NODE_WARN)
+
+        assert isinstance(code, str)
+        fslocation = get_fslocation_from_item(self)
+        self.ihook.pytest_logwarning.call_historic(
+            kwargs=dict(
+                code=code, message=message, nodeid=self.nodeid, fslocation=fslocation
+            )
+        )
+
+    def _std_warn(self, warning):
+        """Issue a warning for this item.
+
+        Warnings will be displayed after the test session, unless explicitly suppressed
+
+        :param Warning warning: the warning instance to issue. Must be a subclass of PytestWarning.
+
+        :raise ValueError: if ``warning`` instance is not a subclass of PytestWarning.
+        """
+        from _pytest.warning_types import PytestWarning
+
+        if not isinstance(warning, PytestWarning):
+            raise ValueError(
+                "warning must be an instance of PytestWarning or subclass, got {!r}".format(
+                    warning
+                )
+            )
+        path, lineno = get_fslocation_from_item(self)
+        warnings.warn_explicit(
+            warning,
+            category=None,
+            filename=str(path),
+            lineno=lineno + 1 if lineno is not None else None,
+        )
+
+    # methods for ordering nodes
+    @property
+    def nodeid(self):
+        """ a ::-separated string denoting its collection tree address. """
+        return self._nodeid
+
+    def __hash__(self):
+        return hash(self.nodeid)
+
+    def setup(self):
+        pass
+
+    def teardown(self):
+        pass
+
+    def listchain(self):
+        """ return list of all parent collectors up to self,
+            starting from root of collection tree. """
+        chain = []
+        item = self
+        while item is not None:
+            chain.append(item)
+            item = item.parent
+        chain.reverse()
+        return chain
+
+    def add_marker(self, marker, append=True):
+        """dynamically add a marker object to the node.
+
+        :type marker: ``str`` or ``pytest.mark.*``  object
+        :param marker:
+            ``append=True`` whether to append the marker,
+            if ``False`` insert at position ``0``.
+        """
+        from _pytest.mark import MarkDecorator, MARK_GEN
+
+        if isinstance(marker, six.string_types):
+            marker = getattr(MARK_GEN, marker)
+        elif not isinstance(marker, MarkDecorator):
+            raise ValueError("is not a string or pytest.mark.* Marker")
+        self.keywords[marker.name] = marker
+        if append:
+            self.own_markers.append(marker.mark)
+        else:
+            self.own_markers.insert(0, marker.mark)
+
+    def iter_markers(self, name=None):
+        """
+        :param name: if given, filter the results by the name attribute
+
+        iterate over all markers of the node
+        """
+        return (x[1] for x in self.iter_markers_with_node(name=name))
+
+    def iter_markers_with_node(self, name=None):
+        """
+        :param name: if given, filter the results by the name attribute
+
+        iterate over all markers of the node
+        returns sequence of tuples (node, mark)
+        """
+        for node in reversed(self.listchain()):
+            for mark in node.own_markers:
+                if name is None or getattr(mark, "name", None) == name:
+                    yield node, mark
+
+    def get_closest_marker(self, name, default=None):
+        """return the first marker matching the name, from closest (for example function) to farther level (for example
+        module level).
+
+        :param default: fallback return value of no marker was found
+        :param name: name to filter by
+        """
+        return next(self.iter_markers(name=name), default)
+
+    def get_marker(self, name):
+        """ get a marker object from this node or None if
+        the node doesn't have a marker with that name.
+
+        .. deprecated:: 3.6
+            This function has been deprecated in favor of
+            :meth:`Node.get_closest_marker <_pytest.nodes.Node.get_closest_marker>` and
+            :meth:`Node.iter_markers <_pytest.nodes.Node.iter_markers>`, see :ref:`update marker code`
+            for more details.
+        """
+        markers = list(self.iter_markers(name=name))
+        if markers:
+            return MarkInfo(markers)
+
+    def listextrakeywords(self):
+        """ Return a set of all extra keywords in self and any parents."""
+        extra_keywords = set()
+        for item in self.listchain():
+            extra_keywords.update(item.extra_keyword_matches)
+        return extra_keywords
+
+    def listnames(self):
+        return [x.name for x in self.listchain()]
+
+    def addfinalizer(self, fin):
+        """ register a function to be called when this node is finalized.
+
+        This method can only be called when this node is active
+        in a setup chain, for example during self.setup().
+        """
+        self.session._setupstate.addfinalizer(fin, self)
+
+    def getparent(self, cls):
+        """ get the next parent node (including ourself)
+        which is an instance of the given class"""
+        current = self
+        while current and not isinstance(current, cls):
+            current = current.parent
+        return current
+
+    def _prunetraceback(self, excinfo):
+        pass
+
+    def _repr_failure_py(self, excinfo, style=None):
+        if excinfo.errisinstance(fail.Exception):
+            if not excinfo.value.pytrace:
+                return six.text_type(excinfo.value)
+        fm = self.session._fixturemanager
+        if excinfo.errisinstance(fm.FixtureLookupError):
+            return excinfo.value.formatrepr()
+        tbfilter = True
+        if self.config.option.fulltrace:
+            style = "long"
+        else:
+            tb = _pytest._code.Traceback([excinfo.traceback[-1]])
+            self._prunetraceback(excinfo)
+            if len(excinfo.traceback) == 0:
+                excinfo.traceback = tb
+            tbfilter = False  # prunetraceback already does it
+            if style == "auto":
+                style = "long"
+        # XXX should excinfo.getrepr record all data and toterminal() process it?
+        if style is None:
+            if self.config.option.tbstyle == "short":
+                style = "short"
+            else:
+                style = "long"
+
+        if self.config.option.verbose > 1:
+            truncate_locals = False
+        else:
+            truncate_locals = True
+
+        try:
+            os.getcwd()
+            abspath = False
+        except OSError:
+            abspath = True
+
+        return excinfo.getrepr(
+            funcargs=True,
+            abspath=abspath,
+            showlocals=self.config.option.showlocals,
+            style=style,
+            tbfilter=tbfilter,
+            truncate_locals=truncate_locals,
+        )
+
+    repr_failure = _repr_failure_py
+
+
+def get_fslocation_from_item(item):
+    """Tries to extract the actual location from an item, depending on available attributes:
+
+    * "fslocation": a pair (path, lineno)
+    * "obj": a Python object that the item wraps.
+    * "fspath": just a path
+
+    :rtype: a tuple of (str|LocalPath, int) with filename and line number.
+    """
+    result = getattr(item, "location", None)
+    if result is not None:
+        return result[:2]
+    obj = getattr(item, "obj", None)
+    if obj is not None:
+        return getfslineno(obj)
+    return getattr(item, "fspath", "unknown location"), -1
+
+
+class Collector(Node):
+    """ Collector instances create children through collect()
+        and thus iteratively build a tree.
+    """
+
+    class CollectError(Exception):
+        """ an error during collection, contains a custom message. """
+
+    def collect(self):
+        """ returns a list of children (items and collectors)
+            for this collection node.
+        """
+        raise NotImplementedError("abstract")
+
+    def repr_failure(self, excinfo):
+        """ represent a collection failure. """
+        if excinfo.errisinstance(self.CollectError):
+            exc = excinfo.value
+            return str(exc.args[0])
+        return self._repr_failure_py(excinfo, style="short")
+
+    def _prunetraceback(self, excinfo):
+        if hasattr(self, "fspath"):
+            traceback = excinfo.traceback
+            ntraceback = traceback.cut(path=self.fspath)
+            if ntraceback == traceback:
+                ntraceback = ntraceback.cut(excludepath=tracebackcutdir)
+            excinfo.traceback = ntraceback.filter()
+
+
+def _check_initialpaths_for_relpath(session, fspath):
+    for initial_path in session._initialpaths:
+        if fspath.common(initial_path) == initial_path:
+            return fspath.relto(initial_path)
+
+
+class FSCollector(Collector):
+    def __init__(self, fspath, parent=None, config=None, session=None, nodeid=None):
+        fspath = py.path.local(fspath)  # xxx only for test_resultlog.py?
+        name = fspath.basename
+        if parent is not None:
+            rel = fspath.relto(parent.fspath)
+            if rel:
+                name = rel
+            name = name.replace(os.sep, SEP)
+        self.fspath = fspath
+
+        session = session or parent.session
+
+        if nodeid is None:
+            nodeid = self.fspath.relto(session.config.rootdir)
+
+            if not nodeid:
+                nodeid = _check_initialpaths_for_relpath(session, fspath)
+            if nodeid and os.sep != SEP:
+                nodeid = nodeid.replace(os.sep, SEP)
+
+        super(FSCollector, self).__init__(
+            name, parent, config, session, nodeid=nodeid, fspath=fspath
+        )
+
+
+class File(FSCollector):
+    """ base class for collecting tests from a file. """
+
+
+class Item(Node):
+    """ a basic test invocation item. Note that for a single function
+    there might be multiple test invocation items.
+    """
+
+    nextitem = None
+
+    def __init__(self, name, parent=None, config=None, session=None, nodeid=None):
+        super(Item, self).__init__(name, parent, config, session, nodeid=nodeid)
+        self._report_sections = []
+
+        #: user properties is a list of tuples (name, value) that holds user
+        #: defined properties for this test.
+        self.user_properties = []
+
+    def add_report_section(self, when, key, content):
+        """
+        Adds a new report section, similar to what's done internally to add stdout and
+        stderr captured output::
+
+            item.add_report_section("call", "stdout", "report section contents")
+
+        :param str when:
+            One of the possible capture states, ``"setup"``, ``"call"``, ``"teardown"``.
+        :param str key:
+            Name of the section, can be customized at will. Pytest uses ``"stdout"`` and
+            ``"stderr"`` internally.
+
+        :param str content:
+            The full contents as a string.
+        """
+        if content:
+            self._report_sections.append((when, key, content))
+
+    def reportinfo(self):
+        return self.fspath, None, ""
+
+    @property
+    def location(self):
+        try:
+            return self._location
+        except AttributeError:
+            location = self.reportinfo()
+            fspath = self.session._node_location_to_relpath(location[0])
+            location = (fspath, location[1], str(location[2]))
+            self._location = location
+            return location
Index: venv/Lib/site-packages/_pytest/main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/main.py	(date 1543190976757)
+++ venv/Lib/site-packages/_pytest/main.py	(date 1543190976757)
@@ -0,0 +1,718 @@
+""" core implementation of testing process: init, session, runtest loop. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import contextlib
+import functools
+import os
+import pkgutil
+import sys
+
+import attr
+import py
+import six
+
+import _pytest._code
+from _pytest import nodes
+from _pytest.config import directory_arg
+from _pytest.config import hookimpl
+from _pytest.config import UsageError
+from _pytest.outcomes import exit
+from _pytest.runner import collect_one_node
+
+
+# exitcodes for the command line
+EXIT_OK = 0
+EXIT_TESTSFAILED = 1
+EXIT_INTERRUPTED = 2
+EXIT_INTERNALERROR = 3
+EXIT_USAGEERROR = 4
+EXIT_NOTESTSCOLLECTED = 5
+
+
+def pytest_addoption(parser):
+    parser.addini(
+        "norecursedirs",
+        "directory patterns to avoid for recursion",
+        type="args",
+        default=[".*", "build", "dist", "CVS", "_darcs", "{arch}", "*.egg", "venv"],
+    )
+    parser.addini(
+        "testpaths",
+        "directories to search for tests when no files or directories are given in the "
+        "command line.",
+        type="args",
+        default=[],
+    )
+    # parser.addini("dirpatterns",
+    #    "patterns specifying possible locations of test files",
+    #    type="linelist", default=["**/test_*.txt",
+    #            "**/test_*.py", "**/*_test.py"]
+    # )
+    group = parser.getgroup("general", "running and selection options")
+    group._addoption(
+        "-x",
+        "--exitfirst",
+        action="store_const",
+        dest="maxfail",
+        const=1,
+        help="exit instantly on first error or failed test.",
+    ),
+    group._addoption(
+        "--maxfail",
+        metavar="num",
+        action="store",
+        type=int,
+        dest="maxfail",
+        default=0,
+        help="exit after first num failures or errors.",
+    )
+    group._addoption(
+        "--strict",
+        action="store_true",
+        help="marks not registered in configuration file raise errors.",
+    )
+    group._addoption(
+        "-c",
+        metavar="file",
+        type=str,
+        dest="inifilename",
+        help="load configuration from `file` instead of trying to locate one of the implicit "
+        "configuration files.",
+    )
+    group._addoption(
+        "--continue-on-collection-errors",
+        action="store_true",
+        default=False,
+        dest="continue_on_collection_errors",
+        help="Force test execution even if collection errors occur.",
+    )
+    group._addoption(
+        "--rootdir",
+        action="store",
+        dest="rootdir",
+        help="Define root directory for tests. Can be relative path: 'root_dir', './root_dir', "
+        "'root_dir/another_dir/'; absolute path: '/home/user/root_dir'; path with variables: "
+        "'$HOME/root_dir'.",
+    )
+
+    group = parser.getgroup("collect", "collection")
+    group.addoption(
+        "--collectonly",
+        "--collect-only",
+        action="store_true",
+        help="only collect tests, don't execute them.",
+    ),
+    group.addoption(
+        "--pyargs",
+        action="store_true",
+        help="try to interpret all arguments as python packages.",
+    )
+    group.addoption(
+        "--ignore",
+        action="append",
+        metavar="path",
+        help="ignore path during collection (multi-allowed).",
+    )
+    group.addoption(
+        "--deselect",
+        action="append",
+        metavar="nodeid_prefix",
+        help="deselect item during collection (multi-allowed).",
+    )
+    # when changing this to --conf-cut-dir, config.py Conftest.setinitial
+    # needs upgrading as well
+    group.addoption(
+        "--confcutdir",
+        dest="confcutdir",
+        default=None,
+        metavar="dir",
+        type=functools.partial(directory_arg, optname="--confcutdir"),
+        help="only load conftest.py's relative to specified dir.",
+    )
+    group.addoption(
+        "--noconftest",
+        action="store_true",
+        dest="noconftest",
+        default=False,
+        help="Don't load any conftest.py files.",
+    )
+    group.addoption(
+        "--keepduplicates",
+        "--keep-duplicates",
+        action="store_true",
+        dest="keepduplicates",
+        default=False,
+        help="Keep duplicate tests.",
+    )
+    group.addoption(
+        "--collect-in-virtualenv",
+        action="store_true",
+        dest="collect_in_virtualenv",
+        default=False,
+        help="Don't ignore tests in a local virtualenv directory",
+    )
+
+    group = parser.getgroup("debugconfig", "test session debugging and configuration")
+    group.addoption(
+        "--basetemp",
+        dest="basetemp",
+        default=None,
+        metavar="dir",
+        help=(
+            "base temporary directory for this test run."
+            "(warning: this directory is removed if it exists)"
+        ),
+    )
+
+
+def pytest_configure(config):
+    __import__("pytest").config = config  # compatibility
+
+
+def wrap_session(config, doit):
+    """Skeleton command line program"""
+    session = Session(config)
+    session.exitstatus = EXIT_OK
+    initstate = 0
+    try:
+        try:
+            config._do_configure()
+            initstate = 1
+            config.hook.pytest_sessionstart(session=session)
+            initstate = 2
+            session.exitstatus = doit(config, session) or 0
+        except UsageError:
+            raise
+        except Failed:
+            session.exitstatus = EXIT_TESTSFAILED
+        except KeyboardInterrupt:
+            excinfo = _pytest._code.ExceptionInfo()
+            exitstatus = EXIT_INTERRUPTED
+            if initstate <= 2 and isinstance(excinfo.value, exit.Exception):
+                sys.stderr.write("{}: {}\n".format(excinfo.typename, excinfo.value.msg))
+                if excinfo.value.returncode is not None:
+                    exitstatus = excinfo.value.returncode
+            config.hook.pytest_keyboard_interrupt(excinfo=excinfo)
+            session.exitstatus = exitstatus
+        except:  # noqa
+            excinfo = _pytest._code.ExceptionInfo()
+            config.notify_exception(excinfo, config.option)
+            session.exitstatus = EXIT_INTERNALERROR
+            if excinfo.errisinstance(SystemExit):
+                sys.stderr.write("mainloop: caught Spurious SystemExit!\n")
+
+    finally:
+        excinfo = None  # Explicitly break reference cycle.
+        session.startdir.chdir()
+        if initstate >= 2:
+            config.hook.pytest_sessionfinish(
+                session=session, exitstatus=session.exitstatus
+            )
+        config._ensure_unconfigure()
+    return session.exitstatus
+
+
+def pytest_cmdline_main(config):
+    return wrap_session(config, _main)
+
+
+def _main(config, session):
+    """ default command line protocol for initialization, session,
+    running tests and reporting. """
+    config.hook.pytest_collection(session=session)
+    config.hook.pytest_runtestloop(session=session)
+
+    if session.testsfailed:
+        return EXIT_TESTSFAILED
+    elif session.testscollected == 0:
+        return EXIT_NOTESTSCOLLECTED
+
+
+def pytest_collection(session):
+    return session.perform_collect()
+
+
+def pytest_runtestloop(session):
+    if session.testsfailed and not session.config.option.continue_on_collection_errors:
+        raise session.Interrupted("%d errors during collection" % session.testsfailed)
+
+    if session.config.option.collectonly:
+        return True
+
+    for i, item in enumerate(session.items):
+        nextitem = session.items[i + 1] if i + 1 < len(session.items) else None
+        item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)
+        if session.shouldfail:
+            raise session.Failed(session.shouldfail)
+        if session.shouldstop:
+            raise session.Interrupted(session.shouldstop)
+    return True
+
+
+def _in_venv(path):
+    """Attempts to detect if ``path`` is the root of a Virtual Environment by
+    checking for the existence of the appropriate activate script"""
+    bindir = path.join("Scripts" if sys.platform.startswith("win") else "bin")
+    if not bindir.isdir():
+        return False
+    activates = (
+        "activate",
+        "activate.csh",
+        "activate.fish",
+        "Activate",
+        "Activate.bat",
+        "Activate.ps1",
+    )
+    return any([fname.basename in activates for fname in bindir.listdir()])
+
+
+def pytest_ignore_collect(path, config):
+    ignore_paths = config._getconftest_pathlist("collect_ignore", path=path.dirpath())
+    ignore_paths = ignore_paths or []
+    excludeopt = config.getoption("ignore")
+    if excludeopt:
+        ignore_paths.extend([py.path.local(x) for x in excludeopt])
+
+    if py.path.local(path) in ignore_paths:
+        return True
+
+    allow_in_venv = config.getoption("collect_in_virtualenv")
+    if not allow_in_venv and _in_venv(path):
+        return True
+
+    return False
+
+
+def pytest_collection_modifyitems(items, config):
+    deselect_prefixes = tuple(config.getoption("deselect") or [])
+    if not deselect_prefixes:
+        return
+
+    remaining = []
+    deselected = []
+    for colitem in items:
+        if colitem.nodeid.startswith(deselect_prefixes):
+            deselected.append(colitem)
+        else:
+            remaining.append(colitem)
+
+    if deselected:
+        config.hook.pytest_deselected(items=deselected)
+        items[:] = remaining
+
+
+@contextlib.contextmanager
+def _patched_find_module():
+    """Patch bug in pkgutil.ImpImporter.find_module
+
+    When using pkgutil.find_loader on python<3.4 it removes symlinks
+    from the path due to a call to os.path.realpath. This is not consistent
+    with actually doing the import (in these versions, pkgutil and __import__
+    did not share the same underlying code). This can break conftest
+    discovery for pytest where symlinks are involved.
+
+    The only supported python<3.4 by pytest is python 2.7.
+    """
+    if six.PY2:  # python 3.4+ uses importlib instead
+
+        def find_module_patched(self, fullname, path=None):
+            # Note: we ignore 'path' argument since it is only used via meta_path
+            subname = fullname.split(".")[-1]
+            if subname != fullname and self.path is None:
+                return None
+            if self.path is None:
+                path = None
+            else:
+                # original: path = [os.path.realpath(self.path)]
+                path = [self.path]
+            try:
+                file, filename, etc = pkgutil.imp.find_module(subname, path)
+            except ImportError:
+                return None
+            return pkgutil.ImpLoader(fullname, file, filename, etc)
+
+        old_find_module = pkgutil.ImpImporter.find_module
+        pkgutil.ImpImporter.find_module = find_module_patched
+        try:
+            yield
+        finally:
+            pkgutil.ImpImporter.find_module = old_find_module
+    else:
+        yield
+
+
+class FSHookProxy(object):
+    def __init__(self, fspath, pm, remove_mods):
+        self.fspath = fspath
+        self.pm = pm
+        self.remove_mods = remove_mods
+
+    def __getattr__(self, name):
+        x = self.pm.subset_hook_caller(name, remove_plugins=self.remove_mods)
+        self.__dict__[name] = x
+        return x
+
+
+class NoMatch(Exception):
+    """ raised if matching cannot locate a matching names. """
+
+
+class Interrupted(KeyboardInterrupt):
+    """ signals an interrupted test run. """
+
+    __module__ = "builtins"  # for py3
+
+
+class Failed(Exception):
+    """ signals a stop as failed test run. """
+
+
+@attr.s
+class _bestrelpath_cache(dict):
+    path = attr.ib()
+
+    def __missing__(self, path):
+        r = self.path.bestrelpath(path)
+        self[path] = r
+        return r
+
+
+class Session(nodes.FSCollector):
+    Interrupted = Interrupted
+    Failed = Failed
+
+    def __init__(self, config):
+        nodes.FSCollector.__init__(
+            self, config.rootdir, parent=None, config=config, session=self, nodeid=""
+        )
+        self.testsfailed = 0
+        self.testscollected = 0
+        self.shouldstop = False
+        self.shouldfail = False
+        self.trace = config.trace.root.get("collection")
+        self._norecursepatterns = config.getini("norecursedirs")
+        self.startdir = py.path.local()
+        self._initialpaths = frozenset()
+        # Keep track of any collected nodes in here, so we don't duplicate fixtures
+        self._node_cache = {}
+        self._bestrelpathcache = _bestrelpath_cache(config.rootdir)
+        # Dirnames of pkgs with dunder-init files.
+        self._pkg_roots = {}
+
+        self.config.pluginmanager.register(self, name="session")
+
+    def _node_location_to_relpath(self, node_path):
+        # bestrelpath is a quite slow function
+        return self._bestrelpathcache[node_path]
+
+    @hookimpl(tryfirst=True)
+    def pytest_collectstart(self):
+        if self.shouldfail:
+            raise self.Failed(self.shouldfail)
+        if self.shouldstop:
+            raise self.Interrupted(self.shouldstop)
+
+    @hookimpl(tryfirst=True)
+    def pytest_runtest_logreport(self, report):
+        if report.failed and not hasattr(report, "wasxfail"):
+            self.testsfailed += 1
+            maxfail = self.config.getvalue("maxfail")
+            if maxfail and self.testsfailed >= maxfail:
+                self.shouldfail = "stopping after %d failures" % (self.testsfailed)
+
+    pytest_collectreport = pytest_runtest_logreport
+
+    def isinitpath(self, path):
+        return path in self._initialpaths
+
+    def gethookproxy(self, fspath):
+        # check if we have the common case of running
+        # hooks with all conftest.py files
+        pm = self.config.pluginmanager
+        my_conftestmodules = pm._getconftestmodules(fspath)
+        remove_mods = pm._conftest_plugins.difference(my_conftestmodules)
+        if remove_mods:
+            # one or more conftests are not in use at this fspath
+            proxy = FSHookProxy(fspath, pm, remove_mods)
+        else:
+            # all plugis are active for this fspath
+            proxy = self.config.hook
+        return proxy
+
+    def perform_collect(self, args=None, genitems=True):
+        hook = self.config.hook
+        try:
+            items = self._perform_collect(args, genitems)
+            self.config.pluginmanager.check_pending()
+            hook.pytest_collection_modifyitems(
+                session=self, config=self.config, items=items
+            )
+        finally:
+            hook.pytest_collection_finish(session=self)
+        self.testscollected = len(items)
+        return items
+
+    def _perform_collect(self, args, genitems):
+        if args is None:
+            args = self.config.args
+        self.trace("perform_collect", self, args)
+        self.trace.root.indent += 1
+        self._notfound = []
+        initialpaths = []
+        self._initialparts = []
+        self.items = items = []
+        for arg in args:
+            parts = self._parsearg(arg)
+            self._initialparts.append(parts)
+            initialpaths.append(parts[0])
+        self._initialpaths = frozenset(initialpaths)
+        rep = collect_one_node(self)
+        self.ihook.pytest_collectreport(report=rep)
+        self.trace.root.indent -= 1
+        if self._notfound:
+            errors = []
+            for arg, exc in self._notfound:
+                line = "(no name %r in any of %r)" % (arg, exc.args[0])
+                errors.append("not found: %s\n%s" % (arg, line))
+                # XXX: test this
+            raise UsageError(*errors)
+        if not genitems:
+            return rep.result
+        else:
+            if rep.passed:
+                for node in rep.result:
+                    self.items.extend(self.genitems(node))
+            return items
+
+    def collect(self):
+        for initialpart in self._initialparts:
+            arg = "::".join(map(str, initialpart))
+            self.trace("processing argument", arg)
+            self.trace.root.indent += 1
+            try:
+                for x in self._collect(arg):
+                    yield x
+            except NoMatch:
+                # we are inside a make_report hook so
+                # we cannot directly pass through the exception
+                self._notfound.append((arg, sys.exc_info()[1]))
+
+            self.trace.root.indent -= 1
+
+    def _collect(self, arg):
+        from _pytest.python import Package
+
+        names = self._parsearg(arg)
+        argpath = names.pop(0)
+
+        # Start with a Session root, and delve to argpath item (dir or file)
+        # and stack all Packages found on the way.
+        # No point in finding packages when collecting doctests
+        if not self.config.option.doctestmodules:
+            pm = self.config.pluginmanager
+            for parent in reversed(argpath.parts()):
+                if pm._confcutdir and pm._confcutdir.relto(parent):
+                    break
+
+                if parent.isdir():
+                    pkginit = parent.join("__init__.py")
+                    if pkginit.isfile():
+                        if pkginit not in self._node_cache:
+                            col = self._collectfile(pkginit, handle_dupes=False)
+                            if col:
+                                if isinstance(col[0], Package):
+                                    self._pkg_roots[parent] = col[0]
+                                # always store a list in the cache, matchnodes expects it
+                                self._node_cache[col[0].fspath] = [col[0]]
+
+        # If it's a directory argument, recurse and look for any Subpackages.
+        # Let the Package collector deal with subnodes, don't collect here.
+        if argpath.check(dir=1):
+            assert not names, "invalid arg %r" % (arg,)
+
+            if six.PY2:
+
+                def filter_(f):
+                    return f.check(file=1) and not f.strpath.endswith("*.pyc")
+
+            else:
+
+                def filter_(f):
+                    return f.check(file=1)
+
+            seen_dirs = set()
+            for path in argpath.visit(
+                fil=filter_, rec=self._recurse, bf=True, sort=True
+            ):
+                dirpath = path.dirpath()
+                if dirpath not in seen_dirs:
+                    # Collect packages first.
+                    seen_dirs.add(dirpath)
+                    pkginit = dirpath.join("__init__.py")
+                    if pkginit.exists():
+                        for x in self._collectfile(pkginit):
+                            yield x
+                            if isinstance(x, Package):
+                                self._pkg_roots[dirpath] = x
+                if dirpath in self._pkg_roots:
+                    # Do not collect packages here.
+                    continue
+
+                for x in self._collectfile(path):
+                    key = (type(x), x.fspath)
+                    if key in self._node_cache:
+                        yield self._node_cache[key]
+                    else:
+                        self._node_cache[key] = x
+                        yield x
+        else:
+            assert argpath.check(file=1)
+
+            if argpath in self._node_cache:
+                col = self._node_cache[argpath]
+            else:
+                collect_root = self._pkg_roots.get(argpath.dirname, self)
+                col = collect_root._collectfile(argpath)
+                if col:
+                    self._node_cache[argpath] = col
+            m = self.matchnodes(col, names)
+            # If __init__.py was the only file requested, then the matched node will be
+            # the corresponding Package, and the first yielded item will be the __init__
+            # Module itself, so just use that. If this special case isn't taken, then all
+            # the files in the package will be yielded.
+            if argpath.basename == "__init__.py":
+                yield next(m[0].collect())
+                return
+            for y in m:
+                yield y
+
+    def _collectfile(self, path, handle_dupes=True):
+        ihook = self.gethookproxy(path)
+        if not self.isinitpath(path):
+            if ihook.pytest_ignore_collect(path=path, config=self.config):
+                return ()
+
+        if handle_dupes:
+            keepduplicates = self.config.getoption("keepduplicates")
+            if not keepduplicates:
+                duplicate_paths = self.config.pluginmanager._duplicatepaths
+                if path in duplicate_paths:
+                    return ()
+                else:
+                    duplicate_paths.add(path)
+
+        return ihook.pytest_collect_file(path=path, parent=self)
+
+    def _recurse(self, dirpath):
+        if dirpath.basename == "__pycache__":
+            return False
+        ihook = self.gethookproxy(dirpath.dirpath())
+        if ihook.pytest_ignore_collect(path=dirpath, config=self.config):
+            return False
+        for pat in self._norecursepatterns:
+            if dirpath.check(fnmatch=pat):
+                return False
+        ihook = self.gethookproxy(dirpath)
+        ihook.pytest_collect_directory(path=dirpath, parent=self)
+        return True
+
+    def _tryconvertpyarg(self, x):
+        """Convert a dotted module name to path."""
+        try:
+            with _patched_find_module():
+                loader = pkgutil.find_loader(x)
+        except ImportError:
+            return x
+        if loader is None:
+            return x
+        # This method is sometimes invoked when AssertionRewritingHook, which
+        # does not define a get_filename method, is already in place:
+        try:
+            with _patched_find_module():
+                path = loader.get_filename(x)
+        except AttributeError:
+            # Retrieve path from AssertionRewritingHook:
+            path = loader.modules[x][0].co_filename
+        if loader.is_package(x):
+            path = os.path.dirname(path)
+        return path
+
+    def _parsearg(self, arg):
+        """ return (fspath, names) tuple after checking the file exists. """
+        parts = str(arg).split("::")
+        if self.config.option.pyargs:
+            parts[0] = self._tryconvertpyarg(parts[0])
+        relpath = parts[0].replace("/", os.sep)
+        path = self.config.invocation_dir.join(relpath, abs=True)
+        if not path.check():
+            if self.config.option.pyargs:
+                raise UsageError(
+                    "file or package not found: " + arg + " (missing __init__.py?)"
+                )
+            raise UsageError("file not found: " + arg)
+        parts[0] = path.realpath()
+        return parts
+
+    def matchnodes(self, matching, names):
+        self.trace("matchnodes", matching, names)
+        self.trace.root.indent += 1
+        nodes = self._matchnodes(matching, names)
+        num = len(nodes)
+        self.trace("matchnodes finished -> ", num, "nodes")
+        self.trace.root.indent -= 1
+        if num == 0:
+            raise NoMatch(matching, names[:1])
+        return nodes
+
+    def _matchnodes(self, matching, names):
+        if not matching or not names:
+            return matching
+        name = names[0]
+        assert name
+        nextnames = names[1:]
+        resultnodes = []
+        for node in matching:
+            if isinstance(node, nodes.Item):
+                if not names:
+                    resultnodes.append(node)
+                continue
+            assert isinstance(node, nodes.Collector)
+            key = (type(node), node.nodeid)
+            if key in self._node_cache:
+                rep = self._node_cache[key]
+            else:
+                rep = collect_one_node(node)
+                self._node_cache[key] = rep
+            if rep.passed:
+                has_matched = False
+                for x in rep.result:
+                    # TODO: remove parametrized workaround once collection structure contains parametrization
+                    if x.name == name or x.name.split("[")[0] == name:
+                        resultnodes.extend(self.matchnodes([x], nextnames))
+                        has_matched = True
+                # XXX accept IDs that don't have "()" for class instances
+                if not has_matched and len(rep.result) == 1 and x.name == "()":
+                    nextnames.insert(0, name)
+                    resultnodes.extend(self.matchnodes([x], nextnames))
+            else:
+                # report collection failures here to avoid failing to run some test
+                # specified in the command line because the module could not be
+                # imported (#134)
+                node.ihook.pytest_collectreport(report=rep)
+        return resultnodes
+
+    def genitems(self, node):
+        self.trace("genitems", node)
+        if isinstance(node, nodes.Item):
+            node.ihook.pytest_itemcollected(item=node)
+            yield node
+        else:
+            assert isinstance(node, nodes.Collector)
+            rep = collect_one_node(node)
+            if rep.passed:
+                for subnode in rep.result:
+                    for x in self.genitems(subnode):
+                        yield x
+            node.ihook.pytest_collectreport(report=rep)
Index: Chapter1/OneCharacterDifference.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/OneCharacterDifference.py	(date 1543190976768)
+++ Chapter1/OneCharacterDifference.py	(date 1543190976768)
@@ -0,0 +1,35 @@
+def is_one_char_away(input1: str, input2: str) -> bool:
+    arr1 = [c for c in input1]
+    arr2 = [c for c in input2]
+
+    # if the difference is len is greater than 1 will always be false
+    if abs(len(arr1) - len(arr2)) > 1:
+        return False
+
+    diff_count = 0
+    if len(arr1) != len(arr2):
+        s_list = arr2 if len(arr2) < len(arr1) else arr1
+        l_list = arr2 if len(arr2) > len(arr1) else arr1
+
+        s_index = 0
+        l_index = 0
+
+        while s_index < len(s_list):
+            if s_list[s_index] != l_list[l_index]:
+                diff_count += 1
+                if diff_count == 1:
+                    l_index += 1
+                else:
+                    break
+
+            s_index += 1
+            l_index += 1
+
+    else:
+        index = 0
+        while index < len(arr1):
+            if arr1[index] != arr2[index]:
+                diff_count += 1
+            index += 1
+
+    return True if diff_count < 2 else False
Index: venv/Lib/site-packages/_pytest/_version.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/_version.py	(date 1543190976777)
+++ venv/Lib/site-packages/_pytest/_version.py	(date 1543190976777)
@@ -0,0 +1,4 @@
+# coding: utf-8
+# file generated by setuptools_scm
+# don't change, don't track in version control
+version = '4.0.0'
Index: Chapter1/tests/test_one_character_difference.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_one_character_difference.py	(date 1543190976787)
+++ Chapter1/tests/test_one_character_difference.py	(date 1543190976787)
@@ -0,0 +1,17 @@
+from Chapter1.OneCharacterDifference import is_one_char_away
+
+
+def test_one_character_drop_char():
+    assert is_one_char_away('pale', 'ple')
+
+
+def test_one_character_add_char():
+    assert is_one_char_away('pales', 'pale')
+
+
+def test_one_character_replace_char():
+    assert is_one_char_away('bale', 'pale')
+
+
+def test_one_character_fail():
+    assert not is_one_char_away('bake', 'pale')
Index: venv/Lib/site-packages/_pytest/pathlib.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/pathlib.py	(date 1543190976801)
+++ venv/Lib/site-packages/_pytest/pathlib.py	(date 1543190976801)
@@ -0,0 +1,320 @@
+import atexit
+import errno
+import fnmatch
+import itertools
+import operator
+import os
+import shutil
+import sys
+import uuid
+from functools import reduce
+from os.path import expanduser
+from os.path import expandvars
+from os.path import isabs
+from os.path import sep
+from posixpath import sep as posix_sep
+
+import six
+from six.moves import map
+
+from .compat import PY36
+
+
+if PY36:
+    from pathlib import Path, PurePath
+else:
+    from pathlib2 import Path, PurePath
+
+__all__ = ["Path", "PurePath"]
+
+
+LOCK_TIMEOUT = 60 * 60 * 3
+
+get_lock_path = operator.methodcaller("joinpath", ".lock")
+
+
+def ensure_reset_dir(path):
+    """
+    ensures the given path is an empty directory
+    """
+    if path.exists():
+        rmtree(path, force=True)
+    path.mkdir()
+
+
+def rmtree(path, force=False):
+    if force:
+        # NOTE: ignore_errors might leave dead folders around.
+        #       Python needs a rm -rf as a followup.
+        shutil.rmtree(str(path), ignore_errors=True)
+    else:
+        shutil.rmtree(str(path))
+
+
+def find_prefixed(root, prefix):
+    """finds all elements in root that begin with the prefix, case insensitive"""
+    l_prefix = prefix.lower()
+    for x in root.iterdir():
+        if x.name.lower().startswith(l_prefix):
+            yield x
+
+
+def extract_suffixes(iter, prefix):
+    """
+    :param iter: iterator over path names
+    :param prefix: expected prefix of the path names
+    :returns: the parts of the paths following the prefix
+    """
+    p_len = len(prefix)
+    for p in iter:
+        yield p.name[p_len:]
+
+
+def find_suffixes(root, prefix):
+    """combines find_prefixes and extract_suffixes
+    """
+    return extract_suffixes(find_prefixed(root, prefix), prefix)
+
+
+def parse_num(maybe_num):
+    """parses number path suffixes, returns -1 on error"""
+    try:
+        return int(maybe_num)
+    except ValueError:
+        return -1
+
+
+if six.PY2:
+
+    def _max(iterable, default):
+        """needed due to python2.7 lacking the default argument for max"""
+        return reduce(max, iterable, default)
+
+
+else:
+    _max = max
+
+
+def _force_symlink(root, target, link_to):
+    """helper to create the current symlink
+
+    it's full of race conditions that are reasonably ok to ignore
+    for the context of best effort linking to the latest testrun
+
+    the presumption being thatin case of much parallelism
+    the inaccuracy is going to be acceptable
+    """
+    current_symlink = root.joinpath(target)
+    try:
+        current_symlink.unlink()
+    except OSError:
+        pass
+    try:
+        current_symlink.symlink_to(link_to)
+    except Exception:
+        pass
+
+
+def make_numbered_dir(root, prefix):
+    """create a directory with an increased number as suffix for the given prefix"""
+    for i in range(10):
+        # try up to 10 times to create the folder
+        max_existing = _max(map(parse_num, find_suffixes(root, prefix)), default=-1)
+        new_number = max_existing + 1
+        new_path = root.joinpath("{}{}".format(prefix, new_number))
+        try:
+            new_path.mkdir()
+        except Exception:
+            pass
+        else:
+            _force_symlink(root, prefix + "current", new_path)
+            return new_path
+    else:
+        raise EnvironmentError(
+            "could not create numbered dir with prefix "
+            "{prefix} in {root} after 10 tries".format(prefix=prefix, root=root)
+        )
+
+
+def create_cleanup_lock(p):
+    """crates a lock to prevent premature folder cleanup"""
+    lock_path = get_lock_path(p)
+    try:
+        fd = os.open(str(lock_path), os.O_WRONLY | os.O_CREAT | os.O_EXCL, 0o644)
+    except OSError as e:
+        if e.errno == errno.EEXIST:
+            six.raise_from(
+                EnvironmentError("cannot create lockfile in {path}".format(path=p)), e
+            )
+        else:
+            raise
+    else:
+        pid = os.getpid()
+        spid = str(pid)
+        if not isinstance(spid, bytes):
+            spid = spid.encode("ascii")
+        os.write(fd, spid)
+        os.close(fd)
+        if not lock_path.is_file():
+            raise EnvironmentError("lock path got renamed after successful creation")
+        return lock_path
+
+
+def register_cleanup_lock_removal(lock_path, register=atexit.register):
+    """registers a cleanup function for removing a lock, by default on atexit"""
+    pid = os.getpid()
+
+    def cleanup_on_exit(lock_path=lock_path, original_pid=pid):
+        current_pid = os.getpid()
+        if current_pid != original_pid:
+            # fork
+            return
+        try:
+            lock_path.unlink()
+        except (OSError, IOError):
+            pass
+
+    return register(cleanup_on_exit)
+
+
+def maybe_delete_a_numbered_dir(path):
+    """removes a numbered directory if its lock can be obtained and it does not seem to be in use"""
+    lock_path = None
+    try:
+        lock_path = create_cleanup_lock(path)
+        parent = path.parent
+
+        garbage = parent.joinpath("garbage-{}".format(uuid.uuid4()))
+        path.rename(garbage)
+        rmtree(garbage, force=True)
+    except (OSError, EnvironmentError):
+        #  known races:
+        #  * other process did a cleanup at the same time
+        #  * deletable folder was found
+        #  * process cwd (Windows)
+        return
+    finally:
+        # if we created the lock, ensure we remove it even if we failed
+        # to properly remove the numbered dir
+        if lock_path is not None:
+            try:
+                lock_path.unlink()
+            except (OSError, IOError):
+                pass
+
+
+def ensure_deletable(path, consider_lock_dead_if_created_before):
+    """checks if a lock exists and breaks it if its considered dead"""
+    if path.is_symlink():
+        return False
+    lock = get_lock_path(path)
+    if not lock.exists():
+        return True
+    try:
+        lock_time = lock.stat().st_mtime
+    except Exception:
+        return False
+    else:
+        if lock_time < consider_lock_dead_if_created_before:
+            lock.unlink()
+            return True
+        else:
+            return False
+
+
+def try_cleanup(path, consider_lock_dead_if_created_before):
+    """tries to cleanup a folder if we can ensure it's deletable"""
+    if ensure_deletable(path, consider_lock_dead_if_created_before):
+        maybe_delete_a_numbered_dir(path)
+
+
+def cleanup_candidates(root, prefix, keep):
+    """lists candidates for numbered directories to be removed - follows py.path"""
+    max_existing = _max(map(parse_num, find_suffixes(root, prefix)), default=-1)
+    max_delete = max_existing - keep
+    paths = find_prefixed(root, prefix)
+    paths, paths2 = itertools.tee(paths)
+    numbers = map(parse_num, extract_suffixes(paths2, prefix))
+    for path, number in zip(paths, numbers):
+        if number <= max_delete:
+            yield path
+
+
+def cleanup_numbered_dir(root, prefix, keep, consider_lock_dead_if_created_before):
+    """cleanup for lock driven numbered directories"""
+    for path in cleanup_candidates(root, prefix, keep):
+        try_cleanup(path, consider_lock_dead_if_created_before)
+    for path in root.glob("garbage-*"):
+        try_cleanup(path, consider_lock_dead_if_created_before)
+
+
+def make_numbered_dir_with_cleanup(root, prefix, keep, lock_timeout):
+    """creates a numbered dir with a cleanup lock and removes old ones"""
+    e = None
+    for i in range(10):
+        try:
+            p = make_numbered_dir(root, prefix)
+            lock_path = create_cleanup_lock(p)
+            register_cleanup_lock_removal(lock_path)
+        except Exception as exc:
+            e = exc
+        else:
+            consider_lock_dead_if_created_before = p.stat().st_mtime - lock_timeout
+            cleanup_numbered_dir(
+                root=root,
+                prefix=prefix,
+                keep=keep,
+                consider_lock_dead_if_created_before=consider_lock_dead_if_created_before,
+            )
+            return p
+    assert e is not None
+    raise e
+
+
+def resolve_from_str(input, root):
+    assert not isinstance(input, Path), "would break on py2"
+    root = Path(root)
+    input = expanduser(input)
+    input = expandvars(input)
+    if isabs(input):
+        return Path(input)
+    else:
+        return root.joinpath(input)
+
+
+def fnmatch_ex(pattern, path):
+    """FNMatcher port from py.path.common which works with PurePath() instances.
+
+    The difference between this algorithm and PurePath.match() is that the latter matches "**" glob expressions
+    for each part of the path, while this algorithm uses the whole path instead.
+
+    For example:
+        "tests/foo/bar/doc/test_foo.py" matches pattern "tests/**/doc/test*.py" with this algorithm, but not with
+        PurePath.match().
+
+    This algorithm was ported to keep backward-compatibility with existing settings which assume paths match according
+    this logic.
+
+    References:
+    * https://bugs.python.org/issue29249
+    * https://bugs.python.org/issue34731
+    """
+    path = PurePath(path)
+    iswin32 = sys.platform.startswith("win")
+
+    if iswin32 and sep not in pattern and posix_sep in pattern:
+        # Running on Windows, the pattern has no Windows path separators,
+        # and the pattern has one or more Posix path separators. Replace
+        # the Posix path separators with the Windows path separator.
+        pattern = pattern.replace(posix_sep, sep)
+
+    if sep not in pattern:
+        name = path.name
+    else:
+        name = six.text_type(path)
+    return fnmatch.fnmatch(name, pattern)
+
+
+def parts(s):
+    parts = s.split(sep)
+    return {sep.join(parts[: i + 1]) or sep for i in range(len(parts))}
Index: venv/Lib/site-packages/_pytest/cacheprovider.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/cacheprovider.py	(date 1543190976824)
+++ venv/Lib/site-packages/_pytest/cacheprovider.py	(date 1543190976824)
@@ -0,0 +1,371 @@
+"""
+merged implementation of the cache provider
+
+the name cache was not chosen to ensure pluggy automatically
+ignores the external pytest-cache
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import json
+import os
+from collections import OrderedDict
+
+import attr
+import py
+import six
+
+import pytest
+from .compat import _PY2 as PY2
+from .pathlib import Path
+from .pathlib import resolve_from_str
+from .pathlib import rmtree
+
+README_CONTENT = u"""\
+# pytest cache directory #
+
+This directory contains data from the pytest's cache plugin,
+which provides the `--lf` and `--ff` options, as well as the `cache` fixture.
+
+**Do not** commit this to version control.
+
+See [the docs](https://docs.pytest.org/en/latest/cache.html) for more information.
+"""
+
+
+@attr.s
+class Cache(object):
+    _cachedir = attr.ib(repr=False)
+    _config = attr.ib(repr=False)
+
+    @classmethod
+    def for_config(cls, config):
+        cachedir = cls.cache_dir_from_config(config)
+        if config.getoption("cacheclear") and cachedir.exists():
+            rmtree(cachedir, force=True)
+            cachedir.mkdir()
+        return cls(cachedir, config)
+
+    @staticmethod
+    def cache_dir_from_config(config):
+        return resolve_from_str(config.getini("cache_dir"), config.rootdir)
+
+    def warn(self, fmt, **args):
+        from _pytest.warnings import _issue_config_warning
+        from _pytest.warning_types import PytestWarning
+
+        _issue_config_warning(
+            PytestWarning(fmt.format(**args) if args else fmt), self._config
+        )
+
+    def makedir(self, name):
+        """ return a directory path object with the given name.  If the
+        directory does not yet exist, it will be created.  You can use it
+        to manage files likes e. g. store/retrieve database
+        dumps across test sessions.
+
+        :param name: must be a string not containing a ``/`` separator.
+             Make sure the name contains your plugin or application
+             identifiers to prevent clashes with other cache users.
+        """
+        name = Path(name)
+        if len(name.parts) > 1:
+            raise ValueError("name is not allowed to contain path separators")
+        res = self._cachedir.joinpath("d", name)
+        res.mkdir(exist_ok=True, parents=True)
+        return py.path.local(res)
+
+    def _getvaluepath(self, key):
+        return self._cachedir.joinpath("v", Path(key))
+
+    def get(self, key, default):
+        """ return cached value for the given key.  If no value
+        was yet cached or the value cannot be read, the specified
+        default is returned.
+
+        :param key: must be a ``/`` separated value. Usually the first
+             name is the name of your plugin or your application.
+        :param default: must be provided in case of a cache-miss or
+             invalid cache values.
+
+        """
+        path = self._getvaluepath(key)
+        try:
+            with path.open("r") as f:
+                return json.load(f)
+        except (ValueError, IOError, OSError):
+            return default
+
+    def set(self, key, value):
+        """ save value for the given key.
+
+        :param key: must be a ``/`` separated value. Usually the first
+             name is the name of your plugin or your application.
+        :param value: must be of any combination of basic
+               python types, including nested types
+               like e. g. lists of dictionaries.
+        """
+        path = self._getvaluepath(key)
+        try:
+            path.parent.mkdir(exist_ok=True, parents=True)
+        except (IOError, OSError):
+            self.warn("could not create cache path {path}", path=path)
+            return
+        try:
+            f = path.open("wb" if PY2 else "w")
+        except (IOError, OSError):
+            self.warn("cache could not write path {path}", path=path)
+        else:
+            with f:
+                json.dump(value, f, indent=2, sort_keys=True)
+                self._ensure_supporting_files()
+
+    def _ensure_supporting_files(self):
+        """Create supporting files in the cache dir that are not really part of the cache."""
+        if self._cachedir.is_dir():
+            readme_path = self._cachedir / "README.md"
+            if not readme_path.is_file():
+                readme_path.write_text(README_CONTENT)
+
+            msg = u"# created by pytest automatically, do not change\n*"
+            self._cachedir.joinpath(".gitignore").write_text(msg, encoding="UTF-8")
+
+
+class LFPlugin(object):
+    """ Plugin which implements the --lf (run last-failing) option """
+
+    def __init__(self, config):
+        self.config = config
+        active_keys = "lf", "failedfirst"
+        self.active = any(config.getoption(key) for key in active_keys)
+        self.lastfailed = config.cache.get("cache/lastfailed", {})
+        self._previously_failed_count = None
+        self._no_failures_behavior = self.config.getoption("last_failed_no_failures")
+
+    def pytest_report_collectionfinish(self):
+        if self.active and self.config.getoption("verbose") >= 0:
+            if not self._previously_failed_count:
+                return None
+            noun = "failure" if self._previously_failed_count == 1 else "failures"
+            suffix = " first" if self.config.getoption("failedfirst") else ""
+            mode = "rerun previous {count} {noun}{suffix}".format(
+                count=self._previously_failed_count, suffix=suffix, noun=noun
+            )
+            return "run-last-failure: %s" % mode
+
+    def pytest_runtest_logreport(self, report):
+        if (report.when == "call" and report.passed) or report.skipped:
+            self.lastfailed.pop(report.nodeid, None)
+        elif report.failed:
+            self.lastfailed[report.nodeid] = True
+
+    def pytest_collectreport(self, report):
+        passed = report.outcome in ("passed", "skipped")
+        if passed:
+            if report.nodeid in self.lastfailed:
+                self.lastfailed.pop(report.nodeid)
+                self.lastfailed.update((item.nodeid, True) for item in report.result)
+        else:
+            self.lastfailed[report.nodeid] = True
+
+    def pytest_collection_modifyitems(self, session, config, items):
+        if self.active:
+            if self.lastfailed:
+                previously_failed = []
+                previously_passed = []
+                for item in items:
+                    if item.nodeid in self.lastfailed:
+                        previously_failed.append(item)
+                    else:
+                        previously_passed.append(item)
+                self._previously_failed_count = len(previously_failed)
+                if not previously_failed:
+                    # running a subset of all tests with recorded failures outside
+                    # of the set of tests currently executing
+                    return
+                if self.config.getoption("lf"):
+                    items[:] = previously_failed
+                    config.hook.pytest_deselected(items=previously_passed)
+                else:
+                    items[:] = previously_failed + previously_passed
+            elif self._no_failures_behavior == "none":
+                config.hook.pytest_deselected(items=items)
+                items[:] = []
+
+    def pytest_sessionfinish(self, session):
+        config = self.config
+        if config.getoption("cacheshow") or hasattr(config, "slaveinput"):
+            return
+
+        saved_lastfailed = config.cache.get("cache/lastfailed", {})
+        if saved_lastfailed != self.lastfailed:
+            config.cache.set("cache/lastfailed", self.lastfailed)
+
+
+class NFPlugin(object):
+    """ Plugin which implements the --nf (run new-first) option """
+
+    def __init__(self, config):
+        self.config = config
+        self.active = config.option.newfirst
+        self.cached_nodeids = config.cache.get("cache/nodeids", [])
+
+    def pytest_collection_modifyitems(self, session, config, items):
+        if self.active:
+            new_items = OrderedDict()
+            other_items = OrderedDict()
+            for item in items:
+                if item.nodeid not in self.cached_nodeids:
+                    new_items[item.nodeid] = item
+                else:
+                    other_items[item.nodeid] = item
+
+            items[:] = self._get_increasing_order(
+                six.itervalues(new_items)
+            ) + self._get_increasing_order(six.itervalues(other_items))
+        self.cached_nodeids = [x.nodeid for x in items if isinstance(x, pytest.Item)]
+
+    def _get_increasing_order(self, items):
+        return sorted(items, key=lambda item: item.fspath.mtime(), reverse=True)
+
+    def pytest_sessionfinish(self, session):
+        config = self.config
+        if config.getoption("cacheshow") or hasattr(config, "slaveinput"):
+            return
+
+        config.cache.set("cache/nodeids", self.cached_nodeids)
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group.addoption(
+        "--lf",
+        "--last-failed",
+        action="store_true",
+        dest="lf",
+        help="rerun only the tests that failed "
+        "at the last run (or all if none failed)",
+    )
+    group.addoption(
+        "--ff",
+        "--failed-first",
+        action="store_true",
+        dest="failedfirst",
+        help="run all tests but run the last failures first.  "
+        "This may re-order tests and thus lead to "
+        "repeated fixture setup/teardown",
+    )
+    group.addoption(
+        "--nf",
+        "--new-first",
+        action="store_true",
+        dest="newfirst",
+        help="run tests from new files first, then the rest of the tests "
+        "sorted by file mtime",
+    )
+    group.addoption(
+        "--cache-show",
+        action="store_true",
+        dest="cacheshow",
+        help="show cache contents, don't perform collection or tests",
+    )
+    group.addoption(
+        "--cache-clear",
+        action="store_true",
+        dest="cacheclear",
+        help="remove all cache contents at start of test run.",
+    )
+    cache_dir_default = ".pytest_cache"
+    if "TOX_ENV_DIR" in os.environ:
+        cache_dir_default = os.path.join(os.environ["TOX_ENV_DIR"], cache_dir_default)
+    parser.addini("cache_dir", default=cache_dir_default, help="cache directory path.")
+    group.addoption(
+        "--lfnf",
+        "--last-failed-no-failures",
+        action="store",
+        dest="last_failed_no_failures",
+        choices=("all", "none"),
+        default="all",
+        help="change the behavior when no test failed in the last run or no "
+        "information about the last failures was found in the cache",
+    )
+
+
+def pytest_cmdline_main(config):
+    if config.option.cacheshow:
+        from _pytest.main import wrap_session
+
+        return wrap_session(config, cacheshow)
+
+
+@pytest.hookimpl(tryfirst=True)
+def pytest_configure(config):
+    config.cache = Cache.for_config(config)
+    config.pluginmanager.register(LFPlugin(config), "lfplugin")
+    config.pluginmanager.register(NFPlugin(config), "nfplugin")
+
+
+@pytest.fixture
+def cache(request):
+    """
+    Return a cache object that can persist state between testing sessions.
+
+    cache.get(key, default)
+    cache.set(key, value)
+
+    Keys must be a ``/`` separated value, where the first part is usually the
+    name of your plugin or application to avoid clashes with other cache users.
+
+    Values can be any object handled by the json stdlib module.
+    """
+    return request.config.cache
+
+
+def pytest_report_header(config):
+    """Display cachedir with --cache-show and if non-default."""
+    if config.option.verbose or config.getini("cache_dir") != ".pytest_cache":
+        cachedir = config.cache._cachedir
+        # TODO: evaluate generating upward relative paths
+        # starting with .., ../.. if sensible
+
+        try:
+            displaypath = cachedir.relative_to(config.rootdir)
+        except ValueError:
+            displaypath = cachedir
+        return "cachedir: {}".format(displaypath)
+
+
+def cacheshow(config, session):
+    from pprint import pformat
+
+    tw = py.io.TerminalWriter()
+    tw.line("cachedir: " + str(config.cache._cachedir))
+    if not config.cache._cachedir.is_dir():
+        tw.line("cache is empty")
+        return 0
+    dummy = object()
+    basedir = config.cache._cachedir
+    vdir = basedir / "v"
+    tw.sep("-", "cache values")
+    for valpath in sorted(x for x in vdir.rglob("*") if x.is_file()):
+        key = valpath.relative_to(vdir)
+        val = config.cache.get(key, dummy)
+        if val is dummy:
+            tw.line("%s contains unreadable content, will be ignored" % key)
+        else:
+            tw.line("%s contains:" % key)
+            for line in pformat(val).splitlines():
+                tw.line("  " + line)
+
+    ddir = basedir / "d"
+    if ddir.is_dir():
+        contents = sorted(ddir.rglob("*"))
+        tw.sep("-", "cache directories")
+        for p in contents:
+            # if p.check(dir=1):
+            #    print("%s/" % p.relto(basedir))
+            if p.is_file():
+                key = p.relative_to(basedir)
+                tw.line("{} is a file of length {:d}".format(key, p.stat().st_size))
+    return 0
Index: venv/Lib/site-packages/_pytest/resultlog.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/resultlog.py	(date 1543190976834)
+++ venv/Lib/site-packages/_pytest/resultlog.py	(date 1543190976834)
@@ -0,0 +1,123 @@
+""" log machine-parseable test session result information in a plain
+text file.
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+
+import py
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("terminal reporting", "resultlog plugin options")
+    group.addoption(
+        "--resultlog",
+        "--result-log",
+        action="store",
+        metavar="path",
+        default=None,
+        help="DEPRECATED path for machine-readable result log.",
+    )
+
+
+def pytest_configure(config):
+    resultlog = config.option.resultlog
+    # prevent opening resultlog on slave nodes (xdist)
+    if resultlog and not hasattr(config, "slaveinput"):
+        dirname = os.path.dirname(os.path.abspath(resultlog))
+        if not os.path.isdir(dirname):
+            os.makedirs(dirname)
+        logfile = open(resultlog, "w", 1)  # line buffered
+        config._resultlog = ResultLog(config, logfile)
+        config.pluginmanager.register(config._resultlog)
+
+        from _pytest.deprecated import RESULT_LOG
+        from _pytest.warnings import _issue_config_warning
+
+        _issue_config_warning(RESULT_LOG, config)
+
+
+def pytest_unconfigure(config):
+    resultlog = getattr(config, "_resultlog", None)
+    if resultlog:
+        resultlog.logfile.close()
+        del config._resultlog
+        config.pluginmanager.unregister(resultlog)
+
+
+def generic_path(item):
+    chain = item.listchain()
+    gpath = [chain[0].name]
+    fspath = chain[0].fspath
+    fspart = False
+    for node in chain[1:]:
+        newfspath = node.fspath
+        if newfspath == fspath:
+            if fspart:
+                gpath.append(":")
+                fspart = False
+            else:
+                gpath.append(".")
+        else:
+            gpath.append("/")
+            fspart = True
+        name = node.name
+        if name[0] in "([":
+            gpath.pop()
+        gpath.append(name)
+        fspath = newfspath
+    return "".join(gpath)
+
+
+class ResultLog(object):
+    def __init__(self, config, logfile):
+        self.config = config
+        self.logfile = logfile  # preferably line buffered
+
+    def write_log_entry(self, testpath, lettercode, longrepr):
+        print("%s %s" % (lettercode, testpath), file=self.logfile)
+        for line in longrepr.splitlines():
+            print(" %s" % line, file=self.logfile)
+
+    def log_outcome(self, report, lettercode, longrepr):
+        testpath = getattr(report, "nodeid", None)
+        if testpath is None:
+            testpath = report.fspath
+        self.write_log_entry(testpath, lettercode, longrepr)
+
+    def pytest_runtest_logreport(self, report):
+        if report.when != "call" and report.passed:
+            return
+        res = self.config.hook.pytest_report_teststatus(report=report)
+        code = res[1]
+        if code == "x":
+            longrepr = str(report.longrepr)
+        elif code == "X":
+            longrepr = ""
+        elif report.passed:
+            longrepr = ""
+        elif report.failed:
+            longrepr = str(report.longrepr)
+        elif report.skipped:
+            longrepr = str(report.longrepr[2])
+        self.log_outcome(report, code, longrepr)
+
+    def pytest_collectreport(self, report):
+        if not report.passed:
+            if report.failed:
+                code = "F"
+                longrepr = str(report.longrepr)
+            else:
+                assert report.skipped
+                code = "S"
+                longrepr = "%s:%d: %s" % report.longrepr
+            self.log_outcome(report, code, longrepr)
+
+    def pytest_internalerror(self, excrepr):
+        reprcrash = getattr(excrepr, "reprcrash", None)
+        path = getattr(reprcrash, "path", None)
+        if path is None:
+            path = "cwd:%s" % py.path.local()
+        self.write_log_entry(path, "!", str(excrepr))
Index: Chapter1/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/__init__.py	(date 1543190975070)
+++ Chapter1/__init__.py	(date 1543190975070)
@@ -0,0 +1,0 @@
Index: venv/Lib/site-packages/_pytest/monkeypatch.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/monkeypatch.py	(date 1543190976847)
+++ venv/Lib/site-packages/_pytest/monkeypatch.py	(date 1543190976847)
@@ -0,0 +1,308 @@
+""" monkeypatching and mocking functionality.  """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import re
+import sys
+import warnings
+from contextlib import contextmanager
+
+import six
+
+import pytest
+from _pytest.fixtures import fixture
+
+RE_IMPORT_ERROR_NAME = re.compile("^No module named (.*)$")
+
+
+@fixture
+def monkeypatch():
+    """The returned ``monkeypatch`` fixture provides these
+    helper methods to modify objects, dictionaries or os.environ::
+
+        monkeypatch.setattr(obj, name, value, raising=True)
+        monkeypatch.delattr(obj, name, raising=True)
+        monkeypatch.setitem(mapping, name, value)
+        monkeypatch.delitem(obj, name, raising=True)
+        monkeypatch.setenv(name, value, prepend=False)
+        monkeypatch.delenv(name, raising=True)
+        monkeypatch.syspath_prepend(path)
+        monkeypatch.chdir(path)
+
+    All modifications will be undone after the requesting
+    test function or fixture has finished. The ``raising``
+    parameter determines if a KeyError or AttributeError
+    will be raised if the set/deletion operation has no target.
+    """
+    mpatch = MonkeyPatch()
+    yield mpatch
+    mpatch.undo()
+
+
+def resolve(name):
+    # simplified from zope.dottedname
+    parts = name.split(".")
+
+    used = parts.pop(0)
+    found = __import__(used)
+    for part in parts:
+        used += "." + part
+        try:
+            found = getattr(found, part)
+        except AttributeError:
+            pass
+        else:
+            continue
+        # we use explicit un-nesting of the handling block in order
+        # to avoid nested exceptions on python 3
+        try:
+            __import__(used)
+        except ImportError as ex:
+            # str is used for py2 vs py3
+            expected = str(ex).split()[-1]
+            if expected == used:
+                raise
+            else:
+                raise ImportError("import error in %s: %s" % (used, ex))
+        found = annotated_getattr(found, part, used)
+    return found
+
+
+def annotated_getattr(obj, name, ann):
+    try:
+        obj = getattr(obj, name)
+    except AttributeError:
+        raise AttributeError(
+            "%r object at %s has no attribute %r" % (type(obj).__name__, ann, name)
+        )
+    return obj
+
+
+def derive_importpath(import_path, raising):
+    if not isinstance(import_path, six.string_types) or "." not in import_path:
+        raise TypeError("must be absolute import path string, not %r" % (import_path,))
+    module, attr = import_path.rsplit(".", 1)
+    target = resolve(module)
+    if raising:
+        annotated_getattr(target, attr, ann=module)
+    return attr, target
+
+
+class Notset(object):
+    def __repr__(self):
+        return "<notset>"
+
+
+notset = Notset()
+
+
+class MonkeyPatch(object):
+    """ Object returned by the ``monkeypatch`` fixture keeping a record of setattr/item/env/syspath changes.
+    """
+
+    def __init__(self):
+        self._setattr = []
+        self._setitem = []
+        self._cwd = None
+        self._savesyspath = None
+
+    @contextmanager
+    def context(self):
+        """
+        Context manager that returns a new :class:`MonkeyPatch` object which
+        undoes any patching done inside the ``with`` block upon exit:
+
+        .. code-block:: python
+
+            import functools
+            def test_partial(monkeypatch):
+                with monkeypatch.context() as m:
+                    m.setattr(functools, "partial", 3)
+
+        Useful in situations where it is desired to undo some patches before the test ends,
+        such as mocking ``stdlib`` functions that might break pytest itself if mocked (for examples
+        of this see `#3290 <https://github.com/pytest-dev/pytest/issues/3290>`_.
+        """
+        m = MonkeyPatch()
+        try:
+            yield m
+        finally:
+            m.undo()
+
+    def setattr(self, target, name, value=notset, raising=True):
+        """ Set attribute value on target, memorizing the old value.
+        By default raise AttributeError if the attribute did not exist.
+
+        For convenience you can specify a string as ``target`` which
+        will be interpreted as a dotted import path, with the last part
+        being the attribute name.  Example:
+        ``monkeypatch.setattr("os.getcwd", lambda: "/")``
+        would set the ``getcwd`` function of the ``os`` module.
+
+        The ``raising`` value determines if the setattr should fail
+        if the attribute is not already present (defaults to True
+        which means it will raise).
+        """
+        __tracebackhide__ = True
+        import inspect
+
+        if value is notset:
+            if not isinstance(target, six.string_types):
+                raise TypeError(
+                    "use setattr(target, name, value) or "
+                    "setattr(target, value) with target being a dotted "
+                    "import string"
+                )
+            value = name
+            name, target = derive_importpath(target, raising)
+
+        oldval = getattr(target, name, notset)
+        if raising and oldval is notset:
+            raise AttributeError("%r has no attribute %r" % (target, name))
+
+        # avoid class descriptors like staticmethod/classmethod
+        if inspect.isclass(target):
+            oldval = target.__dict__.get(name, notset)
+        self._setattr.append((target, name, oldval))
+        setattr(target, name, value)
+
+    def delattr(self, target, name=notset, raising=True):
+        """ Delete attribute ``name`` from ``target``, by default raise
+        AttributeError it the attribute did not previously exist.
+
+        If no ``name`` is specified and ``target`` is a string
+        it will be interpreted as a dotted import path with the
+        last part being the attribute name.
+
+        If ``raising`` is set to False, no exception will be raised if the
+        attribute is missing.
+        """
+        __tracebackhide__ = True
+        if name is notset:
+            if not isinstance(target, six.string_types):
+                raise TypeError(
+                    "use delattr(target, name) or "
+                    "delattr(target) with target being a dotted "
+                    "import string"
+                )
+            name, target = derive_importpath(target, raising)
+
+        if not hasattr(target, name):
+            if raising:
+                raise AttributeError(name)
+        else:
+            self._setattr.append((target, name, getattr(target, name, notset)))
+            delattr(target, name)
+
+    def setitem(self, dic, name, value):
+        """ Set dictionary entry ``name`` to value. """
+        self._setitem.append((dic, name, dic.get(name, notset)))
+        dic[name] = value
+
+    def delitem(self, dic, name, raising=True):
+        """ Delete ``name`` from dict. Raise KeyError if it doesn't exist.
+
+        If ``raising`` is set to False, no exception will be raised if the
+        key is missing.
+        """
+        if name not in dic:
+            if raising:
+                raise KeyError(name)
+        else:
+            self._setitem.append((dic, name, dic.get(name, notset)))
+            del dic[name]
+
+    def _warn_if_env_name_is_not_str(self, name):
+        """On Python 2, warn if the given environment variable name is not a native str (#4056)"""
+        if six.PY2 and not isinstance(name, str):
+            warnings.warn(
+                pytest.PytestWarning(
+                    "Environment variable name {!r} should be str".format(name)
+                )
+            )
+
+    def setenv(self, name, value, prepend=None):
+        """ Set environment variable ``name`` to ``value``.  If ``prepend``
+        is a character, read the current environment variable value
+        and prepend the ``value`` adjoined with the ``prepend`` character."""
+        if not isinstance(value, str):
+            warnings.warn(
+                pytest.PytestWarning(
+                    "Value of environment variable {name} type should be str, but got "
+                    "{value!r} (type: {type}); converted to str implicitly".format(
+                        name=name, value=value, type=type(value).__name__
+                    )
+                ),
+                stacklevel=2,
+            )
+            value = str(value)
+        if prepend and name in os.environ:
+            value = value + prepend + os.environ[name]
+        self._warn_if_env_name_is_not_str(name)
+        self.setitem(os.environ, name, value)
+
+    def delenv(self, name, raising=True):
+        """ Delete ``name`` from the environment. Raise KeyError if it does
+        not exist.
+
+        If ``raising`` is set to False, no exception will be raised if the
+        environment variable is missing.
+        """
+        self._warn_if_env_name_is_not_str(name)
+        self.delitem(os.environ, name, raising=raising)
+
+    def syspath_prepend(self, path):
+        """ Prepend ``path`` to ``sys.path`` list of import locations. """
+        if self._savesyspath is None:
+            self._savesyspath = sys.path[:]
+        sys.path.insert(0, str(path))
+
+    def chdir(self, path):
+        """ Change the current working directory to the specified path.
+        Path can be a string or a py.path.local object.
+        """
+        if self._cwd is None:
+            self._cwd = os.getcwd()
+        if hasattr(path, "chdir"):
+            path.chdir()
+        else:
+            os.chdir(path)
+
+    def undo(self):
+        """ Undo previous changes.  This call consumes the
+        undo stack. Calling it a second time has no effect unless
+        you do more monkeypatching after the undo call.
+
+        There is generally no need to call `undo()`, since it is
+        called automatically during tear-down.
+
+        Note that the same `monkeypatch` fixture is used across a
+        single test function invocation. If `monkeypatch` is used both by
+        the test function itself and one of the test fixtures,
+        calling `undo()` will undo all of the changes made in
+        both functions.
+        """
+        for obj, name, value in reversed(self._setattr):
+            if value is not notset:
+                setattr(obj, name, value)
+            else:
+                delattr(obj, name)
+        self._setattr[:] = []
+        for dictionary, name, value in reversed(self._setitem):
+            if value is notset:
+                try:
+                    del dictionary[name]
+                except KeyError:
+                    pass  # was already deleted, so we have the desired state
+            else:
+                dictionary[name] = value
+        self._setitem[:] = []
+        if self._savesyspath is not None:
+            sys.path[:] = self._savesyspath
+            self._savesyspath = None
+
+        if self._cwd is not None:
+            os.chdir(self._cwd)
+            self._cwd = None
Index: venv/Lib/site-packages/attr/converters.pyi
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/converters.pyi	(date 1543190976858)
+++ venv/Lib/site-packages/attr/converters.pyi	(date 1543190976858)
@@ -0,0 +1,12 @@
+from typing import TypeVar, Optional, Callable, overload
+from . import _ConverterType
+
+_T = TypeVar("_T")
+
+def optional(
+    converter: _ConverterType[_T]
+) -> _ConverterType[Optional[_T]]: ...
+@overload
+def default_if_none(default: _T) -> _ConverterType[_T]: ...
+@overload
+def default_if_none(*, factory: Callable[[], _T]) -> _ConverterType[_T]: ...
Index: venv/Lib/site-packages/_pytest/pastebin.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/pastebin.py	(date 1543190976869)
+++ venv/Lib/site-packages/_pytest/pastebin.py	(date 1543190976869)
@@ -0,0 +1,113 @@
+""" submit failure or test session information to a pastebin service. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+import tempfile
+
+import six
+
+import pytest
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("terminal reporting")
+    group._addoption(
+        "--pastebin",
+        metavar="mode",
+        action="store",
+        dest="pastebin",
+        default=None,
+        choices=["failed", "all"],
+        help="send failed|all info to bpaste.net pastebin service.",
+    )
+
+
+@pytest.hookimpl(trylast=True)
+def pytest_configure(config):
+    if config.option.pastebin == "all":
+        tr = config.pluginmanager.getplugin("terminalreporter")
+        # if no terminal reporter plugin is present, nothing we can do here;
+        # this can happen when this function executes in a slave node
+        # when using pytest-xdist, for example
+        if tr is not None:
+            # pastebin file will be utf-8 encoded binary file
+            config._pastebinfile = tempfile.TemporaryFile("w+b")
+            oldwrite = tr._tw.write
+
+            def tee_write(s, **kwargs):
+                oldwrite(s, **kwargs)
+                if isinstance(s, six.text_type):
+                    s = s.encode("utf-8")
+                config._pastebinfile.write(s)
+
+            tr._tw.write = tee_write
+
+
+def pytest_unconfigure(config):
+    if hasattr(config, "_pastebinfile"):
+        # get terminal contents and delete file
+        config._pastebinfile.seek(0)
+        sessionlog = config._pastebinfile.read()
+        config._pastebinfile.close()
+        del config._pastebinfile
+        # undo our patching in the terminal reporter
+        tr = config.pluginmanager.getplugin("terminalreporter")
+        del tr._tw.__dict__["write"]
+        # write summary
+        tr.write_sep("=", "Sending information to Paste Service")
+        pastebinurl = create_new_paste(sessionlog)
+        tr.write_line("pastebin session-log: %s\n" % pastebinurl)
+
+
+def create_new_paste(contents):
+    """
+    Creates a new paste using bpaste.net service.
+
+    :contents: paste contents as utf-8 encoded bytes
+    :returns: url to the pasted contents
+    """
+    import re
+
+    if sys.version_info < (3, 0):
+        from urllib import urlopen, urlencode
+    else:
+        from urllib.request import urlopen
+        from urllib.parse import urlencode
+
+    params = {
+        "code": contents,
+        "lexer": "python3" if sys.version_info[0] == 3 else "python",
+        "expiry": "1week",
+    }
+    url = "https://bpaste.net"
+    response = urlopen(url, data=urlencode(params).encode("ascii")).read()
+    m = re.search(r'href="/raw/(\w+)"', response.decode("utf-8"))
+    if m:
+        return "%s/show/%s" % (url, m.group(1))
+    else:
+        return "bad response: " + response
+
+
+def pytest_terminal_summary(terminalreporter):
+    import _pytest.config
+
+    if terminalreporter.config.option.pastebin != "failed":
+        return
+    tr = terminalreporter
+    if "failed" in tr.stats:
+        terminalreporter.write_sep("=", "Sending information to Paste Service")
+        for rep in terminalreporter.stats.get("failed"):
+            try:
+                msg = rep.longrepr.reprtraceback.reprentries[-1].reprfileloc
+            except AttributeError:
+                msg = tr._getfailureheadline(rep)
+            tw = _pytest.config.create_terminal_writer(
+                terminalreporter.config, stringio=True
+            )
+            rep.toterminal(tw)
+            s = tw.stringio.getvalue()
+            assert len(s)
+            pastebinurl = create_new_paste(s)
+            tr.write_line("%s --> %s" % (msg, pastebinurl))
Index: venv/Lib/site-packages/attr/_config.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/_config.py	(date 1543190976878)
+++ venv/Lib/site-packages/attr/_config.py	(date 1543190976878)
@@ -0,0 +1,23 @@
+from __future__ import absolute_import, division, print_function
+
+
+__all__ = ["set_run_validators", "get_run_validators"]
+
+_run_validators = True
+
+
+def set_run_validators(run):
+    """
+    Set whether or not validators are run.  By default, they are run.
+    """
+    if not isinstance(run, bool):
+        raise TypeError("'run' must be bool.")
+    global _run_validators
+    _run_validators = run
+
+
+def get_run_validators():
+    """
+    Return whether or not validators are run.
+    """
+    return _run_validators
Index: venv/Lib/site-packages/_pytest/skipping.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/skipping.py	(date 1543190976890)
+++ venv/Lib/site-packages/_pytest/skipping.py	(date 1543190976890)
@@ -0,0 +1,298 @@
+""" support for skip/xfail functions and markers. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+from _pytest.config import hookimpl
+from _pytest.mark.evaluate import MarkEvaluator
+from _pytest.outcomes import fail
+from _pytest.outcomes import skip
+from _pytest.outcomes import xfail
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group.addoption(
+        "--runxfail",
+        action="store_true",
+        dest="runxfail",
+        default=False,
+        help="run tests even if they are marked xfail",
+    )
+
+    parser.addini(
+        "xfail_strict",
+        "default for the strict parameter of xfail "
+        "markers when not given explicitly (default: False)",
+        default=False,
+        type="bool",
+    )
+
+
+def pytest_configure(config):
+    if config.option.runxfail:
+        # yay a hack
+        import pytest
+
+        old = pytest.xfail
+        config._cleanup.append(lambda: setattr(pytest, "xfail", old))
+
+        def nop(*args, **kwargs):
+            pass
+
+        nop.Exception = xfail.Exception
+        setattr(pytest, "xfail", nop)
+
+    config.addinivalue_line(
+        "markers",
+        "skip(reason=None): skip the given test function with an optional reason. "
+        'Example: skip(reason="no way of currently testing this") skips the '
+        "test.",
+    )
+    config.addinivalue_line(
+        "markers",
+        "skipif(condition): skip the given test function if eval(condition) "
+        "results in a True value.  Evaluation happens within the "
+        "module global context. Example: skipif('sys.platform == \"win32\"') "
+        "skips the test if we are on the win32 platform. see "
+        "https://docs.pytest.org/en/latest/skipping.html",
+    )
+    config.addinivalue_line(
+        "markers",
+        "xfail(condition, reason=None, run=True, raises=None, strict=False): "
+        "mark the test function as an expected failure if eval(condition) "
+        "has a True value. Optionally specify a reason for better reporting "
+        "and run=False if you don't even want to execute the test function. "
+        "If only specific exception(s) are expected, you can list them in "
+        "raises, and if the test fails in other ways, it will be reported as "
+        "a true failure. See https://docs.pytest.org/en/latest/skipping.html",
+    )
+
+
+@hookimpl(tryfirst=True)
+def pytest_runtest_setup(item):
+    # Check if skip or skipif are specified as pytest marks
+    item._skipped_by_mark = False
+    eval_skipif = MarkEvaluator(item, "skipif")
+    if eval_skipif.istrue():
+        item._skipped_by_mark = True
+        skip(eval_skipif.getexplanation())
+
+    for skip_info in item.iter_markers(name="skip"):
+        item._skipped_by_mark = True
+        if "reason" in skip_info.kwargs:
+            skip(skip_info.kwargs["reason"])
+        elif skip_info.args:
+            skip(skip_info.args[0])
+        else:
+            skip("unconditional skip")
+
+    item._evalxfail = MarkEvaluator(item, "xfail")
+    check_xfail_no_run(item)
+
+
+@hookimpl(hookwrapper=True)
+def pytest_pyfunc_call(pyfuncitem):
+    check_xfail_no_run(pyfuncitem)
+    outcome = yield
+    passed = outcome.excinfo is None
+    if passed:
+        check_strict_xfail(pyfuncitem)
+
+
+def check_xfail_no_run(item):
+    """check xfail(run=False)"""
+    if not item.config.option.runxfail:
+        evalxfail = item._evalxfail
+        if evalxfail.istrue():
+            if not evalxfail.get("run", True):
+                xfail("[NOTRUN] " + evalxfail.getexplanation())
+
+
+def check_strict_xfail(pyfuncitem):
+    """check xfail(strict=True) for the given PASSING test"""
+    evalxfail = pyfuncitem._evalxfail
+    if evalxfail.istrue():
+        strict_default = pyfuncitem.config.getini("xfail_strict")
+        is_strict_xfail = evalxfail.get("strict", strict_default)
+        if is_strict_xfail:
+            del pyfuncitem._evalxfail
+            explanation = evalxfail.getexplanation()
+            fail("[XPASS(strict)] " + explanation, pytrace=False)
+
+
+@hookimpl(hookwrapper=True)
+def pytest_runtest_makereport(item, call):
+    outcome = yield
+    rep = outcome.get_result()
+    evalxfail = getattr(item, "_evalxfail", None)
+    # unitttest special case, see setting of _unexpectedsuccess
+    if hasattr(item, "_unexpectedsuccess") and rep.when == "call":
+        from _pytest.compat import _is_unittest_unexpected_success_a_failure
+
+        if item._unexpectedsuccess:
+            rep.longrepr = "Unexpected success: {}".format(item._unexpectedsuccess)
+        else:
+            rep.longrepr = "Unexpected success"
+        if _is_unittest_unexpected_success_a_failure():
+            rep.outcome = "failed"
+        else:
+            rep.outcome = "passed"
+            rep.wasxfail = rep.longrepr
+    elif item.config.option.runxfail:
+        pass  # don't interefere
+    elif call.excinfo and call.excinfo.errisinstance(xfail.Exception):
+        rep.wasxfail = "reason: " + call.excinfo.value.msg
+        rep.outcome = "skipped"
+    elif evalxfail and not rep.skipped and evalxfail.wasvalid() and evalxfail.istrue():
+        if call.excinfo:
+            if evalxfail.invalidraise(call.excinfo.value):
+                rep.outcome = "failed"
+            else:
+                rep.outcome = "skipped"
+                rep.wasxfail = evalxfail.getexplanation()
+        elif call.when == "call":
+            strict_default = item.config.getini("xfail_strict")
+            is_strict_xfail = evalxfail.get("strict", strict_default)
+            explanation = evalxfail.getexplanation()
+            if is_strict_xfail:
+                rep.outcome = "failed"
+                rep.longrepr = "[XPASS(strict)] {}".format(explanation)
+            else:
+                rep.outcome = "passed"
+                rep.wasxfail = explanation
+    elif (
+        getattr(item, "_skipped_by_mark", False)
+        and rep.skipped
+        and type(rep.longrepr) is tuple
+    ):
+        # skipped by mark.skipif; change the location of the failure
+        # to point to the item definition, otherwise it will display
+        # the location of where the skip exception was raised within pytest
+        filename, line, reason = rep.longrepr
+        filename, line = item.location[:2]
+        rep.longrepr = filename, line, reason
+
+
+# called by terminalreporter progress reporting
+
+
+def pytest_report_teststatus(report):
+    if hasattr(report, "wasxfail"):
+        if report.skipped:
+            return "xfailed", "x", "xfail"
+        elif report.passed:
+            return "xpassed", "X", ("XPASS", {"yellow": True})
+
+
+# called by the terminalreporter instance/plugin
+
+
+def pytest_terminal_summary(terminalreporter):
+    tr = terminalreporter
+    if not tr.reportchars:
+        # for name in "xfailed skipped failed xpassed":
+        #    if not tr.stats.get(name, 0):
+        #        tr.write_line("HINT: use '-r' option to see extra "
+        #              "summary info about tests")
+        #        break
+        return
+
+    lines = []
+    for char in tr.reportchars:
+        action = REPORTCHAR_ACTIONS.get(char, lambda tr, lines: None)
+        action(terminalreporter, lines)
+
+    if lines:
+        tr._tw.sep("=", "short test summary info")
+        for line in lines:
+            tr._tw.line(line)
+
+
+def show_simple(terminalreporter, lines, stat, format):
+    failed = terminalreporter.stats.get(stat)
+    if failed:
+        for rep in failed:
+            pos = terminalreporter.config.cwd_relative_nodeid(rep.nodeid)
+            lines.append(format % (pos,))
+
+
+def show_xfailed(terminalreporter, lines):
+    xfailed = terminalreporter.stats.get("xfailed")
+    if xfailed:
+        for rep in xfailed:
+            pos = terminalreporter.config.cwd_relative_nodeid(rep.nodeid)
+            reason = rep.wasxfail
+            lines.append("XFAIL %s" % (pos,))
+            if reason:
+                lines.append("  " + str(reason))
+
+
+def show_xpassed(terminalreporter, lines):
+    xpassed = terminalreporter.stats.get("xpassed")
+    if xpassed:
+        for rep in xpassed:
+            pos = terminalreporter.config.cwd_relative_nodeid(rep.nodeid)
+            reason = rep.wasxfail
+            lines.append("XPASS %s %s" % (pos, reason))
+
+
+def folded_skips(skipped):
+    d = {}
+    for event in skipped:
+        key = event.longrepr
+        assert len(key) == 3, (event, key)
+        keywords = getattr(event, "keywords", {})
+        # folding reports with global pytestmark variable
+        # this is workaround, because for now we cannot identify the scope of a skip marker
+        # TODO: revisit after marks scope would be fixed
+        when = getattr(event, "when", None)
+        if when == "setup" and "skip" in keywords and "pytestmark" not in keywords:
+            key = (key[0], None, key[2])
+        d.setdefault(key, []).append(event)
+    values = []
+    for key, events in d.items():
+        values.append((len(events),) + key)
+    return values
+
+
+def show_skipped(terminalreporter, lines):
+    tr = terminalreporter
+    skipped = tr.stats.get("skipped", [])
+    if skipped:
+        # if not tr.hasopt('skipped'):
+        #    tr.write_line(
+        #        "%d skipped tests, specify -rs for more info" %
+        #        len(skipped))
+        #    return
+        fskips = folded_skips(skipped)
+        if fskips:
+            # tr.write_sep("_", "skipped test summary")
+            for num, fspath, lineno, reason in fskips:
+                if reason.startswith("Skipped: "):
+                    reason = reason[9:]
+                if lineno is not None:
+                    lines.append(
+                        "SKIP [%d] %s:%d: %s" % (num, fspath, lineno + 1, reason)
+                    )
+                else:
+                    lines.append("SKIP [%d] %s: %s" % (num, fspath, reason))
+
+
+def shower(stat, format):
+    def show_(terminalreporter, lines):
+        return show_simple(terminalreporter, lines, stat, format)
+
+    return show_
+
+
+REPORTCHAR_ACTIONS = {
+    "x": show_xfailed,
+    "X": show_xpassed,
+    "f": shower("failed", "FAIL %s"),
+    "F": shower("failed", "FAIL %s"),
+    "s": show_skipped,
+    "S": show_skipped,
+    "p": shower("passed", "PASSED %s"),
+    "E": shower("error", "ERROR %s"),
+}
Index: venv/Lib/site-packages/attr/_compat.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/_compat.py	(date 1543190976900)
+++ venv/Lib/site-packages/attr/_compat.py	(date 1543190976900)
@@ -0,0 +1,163 @@
+from __future__ import absolute_import, division, print_function
+
+import platform
+import sys
+import types
+import warnings
+
+
+PY2 = sys.version_info[0] == 2
+PYPY = platform.python_implementation() == "PyPy"
+
+
+if PYPY or sys.version_info[:2] >= (3, 6):
+    ordered_dict = dict
+else:
+    from collections import OrderedDict
+
+    ordered_dict = OrderedDict
+
+
+if PY2:
+    from UserDict import IterableUserDict
+
+    # We 'bundle' isclass instead of using inspect as importing inspect is
+    # fairly expensive (order of 10-15 ms for a modern machine in 2016)
+    def isclass(klass):
+        return isinstance(klass, (type, types.ClassType))
+
+    # TYPE is used in exceptions, repr(int) is different on Python 2 and 3.
+    TYPE = "type"
+
+    def iteritems(d):
+        return d.iteritems()
+
+    # Python 2 is bereft of a read-only dict proxy, so we make one!
+    class ReadOnlyDict(IterableUserDict):
+        """
+        Best-effort read-only dict wrapper.
+        """
+
+        def __setitem__(self, key, val):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise TypeError(
+                "'mappingproxy' object does not support item assignment"
+            )
+
+        def update(self, _):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'update'"
+            )
+
+        def __delitem__(self, _):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise TypeError(
+                "'mappingproxy' object does not support item deletion"
+            )
+
+        def clear(self):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'clear'"
+            )
+
+        def pop(self, key, default=None):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'pop'"
+            )
+
+        def popitem(self):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'popitem'"
+            )
+
+        def setdefault(self, key, default=None):
+            # We gently pretend we're a Python 3 mappingproxy.
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'setdefault'"
+            )
+
+        def __repr__(self):
+            # Override to be identical to the Python 3 version.
+            return "mappingproxy(" + repr(self.data) + ")"
+
+    def metadata_proxy(d):
+        res = ReadOnlyDict()
+        res.data.update(d)  # We blocked update, so we have to do it like this.
+        return res
+
+
+else:
+
+    def isclass(klass):
+        return isinstance(klass, type)
+
+    TYPE = "class"
+
+    def iteritems(d):
+        return d.items()
+
+    def metadata_proxy(d):
+        return types.MappingProxyType(dict(d))
+
+
+def import_ctypes():
+    """
+    Moved into a function for testability.
+    """
+    import ctypes
+
+    return ctypes
+
+
+if not PY2:
+
+    def just_warn(*args, **kw):
+        """
+        We only warn on Python 3 because we are not aware of any concrete
+        consequences of not setting the cell on Python 2.
+        """
+        warnings.warn(
+            "Missing ctypes.  Some features like bare super() or accessing "
+            "__class__ will not work with slots classes.",
+            RuntimeWarning,
+            stacklevel=2,
+        )
+
+
+else:
+
+    def just_warn(*args, **kw):  # pragma: nocover
+        """
+        We only warn on Python 3 because we are not aware of any concrete
+        consequences of not setting the cell on Python 2.
+        """
+
+
+def make_set_closure_cell():
+    """
+    Moved into a function for testability.
+    """
+    if PYPY:  # pragma: no cover
+
+        def set_closure_cell(cell, value):
+            cell.__setstate__((value,))
+
+    else:
+        try:
+            ctypes = import_ctypes()
+
+            set_closure_cell = ctypes.pythonapi.PyCell_Set
+            set_closure_cell.argtypes = (ctypes.py_object, ctypes.py_object)
+            set_closure_cell.restype = ctypes.c_int
+        except Exception:
+            # We try best effort to set the cell, but sometimes it's not
+            # possible.  For example on Jython or on GAE.
+            set_closure_cell = just_warn
+    return set_closure_cell
+
+
+set_closure_cell = make_set_closure_cell()
Index: venv/Lib/site-packages/_pytest/runner.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/runner.py	(date 1543190976911)
+++ venv/Lib/site-packages/_pytest/runner.py	(date 1543190976911)
@@ -0,0 +1,394 @@
+""" basic collect and runtest protocol implementations """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import bdb
+import os
+import sys
+from time import time
+
+import six
+
+from .reports import CollectErrorRepr
+from .reports import CollectReport
+from .reports import TestReport
+from _pytest._code.code import ExceptionInfo
+from _pytest.outcomes import skip
+from _pytest.outcomes import Skipped
+from _pytest.outcomes import TEST_OUTCOME
+
+#
+# pytest plugin hooks
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("terminal reporting", "reporting", after="general")
+    group.addoption(
+        "--durations",
+        action="store",
+        type=int,
+        default=None,
+        metavar="N",
+        help="show N slowest setup/test durations (N=0 for all).",
+    ),
+
+
+def pytest_terminal_summary(terminalreporter):
+    durations = terminalreporter.config.option.durations
+    verbose = terminalreporter.config.getvalue("verbose")
+    if durations is None:
+        return
+    tr = terminalreporter
+    dlist = []
+    for replist in tr.stats.values():
+        for rep in replist:
+            if hasattr(rep, "duration"):
+                dlist.append(rep)
+    if not dlist:
+        return
+    dlist.sort(key=lambda x: x.duration)
+    dlist.reverse()
+    if not durations:
+        tr.write_sep("=", "slowest test durations")
+    else:
+        tr.write_sep("=", "slowest %s test durations" % durations)
+        dlist = dlist[:durations]
+
+    for rep in dlist:
+        if verbose < 2 and rep.duration < 0.005:
+            tr.write_line("")
+            tr.write_line("(0.00 durations hidden.  Use -vv to show these durations.)")
+            break
+        tr.write_line("%02.2fs %-8s %s" % (rep.duration, rep.when, rep.nodeid))
+
+
+def pytest_sessionstart(session):
+    session._setupstate = SetupState()
+
+
+def pytest_sessionfinish(session):
+    session._setupstate.teardown_all()
+
+
+def pytest_runtest_protocol(item, nextitem):
+    item.ihook.pytest_runtest_logstart(nodeid=item.nodeid, location=item.location)
+    runtestprotocol(item, nextitem=nextitem)
+    item.ihook.pytest_runtest_logfinish(nodeid=item.nodeid, location=item.location)
+    return True
+
+
+def runtestprotocol(item, log=True, nextitem=None):
+    hasrequest = hasattr(item, "_request")
+    if hasrequest and not item._request:
+        item._initrequest()
+    rep = call_and_report(item, "setup", log)
+    reports = [rep]
+    if rep.passed:
+        if item.config.option.setupshow:
+            show_test_item(item)
+        if not item.config.option.setuponly:
+            reports.append(call_and_report(item, "call", log))
+    reports.append(call_and_report(item, "teardown", log, nextitem=nextitem))
+    # after all teardown hooks have been called
+    # want funcargs and request info to go away
+    if hasrequest:
+        item._request = False
+        item.funcargs = None
+    return reports
+
+
+def show_test_item(item):
+    """Show test function, parameters and the fixtures of the test item."""
+    tw = item.config.get_terminal_writer()
+    tw.line()
+    tw.write(" " * 8)
+    tw.write(item._nodeid)
+    used_fixtures = sorted(item._fixtureinfo.name2fixturedefs.keys())
+    if used_fixtures:
+        tw.write(" (fixtures used: {})".format(", ".join(used_fixtures)))
+
+
+def pytest_runtest_setup(item):
+    _update_current_test_var(item, "setup")
+    item.session._setupstate.prepare(item)
+
+
+def pytest_runtest_call(item):
+    _update_current_test_var(item, "call")
+    sys.last_type, sys.last_value, sys.last_traceback = (None, None, None)
+    try:
+        item.runtest()
+    except Exception:
+        # Store trace info to allow postmortem debugging
+        type, value, tb = sys.exc_info()
+        tb = tb.tb_next  # Skip *this* frame
+        sys.last_type = type
+        sys.last_value = value
+        sys.last_traceback = tb
+        del type, value, tb  # Get rid of these in this frame
+        raise
+
+
+def pytest_runtest_teardown(item, nextitem):
+    _update_current_test_var(item, "teardown")
+    item.session._setupstate.teardown_exact(item, nextitem)
+    _update_current_test_var(item, None)
+
+
+def _update_current_test_var(item, when):
+    """
+    Update PYTEST_CURRENT_TEST to reflect the current item and stage.
+
+    If ``when`` is None, delete PYTEST_CURRENT_TEST from the environment.
+    """
+    var_name = "PYTEST_CURRENT_TEST"
+    if when:
+        value = "{} ({})".format(item.nodeid, when)
+        # don't allow null bytes on environment variables (see #2644, #2957)
+        value = value.replace("\x00", "(null)")
+        os.environ[var_name] = value
+    else:
+        os.environ.pop(var_name)
+
+
+def pytest_report_teststatus(report):
+    if report.when in ("setup", "teardown"):
+        if report.failed:
+            #      category, shortletter, verbose-word
+            return "error", "E", "ERROR"
+        elif report.skipped:
+            return "skipped", "s", "SKIPPED"
+        else:
+            return "", "", ""
+
+
+#
+# Implementation
+
+
+def call_and_report(item, when, log=True, **kwds):
+    call = call_runtest_hook(item, when, **kwds)
+    hook = item.ihook
+    report = hook.pytest_runtest_makereport(item=item, call=call)
+    if log:
+        hook.pytest_runtest_logreport(report=report)
+    if check_interactive_exception(call, report):
+        hook.pytest_exception_interact(node=item, call=call, report=report)
+    return report
+
+
+def check_interactive_exception(call, report):
+    return call.excinfo and not (
+        hasattr(report, "wasxfail")
+        or call.excinfo.errisinstance(skip.Exception)
+        or call.excinfo.errisinstance(bdb.BdbQuit)
+    )
+
+
+def call_runtest_hook(item, when, **kwds):
+    hookname = "pytest_runtest_" + when
+    ihook = getattr(item.ihook, hookname)
+    return CallInfo(
+        lambda: ihook(item=item, **kwds),
+        when=when,
+        treat_keyboard_interrupt_as_exception=item.config.getvalue("usepdb"),
+    )
+
+
+class CallInfo(object):
+    """ Result/Exception info a function invocation. """
+
+    #: None or ExceptionInfo object.
+    excinfo = None
+
+    def __init__(self, func, when, treat_keyboard_interrupt_as_exception=False):
+        #: context of invocation: one of "setup", "call",
+        #: "teardown", "memocollect"
+        self.when = when
+        self.start = time()
+        try:
+            self.result = func()
+        except KeyboardInterrupt:
+            if treat_keyboard_interrupt_as_exception:
+                self.excinfo = ExceptionInfo()
+            else:
+                self.stop = time()
+                raise
+        except:  # noqa
+            self.excinfo = ExceptionInfo()
+        self.stop = time()
+
+    def __repr__(self):
+        if self.excinfo:
+            status = "exception: %s" % str(self.excinfo.value)
+        else:
+            result = getattr(self, "result", "<NOTSET>")
+            status = "result: %r" % (result,)
+        return "<CallInfo when=%r %s>" % (self.when, status)
+
+
+def pytest_runtest_makereport(item, call):
+    when = call.when
+    duration = call.stop - call.start
+    keywords = {x: 1 for x in item.keywords}
+    excinfo = call.excinfo
+    sections = []
+    if not call.excinfo:
+        outcome = "passed"
+        longrepr = None
+    else:
+        if not isinstance(excinfo, ExceptionInfo):
+            outcome = "failed"
+            longrepr = excinfo
+        elif excinfo.errisinstance(skip.Exception):
+            outcome = "skipped"
+            r = excinfo._getreprcrash()
+            longrepr = (str(r.path), r.lineno, r.message)
+        else:
+            outcome = "failed"
+            if call.when == "call":
+                longrepr = item.repr_failure(excinfo)
+            else:  # exception in setup or teardown
+                longrepr = item._repr_failure_py(
+                    excinfo, style=item.config.option.tbstyle
+                )
+    for rwhen, key, content in item._report_sections:
+        sections.append(("Captured %s %s" % (key, rwhen), content))
+    return TestReport(
+        item.nodeid,
+        item.location,
+        keywords,
+        outcome,
+        longrepr,
+        when,
+        sections,
+        duration,
+        user_properties=item.user_properties,
+    )
+
+
+def pytest_make_collect_report(collector):
+    call = CallInfo(lambda: list(collector.collect()), "collect")
+    longrepr = None
+    if not call.excinfo:
+        outcome = "passed"
+    else:
+        from _pytest import nose
+
+        skip_exceptions = (Skipped,) + nose.get_skip_exceptions()
+        if call.excinfo.errisinstance(skip_exceptions):
+            outcome = "skipped"
+            r = collector._repr_failure_py(call.excinfo, "line").reprcrash
+            longrepr = (str(r.path), r.lineno, r.message)
+        else:
+            outcome = "failed"
+            errorinfo = collector.repr_failure(call.excinfo)
+            if not hasattr(errorinfo, "toterminal"):
+                errorinfo = CollectErrorRepr(errorinfo)
+            longrepr = errorinfo
+    rep = CollectReport(
+        collector.nodeid, outcome, longrepr, getattr(call, "result", None)
+    )
+    rep.call = call  # see collect_one_node
+    return rep
+
+
+class SetupState(object):
+    """ shared state for setting up/tearing down test items or collectors. """
+
+    def __init__(self):
+        self.stack = []
+        self._finalizers = {}
+
+    def addfinalizer(self, finalizer, colitem):
+        """ attach a finalizer to the given colitem.
+        if colitem is None, this will add a finalizer that
+        is called at the end of teardown_all().
+        """
+        assert colitem and not isinstance(colitem, tuple)
+        assert callable(finalizer)
+        # assert colitem in self.stack  # some unit tests don't setup stack :/
+        self._finalizers.setdefault(colitem, []).append(finalizer)
+
+    def _pop_and_teardown(self):
+        colitem = self.stack.pop()
+        self._teardown_with_finalization(colitem)
+
+    def _callfinalizers(self, colitem):
+        finalizers = self._finalizers.pop(colitem, None)
+        exc = None
+        while finalizers:
+            fin = finalizers.pop()
+            try:
+                fin()
+            except TEST_OUTCOME:
+                # XXX Only first exception will be seen by user,
+                #     ideally all should be reported.
+                if exc is None:
+                    exc = sys.exc_info()
+        if exc:
+            six.reraise(*exc)
+
+    def _teardown_with_finalization(self, colitem):
+        self._callfinalizers(colitem)
+        if hasattr(colitem, "teardown"):
+            colitem.teardown()
+        for colitem in self._finalizers:
+            assert (
+                colitem is None or colitem in self.stack or isinstance(colitem, tuple)
+            )
+
+    def teardown_all(self):
+        while self.stack:
+            self._pop_and_teardown()
+        for key in list(self._finalizers):
+            self._teardown_with_finalization(key)
+        assert not self._finalizers
+
+    def teardown_exact(self, item, nextitem):
+        needed_collectors = nextitem and nextitem.listchain() or []
+        self._teardown_towards(needed_collectors)
+
+    def _teardown_towards(self, needed_collectors):
+        exc = None
+        while self.stack:
+            if self.stack == needed_collectors[: len(self.stack)]:
+                break
+            try:
+                self._pop_and_teardown()
+            except TEST_OUTCOME:
+                # XXX Only first exception will be seen by user,
+                #     ideally all should be reported.
+                if exc is None:
+                    exc = sys.exc_info()
+        if exc:
+            six.reraise(*exc)
+
+    def prepare(self, colitem):
+        """ setup objects along the collector chain to the test-method
+            and teardown previously setup objects."""
+        needed_collectors = colitem.listchain()
+        self._teardown_towards(needed_collectors)
+
+        # check if the last collection node has raised an error
+        for col in self.stack:
+            if hasattr(col, "_prepare_exc"):
+                six.reraise(*col._prepare_exc)
+        for col in needed_collectors[len(self.stack) :]:
+            self.stack.append(col)
+            try:
+                col.setup()
+            except TEST_OUTCOME:
+                col._prepare_exc = sys.exc_info()
+                raise
+
+
+def collect_one_node(collector):
+    ihook = collector.ihook
+    ihook.pytest_collectstart(collector=collector)
+    rep = ihook.pytest_make_collect_report(collector=collector)
+    call = rep.__dict__.pop("call", None)
+    if call and check_interactive_exception(call, rep):
+        ihook.pytest_exception_interact(node=collector, call=call, report=rep)
+    return rep
Index: venv/Lib/site-packages/attr/exceptions.pyi
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/exceptions.pyi	(date 1543190976938)
+++ venv/Lib/site-packages/attr/exceptions.pyi	(date 1543190976938)
@@ -0,0 +1,7 @@
+class FrozenInstanceError(AttributeError):
+    msg: str = ...
+
+class AttrsAttributeNotFoundError(ValueError): ...
+class NotAnAttrsClassError(ValueError): ...
+class DefaultAlreadySetError(RuntimeError): ...
+class UnannotatedAttributeError(RuntimeError): ...
Index: venv/Lib/site-packages/_pytest/fixtures.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/fixtures.py	(date 1543190976954)
+++ venv/Lib/site-packages/_pytest/fixtures.py	(date 1543190976954)
@@ -0,0 +1,1398 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import functools
+import inspect
+import sys
+import warnings
+from collections import defaultdict
+from collections import deque
+from collections import OrderedDict
+
+import attr
+import py
+import six
+from more_itertools import flatten
+from py._code.code import FormattedExcinfo
+
+import _pytest
+from _pytest import nodes
+from _pytest._code.code import TerminalRepr
+from _pytest.compat import _format_args
+from _pytest.compat import _PytestWrapper
+from _pytest.compat import exc_clear
+from _pytest.compat import FuncargnamesCompatAttr
+from _pytest.compat import get_real_func
+from _pytest.compat import get_real_method
+from _pytest.compat import getfslineno
+from _pytest.compat import getfuncargnames
+from _pytest.compat import getimfunc
+from _pytest.compat import getlocation
+from _pytest.compat import is_generator
+from _pytest.compat import isclass
+from _pytest.compat import NOTSET
+from _pytest.compat import safe_getattr
+from _pytest.deprecated import FIXTURE_FUNCTION_CALL
+from _pytest.deprecated import FIXTURE_NAMED_REQUEST
+from _pytest.outcomes import fail
+from _pytest.outcomes import TEST_OUTCOME
+
+FIXTURE_MSG = 'fixtures cannot have "pytest_funcarg__" prefix and be decorated with @pytest.fixture:\n{}'
+
+
+@attr.s(frozen=True)
+class PseudoFixtureDef(object):
+    cached_result = attr.ib()
+    scope = attr.ib()
+
+
+def pytest_sessionstart(session):
+    import _pytest.python
+    import _pytest.nodes
+
+    scopename2class.update(
+        {
+            "package": _pytest.python.Package,
+            "class": _pytest.python.Class,
+            "module": _pytest.python.Module,
+            "function": _pytest.nodes.Item,
+            "session": _pytest.main.Session,
+        }
+    )
+    session._fixturemanager = FixtureManager(session)
+
+
+scopename2class = {}
+
+
+scope2props = dict(session=())
+scope2props["package"] = ("fspath",)
+scope2props["module"] = ("fspath", "module")
+scope2props["class"] = scope2props["module"] + ("cls",)
+scope2props["instance"] = scope2props["class"] + ("instance",)
+scope2props["function"] = scope2props["instance"] + ("function", "keywords")
+
+
+def scopeproperty(name=None, doc=None):
+    def decoratescope(func):
+        scopename = name or func.__name__
+
+        def provide(self):
+            if func.__name__ in scope2props[self.scope]:
+                return func(self)
+            raise AttributeError(
+                "%s not available in %s-scoped context" % (scopename, self.scope)
+            )
+
+        return property(provide, None, None, func.__doc__)
+
+    return decoratescope
+
+
+def get_scope_package(node, fixturedef):
+    import pytest
+
+    cls = pytest.Package
+    current = node
+    fixture_package_name = "%s/%s" % (fixturedef.baseid, "__init__.py")
+    while current and (
+        type(current) is not cls or fixture_package_name != current.nodeid
+    ):
+        current = current.parent
+    if current is None:
+        return node.session
+    return current
+
+
+def get_scope_node(node, scope):
+    cls = scopename2class.get(scope)
+    if cls is None:
+        raise ValueError("unknown scope")
+    return node.getparent(cls)
+
+
+def add_funcarg_pseudo_fixture_def(collector, metafunc, fixturemanager):
+    # this function will transform all collected calls to a functions
+    # if they use direct funcargs (i.e. direct parametrization)
+    # because we want later test execution to be able to rely on
+    # an existing FixtureDef structure for all arguments.
+    # XXX we can probably avoid this algorithm  if we modify CallSpec2
+    # to directly care for creating the fixturedefs within its methods.
+    if not metafunc._calls[0].funcargs:
+        return  # this function call does not have direct parametrization
+    # collect funcargs of all callspecs into a list of values
+    arg2params = {}
+    arg2scope = {}
+    for callspec in metafunc._calls:
+        for argname, argvalue in callspec.funcargs.items():
+            assert argname not in callspec.params
+            callspec.params[argname] = argvalue
+            arg2params_list = arg2params.setdefault(argname, [])
+            callspec.indices[argname] = len(arg2params_list)
+            arg2params_list.append(argvalue)
+            if argname not in arg2scope:
+                scopenum = callspec._arg2scopenum.get(argname, scopenum_function)
+                arg2scope[argname] = scopes[scopenum]
+        callspec.funcargs.clear()
+
+    # register artificial FixtureDef's so that later at test execution
+    # time we can rely on a proper FixtureDef to exist for fixture setup.
+    arg2fixturedefs = metafunc._arg2fixturedefs
+    for argname, valuelist in arg2params.items():
+        # if we have a scope that is higher than function we need
+        # to make sure we only ever create an according fixturedef on
+        # a per-scope basis. We thus store and cache the fixturedef on the
+        # node related to the scope.
+        scope = arg2scope[argname]
+        node = None
+        if scope != "function":
+            node = get_scope_node(collector, scope)
+            if node is None:
+                assert scope == "class" and isinstance(collector, _pytest.python.Module)
+                # use module-level collector for class-scope (for now)
+                node = collector
+        if node and argname in node._name2pseudofixturedef:
+            arg2fixturedefs[argname] = [node._name2pseudofixturedef[argname]]
+        else:
+            fixturedef = FixtureDef(
+                fixturemanager,
+                "",
+                argname,
+                get_direct_param_fixture_func,
+                arg2scope[argname],
+                valuelist,
+                False,
+                False,
+            )
+            arg2fixturedefs[argname] = [fixturedef]
+            if node is not None:
+                node._name2pseudofixturedef[argname] = fixturedef
+
+
+def getfixturemarker(obj):
+    """ return fixturemarker or None if it doesn't exist or raised
+    exceptions."""
+    try:
+        return getattr(obj, "_pytestfixturefunction", None)
+    except TEST_OUTCOME:
+        # some objects raise errors like request (from flask import request)
+        # we don't expect them to be fixture functions
+        return None
+
+
+def get_parametrized_fixture_keys(item, scopenum):
+    """ return list of keys for all parametrized arguments which match
+    the specified scope. """
+    assert scopenum < scopenum_function  # function
+    try:
+        cs = item.callspec
+    except AttributeError:
+        pass
+    else:
+        # cs.indices.items() is random order of argnames.  Need to
+        # sort this so that different calls to
+        # get_parametrized_fixture_keys will be deterministic.
+        for argname, param_index in sorted(cs.indices.items()):
+            if cs._arg2scopenum[argname] != scopenum:
+                continue
+            if scopenum == 0:  # session
+                key = (argname, param_index)
+            elif scopenum == 1:  # package
+                key = (argname, param_index, item.fspath.dirpath())
+            elif scopenum == 2:  # module
+                key = (argname, param_index, item.fspath)
+            elif scopenum == 3:  # class
+                key = (argname, param_index, item.fspath, item.cls)
+            yield key
+
+
+# algorithm for sorting on a per-parametrized resource setup basis
+# it is called for scopenum==0 (session) first and performs sorting
+# down to the lower scopes such as to minimize number of "high scope"
+# setups and teardowns
+
+
+def reorder_items(items):
+    argkeys_cache = {}
+    items_by_argkey = {}
+    for scopenum in range(0, scopenum_function):
+        argkeys_cache[scopenum] = d = {}
+        items_by_argkey[scopenum] = item_d = defaultdict(deque)
+        for item in items:
+            keys = OrderedDict.fromkeys(get_parametrized_fixture_keys(item, scopenum))
+            if keys:
+                d[item] = keys
+                for key in keys:
+                    item_d[key].append(item)
+    items = OrderedDict.fromkeys(items)
+    return list(reorder_items_atscope(items, argkeys_cache, items_by_argkey, 0))
+
+
+def fix_cache_order(item, argkeys_cache, items_by_argkey):
+    for scopenum in range(0, scopenum_function):
+        for key in argkeys_cache[scopenum].get(item, []):
+            items_by_argkey[scopenum][key].appendleft(item)
+
+
+def reorder_items_atscope(items, argkeys_cache, items_by_argkey, scopenum):
+    if scopenum >= scopenum_function or len(items) < 3:
+        return items
+    ignore = set()
+    items_deque = deque(items)
+    items_done = OrderedDict()
+    scoped_items_by_argkey = items_by_argkey[scopenum]
+    scoped_argkeys_cache = argkeys_cache[scopenum]
+    while items_deque:
+        no_argkey_group = OrderedDict()
+        slicing_argkey = None
+        while items_deque:
+            item = items_deque.popleft()
+            if item in items_done or item in no_argkey_group:
+                continue
+            argkeys = OrderedDict.fromkeys(
+                k for k in scoped_argkeys_cache.get(item, []) if k not in ignore
+            )
+            if not argkeys:
+                no_argkey_group[item] = None
+            else:
+                slicing_argkey, _ = argkeys.popitem()
+                # we don't have to remove relevant items from later in the deque because they'll just be ignored
+                matching_items = [
+                    i for i in scoped_items_by_argkey[slicing_argkey] if i in items
+                ]
+                for i in reversed(matching_items):
+                    fix_cache_order(i, argkeys_cache, items_by_argkey)
+                    items_deque.appendleft(i)
+                break
+        if no_argkey_group:
+            no_argkey_group = reorder_items_atscope(
+                no_argkey_group, argkeys_cache, items_by_argkey, scopenum + 1
+            )
+            for item in no_argkey_group:
+                items_done[item] = None
+        ignore.add(slicing_argkey)
+    return items_done
+
+
+def fillfixtures(function):
+    """ fill missing funcargs for a test function. """
+    try:
+        request = function._request
+    except AttributeError:
+        # XXX this special code path is only expected to execute
+        # with the oejskit plugin.  It uses classes with funcargs
+        # and we thus have to work a bit to allow this.
+        fm = function.session._fixturemanager
+        fi = fm.getfixtureinfo(function.parent, function.obj, None)
+        function._fixtureinfo = fi
+        request = function._request = FixtureRequest(function)
+        request._fillfixtures()
+        # prune out funcargs for jstests
+        newfuncargs = {}
+        for name in fi.argnames:
+            newfuncargs[name] = function.funcargs[name]
+        function.funcargs = newfuncargs
+    else:
+        request._fillfixtures()
+
+
+def get_direct_param_fixture_func(request):
+    return request.param
+
+
+@attr.s(slots=True)
+class FuncFixtureInfo(object):
+    # original function argument names
+    argnames = attr.ib(type=tuple)
+    # argnames that function immediately requires. These include argnames +
+    # fixture names specified via usefixtures and via autouse=True in fixture
+    # definitions.
+    initialnames = attr.ib(type=tuple)
+    names_closure = attr.ib()  # type: List[str]
+    name2fixturedefs = attr.ib()  # type: List[str, List[FixtureDef]]
+
+    def prune_dependency_tree(self):
+        """Recompute names_closure from initialnames and name2fixturedefs
+
+        Can only reduce names_closure, which means that the new closure will
+        always be a subset of the old one. The order is preserved.
+
+        This method is needed because direct parametrization may shadow some
+        of the fixtures that were included in the originally built dependency
+        tree. In this way the dependency tree can get pruned, and the closure
+        of argnames may get reduced.
+        """
+        closure = set()
+        working_set = set(self.initialnames)
+        while working_set:
+            argname = working_set.pop()
+            # argname may be smth not included in the original names_closure,
+            # in which case we ignore it. This currently happens with pseudo
+            # FixtureDefs which wrap 'get_direct_param_fixture_func(request)'.
+            # So they introduce the new dependency 'request' which might have
+            # been missing in the original tree (closure).
+            if argname not in closure and argname in self.names_closure:
+                closure.add(argname)
+                if argname in self.name2fixturedefs:
+                    working_set.update(self.name2fixturedefs[argname][-1].argnames)
+
+        self.names_closure[:] = sorted(closure, key=self.names_closure.index)
+
+
+class FixtureRequest(FuncargnamesCompatAttr):
+    """ A request for a fixture from a test or fixture function.
+
+    A request object gives access to the requesting test context
+    and has an optional ``param`` attribute in case
+    the fixture is parametrized indirectly.
+    """
+
+    def __init__(self, pyfuncitem):
+        self._pyfuncitem = pyfuncitem
+        #: fixture for which this request is being performed
+        self.fixturename = None
+        #: Scope string, one of "function", "class", "module", "session"
+        self.scope = "function"
+        self._fixture_defs = {}  # argname -> FixtureDef
+        fixtureinfo = pyfuncitem._fixtureinfo
+        self._arg2fixturedefs = fixtureinfo.name2fixturedefs.copy()
+        self._arg2index = {}
+        self._fixturemanager = pyfuncitem.session._fixturemanager
+
+    @property
+    def fixturenames(self):
+        """names of all active fixtures in this request"""
+        result = list(self._pyfuncitem._fixtureinfo.names_closure)
+        result.extend(set(self._fixture_defs).difference(result))
+        return result
+
+    @property
+    def node(self):
+        """ underlying collection node (depends on current request scope)"""
+        return self._getscopeitem(self.scope)
+
+    def _getnextfixturedef(self, argname):
+        fixturedefs = self._arg2fixturedefs.get(argname, None)
+        if fixturedefs is None:
+            # we arrive here because of a dynamic call to
+            # getfixturevalue(argname) usage which was naturally
+            # not known at parsing/collection time
+            parentid = self._pyfuncitem.parent.nodeid
+            fixturedefs = self._fixturemanager.getfixturedefs(argname, parentid)
+            self._arg2fixturedefs[argname] = fixturedefs
+        # fixturedefs list is immutable so we maintain a decreasing index
+        index = self._arg2index.get(argname, 0) - 1
+        if fixturedefs is None or (-index > len(fixturedefs)):
+            raise FixtureLookupError(argname, self)
+        self._arg2index[argname] = index
+        return fixturedefs[index]
+
+    @property
+    def config(self):
+        """ the pytest config object associated with this request. """
+        return self._pyfuncitem.config
+
+    @scopeproperty()
+    def function(self):
+        """ test function object if the request has a per-function scope. """
+        return self._pyfuncitem.obj
+
+    @scopeproperty("class")
+    def cls(self):
+        """ class (can be None) where the test function was collected. """
+        clscol = self._pyfuncitem.getparent(_pytest.python.Class)
+        if clscol:
+            return clscol.obj
+
+    @property
+    def instance(self):
+        """ instance (can be None) on which test function was collected. """
+        # unittest support hack, see _pytest.unittest.TestCaseFunction
+        try:
+            return self._pyfuncitem._testcase
+        except AttributeError:
+            function = getattr(self, "function", None)
+            return getattr(function, "__self__", None)
+
+    @scopeproperty()
+    def module(self):
+        """ python module object where the test function was collected. """
+        return self._pyfuncitem.getparent(_pytest.python.Module).obj
+
+    @scopeproperty()
+    def fspath(self):
+        """ the file system path of the test module which collected this test. """
+        return self._pyfuncitem.fspath
+
+    @property
+    def keywords(self):
+        """ keywords/markers dictionary for the underlying node. """
+        return self.node.keywords
+
+    @property
+    def session(self):
+        """ pytest session object. """
+        return self._pyfuncitem.session
+
+    def addfinalizer(self, finalizer):
+        """ add finalizer/teardown function to be called after the
+        last test within the requesting test context finished
+        execution. """
+        # XXX usually this method is shadowed by fixturedef specific ones
+        self._addfinalizer(finalizer, scope=self.scope)
+
+    def _addfinalizer(self, finalizer, scope):
+        colitem = self._getscopeitem(scope)
+        self._pyfuncitem.session._setupstate.addfinalizer(
+            finalizer=finalizer, colitem=colitem
+        )
+
+    def applymarker(self, marker):
+        """ Apply a marker to a single test function invocation.
+        This method is useful if you don't want to have a keyword/marker
+        on all function invocations.
+
+        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object
+            created by a call to ``pytest.mark.NAME(...)``.
+        """
+        self.node.add_marker(marker)
+
+    def raiseerror(self, msg):
+        """ raise a FixtureLookupError with the given message. """
+        raise self._fixturemanager.FixtureLookupError(None, self, msg)
+
+    def _fillfixtures(self):
+        item = self._pyfuncitem
+        fixturenames = getattr(item, "fixturenames", self.fixturenames)
+        for argname in fixturenames:
+            if argname not in item.funcargs:
+                item.funcargs[argname] = self.getfixturevalue(argname)
+
+    def cached_setup(self, setup, teardown=None, scope="module", extrakey=None):
+        """ (deprecated) Return a testing resource managed by ``setup`` &
+        ``teardown`` calls.  ``scope`` and ``extrakey`` determine when the
+        ``teardown`` function will be called so that subsequent calls to
+        ``setup`` would recreate the resource.  With pytest-2.3 you often
+        do not need ``cached_setup()`` as you can directly declare a scope
+        on a fixture function and register a finalizer through
+        ``request.addfinalizer()``.
+
+        :arg teardown: function receiving a previously setup resource.
+        :arg setup: a no-argument function creating a resource.
+        :arg scope: a string value out of ``function``, ``class``, ``module``
+            or ``session`` indicating the caching lifecycle of the resource.
+        :arg extrakey: added to internal caching key of (funcargname, scope).
+        """
+        from _pytest.deprecated import CACHED_SETUP
+
+        warnings.warn(CACHED_SETUP, stacklevel=2)
+        if not hasattr(self.config, "_setupcache"):
+            self.config._setupcache = {}  # XXX weakref?
+        cachekey = (self.fixturename, self._getscopeitem(scope), extrakey)
+        cache = self.config._setupcache
+        try:
+            val = cache[cachekey]
+        except KeyError:
+            self._check_scope(self.fixturename, self.scope, scope)
+            val = setup()
+            cache[cachekey] = val
+            if teardown is not None:
+
+                def finalizer():
+                    del cache[cachekey]
+                    teardown(val)
+
+                self._addfinalizer(finalizer, scope=scope)
+        return val
+
+    def getfixturevalue(self, argname):
+        """ Dynamically run a named fixture function.
+
+        Declaring fixtures via function argument is recommended where possible.
+        But if you can only decide whether to use another fixture at test
+        setup time, you may use this function to retrieve it inside a fixture
+        or test function body.
+        """
+        return self._get_active_fixturedef(argname).cached_result[0]
+
+    def getfuncargvalue(self, argname):
+        """ Deprecated, use getfixturevalue. """
+        from _pytest import deprecated
+
+        warnings.warn(deprecated.GETFUNCARGVALUE, stacklevel=2)
+        return self.getfixturevalue(argname)
+
+    def _get_active_fixturedef(self, argname):
+        try:
+            return self._fixture_defs[argname]
+        except KeyError:
+            try:
+                fixturedef = self._getnextfixturedef(argname)
+            except FixtureLookupError:
+                if argname == "request":
+                    cached_result = (self, [0], None)
+                    scope = "function"
+                    return PseudoFixtureDef(cached_result, scope)
+                raise
+        # remove indent to prevent the python3 exception
+        # from leaking into the call
+        self._compute_fixture_value(fixturedef)
+        self._fixture_defs[argname] = fixturedef
+        return fixturedef
+
+    def _get_fixturestack(self):
+        current = self
+        values = []
+        while 1:
+            fixturedef = getattr(current, "_fixturedef", None)
+            if fixturedef is None:
+                values.reverse()
+                return values
+            values.append(fixturedef)
+            current = current._parent_request
+
+    def _compute_fixture_value(self, fixturedef):
+        """
+        Creates a SubRequest based on "self" and calls the execute method of the given fixturedef object. This will
+        force the FixtureDef object to throw away any previous results and compute a new fixture value, which
+        will be stored into the FixtureDef object itself.
+
+        :param FixtureDef fixturedef:
+        """
+        # prepare a subrequest object before calling fixture function
+        # (latter managed by fixturedef)
+        argname = fixturedef.argname
+        funcitem = self._pyfuncitem
+        scope = fixturedef.scope
+        try:
+            param = funcitem.callspec.getparam(argname)
+        except (AttributeError, ValueError):
+            param = NOTSET
+            param_index = 0
+            has_params = fixturedef.params is not None
+            fixtures_not_supported = getattr(funcitem, "nofuncargs", False)
+            if has_params and fixtures_not_supported:
+                msg = (
+                    "{name} does not support fixtures, maybe unittest.TestCase subclass?\n"
+                    "Node id: {nodeid}\n"
+                    "Function type: {typename}"
+                ).format(
+                    name=funcitem.name,
+                    nodeid=funcitem.nodeid,
+                    typename=type(funcitem).__name__,
+                )
+                fail(msg, pytrace=False)
+            if has_params:
+                frame = inspect.stack()[3]
+                frameinfo = inspect.getframeinfo(frame[0])
+                source_path = frameinfo.filename
+                source_lineno = frameinfo.lineno
+                source_path = py.path.local(source_path)
+                if source_path.relto(funcitem.config.rootdir):
+                    source_path = source_path.relto(funcitem.config.rootdir)
+                msg = (
+                    "The requested fixture has no parameter defined for test:\n"
+                    "    {}\n\n"
+                    "Requested fixture '{}' defined in:\n{}"
+                    "\n\nRequested here:\n{}:{}".format(
+                        funcitem.nodeid,
+                        fixturedef.argname,
+                        getlocation(fixturedef.func, funcitem.config.rootdir),
+                        source_path,
+                        source_lineno,
+                    )
+                )
+                fail(msg, pytrace=False)
+        else:
+            # indices might not be set if old-style metafunc.addcall() was used
+            param_index = funcitem.callspec.indices.get(argname, 0)
+            # if a parametrize invocation set a scope it will override
+            # the static scope defined with the fixture function
+            paramscopenum = funcitem.callspec._arg2scopenum.get(argname)
+            if paramscopenum is not None:
+                scope = scopes[paramscopenum]
+
+        subrequest = SubRequest(self, scope, param, param_index, fixturedef)
+
+        # check if a higher-level scoped fixture accesses a lower level one
+        subrequest._check_scope(argname, self.scope, scope)
+
+        # clear sys.exc_info before invoking the fixture (python bug?)
+        # if it's not explicitly cleared it will leak into the call
+        exc_clear()
+        try:
+            # call the fixture function
+            fixturedef.execute(request=subrequest)
+        finally:
+            # if fixture function failed it might have registered finalizers
+            self.session._setupstate.addfinalizer(
+                functools.partial(fixturedef.finish, request=subrequest),
+                subrequest.node,
+            )
+
+    def _check_scope(self, argname, invoking_scope, requested_scope):
+        if argname == "request":
+            return
+        if scopemismatch(invoking_scope, requested_scope):
+            # try to report something helpful
+            lines = self._factorytraceback()
+            fail(
+                "ScopeMismatch: You tried to access the %r scoped "
+                "fixture %r with a %r scoped request object, "
+                "involved factories\n%s"
+                % ((requested_scope, argname, invoking_scope, "\n".join(lines))),
+                pytrace=False,
+            )
+
+    def _factorytraceback(self):
+        lines = []
+        for fixturedef in self._get_fixturestack():
+            factory = fixturedef.func
+            fs, lineno = getfslineno(factory)
+            p = self._pyfuncitem.session.fspath.bestrelpath(fs)
+            args = _format_args(factory)
+            lines.append("%s:%d:  def %s%s" % (p, lineno, factory.__name__, args))
+        return lines
+
+    def _getscopeitem(self, scope):
+        if scope == "function":
+            # this might also be a non-function Item despite its attribute name
+            return self._pyfuncitem
+        if scope == "package":
+            node = get_scope_package(self._pyfuncitem, self._fixturedef)
+        else:
+            node = get_scope_node(self._pyfuncitem, scope)
+        if node is None and scope == "class":
+            # fallback to function item itself
+            node = self._pyfuncitem
+        assert node, 'Could not obtain a node for scope "{}" for function {!r}'.format(
+            scope, self._pyfuncitem
+        )
+        return node
+
+    def __repr__(self):
+        return "<FixtureRequest for %r>" % (self.node)
+
+
+class SubRequest(FixtureRequest):
+    """ a sub request for handling getting a fixture from a
+    test function/fixture. """
+
+    def __init__(self, request, scope, param, param_index, fixturedef):
+        self._parent_request = request
+        self.fixturename = fixturedef.argname
+        if param is not NOTSET:
+            self.param = param
+        self.param_index = param_index
+        self.scope = scope
+        self._fixturedef = fixturedef
+        self._pyfuncitem = request._pyfuncitem
+        self._fixture_defs = request._fixture_defs
+        self._arg2fixturedefs = request._arg2fixturedefs
+        self._arg2index = request._arg2index
+        self._fixturemanager = request._fixturemanager
+
+    def __repr__(self):
+        return "<SubRequest %r for %r>" % (self.fixturename, self._pyfuncitem)
+
+    def addfinalizer(self, finalizer):
+        self._fixturedef.addfinalizer(finalizer)
+
+
+class ScopeMismatchError(Exception):
+    """ A fixture function tries to use a different fixture function which
+    which has a lower scope (e.g. a Session one calls a function one)
+    """
+
+
+scopes = "session package module class function".split()
+scopenum_function = scopes.index("function")
+
+
+def scopemismatch(currentscope, newscope):
+    return scopes.index(newscope) > scopes.index(currentscope)
+
+
+def scope2index(scope, descr, where=None):
+    """Look up the index of ``scope`` and raise a descriptive value error
+    if not defined.
+    """
+    try:
+        return scopes.index(scope)
+    except ValueError:
+        fail(
+            "{} {}got an unexpected scope value '{}'".format(
+                descr, "from {} ".format(where) if where else "", scope
+            ),
+            pytrace=False,
+        )
+
+
+class FixtureLookupError(LookupError):
+    """ could not return a requested Fixture (missing or invalid). """
+
+    def __init__(self, argname, request, msg=None):
+        self.argname = argname
+        self.request = request
+        self.fixturestack = request._get_fixturestack()
+        self.msg = msg
+
+    def formatrepr(self):
+        tblines = []
+        addline = tblines.append
+        stack = [self.request._pyfuncitem.obj]
+        stack.extend(map(lambda x: x.func, self.fixturestack))
+        msg = self.msg
+        if msg is not None:
+            # the last fixture raise an error, let's present
+            # it at the requesting side
+            stack = stack[:-1]
+        for function in stack:
+            fspath, lineno = getfslineno(function)
+            try:
+                lines, _ = inspect.getsourcelines(get_real_func(function))
+            except (IOError, IndexError, TypeError):
+                error_msg = "file %s, line %s: source code not available"
+                addline(error_msg % (fspath, lineno + 1))
+            else:
+                addline("file %s, line %s" % (fspath, lineno + 1))
+                for i, line in enumerate(lines):
+                    line = line.rstrip()
+                    addline("  " + line)
+                    if line.lstrip().startswith("def"):
+                        break
+
+        if msg is None:
+            fm = self.request._fixturemanager
+            available = set()
+            parentid = self.request._pyfuncitem.parent.nodeid
+            for name, fixturedefs in fm._arg2fixturedefs.items():
+                faclist = list(fm._matchfactories(fixturedefs, parentid))
+                if faclist:
+                    available.add(name)
+            if self.argname in available:
+                msg = " recursive dependency involving fixture '{}' detected".format(
+                    self.argname
+                )
+            else:
+                msg = "fixture '{}' not found".format(self.argname)
+            msg += "\n available fixtures: {}".format(", ".join(sorted(available)))
+            msg += "\n use 'pytest --fixtures [testpath]' for help on them."
+
+        return FixtureLookupErrorRepr(fspath, lineno, tblines, msg, self.argname)
+
+
+class FixtureLookupErrorRepr(TerminalRepr):
+    def __init__(self, filename, firstlineno, tblines, errorstring, argname):
+        self.tblines = tblines
+        self.errorstring = errorstring
+        self.filename = filename
+        self.firstlineno = firstlineno
+        self.argname = argname
+
+    def toterminal(self, tw):
+        # tw.line("FixtureLookupError: %s" %(self.argname), red=True)
+        for tbline in self.tblines:
+            tw.line(tbline.rstrip())
+        lines = self.errorstring.split("\n")
+        if lines:
+            tw.line(
+                "{}       {}".format(FormattedExcinfo.fail_marker, lines[0].strip()),
+                red=True,
+            )
+            for line in lines[1:]:
+                tw.line(
+                    "{}       {}".format(FormattedExcinfo.flow_marker, line.strip()),
+                    red=True,
+                )
+        tw.line()
+        tw.line("%s:%d" % (self.filename, self.firstlineno + 1))
+
+
+def fail_fixturefunc(fixturefunc, msg):
+    fs, lineno = getfslineno(fixturefunc)
+    location = "%s:%s" % (fs, lineno + 1)
+    source = _pytest._code.Source(fixturefunc)
+    fail(msg + ":\n\n" + str(source.indent()) + "\n" + location, pytrace=False)
+
+
+def call_fixture_func(fixturefunc, request, kwargs):
+    yieldctx = is_generator(fixturefunc)
+    if yieldctx:
+        it = fixturefunc(**kwargs)
+        res = next(it)
+        finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, it)
+        request.addfinalizer(finalizer)
+    else:
+        res = fixturefunc(**kwargs)
+    return res
+
+
+def _teardown_yield_fixture(fixturefunc, it):
+    """Executes the teardown of a fixture function by advancing the iterator after the
+    yield and ensure the iteration ends (if not it means there is more than one yield in the function)"""
+    try:
+        next(it)
+    except StopIteration:
+        pass
+    else:
+        fail_fixturefunc(
+            fixturefunc, "yield_fixture function has more than one 'yield'"
+        )
+
+
+class FixtureDef(object):
+    """ A container for a factory definition. """
+
+    def __init__(
+        self,
+        fixturemanager,
+        baseid,
+        argname,
+        func,
+        scope,
+        params,
+        unittest=False,
+        ids=None,
+    ):
+        self._fixturemanager = fixturemanager
+        self.baseid = baseid or ""
+        self.has_location = baseid is not None
+        self.func = func
+        self.argname = argname
+        self.scope = scope
+        self.scopenum = scope2index(
+            scope or "function",
+            descr="Fixture '{}'".format(func.__name__),
+            where=baseid,
+        )
+        self.params = params
+        self.argnames = getfuncargnames(func, is_method=unittest)
+        self.unittest = unittest
+        self.ids = ids
+        self._finalizers = []
+
+    def addfinalizer(self, finalizer):
+        self._finalizers.append(finalizer)
+
+    def finish(self, request):
+        exceptions = []
+        try:
+            while self._finalizers:
+                try:
+                    func = self._finalizers.pop()
+                    func()
+                except:  # noqa
+                    exceptions.append(sys.exc_info())
+            if exceptions:
+                e = exceptions[0]
+                del exceptions  # ensure we don't keep all frames alive because of the traceback
+                six.reraise(*e)
+
+        finally:
+            hook = self._fixturemanager.session.gethookproxy(request.node.fspath)
+            hook.pytest_fixture_post_finalizer(fixturedef=self, request=request)
+            # even if finalization fails, we invalidate
+            # the cached fixture value and remove
+            # all finalizers because they may be bound methods which will
+            # keep instances alive
+            if hasattr(self, "cached_result"):
+                del self.cached_result
+            self._finalizers = []
+
+    def execute(self, request):
+        # get required arguments and register our own finish()
+        # with their finalization
+        for argname in self.argnames:
+            fixturedef = request._get_active_fixturedef(argname)
+            if argname != "request":
+                fixturedef.addfinalizer(functools.partial(self.finish, request=request))
+
+        my_cache_key = request.param_index
+        cached_result = getattr(self, "cached_result", None)
+        if cached_result is not None:
+            result, cache_key, err = cached_result
+            if my_cache_key == cache_key:
+                if err is not None:
+                    six.reraise(*err)
+                else:
+                    return result
+            # we have a previous but differently parametrized fixture instance
+            # so we need to tear it down before creating a new one
+            self.finish(request)
+            assert not hasattr(self, "cached_result")
+
+        hook = self._fixturemanager.session.gethookproxy(request.node.fspath)
+        return hook.pytest_fixture_setup(fixturedef=self, request=request)
+
+    def __repr__(self):
+        return "<FixtureDef argname=%r scope=%r baseid=%r>" % (
+            self.argname,
+            self.scope,
+            self.baseid,
+        )
+
+
+def resolve_fixture_function(fixturedef, request):
+    """Gets the actual callable that can be called to obtain the fixture value, dealing with unittest-specific
+    instances and bound methods.
+    """
+    fixturefunc = fixturedef.func
+    if fixturedef.unittest:
+        if request.instance is not None:
+            # bind the unbound method to the TestCase instance
+            fixturefunc = fixturedef.func.__get__(request.instance)
+    else:
+        # the fixture function needs to be bound to the actual
+        # request.instance so that code working with "fixturedef" behaves
+        # as expected.
+        if request.instance is not None:
+            fixturefunc = getimfunc(fixturedef.func)
+            if fixturefunc != fixturedef.func:
+                fixturefunc = fixturefunc.__get__(request.instance)
+    return fixturefunc
+
+
+def pytest_fixture_setup(fixturedef, request):
+    """ Execution of fixture setup. """
+    kwargs = {}
+    for argname in fixturedef.argnames:
+        fixdef = request._get_active_fixturedef(argname)
+        result, arg_cache_key, exc = fixdef.cached_result
+        request._check_scope(argname, request.scope, fixdef.scope)
+        kwargs[argname] = result
+
+    fixturefunc = resolve_fixture_function(fixturedef, request)
+    my_cache_key = request.param_index
+    try:
+        result = call_fixture_func(fixturefunc, request, kwargs)
+    except TEST_OUTCOME:
+        fixturedef.cached_result = (None, my_cache_key, sys.exc_info())
+        raise
+    fixturedef.cached_result = (result, my_cache_key, None)
+    return result
+
+
+def _ensure_immutable_ids(ids):
+    if ids is None:
+        return
+    if callable(ids):
+        return ids
+    return tuple(ids)
+
+
+def wrap_function_to_warning_if_called_directly(function, fixture_marker):
+    """Wrap the given fixture function so we can issue warnings about it being called directly, instead of
+    used as an argument in a test function.
+    """
+    is_yield_function = is_generator(function)
+    warning = FIXTURE_FUNCTION_CALL.format(
+        name=fixture_marker.name or function.__name__
+    )
+
+    if is_yield_function:
+
+        @functools.wraps(function)
+        def result(*args, **kwargs):
+            __tracebackhide__ = True
+            warnings.warn(warning, stacklevel=3)
+            for x in function(*args, **kwargs):
+                yield x
+
+    else:
+
+        @functools.wraps(function)
+        def result(*args, **kwargs):
+            __tracebackhide__ = True
+            warnings.warn(warning, stacklevel=3)
+            return function(*args, **kwargs)
+
+    if six.PY2:
+        result.__wrapped__ = function
+
+    # keep reference to the original function in our own custom attribute so we don't unwrap
+    # further than this point and lose useful wrappings like @mock.patch (#3774)
+    result.__pytest_wrapped__ = _PytestWrapper(function)
+
+    return result
+
+
+@attr.s(frozen=True)
+class FixtureFunctionMarker(object):
+    scope = attr.ib()
+    params = attr.ib(converter=attr.converters.optional(tuple))
+    autouse = attr.ib(default=False)
+    ids = attr.ib(default=None, converter=_ensure_immutable_ids)
+    name = attr.ib(default=None)
+
+    def __call__(self, function):
+        if isclass(function):
+            raise ValueError("class fixtures not supported (maybe in the future)")
+
+        if getattr(function, "_pytestfixturefunction", False):
+            raise ValueError(
+                "fixture is being applied more than once to the same function"
+            )
+
+        function = wrap_function_to_warning_if_called_directly(function, self)
+
+        name = self.name or function.__name__
+        if name == "request":
+            warnings.warn(FIXTURE_NAMED_REQUEST)
+        function._pytestfixturefunction = self
+        return function
+
+
+def fixture(scope="function", params=None, autouse=False, ids=None, name=None):
+    """Decorator to mark a fixture factory function.
+
+    This decorator can be used, with or without parameters, to define a
+    fixture function.
+
+    The name of the fixture function can later be referenced to cause its
+    invocation ahead of running tests: test
+    modules or classes can use the ``pytest.mark.usefixtures(fixturename)``
+    marker.
+
+    Test functions can directly use fixture names as input
+    arguments in which case the fixture instance returned from the fixture
+    function will be injected.
+
+    Fixtures can provide their values to test functions using ``return`` or ``yield``
+    statements. When using ``yield`` the code block after the ``yield`` statement is executed
+    as teardown code regardless of the test outcome, and must yield exactly once.
+
+    :arg scope: the scope for which this fixture is shared, one of
+                ``"function"`` (default), ``"class"``, ``"module"``,
+                ``"package"`` or ``"session"``.
+
+                ``"package"`` is considered **experimental** at this time.
+
+    :arg params: an optional list of parameters which will cause multiple
+                invocations of the fixture function and all of the tests
+                using it.
+
+    :arg autouse: if True, the fixture func is activated for all tests that
+                can see it.  If False (the default) then an explicit
+                reference is needed to activate the fixture.
+
+    :arg ids: list of string ids each corresponding to the params
+                so that they are part of the test id. If no ids are provided
+                they will be generated automatically from the params.
+
+    :arg name: the name of the fixture. This defaults to the name of the
+                decorated function. If a fixture is used in the same module in
+                which it is defined, the function name of the fixture will be
+                shadowed by the function arg that requests the fixture; one way
+                to resolve this is to name the decorated function
+                ``fixture_<fixturename>`` and then use
+                ``@pytest.fixture(name='<fixturename>')``.
+    """
+    if callable(scope) and params is None and autouse is False:
+        # direct decoration
+        return FixtureFunctionMarker("function", params, autouse, name=name)(scope)
+    if params is not None and not isinstance(params, (list, tuple)):
+        params = list(params)
+    return FixtureFunctionMarker(scope, params, autouse, ids=ids, name=name)
+
+
+def yield_fixture(scope="function", params=None, autouse=False, ids=None, name=None):
+    """ (return a) decorator to mark a yield-fixture factory function.
+
+    .. deprecated:: 3.0
+        Use :py:func:`pytest.fixture` directly instead.
+    """
+    return fixture(scope=scope, params=params, autouse=autouse, ids=ids, name=name)
+
+
+defaultfuncargprefixmarker = fixture()
+
+
+@fixture(scope="session")
+def pytestconfig(request):
+    """Session-scoped fixture that returns the :class:`_pytest.config.Config` object.
+
+    Example::
+
+        def test_foo(pytestconfig):
+            if pytestconfig.getoption("verbose"):
+                ...
+
+    """
+    return request.config
+
+
+class FixtureManager(object):
+    """
+    pytest fixtures definitions and information is stored and managed
+    from this class.
+
+    During collection fm.parsefactories() is called multiple times to parse
+    fixture function definitions into FixtureDef objects and internal
+    data structures.
+
+    During collection of test functions, metafunc-mechanics instantiate
+    a FuncFixtureInfo object which is cached per node/func-name.
+    This FuncFixtureInfo object is later retrieved by Function nodes
+    which themselves offer a fixturenames attribute.
+
+    The FuncFixtureInfo object holds information about fixtures and FixtureDefs
+    relevant for a particular function.  An initial list of fixtures is
+    assembled like this:
+
+    - ini-defined usefixtures
+    - autouse-marked fixtures along the collection chain up from the function
+    - usefixtures markers at module/class/function level
+    - test function funcargs
+
+    Subsequently the funcfixtureinfo.fixturenames attribute is computed
+    as the closure of the fixtures needed to setup the initial fixtures,
+    i. e. fixtures needed by fixture functions themselves are appended
+    to the fixturenames list.
+
+    Upon the test-setup phases all fixturenames are instantiated, retrieved
+    by a lookup of their FuncFixtureInfo.
+    """
+
+    _argprefix = "pytest_funcarg__"
+    FixtureLookupError = FixtureLookupError
+    FixtureLookupErrorRepr = FixtureLookupErrorRepr
+
+    def __init__(self, session):
+        self.session = session
+        self.config = session.config
+        self._arg2fixturedefs = {}
+        self._holderobjseen = set()
+        self._arg2finish = {}
+        self._nodeid_and_autousenames = [("", self.config.getini("usefixtures"))]
+        session.config.pluginmanager.register(self, "funcmanage")
+
+    def getfixtureinfo(self, node, func, cls, funcargs=True):
+        if funcargs and not getattr(node, "nofuncargs", False):
+            argnames = getfuncargnames(func, cls=cls)
+        else:
+            argnames = ()
+        usefixtures = flatten(
+            mark.args for mark in node.iter_markers(name="usefixtures")
+        )
+        initialnames = tuple(usefixtures) + argnames
+        fm = node.session._fixturemanager
+        initialnames, names_closure, arg2fixturedefs = fm.getfixtureclosure(
+            initialnames, node
+        )
+        return FuncFixtureInfo(argnames, initialnames, names_closure, arg2fixturedefs)
+
+    def pytest_plugin_registered(self, plugin):
+        nodeid = None
+        try:
+            p = py.path.local(plugin.__file__).realpath()
+        except AttributeError:
+            pass
+        else:
+            # construct the base nodeid which is later used to check
+            # what fixtures are visible for particular tests (as denoted
+            # by their test id)
+            if p.basename.startswith("conftest.py"):
+                nodeid = p.dirpath().relto(self.config.rootdir)
+                if p.sep != nodes.SEP:
+                    nodeid = nodeid.replace(p.sep, nodes.SEP)
+
+        self.parsefactories(plugin, nodeid)
+
+    def _getautousenames(self, nodeid):
+        """ return a tuple of fixture names to be used. """
+        autousenames = []
+        for baseid, basenames in self._nodeid_and_autousenames:
+            if nodeid.startswith(baseid):
+                if baseid:
+                    i = len(baseid)
+                    nextchar = nodeid[i : i + 1]
+                    if nextchar and nextchar not in ":/":
+                        continue
+                autousenames.extend(basenames)
+        return autousenames
+
+    def getfixtureclosure(self, fixturenames, parentnode):
+        # collect the closure of all fixtures , starting with the given
+        # fixturenames as the initial set.  As we have to visit all
+        # factory definitions anyway, we also return an arg2fixturedefs
+        # mapping so that the caller can reuse it and does not have
+        # to re-discover fixturedefs again for each fixturename
+        # (discovering matching fixtures for a given name/node is expensive)
+
+        parentid = parentnode.nodeid
+        fixturenames_closure = self._getautousenames(parentid)
+
+        def merge(otherlist):
+            for arg in otherlist:
+                if arg not in fixturenames_closure:
+                    fixturenames_closure.append(arg)
+
+        merge(fixturenames)
+
+        # at this point, fixturenames_closure contains what we call "initialnames",
+        # which is a set of fixturenames the function immediately requests. We
+        # need to return it as well, so save this.
+        initialnames = tuple(fixturenames_closure)
+
+        arg2fixturedefs = {}
+        lastlen = -1
+        while lastlen != len(fixturenames_closure):
+            lastlen = len(fixturenames_closure)
+            for argname in fixturenames_closure:
+                if argname in arg2fixturedefs:
+                    continue
+                fixturedefs = self.getfixturedefs(argname, parentid)
+                if fixturedefs:
+                    arg2fixturedefs[argname] = fixturedefs
+                    merge(fixturedefs[-1].argnames)
+
+        def sort_by_scope(arg_name):
+            try:
+                fixturedefs = arg2fixturedefs[arg_name]
+            except KeyError:
+                return scopes.index("function")
+            else:
+                return fixturedefs[-1].scopenum
+
+        fixturenames_closure.sort(key=sort_by_scope)
+        return initialnames, fixturenames_closure, arg2fixturedefs
+
+    def pytest_generate_tests(self, metafunc):
+        for argname in metafunc.fixturenames:
+            faclist = metafunc._arg2fixturedefs.get(argname)
+            if faclist:
+                fixturedef = faclist[-1]
+                if fixturedef.params is not None:
+                    parametrize_func = getattr(metafunc.function, "parametrize", None)
+                    if parametrize_func is not None:
+                        parametrize_func = parametrize_func.combined
+                    func_params = getattr(parametrize_func, "args", [[None]])
+                    func_kwargs = getattr(parametrize_func, "kwargs", {})
+                    # skip directly parametrized arguments
+                    if "argnames" in func_kwargs:
+                        argnames = parametrize_func.kwargs["argnames"]
+                    else:
+                        argnames = func_params[0]
+                    if not isinstance(argnames, (tuple, list)):
+                        argnames = [x.strip() for x in argnames.split(",") if x.strip()]
+                    if argname not in func_params and argname not in argnames:
+                        metafunc.parametrize(
+                            argname,
+                            fixturedef.params,
+                            indirect=True,
+                            scope=fixturedef.scope,
+                            ids=fixturedef.ids,
+                        )
+            else:
+                continue  # will raise FixtureLookupError at setup time
+
+    def pytest_collection_modifyitems(self, items):
+        # separate parametrized setups
+        items[:] = reorder_items(items)
+
+    def parsefactories(self, node_or_obj, nodeid=NOTSET, unittest=False):
+        from _pytest import deprecated
+
+        if nodeid is not NOTSET:
+            holderobj = node_or_obj
+        else:
+            holderobj = node_or_obj.obj
+            nodeid = node_or_obj.nodeid
+        if holderobj in self._holderobjseen:
+            return
+
+        from _pytest.nodes import _CompatProperty
+
+        self._holderobjseen.add(holderobj)
+        autousenames = []
+        for name in dir(holderobj):
+            # The attribute can be an arbitrary descriptor, so the attribute
+            # access below can raise. safe_getatt() ignores such exceptions.
+            maybe_property = safe_getattr(type(holderobj), name, None)
+            if isinstance(maybe_property, _CompatProperty):
+                # deprecated
+                continue
+            obj = safe_getattr(holderobj, name, None)
+            marker = getfixturemarker(obj)
+            # fixture functions have a pytest_funcarg__ prefix (pre-2.3 style)
+            # or are "@pytest.fixture" marked
+            if marker is None:
+                if not name.startswith(self._argprefix):
+                    continue
+                if not callable(obj):
+                    continue
+                marker = defaultfuncargprefixmarker
+
+                filename, lineno = getfslineno(obj)
+                warnings.warn_explicit(
+                    deprecated.FUNCARG_PREFIX.format(name=name),
+                    category=None,
+                    filename=str(filename),
+                    lineno=lineno + 1,
+                )
+                name = name[len(self._argprefix) :]
+            elif not isinstance(marker, FixtureFunctionMarker):
+                # magic globals  with __getattr__ might have got us a wrong
+                # fixture attribute
+                continue
+            else:
+                if marker.name:
+                    name = marker.name
+                assert not name.startswith(self._argprefix), FIXTURE_MSG.format(name)
+
+            # during fixture definition we wrap the original fixture function
+            # to issue a warning if called directly, so here we unwrap it in order to not emit the warning
+            # when pytest itself calls the fixture function
+            if six.PY2 and unittest:
+                # hack on Python 2 because of the unbound methods
+                obj = get_real_func(obj)
+            else:
+                obj = get_real_method(obj, holderobj)
+
+            fixture_def = FixtureDef(
+                self,
+                nodeid,
+                name,
+                obj,
+                marker.scope,
+                marker.params,
+                unittest=unittest,
+                ids=marker.ids,
+            )
+
+            faclist = self._arg2fixturedefs.setdefault(name, [])
+            if fixture_def.has_location:
+                faclist.append(fixture_def)
+            else:
+                # fixturedefs with no location are at the front
+                # so this inserts the current fixturedef after the
+                # existing fixturedefs from external plugins but
+                # before the fixturedefs provided in conftests.
+                i = len([f for f in faclist if not f.has_location])
+                faclist.insert(i, fixture_def)
+            if marker.autouse:
+                autousenames.append(name)
+
+        if autousenames:
+            self._nodeid_and_autousenames.append((nodeid or "", autousenames))
+
+    def getfixturedefs(self, argname, nodeid):
+        """
+        Gets a list of fixtures which are applicable to the given node id.
+
+        :param str argname: name of the fixture to search for
+        :param str nodeid: full node id of the requesting test.
+        :return: list[FixtureDef]
+        """
+        try:
+            fixturedefs = self._arg2fixturedefs[argname]
+        except KeyError:
+            return None
+        return tuple(self._matchfactories(fixturedefs, nodeid))
+
+    def _matchfactories(self, fixturedefs, nodeid):
+        for fixturedef in fixturedefs:
+            if nodes.ischildnode(fixturedef.baseid, nodeid):
+                yield fixturedef
Index: venv/Lib/site-packages/attr/converters.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/converters.py	(date 1543190976964)
+++ venv/Lib/site-packages/attr/converters.py	(date 1543190976964)
@@ -0,0 +1,78 @@
+"""
+Commonly useful converters.
+"""
+
+from __future__ import absolute_import, division, print_function
+
+from ._make import NOTHING, Factory
+
+
+def optional(converter):
+    """
+    A converter that allows an attribute to be optional. An optional attribute
+    is one which can be set to ``None``.
+
+    :param callable converter: the converter that is used for non-``None``
+        values.
+
+    .. versionadded:: 17.1.0
+    """
+
+    def optional_converter(val):
+        if val is None:
+            return None
+        return converter(val)
+
+    return optional_converter
+
+
+def default_if_none(default=NOTHING, factory=None):
+    """
+    A converter that allows to replace ``None`` values by *default* or the
+    result of *factory*.
+
+    :param default: Value to be used if ``None`` is passed. Passing an instance
+       of :class:`attr.Factory` is supported, however the ``takes_self`` option
+       is *not*.
+    :param callable factory: A callable that takes not parameters whose result
+       is used if ``None`` is passed.
+
+    :raises TypeError: If **neither** *default* or *factory* is passed.
+    :raises TypeError: If **both** *default* and *factory* are passed.
+    :raises ValueError: If an instance of :class:`attr.Factory` is passed with
+       ``takes_self=True``.
+
+    .. versionadded:: 18.2.0
+    """
+    if default is NOTHING and factory is None:
+        raise TypeError("Must pass either `default` or `factory`.")
+
+    if default is not NOTHING and factory is not None:
+        raise TypeError(
+            "Must pass either `default` or `factory` but not both."
+        )
+
+    if factory is not None:
+        default = Factory(factory)
+
+    if isinstance(default, Factory):
+        if default.takes_self:
+            raise ValueError(
+                "`takes_self` is not supported by default_if_none."
+            )
+
+        def default_if_none_converter(val):
+            if val is not None:
+                return val
+
+            return default.factory()
+
+    else:
+
+        def default_if_none_converter(val):
+            if val is not None:
+                return val
+
+            return default
+
+    return default_if_none_converter
Index: venv/Lib/site-packages/_pytest/hookspec.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/hookspec.py	(date 1543190976978)
+++ venv/Lib/site-packages/_pytest/hookspec.py	(date 1543190976978)
@@ -0,0 +1,623 @@
+""" hook specifications for pytest plugins, invoked from main.py and builtin plugins.  """
+from pluggy import HookspecMarker
+
+from .deprecated import PYTEST_NAMESPACE
+
+
+hookspec = HookspecMarker("pytest")
+
+# -------------------------------------------------------------------------
+# Initialization hooks called for every plugin
+# -------------------------------------------------------------------------
+
+
+@hookspec(historic=True)
+def pytest_addhooks(pluginmanager):
+    """called at plugin registration time to allow adding new hooks via a call to
+    ``pluginmanager.add_hookspecs(module_or_class, prefix)``.
+
+
+    :param _pytest.config.PytestPluginManager pluginmanager: pytest plugin manager
+
+    .. note::
+        This hook is incompatible with ``hookwrapper=True``.
+    """
+
+
+@hookspec(historic=True, warn_on_impl=PYTEST_NAMESPACE)
+def pytest_namespace():
+    """
+    return dict of name->object to be made globally available in
+    the pytest namespace.
+
+    This hook is called at plugin registration time.
+
+    .. note::
+        This hook is incompatible with ``hookwrapper=True``.
+
+    .. warning::
+        This hook has been **deprecated** and will be removed in pytest 4.0.
+
+        Plugins whose users depend on the current namespace functionality should prepare to migrate to a
+        namespace they actually own.
+
+        To support the migration it's suggested to trigger ``DeprecationWarnings`` for objects they put into the
+        pytest namespace.
+
+        A stopgap measure to avoid the warning is to monkeypatch the ``pytest`` module, but just as the
+        ``pytest_namespace`` hook this should be seen as a temporary measure to be removed in future versions after
+        an appropriate transition period.
+    """
+
+
+@hookspec(historic=True)
+def pytest_plugin_registered(plugin, manager):
+    """ a new pytest plugin got registered.
+
+    :param plugin: the plugin module or instance
+    :param _pytest.config.PytestPluginManager manager: pytest plugin manager
+
+    .. note::
+        This hook is incompatible with ``hookwrapper=True``.
+    """
+
+
+@hookspec(historic=True)
+def pytest_addoption(parser):
+    """register argparse-style options and ini-style config values,
+    called once at the beginning of a test run.
+
+    .. note::
+
+        This function should be implemented only in plugins or ``conftest.py``
+        files situated at the tests root directory due to how pytest
+        :ref:`discovers plugins during startup <pluginorder>`.
+
+    :arg _pytest.config.Parser parser: To add command line options, call
+        :py:func:`parser.addoption(...) <_pytest.config.Parser.addoption>`.
+        To add ini-file values call :py:func:`parser.addini(...)
+        <_pytest.config.Parser.addini>`.
+
+    Options can later be accessed through the
+    :py:class:`config <_pytest.config.Config>` object, respectively:
+
+    - :py:func:`config.getoption(name) <_pytest.config.Config.getoption>` to
+      retrieve the value of a command line option.
+
+    - :py:func:`config.getini(name) <_pytest.config.Config.getini>` to retrieve
+      a value read from an ini-style file.
+
+    The config object is passed around on many internal objects via the ``.config``
+    attribute or can be retrieved as the ``pytestconfig`` fixture.
+
+    .. note::
+        This hook is incompatible with ``hookwrapper=True``.
+    """
+
+
+@hookspec(historic=True)
+def pytest_configure(config):
+    """
+    Allows plugins and conftest files to perform initial configuration.
+
+    This hook is called for every plugin and initial conftest file
+    after command line options have been parsed.
+
+    After that, the hook is called for other conftest files as they are
+    imported.
+
+    .. note::
+        This hook is incompatible with ``hookwrapper=True``.
+
+    :arg _pytest.config.Config config: pytest config object
+    """
+
+
+# -------------------------------------------------------------------------
+# Bootstrapping hooks called for plugins registered early enough:
+# internal and 3rd party plugins.
+# -------------------------------------------------------------------------
+
+
+@hookspec(firstresult=True)
+def pytest_cmdline_parse(pluginmanager, args):
+    """return initialized config object, parsing the specified args.
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    .. note::
+        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.
+
+    :param _pytest.config.PytestPluginManager pluginmanager: pytest plugin manager
+    :param list[str] args: list of arguments passed on the command line
+    """
+
+
+def pytest_cmdline_preparse(config, args):
+    """(**Deprecated**) modify command line arguments before option parsing.
+
+    This hook is considered deprecated and will be removed in a future pytest version. Consider
+    using :func:`pytest_load_initial_conftests` instead.
+
+    .. note::
+        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.
+
+    :param _pytest.config.Config config: pytest config object
+    :param list[str] args: list of arguments passed on the command line
+    """
+
+
+@hookspec(firstresult=True)
+def pytest_cmdline_main(config):
+    """ called for performing the main command line action. The default
+    implementation will invoke the configure hooks and runtest_mainloop.
+
+    .. note::
+        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    :param _pytest.config.Config config: pytest config object
+    """
+
+
+def pytest_load_initial_conftests(early_config, parser, args):
+    """ implements the loading of initial conftest files ahead
+    of command line option parsing.
+
+    .. note::
+        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.
+
+    :param _pytest.config.Config early_config: pytest config object
+    :param list[str] args: list of arguments passed on the command line
+    :param _pytest.config.Parser parser: to add command line options
+    """
+
+
+# -------------------------------------------------------------------------
+# collection hooks
+# -------------------------------------------------------------------------
+
+
+@hookspec(firstresult=True)
+def pytest_collection(session):
+    """Perform the collection protocol for the given session.
+
+    Stops at first non-None result, see :ref:`firstresult`.
+
+    :param _pytest.main.Session session: the pytest session object
+    """
+
+
+def pytest_collection_modifyitems(session, config, items):
+    """ called after collection has been performed, may filter or re-order
+    the items in-place.
+
+    :param _pytest.main.Session session: the pytest session object
+    :param _pytest.config.Config config: pytest config object
+    :param List[_pytest.nodes.Item] items: list of item objects
+    """
+
+
+def pytest_collection_finish(session):
+    """ called after collection has been performed and modified.
+
+    :param _pytest.main.Session session: the pytest session object
+    """
+
+
+@hookspec(firstresult=True)
+def pytest_ignore_collect(path, config):
+    """ return True to prevent considering this path for collection.
+    This hook is consulted for all files and directories prior to calling
+    more specific hooks.
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    :param str path: the path to analyze
+    :param _pytest.config.Config config: pytest config object
+    """
+
+
+@hookspec(firstresult=True)
+def pytest_collect_directory(path, parent):
+    """ called before traversing a directory for collection files.
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    :param str path: the path to analyze
+    """
+
+
+def pytest_collect_file(path, parent):
+    """ return collection Node or None for the given path. Any new node
+    needs to have the specified ``parent`` as a parent.
+
+    :param str path: the path to collect
+    """
+
+
+# logging hooks for collection
+
+
+def pytest_collectstart(collector):
+    """ collector starts collecting. """
+
+
+def pytest_itemcollected(item):
+    """ we just collected a test item. """
+
+
+def pytest_collectreport(report):
+    """ collector finished collecting. """
+
+
+def pytest_deselected(items):
+    """ called for test items deselected by keyword. """
+
+
+@hookspec(firstresult=True)
+def pytest_make_collect_report(collector):
+    """ perform ``collector.collect()`` and return a CollectReport.
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+# -------------------------------------------------------------------------
+# Python test function related hooks
+# -------------------------------------------------------------------------
+
+
+@hookspec(firstresult=True)
+def pytest_pycollect_makemodule(path, parent):
+    """ return a Module collector or None for the given path.
+    This hook will be called for each matching test module path.
+    The pytest_collect_file hook needs to be used if you want to
+    create test modules for files that do not match as a test module.
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+@hookspec(firstresult=True)
+def pytest_pycollect_makeitem(collector, name, obj):
+    """ return custom item/collector for a python object in a module, or None.
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+@hookspec(firstresult=True)
+def pytest_pyfunc_call(pyfuncitem):
+    """ call underlying test function.
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+def pytest_generate_tests(metafunc):
+    """ generate (multiple) parametrized calls to a test function."""
+
+
+@hookspec(firstresult=True)
+def pytest_make_parametrize_id(config, val, argname):
+    """Return a user-friendly string representation of the given ``val`` that will be used
+    by @pytest.mark.parametrize calls. Return None if the hook doesn't know about ``val``.
+    The parameter name is available as ``argname``, if required.
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    :param _pytest.config.Config config: pytest config object
+    :param val: the parametrized value
+    :param str argname: the automatic parameter name produced by pytest
+    """
+
+
+# -------------------------------------------------------------------------
+# generic runtest related hooks
+# -------------------------------------------------------------------------
+
+
+@hookspec(firstresult=True)
+def pytest_runtestloop(session):
+    """ called for performing the main runtest loop
+    (after collection finished).
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    :param _pytest.main.Session session: the pytest session object
+    """
+
+
+def pytest_itemstart(item, node):
+    """(**Deprecated**) use pytest_runtest_logstart. """
+
+
+@hookspec(firstresult=True)
+def pytest_runtest_protocol(item, nextitem):
+    """ implements the runtest_setup/call/teardown protocol for
+    the given test item, including capturing exceptions and calling
+    reporting hooks.
+
+    :arg item: test item for which the runtest protocol is performed.
+
+    :arg nextitem: the scheduled-to-be-next test item (or None if this
+                   is the end my friend).  This argument is passed on to
+                   :py:func:`pytest_runtest_teardown`.
+
+    :return boolean: True if no further hook implementations should be invoked.
+
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+def pytest_runtest_logstart(nodeid, location):
+    """ signal the start of running a single test item.
+
+    This hook will be called **before** :func:`pytest_runtest_setup`, :func:`pytest_runtest_call` and
+    :func:`pytest_runtest_teardown` hooks.
+
+    :param str nodeid: full id of the item
+    :param location: a triple of ``(filename, linenum, testname)``
+    """
+
+
+def pytest_runtest_logfinish(nodeid, location):
+    """ signal the complete finish of running a single test item.
+
+    This hook will be called **after** :func:`pytest_runtest_setup`, :func:`pytest_runtest_call` and
+    :func:`pytest_runtest_teardown` hooks.
+
+    :param str nodeid: full id of the item
+    :param location: a triple of ``(filename, linenum, testname)``
+    """
+
+
+def pytest_runtest_setup(item):
+    """ called before ``pytest_runtest_call(item)``. """
+
+
+def pytest_runtest_call(item):
+    """ called to execute the test ``item``. """
+
+
+def pytest_runtest_teardown(item, nextitem):
+    """ called after ``pytest_runtest_call``.
+
+    :arg nextitem: the scheduled-to-be-next test item (None if no further
+                   test item is scheduled).  This argument can be used to
+                   perform exact teardowns, i.e. calling just enough finalizers
+                   so that nextitem only needs to call setup-functions.
+    """
+
+
+@hookspec(firstresult=True)
+def pytest_runtest_makereport(item, call):
+    """ return a :py:class:`_pytest.runner.TestReport` object
+    for the given :py:class:`pytest.Item <_pytest.main.Item>` and
+    :py:class:`_pytest.runner.CallInfo`.
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+def pytest_runtest_logreport(report):
+    """ process a test setup/call/teardown report relating to
+    the respective phase of executing a test. """
+
+
+# -------------------------------------------------------------------------
+# Fixture related hooks
+# -------------------------------------------------------------------------
+
+
+@hookspec(firstresult=True)
+def pytest_fixture_setup(fixturedef, request):
+    """ performs fixture setup execution.
+
+    :return: The return value of the call to the fixture function
+
+    Stops at first non-None result, see :ref:`firstresult`
+
+    .. note::
+        If the fixture function returns None, other implementations of
+        this hook function will continue to be called, according to the
+        behavior of the :ref:`firstresult` option.
+    """
+
+
+def pytest_fixture_post_finalizer(fixturedef, request):
+    """ called after fixture teardown, but before the cache is cleared so
+    the fixture result cache ``fixturedef.cached_result`` can
+    still be accessed."""
+
+
+# -------------------------------------------------------------------------
+# test session related hooks
+# -------------------------------------------------------------------------
+
+
+def pytest_sessionstart(session):
+    """ called after the ``Session`` object has been created and before performing collection
+    and entering the run test loop.
+
+    :param _pytest.main.Session session: the pytest session object
+    """
+
+
+def pytest_sessionfinish(session, exitstatus):
+    """ called after whole test run finished, right before returning the exit status to the system.
+
+    :param _pytest.main.Session session: the pytest session object
+    :param int exitstatus: the status which pytest will return to the system
+    """
+
+
+def pytest_unconfigure(config):
+    """ called before test process is exited.
+
+    :param _pytest.config.Config config: pytest config object
+    """
+
+
+# -------------------------------------------------------------------------
+# hooks for customizing the assert methods
+# -------------------------------------------------------------------------
+
+
+def pytest_assertrepr_compare(config, op, left, right):
+    """return explanation for comparisons in failing assert expressions.
+
+    Return None for no custom explanation, otherwise return a list
+    of strings.  The strings will be joined by newlines but any newlines
+    *in* a string will be escaped.  Note that all but the first line will
+    be indented slightly, the intention is for the first line to be a summary.
+
+    :param _pytest.config.Config config: pytest config object
+    """
+
+
+# -------------------------------------------------------------------------
+# hooks for influencing reporting (invoked from _pytest_terminal)
+# -------------------------------------------------------------------------
+
+
+def pytest_report_header(config, startdir):
+    """ return a string or list of strings to be displayed as header info for terminal reporting.
+
+    :param _pytest.config.Config config: pytest config object
+    :param startdir: py.path object with the starting dir
+
+    .. note::
+
+        This function should be implemented only in plugins or ``conftest.py``
+        files situated at the tests root directory due to how pytest
+        :ref:`discovers plugins during startup <pluginorder>`.
+    """
+
+
+def pytest_report_collectionfinish(config, startdir, items):
+    """
+    .. versionadded:: 3.2
+
+    return a string or list of strings to be displayed after collection has finished successfully.
+
+    This strings will be displayed after the standard "collected X items" message.
+
+    :param _pytest.config.Config config: pytest config object
+    :param startdir: py.path object with the starting dir
+    :param items: list of pytest items that are going to be executed; this list should not be modified.
+    """
+
+
+@hookspec(firstresult=True)
+def pytest_report_teststatus(report):
+    """ return result-category, shortletter and verbose word for reporting.
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+def pytest_terminal_summary(terminalreporter, exitstatus):
+    """Add a section to terminal summary reporting.
+
+    :param _pytest.terminal.TerminalReporter terminalreporter: the internal terminal reporter object
+    :param int exitstatus: the exit status that will be reported back to the OS
+
+    .. versionadded:: 3.5
+        The ``config`` parameter.
+    """
+
+
+@hookspec(historic=True)
+def pytest_logwarning(message, code, nodeid, fslocation):
+    """
+    .. deprecated:: 3.8
+
+        This hook is will stop working in a future release.
+
+        pytest no longer triggers this hook, but the
+        terminal writer still implements it to display warnings issued by
+        :meth:`_pytest.config.Config.warn` and :meth:`_pytest.nodes.Node.warn`. Calling those functions will be
+        an error in future releases.
+
+    process a warning specified by a message, a code string,
+    a nodeid and fslocation (both of which may be None
+    if the warning is not tied to a particular node/location).
+
+    .. note::
+        This hook is incompatible with ``hookwrapper=True``.
+    """
+
+
+@hookspec(historic=True)
+def pytest_warning_captured(warning_message, when, item):
+    """
+    Process a warning captured by the internal pytest warnings plugin.
+
+    :param warnings.WarningMessage warning_message:
+        The captured warning. This is the same object produced by :py:func:`warnings.catch_warnings`, and contains
+        the same attributes as the parameters of :py:func:`warnings.showwarning`.
+
+    :param str when:
+        Indicates when the warning was captured. Possible values:
+
+        * ``"config"``: during pytest configuration/initialization stage.
+        * ``"collect"``: during test collection.
+        * ``"runtest"``: during test execution.
+
+    :param pytest.Item|None item:
+        **DEPRECATED**: This parameter is incompatible with ``pytest-xdist``, and will always receive ``None``
+        in a future release.
+
+        The item being executed if ``when`` is ``"runtest"``, otherwise ``None``.
+    """
+
+
+# -------------------------------------------------------------------------
+# doctest hooks
+# -------------------------------------------------------------------------
+
+
+@hookspec(firstresult=True)
+def pytest_doctest_prepare_content(content):
+    """ return processed content for a given doctest
+
+    Stops at first non-None result, see :ref:`firstresult` """
+
+
+# -------------------------------------------------------------------------
+# error handling and internal debugging hooks
+# -------------------------------------------------------------------------
+
+
+def pytest_internalerror(excrepr, excinfo):
+    """ called for internal errors. """
+
+
+def pytest_keyboard_interrupt(excinfo):
+    """ called for keyboard interrupt. """
+
+
+def pytest_exception_interact(node, call, report):
+    """called when an exception was raised which can potentially be
+    interactively handled.
+
+    This hook is only called if an exception was raised
+    that is not an internal exception like ``skip.Exception``.
+    """
+
+
+def pytest_enter_pdb(config, pdb):
+    """ called upon pdb.set_trace(), can be used by plugins to take special
+    action just before the python debugger enters in interactive mode.
+
+    :param _pytest.config.Config config: pytest config object
+    :param pdb.Pdb pdb: Pdb instance
+    """
+
+
+def pytest_leave_pdb(config, pdb):
+    """ called when leaving pdb (e.g. with continue after pdb.set_trace()).
+
+    Can be used by plugins to take special action just after the python
+    debugger leaves interactive mode.
+
+    :param _pytest.config.Config config: pytest config object
+    :param pdb.Pdb pdb: Pdb instance
+    """
Index: venv/Lib/site-packages/attr/_funcs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/_funcs.py	(date 1543190976990)
+++ venv/Lib/site-packages/attr/_funcs.py	(date 1543190976990)
@@ -0,0 +1,290 @@
+from __future__ import absolute_import, division, print_function
+
+import copy
+
+from ._compat import iteritems
+from ._make import NOTHING, _obj_setattr, fields
+from .exceptions import AttrsAttributeNotFoundError
+
+
+def asdict(
+    inst,
+    recurse=True,
+    filter=None,
+    dict_factory=dict,
+    retain_collection_types=False,
+):
+    """
+    Return the ``attrs`` attribute values of *inst* as a dict.
+
+    Optionally recurse into other ``attrs``-decorated classes.
+
+    :param inst: Instance of an ``attrs``-decorated class.
+    :param bool recurse: Recurse into classes that are also
+        ``attrs``-decorated.
+    :param callable filter: A callable whose return code determines whether an
+        attribute or element is included (``True``) or dropped (``False``).  Is
+        called with the :class:`attr.Attribute` as the first argument and the
+        value as the second argument.
+    :param callable dict_factory: A callable to produce dictionaries from.  For
+        example, to produce ordered dictionaries instead of normal Python
+        dictionaries, pass in ``collections.OrderedDict``.
+    :param bool retain_collection_types: Do not convert to ``list`` when
+        encountering an attribute whose type is ``tuple`` or ``set``.  Only
+        meaningful if ``recurse`` is ``True``.
+
+    :rtype: return type of *dict_factory*
+
+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``
+        class.
+
+    ..  versionadded:: 16.0.0 *dict_factory*
+    ..  versionadded:: 16.1.0 *retain_collection_types*
+    """
+    attrs = fields(inst.__class__)
+    rv = dict_factory()
+    for a in attrs:
+        v = getattr(inst, a.name)
+        if filter is not None and not filter(a, v):
+            continue
+        if recurse is True:
+            if has(v.__class__):
+                rv[a.name] = asdict(
+                    v, True, filter, dict_factory, retain_collection_types
+                )
+            elif isinstance(v, (tuple, list, set)):
+                cf = v.__class__ if retain_collection_types is True else list
+                rv[a.name] = cf(
+                    [
+                        _asdict_anything(
+                            i, filter, dict_factory, retain_collection_types
+                        )
+                        for i in v
+                    ]
+                )
+            elif isinstance(v, dict):
+                df = dict_factory
+                rv[a.name] = df(
+                    (
+                        _asdict_anything(
+                            kk, filter, df, retain_collection_types
+                        ),
+                        _asdict_anything(
+                            vv, filter, df, retain_collection_types
+                        ),
+                    )
+                    for kk, vv in iteritems(v)
+                )
+            else:
+                rv[a.name] = v
+        else:
+            rv[a.name] = v
+    return rv
+
+
+def _asdict_anything(val, filter, dict_factory, retain_collection_types):
+    """
+    ``asdict`` only works on attrs instances, this works on anything.
+    """
+    if getattr(val.__class__, "__attrs_attrs__", None) is not None:
+        # Attrs class.
+        rv = asdict(val, True, filter, dict_factory, retain_collection_types)
+    elif isinstance(val, (tuple, list, set)):
+        cf = val.__class__ if retain_collection_types is True else list
+        rv = cf(
+            [
+                _asdict_anything(
+                    i, filter, dict_factory, retain_collection_types
+                )
+                for i in val
+            ]
+        )
+    elif isinstance(val, dict):
+        df = dict_factory
+        rv = df(
+            (
+                _asdict_anything(kk, filter, df, retain_collection_types),
+                _asdict_anything(vv, filter, df, retain_collection_types),
+            )
+            for kk, vv in iteritems(val)
+        )
+    else:
+        rv = val
+    return rv
+
+
+def astuple(
+    inst,
+    recurse=True,
+    filter=None,
+    tuple_factory=tuple,
+    retain_collection_types=False,
+):
+    """
+    Return the ``attrs`` attribute values of *inst* as a tuple.
+
+    Optionally recurse into other ``attrs``-decorated classes.
+
+    :param inst: Instance of an ``attrs``-decorated class.
+    :param bool recurse: Recurse into classes that are also
+        ``attrs``-decorated.
+    :param callable filter: A callable whose return code determines whether an
+        attribute or element is included (``True``) or dropped (``False``).  Is
+        called with the :class:`attr.Attribute` as the first argument and the
+        value as the second argument.
+    :param callable tuple_factory: A callable to produce tuples from.  For
+        example, to produce lists instead of tuples.
+    :param bool retain_collection_types: Do not convert to ``list``
+        or ``dict`` when encountering an attribute which type is
+        ``tuple``, ``dict`` or ``set``.  Only meaningful if ``recurse`` is
+        ``True``.
+
+    :rtype: return type of *tuple_factory*
+
+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``
+        class.
+
+    ..  versionadded:: 16.2.0
+    """
+    attrs = fields(inst.__class__)
+    rv = []
+    retain = retain_collection_types  # Very long. :/
+    for a in attrs:
+        v = getattr(inst, a.name)
+        if filter is not None and not filter(a, v):
+            continue
+        if recurse is True:
+            if has(v.__class__):
+                rv.append(
+                    astuple(
+                        v,
+                        recurse=True,
+                        filter=filter,
+                        tuple_factory=tuple_factory,
+                        retain_collection_types=retain,
+                    )
+                )
+            elif isinstance(v, (tuple, list, set)):
+                cf = v.__class__ if retain is True else list
+                rv.append(
+                    cf(
+                        [
+                            astuple(
+                                j,
+                                recurse=True,
+                                filter=filter,
+                                tuple_factory=tuple_factory,
+                                retain_collection_types=retain,
+                            )
+                            if has(j.__class__)
+                            else j
+                            for j in v
+                        ]
+                    )
+                )
+            elif isinstance(v, dict):
+                df = v.__class__ if retain is True else dict
+                rv.append(
+                    df(
+                        (
+                            astuple(
+                                kk,
+                                tuple_factory=tuple_factory,
+                                retain_collection_types=retain,
+                            )
+                            if has(kk.__class__)
+                            else kk,
+                            astuple(
+                                vv,
+                                tuple_factory=tuple_factory,
+                                retain_collection_types=retain,
+                            )
+                            if has(vv.__class__)
+                            else vv,
+                        )
+                        for kk, vv in iteritems(v)
+                    )
+                )
+            else:
+                rv.append(v)
+        else:
+            rv.append(v)
+    return rv if tuple_factory is list else tuple_factory(rv)
+
+
+def has(cls):
+    """
+    Check whether *cls* is a class with ``attrs`` attributes.
+
+    :param type cls: Class to introspect.
+    :raise TypeError: If *cls* is not a class.
+
+    :rtype: :class:`bool`
+    """
+    return getattr(cls, "__attrs_attrs__", None) is not None
+
+
+def assoc(inst, **changes):
+    """
+    Copy *inst* and apply *changes*.
+
+    :param inst: Instance of a class with ``attrs`` attributes.
+    :param changes: Keyword changes in the new copy.
+
+    :return: A copy of inst with *changes* incorporated.
+
+    :raise attr.exceptions.AttrsAttributeNotFoundError: If *attr_name* couldn't
+        be found on *cls*.
+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``
+        class.
+
+    ..  deprecated:: 17.1.0
+        Use :func:`evolve` instead.
+    """
+    import warnings
+
+    warnings.warn(
+        "assoc is deprecated and will be removed after 2018/01.",
+        DeprecationWarning,
+        stacklevel=2,
+    )
+    new = copy.copy(inst)
+    attrs = fields(inst.__class__)
+    for k, v in iteritems(changes):
+        a = getattr(attrs, k, NOTHING)
+        if a is NOTHING:
+            raise AttrsAttributeNotFoundError(
+                "{k} is not an attrs attribute on {cl}.".format(
+                    k=k, cl=new.__class__
+                )
+            )
+        _obj_setattr(new, k, v)
+    return new
+
+
+def evolve(inst, **changes):
+    """
+    Create a new instance, based on *inst* with *changes* applied.
+
+    :param inst: Instance of a class with ``attrs`` attributes.
+    :param changes: Keyword changes in the new copy.
+
+    :return: A copy of inst with *changes* incorporated.
+
+    :raise TypeError: If *attr_name* couldn't be found in the class
+        ``__init__``.
+    :raise attr.exceptions.NotAnAttrsClassError: If *cls* is not an ``attrs``
+        class.
+
+    ..  versionadded:: 17.1.0
+    """
+    cls = inst.__class__
+    attrs = fields(cls)
+    for a in attrs:
+        if not a.init:
+            continue
+        attr_name = a.name  # To deal with private attributes.
+        init_name = attr_name if attr_name[0] != "_" else attr_name[1:]
+        if init_name not in changes:
+            changes[init_name] = getattr(inst, attr_name)
+    return cls(**changes)
Index: venv/Lib/site-packages/_pytest/doctest.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/doctest.py	(date 1543190977004)
+++ venv/Lib/site-packages/_pytest/doctest.py	(date 1543190977004)
@@ -0,0 +1,516 @@
+""" discover and run doctests in modules and test files."""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import platform
+import sys
+import traceback
+
+import pytest
+from _pytest._code.code import ExceptionInfo
+from _pytest._code.code import ReprFileLocation
+from _pytest._code.code import TerminalRepr
+from _pytest.fixtures import FixtureRequest
+
+
+DOCTEST_REPORT_CHOICE_NONE = "none"
+DOCTEST_REPORT_CHOICE_CDIFF = "cdiff"
+DOCTEST_REPORT_CHOICE_NDIFF = "ndiff"
+DOCTEST_REPORT_CHOICE_UDIFF = "udiff"
+DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE = "only_first_failure"
+
+DOCTEST_REPORT_CHOICES = (
+    DOCTEST_REPORT_CHOICE_NONE,
+    DOCTEST_REPORT_CHOICE_CDIFF,
+    DOCTEST_REPORT_CHOICE_NDIFF,
+    DOCTEST_REPORT_CHOICE_UDIFF,
+    DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE,
+)
+
+# Lazy definition of runner class
+RUNNER_CLASS = None
+
+
+def pytest_addoption(parser):
+    parser.addini(
+        "doctest_optionflags",
+        "option flags for doctests",
+        type="args",
+        default=["ELLIPSIS"],
+    )
+    parser.addini(
+        "doctest_encoding", "encoding used for doctest files", default="utf-8"
+    )
+    group = parser.getgroup("collect")
+    group.addoption(
+        "--doctest-modules",
+        action="store_true",
+        default=False,
+        help="run doctests in all .py modules",
+        dest="doctestmodules",
+    )
+    group.addoption(
+        "--doctest-report",
+        type=str.lower,
+        default="udiff",
+        help="choose another output format for diffs on doctest failure",
+        choices=DOCTEST_REPORT_CHOICES,
+        dest="doctestreport",
+    )
+    group.addoption(
+        "--doctest-glob",
+        action="append",
+        default=[],
+        metavar="pat",
+        help="doctests file matching pattern, default: test*.txt",
+        dest="doctestglob",
+    )
+    group.addoption(
+        "--doctest-ignore-import-errors",
+        action="store_true",
+        default=False,
+        help="ignore doctest ImportErrors",
+        dest="doctest_ignore_import_errors",
+    )
+    group.addoption(
+        "--doctest-continue-on-failure",
+        action="store_true",
+        default=False,
+        help="for a given doctest, continue to run after the first failure",
+        dest="doctest_continue_on_failure",
+    )
+
+
+def pytest_collect_file(path, parent):
+    config = parent.config
+    if path.ext == ".py":
+        if config.option.doctestmodules and not _is_setup_py(config, path, parent):
+            return DoctestModule(path, parent)
+    elif _is_doctest(config, path, parent):
+        return DoctestTextfile(path, parent)
+
+
+def _is_setup_py(config, path, parent):
+    if path.basename != "setup.py":
+        return False
+    contents = path.read()
+    return "setuptools" in contents or "distutils" in contents
+
+
+def _is_doctest(config, path, parent):
+    if path.ext in (".txt", ".rst") and parent.session.isinitpath(path):
+        return True
+    globs = config.getoption("doctestglob") or ["test*.txt"]
+    for glob in globs:
+        if path.check(fnmatch=glob):
+            return True
+    return False
+
+
+class ReprFailDoctest(TerminalRepr):
+    def __init__(self, reprlocation_lines):
+        # List of (reprlocation, lines) tuples
+        self.reprlocation_lines = reprlocation_lines
+
+    def toterminal(self, tw):
+        for reprlocation, lines in self.reprlocation_lines:
+            for line in lines:
+                tw.line(line)
+            reprlocation.toterminal(tw)
+
+
+class MultipleDoctestFailures(Exception):
+    def __init__(self, failures):
+        super(MultipleDoctestFailures, self).__init__()
+        self.failures = failures
+
+
+def _init_runner_class():
+    import doctest
+
+    class PytestDoctestRunner(doctest.DebugRunner):
+        """
+        Runner to collect failures.  Note that the out variable in this case is
+        a list instead of a stdout-like object
+        """
+
+        def __init__(
+            self, checker=None, verbose=None, optionflags=0, continue_on_failure=True
+        ):
+            doctest.DebugRunner.__init__(
+                self, checker=checker, verbose=verbose, optionflags=optionflags
+            )
+            self.continue_on_failure = continue_on_failure
+
+        def report_failure(self, out, test, example, got):
+            failure = doctest.DocTestFailure(test, example, got)
+            if self.continue_on_failure:
+                out.append(failure)
+            else:
+                raise failure
+
+        def report_unexpected_exception(self, out, test, example, exc_info):
+            failure = doctest.UnexpectedException(test, example, exc_info)
+            if self.continue_on_failure:
+                out.append(failure)
+            else:
+                raise failure
+
+    return PytestDoctestRunner
+
+
+def _get_runner(checker=None, verbose=None, optionflags=0, continue_on_failure=True):
+    # We need this in order to do a lazy import on doctest
+    global RUNNER_CLASS
+    if RUNNER_CLASS is None:
+        RUNNER_CLASS = _init_runner_class()
+    return RUNNER_CLASS(
+        checker=checker,
+        verbose=verbose,
+        optionflags=optionflags,
+        continue_on_failure=continue_on_failure,
+    )
+
+
+class DoctestItem(pytest.Item):
+    def __init__(self, name, parent, runner=None, dtest=None):
+        super(DoctestItem, self).__init__(name, parent)
+        self.runner = runner
+        self.dtest = dtest
+        self.obj = None
+        self.fixture_request = None
+
+    def setup(self):
+        if self.dtest is not None:
+            self.fixture_request = _setup_fixtures(self)
+            globs = dict(getfixture=self.fixture_request.getfixturevalue)
+            for name, value in self.fixture_request.getfixturevalue(
+                "doctest_namespace"
+            ).items():
+                globs[name] = value
+            self.dtest.globs.update(globs)
+
+    def runtest(self):
+        _check_all_skipped(self.dtest)
+        self._disable_output_capturing_for_darwin()
+        failures = []
+        self.runner.run(self.dtest, out=failures)
+        if failures:
+            raise MultipleDoctestFailures(failures)
+
+    def _disable_output_capturing_for_darwin(self):
+        """
+        Disable output capturing. Otherwise, stdout is lost to doctest (#985)
+        """
+        if platform.system() != "Darwin":
+            return
+        capman = self.config.pluginmanager.getplugin("capturemanager")
+        if capman:
+            capman.suspend_global_capture(in_=True)
+            out, err = capman.read_global_capture()
+            sys.stdout.write(out)
+            sys.stderr.write(err)
+
+    def repr_failure(self, excinfo):
+        import doctest
+
+        failures = None
+        if excinfo.errisinstance((doctest.DocTestFailure, doctest.UnexpectedException)):
+            failures = [excinfo.value]
+        elif excinfo.errisinstance(MultipleDoctestFailures):
+            failures = excinfo.value.failures
+
+        if failures is not None:
+            reprlocation_lines = []
+            for failure in failures:
+                example = failure.example
+                test = failure.test
+                filename = test.filename
+                if test.lineno is None:
+                    lineno = None
+                else:
+                    lineno = test.lineno + example.lineno + 1
+                message = type(failure).__name__
+                reprlocation = ReprFileLocation(filename, lineno, message)
+                checker = _get_checker()
+                report_choice = _get_report_choice(
+                    self.config.getoption("doctestreport")
+                )
+                if lineno is not None:
+                    lines = failure.test.docstring.splitlines(False)
+                    # add line numbers to the left of the error message
+                    lines = [
+                        "%03d %s" % (i + test.lineno + 1, x)
+                        for (i, x) in enumerate(lines)
+                    ]
+                    # trim docstring error lines to 10
+                    lines = lines[max(example.lineno - 9, 0) : example.lineno + 1]
+                else:
+                    lines = [
+                        "EXAMPLE LOCATION UNKNOWN, not showing all tests of that example"
+                    ]
+                    indent = ">>>"
+                    for line in example.source.splitlines():
+                        lines.append("??? %s %s" % (indent, line))
+                        indent = "..."
+                if isinstance(failure, doctest.DocTestFailure):
+                    lines += checker.output_difference(
+                        example, failure.got, report_choice
+                    ).split("\n")
+                else:
+                    inner_excinfo = ExceptionInfo(failure.exc_info)
+                    lines += ["UNEXPECTED EXCEPTION: %s" % repr(inner_excinfo.value)]
+                    lines += traceback.format_exception(*failure.exc_info)
+                reprlocation_lines.append((reprlocation, lines))
+            return ReprFailDoctest(reprlocation_lines)
+        else:
+            return super(DoctestItem, self).repr_failure(excinfo)
+
+    def reportinfo(self):
+        return self.fspath, self.dtest.lineno, "[doctest] %s" % self.name
+
+
+def _get_flag_lookup():
+    import doctest
+
+    return dict(
+        DONT_ACCEPT_TRUE_FOR_1=doctest.DONT_ACCEPT_TRUE_FOR_1,
+        DONT_ACCEPT_BLANKLINE=doctest.DONT_ACCEPT_BLANKLINE,
+        NORMALIZE_WHITESPACE=doctest.NORMALIZE_WHITESPACE,
+        ELLIPSIS=doctest.ELLIPSIS,
+        IGNORE_EXCEPTION_DETAIL=doctest.IGNORE_EXCEPTION_DETAIL,
+        COMPARISON_FLAGS=doctest.COMPARISON_FLAGS,
+        ALLOW_UNICODE=_get_allow_unicode_flag(),
+        ALLOW_BYTES=_get_allow_bytes_flag(),
+    )
+
+
+def get_optionflags(parent):
+    optionflags_str = parent.config.getini("doctest_optionflags")
+    flag_lookup_table = _get_flag_lookup()
+    flag_acc = 0
+    for flag in optionflags_str:
+        flag_acc |= flag_lookup_table[flag]
+    return flag_acc
+
+
+def _get_continue_on_failure(config):
+    continue_on_failure = config.getvalue("doctest_continue_on_failure")
+    if continue_on_failure:
+        # We need to turn off this if we use pdb since we should stop at
+        # the first failure
+        if config.getvalue("usepdb"):
+            continue_on_failure = False
+    return continue_on_failure
+
+
+class DoctestTextfile(pytest.Module):
+    obj = None
+
+    def collect(self):
+        import doctest
+
+        # inspired by doctest.testfile; ideally we would use it directly,
+        # but it doesn't support passing a custom checker
+        encoding = self.config.getini("doctest_encoding")
+        text = self.fspath.read_text(encoding)
+        filename = str(self.fspath)
+        name = self.fspath.basename
+        globs = {"__name__": "__main__"}
+
+        optionflags = get_optionflags(self)
+
+        runner = _get_runner(
+            verbose=0,
+            optionflags=optionflags,
+            checker=_get_checker(),
+            continue_on_failure=_get_continue_on_failure(self.config),
+        )
+        _fix_spoof_python2(runner, encoding)
+
+        parser = doctest.DocTestParser()
+        test = parser.get_doctest(text, globs, name, filename, 0)
+        if test.examples:
+            yield DoctestItem(test.name, self, runner, test)
+
+
+def _check_all_skipped(test):
+    """raises pytest.skip() if all examples in the given DocTest have the SKIP
+    option set.
+    """
+    import doctest
+
+    all_skipped = all(x.options.get(doctest.SKIP, False) for x in test.examples)
+    if all_skipped:
+        pytest.skip("all tests skipped by +SKIP option")
+
+
+class DoctestModule(pytest.Module):
+    def collect(self):
+        import doctest
+
+        if self.fspath.basename == "conftest.py":
+            module = self.config.pluginmanager._importconftest(self.fspath)
+        else:
+            try:
+                module = self.fspath.pyimport()
+            except ImportError:
+                if self.config.getvalue("doctest_ignore_import_errors"):
+                    pytest.skip("unable to import module %r" % self.fspath)
+                else:
+                    raise
+        # uses internal doctest module parsing mechanism
+        finder = doctest.DocTestFinder()
+        optionflags = get_optionflags(self)
+        runner = _get_runner(
+            verbose=0,
+            optionflags=optionflags,
+            checker=_get_checker(),
+            continue_on_failure=_get_continue_on_failure(self.config),
+        )
+
+        for test in finder.find(module, module.__name__):
+            if test.examples:  # skip empty doctests
+                yield DoctestItem(test.name, self, runner, test)
+
+
+def _setup_fixtures(doctest_item):
+    """
+    Used by DoctestTextfile and DoctestItem to setup fixture information.
+    """
+
+    def func():
+        pass
+
+    doctest_item.funcargs = {}
+    fm = doctest_item.session._fixturemanager
+    doctest_item._fixtureinfo = fm.getfixtureinfo(
+        node=doctest_item, func=func, cls=None, funcargs=False
+    )
+    fixture_request = FixtureRequest(doctest_item)
+    fixture_request._fillfixtures()
+    return fixture_request
+
+
+def _get_checker():
+    """
+    Returns a doctest.OutputChecker subclass that takes in account the
+    ALLOW_UNICODE option to ignore u'' prefixes in strings and ALLOW_BYTES
+    to strip b'' prefixes.
+    Useful when the same doctest should run in Python 2 and Python 3.
+
+    An inner class is used to avoid importing "doctest" at the module
+    level.
+    """
+    if hasattr(_get_checker, "LiteralsOutputChecker"):
+        return _get_checker.LiteralsOutputChecker()
+
+    import doctest
+    import re
+
+    class LiteralsOutputChecker(doctest.OutputChecker):
+        """
+        Copied from doctest_nose_plugin.py from the nltk project:
+            https://github.com/nltk/nltk
+
+        Further extended to also support byte literals.
+        """
+
+        _unicode_literal_re = re.compile(r"(\W|^)[uU]([rR]?[\'\"])", re.UNICODE)
+        _bytes_literal_re = re.compile(r"(\W|^)[bB]([rR]?[\'\"])", re.UNICODE)
+
+        def check_output(self, want, got, optionflags):
+            res = doctest.OutputChecker.check_output(self, want, got, optionflags)
+            if res:
+                return True
+
+            allow_unicode = optionflags & _get_allow_unicode_flag()
+            allow_bytes = optionflags & _get_allow_bytes_flag()
+            if not allow_unicode and not allow_bytes:
+                return False
+
+            else:  # pragma: no cover
+
+                def remove_prefixes(regex, txt):
+                    return re.sub(regex, r"\1\2", txt)
+
+                if allow_unicode:
+                    want = remove_prefixes(self._unicode_literal_re, want)
+                    got = remove_prefixes(self._unicode_literal_re, got)
+                if allow_bytes:
+                    want = remove_prefixes(self._bytes_literal_re, want)
+                    got = remove_prefixes(self._bytes_literal_re, got)
+                res = doctest.OutputChecker.check_output(self, want, got, optionflags)
+                return res
+
+    _get_checker.LiteralsOutputChecker = LiteralsOutputChecker
+    return _get_checker.LiteralsOutputChecker()
+
+
+def _get_allow_unicode_flag():
+    """
+    Registers and returns the ALLOW_UNICODE flag.
+    """
+    import doctest
+
+    return doctest.register_optionflag("ALLOW_UNICODE")
+
+
+def _get_allow_bytes_flag():
+    """
+    Registers and returns the ALLOW_BYTES flag.
+    """
+    import doctest
+
+    return doctest.register_optionflag("ALLOW_BYTES")
+
+
+def _get_report_choice(key):
+    """
+    This function returns the actual `doctest` module flag value, we want to do it as late as possible to avoid
+    importing `doctest` and all its dependencies when parsing options, as it adds overhead and breaks tests.
+    """
+    import doctest
+
+    return {
+        DOCTEST_REPORT_CHOICE_UDIFF: doctest.REPORT_UDIFF,
+        DOCTEST_REPORT_CHOICE_CDIFF: doctest.REPORT_CDIFF,
+        DOCTEST_REPORT_CHOICE_NDIFF: doctest.REPORT_NDIFF,
+        DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE: doctest.REPORT_ONLY_FIRST_FAILURE,
+        DOCTEST_REPORT_CHOICE_NONE: 0,
+    }[key]
+
+
+def _fix_spoof_python2(runner, encoding):
+    """
+    Installs a "SpoofOut" into the given DebugRunner so it properly deals with unicode output. This
+    should patch only doctests for text files because they don't have a way to declare their
+    encoding. Doctests in docstrings from Python modules don't have the same problem given that
+    Python already decoded the strings.
+
+    This fixes the problem related in issue #2434.
+    """
+    from _pytest.compat import _PY2
+
+    if not _PY2:
+        return
+
+    from doctest import _SpoofOut
+
+    class UnicodeSpoof(_SpoofOut):
+        def getvalue(self):
+            result = _SpoofOut.getvalue(self)
+            if encoding and isinstance(result, bytes):
+                result = result.decode(encoding)
+            return result
+
+    runner._fakeout = UnicodeSpoof()
+
+
+@pytest.fixture(scope="session")
+def doctest_namespace():
+    """
+    Fixture that returns a :py:class:`dict` that will be injected into the namespace of doctests.
+    """
+    return dict()
Index: venv/Lib/site-packages/attr/__init__.pyi
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/__init__.pyi	(date 1543190977016)
+++ venv/Lib/site-packages/attr/__init__.pyi	(date 1543190977016)
@@ -0,0 +1,252 @@
+from typing import (
+    Any,
+    Callable,
+    Dict,
+    Generic,
+    List,
+    Optional,
+    Sequence,
+    Mapping,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    overload,
+)
+
+# `import X as X` is required to make these public
+from . import exceptions as exceptions
+from . import filters as filters
+from . import converters as converters
+from . import validators as validators
+
+_T = TypeVar("_T")
+_C = TypeVar("_C", bound=type)
+
+_ValidatorType = Callable[[Any, Attribute, _T], Any]
+_ConverterType = Callable[[Any], _T]
+_FilterType = Callable[[Attribute, Any], bool]
+# FIXME: in reality, if multiple validators are passed they must be in a list or tuple,
+# but those are invariant and so would prevent subtypes of _ValidatorType from working
+# when passed in a list or tuple.
+_ValidatorArgType = Union[_ValidatorType[_T], Sequence[_ValidatorType[_T]]]
+
+# _make --
+
+NOTHING: object
+
+# NOTE: Factory lies about its return type to make this possible: `x: List[int] = Factory(list)`
+# Work around mypy issue #4554 in the common case by using an overload.
+@overload
+def Factory(factory: Callable[[], _T]) -> _T: ...
+@overload
+def Factory(
+    factory: Union[Callable[[Any], _T], Callable[[], _T]],
+    takes_self: bool = ...,
+) -> _T: ...
+
+class Attribute(Generic[_T]):
+    name: str
+    default: Optional[_T]
+    validator: Optional[_ValidatorType[_T]]
+    repr: bool
+    cmp: bool
+    hash: Optional[bool]
+    init: bool
+    converter: Optional[_ConverterType[_T]]
+    metadata: Dict[Any, Any]
+    type: Optional[Type[_T]]
+    kw_only: bool
+    def __lt__(self, x: Attribute) -> bool: ...
+    def __le__(self, x: Attribute) -> bool: ...
+    def __gt__(self, x: Attribute) -> bool: ...
+    def __ge__(self, x: Attribute) -> bool: ...
+
+# NOTE: We had several choices for the annotation to use for type arg:
+# 1) Type[_T]
+#   - Pros: Handles simple cases correctly
+#   - Cons: Might produce less informative errors in the case of conflicting TypeVars
+#   e.g. `attr.ib(default='bad', type=int)`
+# 2) Callable[..., _T]
+#   - Pros: Better error messages than #1 for conflicting TypeVars
+#   - Cons: Terrible error messages for validator checks.
+#   e.g. attr.ib(type=int, validator=validate_str)
+#        -> error: Cannot infer function type argument
+# 3) type (and do all of the work in the mypy plugin)
+#   - Pros: Simple here, and we could customize the plugin with our own errors.
+#   - Cons: Would need to write mypy plugin code to handle all the cases.
+# We chose option #1.
+
+# `attr` lies about its return type to make the following possible:
+#     attr()    -> Any
+#     attr(8)   -> int
+#     attr(validator=<some callable>)  -> Whatever the callable expects.
+# This makes this type of assignments possible:
+#     x: int = attr(8)
+#
+# This form catches explicit None or no default but with no other arguments returns Any.
+@overload
+def attrib(
+    default: None = ...,
+    validator: None = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: None = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: None = ...,
+    converter: None = ...,
+    factory: None = ...,
+    kw_only: bool = ...,
+) -> Any: ...
+
+# This form catches an explicit None or no default and infers the type from the other arguments.
+@overload
+def attrib(
+    default: None = ...,
+    validator: Optional[_ValidatorArgType[_T]] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: Optional[_ConverterType[_T]] = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: Optional[Type[_T]] = ...,
+    converter: Optional[_ConverterType[_T]] = ...,
+    factory: Optional[Callable[[], _T]] = ...,
+    kw_only: bool = ...,
+) -> _T: ...
+
+# This form catches an explicit default argument.
+@overload
+def attrib(
+    default: _T,
+    validator: Optional[_ValidatorArgType[_T]] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: Optional[_ConverterType[_T]] = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: Optional[Type[_T]] = ...,
+    converter: Optional[_ConverterType[_T]] = ...,
+    factory: Optional[Callable[[], _T]] = ...,
+    kw_only: bool = ...,
+) -> _T: ...
+
+# This form covers type=non-Type: e.g. forward references (str), Any
+@overload
+def attrib(
+    default: Optional[_T] = ...,
+    validator: Optional[_ValidatorArgType[_T]] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: Optional[_ConverterType[_T]] = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: object = ...,
+    converter: Optional[_ConverterType[_T]] = ...,
+    factory: Optional[Callable[[], _T]] = ...,
+    kw_only: bool = ...,
+) -> Any: ...
+@overload
+def attrs(
+    maybe_cls: _C,
+    these: Optional[Dict[str, Any]] = ...,
+    repr_ns: Optional[str] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    slots: bool = ...,
+    frozen: bool = ...,
+    weakref_slot: bool = ...,
+    str: bool = ...,
+    auto_attribs: bool = ...,
+    kw_only: bool = ...,
+    cache_hash: bool = ...,
+) -> _C: ...
+@overload
+def attrs(
+    maybe_cls: None = ...,
+    these: Optional[Dict[str, Any]] = ...,
+    repr_ns: Optional[str] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    slots: bool = ...,
+    frozen: bool = ...,
+    weakref_slot: bool = ...,
+    str: bool = ...,
+    auto_attribs: bool = ...,
+    kw_only: bool = ...,
+    cache_hash: bool = ...,
+) -> Callable[[_C], _C]: ...
+
+# TODO: add support for returning NamedTuple from the mypy plugin
+class _Fields(Tuple[Attribute, ...]):
+    def __getattr__(self, name: str) -> Attribute: ...
+
+def fields(cls: type) -> _Fields: ...
+def fields_dict(cls: type) -> Dict[str, Attribute]: ...
+def validate(inst: Any) -> None: ...
+
+# TODO: add support for returning a proper attrs class from the mypy plugin
+# we use Any instead of _CountingAttr so that e.g. `make_class('Foo', [attr.ib()])` is valid
+def make_class(
+    name: str,
+    attrs: Union[List[str], Tuple[str, ...], Dict[str, Any]],
+    bases: Tuple[type, ...] = ...,
+    repr_ns: Optional[str] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    slots: bool = ...,
+    frozen: bool = ...,
+    weakref_slot: bool = ...,
+    str: bool = ...,
+    auto_attribs: bool = ...,
+    kw_only: bool = ...,
+    cache_hash: bool = ...,
+) -> type: ...
+
+# _funcs --
+
+# TODO: add support for returning TypedDict from the mypy plugin
+# FIXME: asdict/astuple do not honor their factory args.  waiting on one of these:
+# https://github.com/python/mypy/issues/4236
+# https://github.com/python/typing/issues/253
+def asdict(
+    inst: Any,
+    recurse: bool = ...,
+    filter: Optional[_FilterType] = ...,
+    dict_factory: Type[Mapping[Any, Any]] = ...,
+    retain_collection_types: bool = ...,
+) -> Dict[str, Any]: ...
+
+# TODO: add support for returning NamedTuple from the mypy plugin
+def astuple(
+    inst: Any,
+    recurse: bool = ...,
+    filter: Optional[_FilterType] = ...,
+    tuple_factory: Type[Sequence] = ...,
+    retain_collection_types: bool = ...,
+) -> Tuple[Any, ...]: ...
+def has(cls: type) -> bool: ...
+def assoc(inst: _T, **changes: Any) -> _T: ...
+def evolve(inst: _T, **changes: Any) -> _T: ...
+
+# _config --
+
+def set_run_validators(run: bool) -> None: ...
+def get_run_validators() -> bool: ...
+
+# aliases --
+
+s = attributes = attrs
+ib = attr = attrib
+dataclass = attrs  # Technically, partial(attrs, auto_attribs=True) ;)
Index: venv/Lib/site-packages/_pytest/unittest.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/unittest.py	(date 1543190977028)
+++ venv/Lib/site-packages/_pytest/unittest.py	(date 1543190977028)
@@ -0,0 +1,259 @@
+""" discovery and running of std-library "unittest" style tests. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+import traceback
+
+import _pytest._code
+from _pytest.compat import getimfunc
+from _pytest.config import hookimpl
+from _pytest.outcomes import fail
+from _pytest.outcomes import skip
+from _pytest.outcomes import xfail
+from _pytest.python import Class
+from _pytest.python import Function
+from _pytest.python import Module
+from _pytest.python import transfer_markers
+
+
+def pytest_pycollect_makeitem(collector, name, obj):
+    # has unittest been imported and is obj a subclass of its TestCase?
+    try:
+        if not issubclass(obj, sys.modules["unittest"].TestCase):
+            return
+    except Exception:
+        return
+    # yes, so let's collect it
+    return UnitTestCase(name, parent=collector)
+
+
+class UnitTestCase(Class):
+    # marker for fixturemanger.getfixtureinfo()
+    # to declare that our children do not support funcargs
+    nofuncargs = True
+
+    def setup(self):
+        cls = self.obj
+        if getattr(cls, "__unittest_skip__", False):
+            return  # skipped
+        setup = getattr(cls, "setUpClass", None)
+        if setup is not None:
+            setup()
+        teardown = getattr(cls, "tearDownClass", None)
+        if teardown is not None:
+            self.addfinalizer(teardown)
+        super(UnitTestCase, self).setup()
+
+    def collect(self):
+        from unittest import TestLoader
+
+        cls = self.obj
+        if not getattr(cls, "__test__", True):
+            return
+        self.session._fixturemanager.parsefactories(self, unittest=True)
+        loader = TestLoader()
+        module = self.getparent(Module).obj
+        foundsomething = False
+        for name in loader.getTestCaseNames(self.obj):
+            x = getattr(self.obj, name)
+            if not getattr(x, "__test__", True):
+                continue
+            funcobj = getimfunc(x)
+            transfer_markers(funcobj, cls, module)
+            yield TestCaseFunction(name, parent=self, callobj=funcobj)
+            foundsomething = True
+
+        if not foundsomething:
+            runtest = getattr(self.obj, "runTest", None)
+            if runtest is not None:
+                ut = sys.modules.get("twisted.trial.unittest", None)
+                if ut is None or runtest != ut.TestCase.runTest:
+                    yield TestCaseFunction("runTest", parent=self)
+
+
+class TestCaseFunction(Function):
+    nofuncargs = True
+    _excinfo = None
+    _testcase = None
+
+    def setup(self):
+        self._testcase = self.parent.obj(self.name)
+        self._fix_unittest_skip_decorator()
+        self._obj = getattr(self._testcase, self.name)
+        if hasattr(self._testcase, "setup_method"):
+            self._testcase.setup_method(self._obj)
+        if hasattr(self, "_request"):
+            self._request._fillfixtures()
+
+    def _fix_unittest_skip_decorator(self):
+        """
+        The @unittest.skip decorator calls functools.wraps(self._testcase)
+        The call to functools.wraps() fails unless self._testcase
+        has a __name__ attribute. This is usually automatically supplied
+        if the test is a function or method, but we need to add manually
+        here.
+
+        See issue #1169
+        """
+        if sys.version_info[0] == 2:
+            setattr(self._testcase, "__name__", self.name)
+
+    def teardown(self):
+        if hasattr(self._testcase, "teardown_method"):
+            self._testcase.teardown_method(self._obj)
+        # Allow garbage collection on TestCase instance attributes.
+        self._testcase = None
+        self._obj = None
+
+    def startTest(self, testcase):
+        pass
+
+    def _addexcinfo(self, rawexcinfo):
+        # unwrap potential exception info (see twisted trial support below)
+        rawexcinfo = getattr(rawexcinfo, "_rawexcinfo", rawexcinfo)
+        try:
+            excinfo = _pytest._code.ExceptionInfo(rawexcinfo)
+        except TypeError:
+            try:
+                try:
+                    values = traceback.format_exception(*rawexcinfo)
+                    values.insert(
+                        0,
+                        "NOTE: Incompatible Exception Representation, "
+                        "displaying natively:\n\n",
+                    )
+                    fail("".join(values), pytrace=False)
+                except (fail.Exception, KeyboardInterrupt):
+                    raise
+                except:  # noqa
+                    fail(
+                        "ERROR: Unknown Incompatible Exception "
+                        "representation:\n%r" % (rawexcinfo,),
+                        pytrace=False,
+                    )
+            except KeyboardInterrupt:
+                raise
+            except fail.Exception:
+                excinfo = _pytest._code.ExceptionInfo()
+        self.__dict__.setdefault("_excinfo", []).append(excinfo)
+
+    def addError(self, testcase, rawexcinfo):
+        self._addexcinfo(rawexcinfo)
+
+    def addFailure(self, testcase, rawexcinfo):
+        self._addexcinfo(rawexcinfo)
+
+    def addSkip(self, testcase, reason):
+        try:
+            skip(reason)
+        except skip.Exception:
+            self._skipped_by_mark = True
+            self._addexcinfo(sys.exc_info())
+
+    def addExpectedFailure(self, testcase, rawexcinfo, reason=""):
+        try:
+            xfail(str(reason))
+        except xfail.Exception:
+            self._addexcinfo(sys.exc_info())
+
+    def addUnexpectedSuccess(self, testcase, reason=""):
+        self._unexpectedsuccess = reason
+
+    def addSuccess(self, testcase):
+        pass
+
+    def stopTest(self, testcase):
+        pass
+
+    def _handle_skip(self):
+        # implements the skipping machinery (see #2137)
+        # analog to pythons Lib/unittest/case.py:run
+        testMethod = getattr(self._testcase, self._testcase._testMethodName)
+        if getattr(self._testcase.__class__, "__unittest_skip__", False) or getattr(
+            testMethod, "__unittest_skip__", False
+        ):
+            # If the class or method was skipped.
+            skip_why = getattr(
+                self._testcase.__class__, "__unittest_skip_why__", ""
+            ) or getattr(testMethod, "__unittest_skip_why__", "")
+            try:  # PY3, unittest2 on PY2
+                self._testcase._addSkip(self, self._testcase, skip_why)
+            except TypeError:  # PY2
+                if sys.version_info[0] != 2:
+                    raise
+                self._testcase._addSkip(self, skip_why)
+            return True
+        return False
+
+    def runtest(self):
+        if self.config.pluginmanager.get_plugin("pdbinvoke") is None:
+            self._testcase(result=self)
+        else:
+            # disables tearDown and cleanups for post mortem debugging (see #1890)
+            if self._handle_skip():
+                return
+            self._testcase.debug()
+
+    def _prunetraceback(self, excinfo):
+        Function._prunetraceback(self, excinfo)
+        traceback = excinfo.traceback.filter(
+            lambda x: not x.frame.f_globals.get("__unittest")
+        )
+        if traceback:
+            excinfo.traceback = traceback
+
+
+@hookimpl(tryfirst=True)
+def pytest_runtest_makereport(item, call):
+    if isinstance(item, TestCaseFunction):
+        if item._excinfo:
+            call.excinfo = item._excinfo.pop(0)
+            try:
+                del call.result
+            except AttributeError:
+                pass
+
+
+# twisted trial support
+
+
+@hookimpl(hookwrapper=True)
+def pytest_runtest_protocol(item):
+    if isinstance(item, TestCaseFunction) and "twisted.trial.unittest" in sys.modules:
+        ut = sys.modules["twisted.python.failure"]
+        Failure__init__ = ut.Failure.__init__
+        check_testcase_implements_trial_reporter()
+
+        def excstore(
+            self, exc_value=None, exc_type=None, exc_tb=None, captureVars=None
+        ):
+            if exc_value is None:
+                self._rawexcinfo = sys.exc_info()
+            else:
+                if exc_type is None:
+                    exc_type = type(exc_value)
+                self._rawexcinfo = (exc_type, exc_value, exc_tb)
+            try:
+                Failure__init__(
+                    self, exc_value, exc_type, exc_tb, captureVars=captureVars
+                )
+            except TypeError:
+                Failure__init__(self, exc_value, exc_type, exc_tb)
+
+        ut.Failure.__init__ = excstore
+        yield
+        ut.Failure.__init__ = Failure__init__
+    else:
+        yield
+
+
+def check_testcase_implements_trial_reporter(done=[]):
+    if done:
+        return
+    from zope.interface import classImplements
+    from twisted.trial.itrial import IReporter
+
+    classImplements(TestCaseFunction, IReporter)
+    done.append(1)
Index: venv/Lib/site-packages/attrs-18.2.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attrs-18.2.0.dist-info/METADATA	(date 1543190977041)
+++ venv/Lib/site-packages/attrs-18.2.0.dist-info/METADATA	(date 1543190977041)
@@ -0,0 +1,260 @@
+Metadata-Version: 2.1
+Name: attrs
+Version: 18.2.0
+Summary: Classes Without Boilerplate
+Home-page: https://www.attrs.org/
+Author: Hynek Schlawack
+Author-email: hs@ox.cx
+Maintainer: Hynek Schlawack
+Maintainer-email: hs@ox.cx
+License: MIT
+Project-URL: Documentation, https://www.attrs.org/
+Project-URL: Bug Tracker, https://github.com/python-attrs/attrs/issues
+Project-URL: Source Code, https://github.com/python-attrs/attrs
+Keywords: class,attribute,boilerplate
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: Natural Language :: English
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Provides-Extra: docs
+Provides-Extra: dev
+Provides-Extra: tests
+Provides-Extra: dev
+Requires-Dist: coverage; extra == 'dev'
+Requires-Dist: hypothesis; extra == 'dev'
+Requires-Dist: pympler; extra == 'dev'
+Requires-Dist: pytest; extra == 'dev'
+Requires-Dist: six; extra == 'dev'
+Requires-Dist: zope.interface; extra == 'dev'
+Requires-Dist: sphinx; extra == 'dev'
+Requires-Dist: zope.interface; extra == 'dev'
+Requires-Dist: pre-commit; extra == 'dev'
+Provides-Extra: docs
+Requires-Dist: sphinx; extra == 'docs'
+Requires-Dist: zope.interface; extra == 'docs'
+Provides-Extra: tests
+Requires-Dist: coverage; extra == 'tests'
+Requires-Dist: hypothesis; extra == 'tests'
+Requires-Dist: pympler; extra == 'tests'
+Requires-Dist: pytest; extra == 'tests'
+Requires-Dist: six; extra == 'tests'
+Requires-Dist: zope.interface; extra == 'tests'
+
+.. image:: https://www.attrs.org/en/latest/_static/attrs_logo.png
+   :alt: attrs Logo
+
+======================================
+``attrs``: Classes Without Boilerplate
+======================================
+
+.. image:: https://readthedocs.org/projects/attrs/badge/?version=stable
+   :target: https://www.attrs.org/en/stable/?badge=stable
+   :alt: Documentation Status
+
+.. image:: https://travis-ci.org/python-attrs/attrs.svg?branch=master
+   :target: https://travis-ci.org/python-attrs/attrs
+   :alt: CI Status
+
+.. image:: https://codecov.io/github/python-attrs/attrs/branch/master/graph/badge.svg
+   :target: https://codecov.io/github/python-attrs/attrs
+   :alt: Test Coverage
+
+.. image:: https://img.shields.io/badge/code%20style-black-000000.svg
+   :target: https://github.com/ambv/black
+   :alt: Code style: black
+
+.. teaser-begin
+
+``attrs`` is the Python package that will bring back the **joy** of **writing classes** by relieving you from the drudgery of implementing object protocols (aka `dunder <https://nedbatchelder.com/blog/200605/dunder.html>`_ methods).
+
+Its main goal is to help you to write **concise** and **correct** software without slowing down your code.
+
+.. -spiel-end-
+
+For that, it gives you a class decorator and a way to declaratively define the attributes on that class:
+
+.. -code-begin-
+
+.. code-block:: pycon
+
+   >>> import attr
+
+   >>> @attr.s
+   ... class SomeClass(object):
+   ...     a_number = attr.ib(default=42)
+   ...     list_of_numbers = attr.ib(factory=list)
+   ...
+   ...     def hard_math(self, another_number):
+   ...         return self.a_number + sum(self.list_of_numbers) * another_number
+
+
+   >>> sc = SomeClass(1, [1, 2, 3])
+   >>> sc
+   SomeClass(a_number=1, list_of_numbers=[1, 2, 3])
+
+   >>> sc.hard_math(3)
+   19
+   >>> sc == SomeClass(1, [1, 2, 3])
+   True
+   >>> sc != SomeClass(2, [3, 2, 1])
+   True
+
+   >>> attr.asdict(sc)
+   {'a_number': 1, 'list_of_numbers': [1, 2, 3]}
+
+   >>> SomeClass()
+   SomeClass(a_number=42, list_of_numbers=[])
+
+   >>> C = attr.make_class("C", ["a", "b"])
+   >>> C("foo", "bar")
+   C(a='foo', b='bar')
+
+
+After *declaring* your attributes ``attrs`` gives you:
+
+- a concise and explicit overview of the class's attributes,
+- a nice human-readable ``__repr__``,
+- a complete set of comparison methods,
+- an initializer,
+- and much more,
+
+*without* writing dull boilerplate code again and again and *without* runtime performance penalties.
+
+On Python 3.6 and later, you can often even drop the calls to ``attr.ib()`` by using `type annotations <https://www.attrs.org/en/latest/types.html>`_.
+
+This gives you the power to use actual classes with actual types in your code instead of confusing ``tuple``\ s or `confusingly behaving <https://www.attrs.org/en/stable/why.html#namedtuples>`_ ``namedtuple``\ s.
+Which in turn encourages you to write *small classes* that do `one thing well <https://www.destroyallsoftware.com/talks/boundaries>`_.
+Never again violate the `single responsibility principle <https://en.wikipedia.org/wiki/Single_responsibility_principle>`_ just because implementing ``__init__`` et al is a painful drag.
+
+
+.. -testimonials-
+
+Testimonials
+============
+
+**Amber Hawkie Brown**, Twisted Release Manager and Computer Owl:
+
+  Writing a fully-functional class using attrs takes me less time than writing this testimonial.
+
+
+**Glyph Lefkowitz**, creator of `Twisted <https://twistedmatrix.com/>`_, `Automat <https://pypi.org/project/Automat/>`_, and other open source software, in `The One Python Library Everyone Needs <https://glyph.twistedmatrix.com/2016/08/attrs.html>`_:
+
+  I’m looking forward to is being able to program in Python-with-attrs everywhere.
+  It exerts a subtle, but positive, design influence in all the codebases I’ve see it used in.
+
+
+**Kenneth Reitz**, author of `Requests <http://www.python-requests.org/>`_ and Developer Advocate at DigitalOcean, (`on paper no less <https://twitter.com/hynek/status/866817877650751488>`_!):
+
+  attrs—classes for humans.  I like it.
+
+
+**Łukasz Langa**, prolific CPython core developer and Production Engineer at Facebook:
+
+  I'm increasingly digging your attr.ocity. Good job!
+
+
+.. -end-
+
+.. -project-information-
+
+Getting Help
+============
+
+Please use the ``python-attrs`` tag on `StackOverflow <https://stackoverflow.com/questions/tagged/python-attrs>`_ to get help.
+
+Answering questions of your fellow developers is also great way to help the project!
+
+
+Project Information
+===================
+
+``attrs`` is released under the `MIT <https://choosealicense.com/licenses/mit/>`_ license,
+its documentation lives at `Read the Docs <https://www.attrs.org/>`_,
+the code on `GitHub <https://github.com/python-attrs/attrs>`_,
+and the latest release on `PyPI <https://pypi.org/project/attrs/>`_.
+It’s rigorously tested on Python 2.7, 3.4+, and PyPy.
+
+We collect information on **third-party extensions** in our `wiki <https://github.com/python-attrs/attrs/wiki/Extensions-to-attrs>`_.
+Feel free to browse and add your own!
+
+If you'd like to contribute to ``attrs`` you're most welcome and we've written `a little guide <https://www.attrs.org/en/latest/contributing.html>`_ to get you started!
+
+
+Release Information
+===================
+
+18.2.0 (2018-09-01)
+-------------------
+
+Deprecations
+^^^^^^^^^^^^
+
+- Comparing subclasses using ``<``, ``>``, ``<=``, and ``>=`` is now deprecated.
+  The docs always claimed that instances are only compared if the types are identical, so this is a first step to conform to the docs.
+
+  Equality operators (``==`` and ``!=``) were always strict in this regard.
+  `#394 <https://github.com/python-attrs/attrs/issues/394>`_
+
+
+Changes
+^^^^^^^
+
+- ``attrs`` now ships its own `PEP 484 <https://www.python.org/dev/peps/pep-0484/>`_ type hints.
+  Together with `mypy <http://mypy-lang.org>`_'s ``attrs`` plugin, you've got all you need for writing statically typed code in both Python 2 and 3!
+
+  At that occasion, we've also added `narrative docs <https://www.attrs.org/en/stable/types.html>`_ about type annotations in ``attrs``.
+  `#238 <https://github.com/python-attrs/attrs/issues/238>`_
+- Added *kw_only* arguments to ``attr.ib`` and ``attr.s``, and a corresponding *kw_only* attribute to ``attr.Attribute``.
+  This change makes it possible to have a generated ``__init__`` with keyword-only arguments on Python 3, relaxing the required ordering of default and non-default valued attributes.
+  `#281 <https://github.com/python-attrs/attrs/issues/281>`_,
+  `#411 <https://github.com/python-attrs/attrs/issues/411>`_
+- The test suite now runs with ``hypothesis.HealthCheck.too_slow`` disabled to prevent CI breakage on slower computers.
+  `#364 <https://github.com/python-attrs/attrs/issues/364>`_,
+  `#396 <https://github.com/python-attrs/attrs/issues/396>`_
+- ``attr.validators.in_()`` now raises a ``ValueError`` with a useful message even if the options are a string and the value is not a string.
+  `#383 <https://github.com/python-attrs/attrs/issues/383>`_
+- ``attr.asdict()`` now properly handles deeply nested lists and dictionaries.
+  `#395 <https://github.com/python-attrs/attrs/issues/395>`_
+- Added ``attr.converters.default_if_none()`` that allows to replace ``None`` values in attributes.
+  For example ``attr.ib(converter=default_if_none(""))`` replaces ``None`` by empty strings.
+  `#400 <https://github.com/python-attrs/attrs/issues/400>`_,
+  `#414 <https://github.com/python-attrs/attrs/issues/414>`_
+- Fixed a reference leak where the original class would remain live after being replaced when ``slots=True`` is set.
+  `#407 <https://github.com/python-attrs/attrs/issues/407>`_
+- Slotted classes can now be made weakly referenceable by passing ``@attr.s(weakref_slot=True)``.
+  `#420 <https://github.com/python-attrs/attrs/issues/420>`_
+- Added *cache_hash* option to ``@attr.s`` which causes the hash code to be computed once and stored on the object.
+  `#425 <https://github.com/python-attrs/attrs/issues/425>`_
+- Attributes can be named ``property`` and ``itemgetter`` now.
+  `#430 <https://github.com/python-attrs/attrs/issues/430>`_
+- It is now possible to override a base class' class variable using only class annotations.
+  `#431 <https://github.com/python-attrs/attrs/issues/431>`_
+
+`Full changelog <https://www.attrs.org/en/stable/changelog.html>`_.
+
+Credits
+=======
+
+``attrs`` is written and maintained by `Hynek Schlawack <https://hynek.me/>`_.
+
+The development is kindly supported by `Variomedia AG <https://www.variomedia.de/>`_.
+
+A full list of contributors can be found in `GitHub's overview <https://github.com/python-attrs/attrs/graphs/contributors>`_.
+
+It’s the spiritual successor of `characteristic <https://characteristic.readthedocs.io/>`_ and aspires to fix some of it clunkiness and unfortunate decisions.
+Both were inspired by Twisted’s `FancyEqMixin <https://twistedmatrix.com/documents/current/api/twisted.python.util.FancyEqMixin.html>`_ but both are implemented using class decorators because `subclassing is bad for you <https://www.youtube.com/watch?v=3MNVP9-hglc>`_, m’kay?
+
+
Index: venv/Lib/site-packages/attrs-18.2.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attrs-18.2.0.dist-info/INSTALLER	(date 1543190977051)
+++ venv/Lib/site-packages/attrs-18.2.0.dist-info/INSTALLER	(date 1543190977051)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/py/_code/_assertionold.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/_assertionold.py	(date 1543190977064)
+++ venv/Lib/site-packages/py/_code/_assertionold.py	(date 1543190977064)
@@ -0,0 +1,556 @@
+import py
+import sys, inspect
+from compiler import parse, ast, pycodegen
+from py._code.assertion import BuiltinAssertionError, _format_explanation
+import types
+
+passthroughex = py.builtin._sysex
+
+class Failure:
+    def __init__(self, node):
+        self.exc, self.value, self.tb = sys.exc_info()
+        self.node = node
+
+class View(object):
+    """View base class.
+
+    If C is a subclass of View, then C(x) creates a proxy object around
+    the object x.  The actual class of the proxy is not C in general,
+    but a *subclass* of C determined by the rules below.  To avoid confusion
+    we call view class the class of the proxy (a subclass of C, so of View)
+    and object class the class of x.
+
+    Attributes and methods not found in the proxy are automatically read on x.
+    Other operations like setting attributes are performed on the proxy, as
+    determined by its view class.  The object x is available from the proxy
+    as its __obj__ attribute.
+
+    The view class selection is determined by the __view__ tuples and the
+    optional __viewkey__ method.  By default, the selected view class is the
+    most specific subclass of C whose __view__ mentions the class of x.
+    If no such subclass is found, the search proceeds with the parent
+    object classes.  For example, C(True) will first look for a subclass
+    of C with __view__ = (..., bool, ...) and only if it doesn't find any
+    look for one with __view__ = (..., int, ...), and then ..., object,...
+    If everything fails the class C itself is considered to be the default.
+
+    Alternatively, the view class selection can be driven by another aspect
+    of the object x, instead of the class of x, by overriding __viewkey__.
+    See last example at the end of this module.
+    """
+
+    _viewcache = {}
+    __view__ = ()
+
+    def __new__(rootclass, obj, *args, **kwds):
+        self = object.__new__(rootclass)
+        self.__obj__ = obj
+        self.__rootclass__ = rootclass
+        key = self.__viewkey__()
+        try:
+            self.__class__ = self._viewcache[key]
+        except KeyError:
+            self.__class__ = self._selectsubclass(key)
+        return self
+
+    def __getattr__(self, attr):
+        # attributes not found in the normal hierarchy rooted on View
+        # are looked up in the object's real class
+        return getattr(self.__obj__, attr)
+
+    def __viewkey__(self):
+        return self.__obj__.__class__
+
+    def __matchkey__(self, key, subclasses):
+        if inspect.isclass(key):
+            keys = inspect.getmro(key)
+        else:
+            keys = [key]
+        for key in keys:
+            result = [C for C in subclasses if key in C.__view__]
+            if result:
+                return result
+        return []
+
+    def _selectsubclass(self, key):
+        subclasses = list(enumsubclasses(self.__rootclass__))
+        for C in subclasses:
+            if not isinstance(C.__view__, tuple):
+                C.__view__ = (C.__view__,)
+        choices = self.__matchkey__(key, subclasses)
+        if not choices:
+            return self.__rootclass__
+        elif len(choices) == 1:
+            return choices[0]
+        else:
+            # combine the multiple choices
+            return type('?', tuple(choices), {})
+
+    def __repr__(self):
+        return '%s(%r)' % (self.__rootclass__.__name__, self.__obj__)
+
+
+def enumsubclasses(cls):
+    for subcls in cls.__subclasses__():
+        for subsubclass in enumsubclasses(subcls):
+            yield subsubclass
+    yield cls
+
+
+class Interpretable(View):
+    """A parse tree node with a few extra methods."""
+    explanation = None
+
+    def is_builtin(self, frame):
+        return False
+
+    def eval(self, frame):
+        # fall-back for unknown expression nodes
+        try:
+            expr = ast.Expression(self.__obj__)
+            expr.filename = '<eval>'
+            self.__obj__.filename = '<eval>'
+            co = pycodegen.ExpressionCodeGenerator(expr).getCode()
+            result = frame.eval(co)
+        except passthroughex:
+            raise
+        except:
+            raise Failure(self)
+        self.result = result
+        self.explanation = self.explanation or frame.repr(self.result)
+
+    def run(self, frame):
+        # fall-back for unknown statement nodes
+        try:
+            expr = ast.Module(None, ast.Stmt([self.__obj__]))
+            expr.filename = '<run>'
+            co = pycodegen.ModuleCodeGenerator(expr).getCode()
+            frame.exec_(co)
+        except passthroughex:
+            raise
+        except:
+            raise Failure(self)
+
+    def nice_explanation(self):
+        return _format_explanation(self.explanation)
+
+
+class Name(Interpretable):
+    __view__ = ast.Name
+
+    def is_local(self, frame):
+        source = '%r in locals() is not globals()' % self.name
+        try:
+            return frame.is_true(frame.eval(source))
+        except passthroughex:
+            raise
+        except:
+            return False
+
+    def is_global(self, frame):
+        source = '%r in globals()' % self.name
+        try:
+            return frame.is_true(frame.eval(source))
+        except passthroughex:
+            raise
+        except:
+            return False
+
+    def is_builtin(self, frame):
+        source = '%r not in locals() and %r not in globals()' % (
+            self.name, self.name)
+        try:
+            return frame.is_true(frame.eval(source))
+        except passthroughex:
+            raise
+        except:
+            return False
+
+    def eval(self, frame):
+        super(Name, self).eval(frame)
+        if not self.is_local(frame):
+            self.explanation = self.name
+
+class Compare(Interpretable):
+    __view__ = ast.Compare
+
+    def eval(self, frame):
+        expr = Interpretable(self.expr)
+        expr.eval(frame)
+        for operation, expr2 in self.ops:
+            if hasattr(self, 'result'):
+                # shortcutting in chained expressions
+                if not frame.is_true(self.result):
+                    break
+            expr2 = Interpretable(expr2)
+            expr2.eval(frame)
+            self.explanation = "%s %s %s" % (
+                expr.explanation, operation, expr2.explanation)
+            source = "__exprinfo_left %s __exprinfo_right" % operation
+            try:
+                self.result = frame.eval(source,
+                                         __exprinfo_left=expr.result,
+                                         __exprinfo_right=expr2.result)
+            except passthroughex:
+                raise
+            except:
+                raise Failure(self)
+            expr = expr2
+
+class And(Interpretable):
+    __view__ = ast.And
+
+    def eval(self, frame):
+        explanations = []
+        for expr in self.nodes:
+            expr = Interpretable(expr)
+            expr.eval(frame)
+            explanations.append(expr.explanation)
+            self.result = expr.result
+            if not frame.is_true(expr.result):
+                break
+        self.explanation = '(' + ' and '.join(explanations) + ')'
+
+class Or(Interpretable):
+    __view__ = ast.Or
+
+    def eval(self, frame):
+        explanations = []
+        for expr in self.nodes:
+            expr = Interpretable(expr)
+            expr.eval(frame)
+            explanations.append(expr.explanation)
+            self.result = expr.result
+            if frame.is_true(expr.result):
+                break
+        self.explanation = '(' + ' or '.join(explanations) + ')'
+
+
+# == Unary operations ==
+keepalive = []
+for astclass, astpattern in {
+    ast.Not    : 'not __exprinfo_expr',
+    ast.Invert : '(~__exprinfo_expr)',
+    }.items():
+
+    class UnaryArith(Interpretable):
+        __view__ = astclass
+
+        def eval(self, frame, astpattern=astpattern):
+            expr = Interpretable(self.expr)
+            expr.eval(frame)
+            self.explanation = astpattern.replace('__exprinfo_expr',
+                                                  expr.explanation)
+            try:
+                self.result = frame.eval(astpattern,
+                                         __exprinfo_expr=expr.result)
+            except passthroughex:
+                raise
+            except:
+                raise Failure(self)
+
+    keepalive.append(UnaryArith)
+
+# == Binary operations ==
+for astclass, astpattern in {
+    ast.Add    : '(__exprinfo_left + __exprinfo_right)',
+    ast.Sub    : '(__exprinfo_left - __exprinfo_right)',
+    ast.Mul    : '(__exprinfo_left * __exprinfo_right)',
+    ast.Div    : '(__exprinfo_left / __exprinfo_right)',
+    ast.Mod    : '(__exprinfo_left % __exprinfo_right)',
+    ast.Power  : '(__exprinfo_left ** __exprinfo_right)',
+    }.items():
+
+    class BinaryArith(Interpretable):
+        __view__ = astclass
+
+        def eval(self, frame, astpattern=astpattern):
+            left = Interpretable(self.left)
+            left.eval(frame)
+            right = Interpretable(self.right)
+            right.eval(frame)
+            self.explanation = (astpattern
+                                .replace('__exprinfo_left',  left .explanation)
+                                .replace('__exprinfo_right', right.explanation))
+            try:
+                self.result = frame.eval(astpattern,
+                                         __exprinfo_left=left.result,
+                                         __exprinfo_right=right.result)
+            except passthroughex:
+                raise
+            except:
+                raise Failure(self)
+
+    keepalive.append(BinaryArith)
+
+
+class CallFunc(Interpretable):
+    __view__ = ast.CallFunc
+
+    def is_bool(self, frame):
+        source = 'isinstance(__exprinfo_value, bool)'
+        try:
+            return frame.is_true(frame.eval(source,
+                                            __exprinfo_value=self.result))
+        except passthroughex:
+            raise
+        except:
+            return False
+
+    def eval(self, frame):
+        node = Interpretable(self.node)
+        node.eval(frame)
+        explanations = []
+        vars = {'__exprinfo_fn': node.result}
+        source = '__exprinfo_fn('
+        for a in self.args:
+            if isinstance(a, ast.Keyword):
+                keyword = a.name
+                a = a.expr
+            else:
+                keyword = None
+            a = Interpretable(a)
+            a.eval(frame)
+            argname = '__exprinfo_%d' % len(vars)
+            vars[argname] = a.result
+            if keyword is None:
+                source += argname + ','
+                explanations.append(a.explanation)
+            else:
+                source += '%s=%s,' % (keyword, argname)
+                explanations.append('%s=%s' % (keyword, a.explanation))
+        if self.star_args:
+            star_args = Interpretable(self.star_args)
+            star_args.eval(frame)
+            argname = '__exprinfo_star'
+            vars[argname] = star_args.result
+            source += '*' + argname + ','
+            explanations.append('*' + star_args.explanation)
+        if self.dstar_args:
+            dstar_args = Interpretable(self.dstar_args)
+            dstar_args.eval(frame)
+            argname = '__exprinfo_kwds'
+            vars[argname] = dstar_args.result
+            source += '**' + argname + ','
+            explanations.append('**' + dstar_args.explanation)
+        self.explanation = "%s(%s)" % (
+            node.explanation, ', '.join(explanations))
+        if source.endswith(','):
+            source = source[:-1]
+        source += ')'
+        try:
+            self.result = frame.eval(source, **vars)
+        except passthroughex:
+            raise
+        except:
+            raise Failure(self)
+        if not node.is_builtin(frame) or not self.is_bool(frame):
+            r = frame.repr(self.result)
+            self.explanation = '%s\n{%s = %s\n}' % (r, r, self.explanation)
+
+class Getattr(Interpretable):
+    __view__ = ast.Getattr
+
+    def eval(self, frame):
+        expr = Interpretable(self.expr)
+        expr.eval(frame)
+        source = '__exprinfo_expr.%s' % self.attrname
+        try:
+            self.result = frame.eval(source, __exprinfo_expr=expr.result)
+        except passthroughex:
+            raise
+        except:
+            raise Failure(self)
+        self.explanation = '%s.%s' % (expr.explanation, self.attrname)
+        # if the attribute comes from the instance, its value is interesting
+        source = ('hasattr(__exprinfo_expr, "__dict__") and '
+                  '%r in __exprinfo_expr.__dict__' % self.attrname)
+        try:
+            from_instance = frame.is_true(
+                frame.eval(source, __exprinfo_expr=expr.result))
+        except passthroughex:
+            raise
+        except:
+            from_instance = True
+        if from_instance:
+            r = frame.repr(self.result)
+            self.explanation = '%s\n{%s = %s\n}' % (r, r, self.explanation)
+
+# == Re-interpretation of full statements ==
+
+class Assert(Interpretable):
+    __view__ = ast.Assert
+
+    def run(self, frame):
+        test = Interpretable(self.test)
+        test.eval(frame)
+        # simplify 'assert False where False = ...'
+        if (test.explanation.startswith('False\n{False = ') and
+            test.explanation.endswith('\n}')):
+            test.explanation = test.explanation[15:-2]
+        # print the result as  'assert <explanation>'
+        self.result = test.result
+        self.explanation = 'assert ' + test.explanation
+        if not frame.is_true(test.result):
+            try:
+                raise BuiltinAssertionError
+            except passthroughex:
+                raise
+            except:
+                raise Failure(self)
+
+class Assign(Interpretable):
+    __view__ = ast.Assign
+
+    def run(self, frame):
+        expr = Interpretable(self.expr)
+        expr.eval(frame)
+        self.result = expr.result
+        self.explanation = '... = ' + expr.explanation
+        # fall-back-run the rest of the assignment
+        ass = ast.Assign(self.nodes, ast.Name('__exprinfo_expr'))
+        mod = ast.Module(None, ast.Stmt([ass]))
+        mod.filename = '<run>'
+        co = pycodegen.ModuleCodeGenerator(mod).getCode()
+        try:
+            frame.exec_(co, __exprinfo_expr=expr.result)
+        except passthroughex:
+            raise
+        except:
+            raise Failure(self)
+
+class Discard(Interpretable):
+    __view__ = ast.Discard
+
+    def run(self, frame):
+        expr = Interpretable(self.expr)
+        expr.eval(frame)
+        self.result = expr.result
+        self.explanation = expr.explanation
+
+class Stmt(Interpretable):
+    __view__ = ast.Stmt
+
+    def run(self, frame):
+        for stmt in self.nodes:
+            stmt = Interpretable(stmt)
+            stmt.run(frame)
+
+
+def report_failure(e):
+    explanation = e.node.nice_explanation()
+    if explanation:
+        explanation = ", in: " + explanation
+    else:
+        explanation = ""
+    sys.stdout.write("%s: %s%s\n" % (e.exc.__name__, e.value, explanation))
+
+def check(s, frame=None):
+    if frame is None:
+        frame = sys._getframe(1)
+        frame = py.code.Frame(frame)
+    expr = parse(s, 'eval')
+    assert isinstance(expr, ast.Expression)
+    node = Interpretable(expr.node)
+    try:
+        node.eval(frame)
+    except passthroughex:
+        raise
+    except Failure:
+        e = sys.exc_info()[1]
+        report_failure(e)
+    else:
+        if not frame.is_true(node.result):
+            sys.stderr.write("assertion failed: %s\n" % node.nice_explanation())
+
+
+###########################################################
+# API / Entry points
+# #########################################################
+
+def interpret(source, frame, should_fail=False):
+    module = Interpretable(parse(source, 'exec').node)
+    #print "got module", module
+    if isinstance(frame, types.FrameType):
+        frame = py.code.Frame(frame)
+    try:
+        module.run(frame)
+    except Failure:
+        e = sys.exc_info()[1]
+        return getfailure(e)
+    except passthroughex:
+        raise
+    except:
+        import traceback
+        traceback.print_exc()
+    if should_fail:
+        return ("(assertion failed, but when it was re-run for "
+                "printing intermediate values, it did not fail.  Suggestions: "
+                "compute assert expression before the assert or use --nomagic)")
+    else:
+        return None
+
+def getmsg(excinfo):
+    if isinstance(excinfo, tuple):
+        excinfo = py.code.ExceptionInfo(excinfo)
+    #frame, line = gettbline(tb)
+    #frame = py.code.Frame(frame)
+    #return interpret(line, frame)
+
+    tb = excinfo.traceback[-1]
+    source = str(tb.statement).strip()
+    x = interpret(source, tb.frame, should_fail=True)
+    if not isinstance(x, str):
+        raise TypeError("interpret returned non-string %r" % (x,))
+    return x
+
+def getfailure(e):
+    explanation = e.node.nice_explanation()
+    if str(e.value):
+        lines = explanation.split('\n')
+        lines[0] += "  << %s" % (e.value,)
+        explanation = '\n'.join(lines)
+    text = "%s: %s" % (e.exc.__name__, explanation)
+    if text.startswith('AssertionError: assert '):
+        text = text[16:]
+    return text
+
+def run(s, frame=None):
+    if frame is None:
+        frame = sys._getframe(1)
+        frame = py.code.Frame(frame)
+    module = Interpretable(parse(s, 'exec').node)
+    try:
+        module.run(frame)
+    except Failure:
+        e = sys.exc_info()[1]
+        report_failure(e)
+
+
+if __name__ == '__main__':
+    # example:
+    def f():
+        return 5
+    def g():
+        return 3
+    def h(x):
+        return 'never'
+    check("f() * g() == 5")
+    check("not f()")
+    check("not (f() and g() or 0)")
+    check("f() == g()")
+    i = 4
+    check("i == f()")
+    check("len(f()) == 0")
+    check("isinstance(2+3+4, float)")
+
+    run("x = i")
+    check("x == 5")
+
+    run("assert not f(), 'oops'")
+    run("a, b, c = 1, 2")
+    run("a, b, c = f()")
+
+    check("max([f(),g()]) == 4")
+    check("'hello'[g()] == 'h'")
+    run("'guk%d' % h(f())")
Index: venv/Lib/site-packages/attrs-18.2.0.dist-info/LICENSE.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attrs-18.2.0.dist-info/LICENSE.txt	(date 1543190977074)
+++ venv/Lib/site-packages/attrs-18.2.0.dist-info/LICENSE.txt	(date 1543190977074)
@@ -0,0 +1,21 @@
+The MIT License (MIT)
+
+Copyright (c) 2015 Hynek Schlawack
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
Index: venv/Lib/site-packages/py/_log/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_log/__init__.py	(date 1543190977082)
+++ venv/Lib/site-packages/py/_log/__init__.py	(date 1543190977082)
@@ -0,0 +1,2 @@
+""" logging API ('producers' and 'consumers' connected via keywords) """
+
Index: venv/Lib/site-packages/attrs-18.2.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attrs-18.2.0.dist-info/top_level.txt	(date 1543190977091)
+++ venv/Lib/site-packages/attrs-18.2.0.dist-info/top_level.txt	(date 1543190977091)
@@ -0,0 +1,1 @@
+attr
Index: venv/Lib/site-packages/attrs-18.2.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attrs-18.2.0.dist-info/WHEEL	(date 1543190977099)
+++ venv/Lib/site-packages/attrs-18.2.0.dist-info/WHEEL	(date 1543190977099)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.31.1)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/py/_log/warning.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_log/warning.py	(date 1543190977111)
+++ venv/Lib/site-packages/py/_log/warning.py	(date 1543190977111)
@@ -0,0 +1,79 @@
+import py, sys
+
+class DeprecationWarning(DeprecationWarning):
+    def __init__(self, msg, path, lineno):
+        self.msg = msg
+        self.path = path
+        self.lineno = lineno
+    def __repr__(self):
+        return "%s:%d: %s" %(self.path, self.lineno+1, self.msg)
+    def __str__(self):
+        return self.msg
+
+def _apiwarn(startversion, msg, stacklevel=2, function=None):
+    # below is mostly COPIED from python2.4/warnings.py's def warn()
+    # Get context information
+    if isinstance(stacklevel, str):
+        frame = sys._getframe(1)
+        level = 1
+        found = frame.f_code.co_filename.find(stacklevel) != -1
+        while frame:
+            co = frame.f_code
+            if co.co_filename.find(stacklevel) == -1:
+                if found:
+                    stacklevel = level
+                    break
+            else:
+                found = True
+            level += 1
+            frame = frame.f_back
+        else:
+            stacklevel = 1
+    msg = "%s (since version %s)" %(msg, startversion)
+    warn(msg, stacklevel=stacklevel+1, function=function)
+
+
+def warn(msg, stacklevel=1, function=None):
+    if function is not None:
+        import inspect
+        filename = inspect.getfile(function)
+        lineno = py.code.getrawcode(function).co_firstlineno
+    else:
+        try:
+            caller = sys._getframe(stacklevel)
+        except ValueError:
+            globals = sys.__dict__
+            lineno = 1
+        else:
+            globals = caller.f_globals
+            lineno = caller.f_lineno
+        if '__name__' in globals:
+            module = globals['__name__']
+        else:
+            module = "<string>"
+        filename = globals.get('__file__')
+    if filename:
+        fnl = filename.lower()
+        if fnl.endswith(".pyc") or fnl.endswith(".pyo"):
+            filename = filename[:-1]
+        elif fnl.endswith("$py.class"):
+            filename = filename.replace('$py.class', '.py')
+    else:
+        if module == "__main__":
+            try:
+                filename = sys.argv[0]
+            except AttributeError:
+                # embedded interpreters don't have sys.argv, see bug #839151
+                filename = '__main__'
+        if not filename:
+            filename = module
+    path = py.path.local(filename)
+    warning = DeprecationWarning(msg, path, lineno)
+    import warnings
+    warnings.warn_explicit(warning, category=Warning,
+        filename=str(warning.path),
+        lineno=warning.lineno,
+        registry=warnings.__dict__.setdefault(
+            "__warningsregistry__", {})
+    )
+
Index: venv/Lib/site-packages/py/_xmlgen.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_xmlgen.py	(date 1543190977123)
+++ venv/Lib/site-packages/py/_xmlgen.py	(date 1543190977123)
@@ -0,0 +1,255 @@
+"""
+module for generating and serializing xml and html structures
+by using simple python objects.
+
+(c) holger krekel, holger at merlinux eu. 2009
+"""
+import sys, re
+
+if sys.version_info >= (3,0):
+    def u(s):
+        return s
+    def unicode(x, errors=None):
+        if hasattr(x, '__unicode__'):
+            return x.__unicode__()
+        return str(x)
+else:
+    def u(s):
+        return unicode(s)
+    unicode = unicode
+
+
+class NamespaceMetaclass(type):
+    def __getattr__(self, name):
+        if name[:1] == '_':
+            raise AttributeError(name)
+        if self == Namespace:
+            raise ValueError("Namespace class is abstract")
+        tagspec = self.__tagspec__
+        if tagspec is not None and name not in tagspec:
+            raise AttributeError(name)
+        classattr = {}
+        if self.__stickyname__:
+            classattr['xmlname'] = name
+        cls = type(name, (self.__tagclass__,), classattr)
+        setattr(self, name, cls)
+        return cls
+
+class Tag(list):
+    class Attr(object):
+        def __init__(self, **kwargs):
+            self.__dict__.update(kwargs)
+
+    def __init__(self, *args, **kwargs):
+        super(Tag, self).__init__(args)
+        self.attr = self.Attr(**kwargs)
+
+    def __unicode__(self):
+        return self.unicode(indent=0)
+    __str__ = __unicode__
+
+    def unicode(self, indent=2):
+        l = []
+        SimpleUnicodeVisitor(l.append, indent).visit(self)
+        return u("").join(l)
+
+    def __repr__(self):
+        name = self.__class__.__name__
+        return "<%r tag object %d>" % (name, id(self))
+
+Namespace = NamespaceMetaclass('Namespace', (object, ), {
+    '__tagspec__': None,
+    '__tagclass__': Tag,
+    '__stickyname__': False,
+})
+
+class HtmlTag(Tag):
+    def unicode(self, indent=2):
+        l = []
+        HtmlVisitor(l.append, indent, shortempty=False).visit(self)
+        return u("").join(l)
+
+# exported plain html namespace
+class html(Namespace):
+    __tagclass__ = HtmlTag
+    __stickyname__ = True
+    __tagspec__ = dict([(x,1) for x in (
+        'a,abbr,acronym,address,applet,area,article,aside,audio,b,'
+        'base,basefont,bdi,bdo,big,blink,blockquote,body,br,button,'
+        'canvas,caption,center,cite,code,col,colgroup,command,comment,'
+        'datalist,dd,del,details,dfn,dir,div,dl,dt,em,embed,'
+        'fieldset,figcaption,figure,footer,font,form,frame,frameset,h1,'
+        'h2,h3,h4,h5,h6,head,header,hgroup,hr,html,i,iframe,img,input,'
+        'ins,isindex,kbd,keygen,label,legend,li,link,listing,map,mark,'
+        'marquee,menu,meta,meter,multicol,nav,nobr,noembed,noframes,'
+        'noscript,object,ol,optgroup,option,output,p,param,pre,progress,'
+        'q,rp,rt,ruby,s,samp,script,section,select,small,source,span,'
+        'strike,strong,style,sub,summary,sup,table,tbody,td,textarea,'
+        'tfoot,th,thead,time,title,tr,track,tt,u,ul,xmp,var,video,wbr'
+    ).split(',') if x])
+
+    class Style(object):
+        def __init__(self, **kw):
+            for x, y in kw.items():
+                x = x.replace('_', '-')
+                setattr(self, x, y)
+
+
+class raw(object):
+    """just a box that can contain a unicode string that will be
+    included directly in the output"""
+    def __init__(self, uniobj):
+        self.uniobj = uniobj
+
+class SimpleUnicodeVisitor(object):
+    """ recursive visitor to write unicode. """
+    def __init__(self, write, indent=0, curindent=0, shortempty=True):
+        self.write = write
+        self.cache = {}
+        self.visited = {} # for detection of recursion
+        self.indent = indent
+        self.curindent = curindent
+        self.parents = []
+        self.shortempty = shortempty  # short empty tags or not
+
+    def visit(self, node):
+        """ dispatcher on node's class/bases name. """
+        cls = node.__class__
+        try:
+            visitmethod = self.cache[cls]
+        except KeyError:
+            for subclass in cls.__mro__:
+                visitmethod = getattr(self, subclass.__name__, None)
+                if visitmethod is not None:
+                    break
+            else:
+                visitmethod = self.__object
+            self.cache[cls] = visitmethod
+        visitmethod(node)
+
+    # the default fallback handler is marked private
+    # to avoid clashes with the tag name object
+    def __object(self, obj):
+        #self.write(obj)
+        self.write(escape(unicode(obj)))
+
+    def raw(self, obj):
+        self.write(obj.uniobj)
+
+    def list(self, obj):
+        assert id(obj) not in self.visited
+        self.visited[id(obj)] = 1
+        for elem in obj:
+            self.visit(elem)
+
+    def Tag(self, tag):
+        assert id(tag) not in self.visited
+        try:
+            tag.parent = self.parents[-1]
+        except IndexError:
+            tag.parent = None
+        self.visited[id(tag)] = 1
+        tagname = getattr(tag, 'xmlname', tag.__class__.__name__)
+        if self.curindent and not self._isinline(tagname):
+            self.write("\n" + u(' ') * self.curindent)
+        if tag:
+            self.curindent += self.indent
+            self.write(u('<%s%s>') % (tagname, self.attributes(tag)))
+            self.parents.append(tag)
+            for x in tag:
+                self.visit(x)
+            self.parents.pop()
+            self.write(u('</%s>') % tagname)
+            self.curindent -= self.indent
+        else:
+            nameattr = tagname+self.attributes(tag)
+            if self._issingleton(tagname):
+                self.write(u('<%s/>') % (nameattr,))
+            else:
+                self.write(u('<%s></%s>') % (nameattr, tagname))
+
+    def attributes(self, tag):
+        # serialize attributes
+        attrlist = dir(tag.attr)
+        attrlist.sort()
+        l = []
+        for name in attrlist:
+            res = self.repr_attribute(tag.attr, name)
+            if res is not None:
+                l.append(res)
+        l.extend(self.getstyle(tag))
+        return u("").join(l)
+
+    def repr_attribute(self, attrs, name):
+        if name[:2] != '__':
+            value = getattr(attrs, name)
+            if name.endswith('_'):
+                name = name[:-1]
+            if isinstance(value, raw):
+                insert = value.uniobj
+            else:
+                insert = escape(unicode(value))
+            return ' %s="%s"' % (name, insert)
+
+    def getstyle(self, tag):
+        """ return attribute list suitable for styling. """
+        try:
+            styledict = tag.style.__dict__
+        except AttributeError:
+            return []
+        else:
+            stylelist = [x+': ' + y for x,y in styledict.items()]
+            return [u(' style="%s"') % u('; ').join(stylelist)]
+
+    def _issingleton(self, tagname):
+        """can (and will) be overridden in subclasses"""
+        return self.shortempty
+
+    def _isinline(self, tagname):
+        """can (and will) be overridden in subclasses"""
+        return False
+
+class HtmlVisitor(SimpleUnicodeVisitor):
+
+    single = dict([(x, 1) for x in
+                ('br,img,area,param,col,hr,meta,link,base,'
+                    'input,frame').split(',')])
+    inline = dict([(x, 1) for x in
+                ('a abbr acronym b basefont bdo big br cite code dfn em font '
+                 'i img input kbd label q s samp select small span strike '
+                 'strong sub sup textarea tt u var'.split(' '))])
+
+    def repr_attribute(self, attrs, name):
+        if name == 'class_':
+            value = getattr(attrs, name)
+            if value is None:
+                return
+        return super(HtmlVisitor, self).repr_attribute(attrs, name)
+
+    def _issingleton(self, tagname):
+        return tagname in self.single
+
+    def _isinline(self, tagname):
+        return tagname in self.inline
+
+
+class _escape:
+    def __init__(self):
+        self.escape = {
+            u('"') : u('&quot;'), u('<') : u('&lt;'), u('>') : u('&gt;'),
+            u('&') : u('&amp;'), u("'") : u('&apos;'),
+            }
+        self.charef_rex = re.compile(u("|").join(self.escape.keys()))
+
+    def _replacer(self, match):
+        return self.escape[match.group(0)]
+
+    def __call__(self, ustring):
+        """ xml-escape the given unicode string. """
+        try:
+            ustring = unicode(ustring)
+        except UnicodeDecodeError:
+            ustring = unicode(ustring, 'utf-8', errors='replace')
+        return self.charef_rex.sub(self._replacer, ustring)
+
+escape = _escape()
Index: venv/Lib/site-packages/py/_log/log.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_log/log.py	(date 1543190977135)
+++ venv/Lib/site-packages/py/_log/log.py	(date 1543190977135)
@@ -0,0 +1,206 @@
+"""
+basic logging functionality based on a producer/consumer scheme.
+
+XXX implement this API: (maybe put it into slogger.py?)
+
+        log = Logger(
+                    info=py.log.STDOUT,
+                    debug=py.log.STDOUT,
+                    command=None)
+        log.info("hello", "world")
+        log.command("hello", "world")
+
+        log = Logger(info=Logger(something=...),
+                     debug=py.log.STDOUT,
+                     command=None)
+"""
+import py
+import sys
+
+
+class Message(object):
+    def __init__(self, keywords, args):
+        self.keywords = keywords
+        self.args = args
+
+    def content(self):
+        return " ".join(map(str, self.args))
+
+    def prefix(self):
+        return "[%s] " % (":".join(self.keywords))
+
+    def __str__(self):
+        return self.prefix() + self.content()
+
+
+class Producer(object):
+    """ (deprecated) Log producer API which sends messages to be logged
+        to a 'consumer' object, which then prints them to stdout,
+        stderr, files, etc. Used extensively by PyPy-1.1.
+    """
+
+    Message = Message  # to allow later customization
+    keywords2consumer = {}
+
+    def __init__(self, keywords, keywordmapper=None, **kw):
+        if hasattr(keywords, 'split'):
+            keywords = tuple(keywords.split())
+        self._keywords = keywords
+        if keywordmapper is None:
+            keywordmapper = default_keywordmapper
+        self._keywordmapper = keywordmapper
+
+    def __repr__(self):
+        return "<py.log.Producer %s>" % ":".join(self._keywords)
+
+    def __getattr__(self, name):
+        if '_' in name:
+            raise AttributeError(name)
+        producer = self.__class__(self._keywords + (name,))
+        setattr(self, name, producer)
+        return producer
+
+    def __call__(self, *args):
+        """ write a message to the appropriate consumer(s) """
+        func = self._keywordmapper.getconsumer(self._keywords)
+        if func is not None:
+            func(self.Message(self._keywords, args))
+
+class KeywordMapper:
+    def __init__(self):
+        self.keywords2consumer = {}
+
+    def getstate(self):
+        return self.keywords2consumer.copy()
+
+    def setstate(self, state):
+        self.keywords2consumer.clear()
+        self.keywords2consumer.update(state)
+
+    def getconsumer(self, keywords):
+        """ return a consumer matching the given keywords.
+
+            tries to find the most suitable consumer by walking, starting from
+            the back, the list of keywords, the first consumer matching a
+            keyword is returned (falling back to py.log.default)
+        """
+        for i in range(len(keywords), 0, -1):
+            try:
+                return self.keywords2consumer[keywords[:i]]
+            except KeyError:
+                continue
+        return self.keywords2consumer.get('default', default_consumer)
+
+    def setconsumer(self, keywords, consumer):
+        """ set a consumer for a set of keywords. """
+        # normalize to tuples
+        if isinstance(keywords, str):
+            keywords = tuple(filter(None, keywords.split()))
+        elif hasattr(keywords, '_keywords'):
+            keywords = keywords._keywords
+        elif not isinstance(keywords, tuple):
+            raise TypeError("key %r is not a string or tuple" % (keywords,))
+        if consumer is not None and not py.builtin.callable(consumer):
+            if not hasattr(consumer, 'write'):
+                raise TypeError(
+                    "%r should be None, callable or file-like" % (consumer,))
+            consumer = File(consumer)
+        self.keywords2consumer[keywords] = consumer
+
+
+def default_consumer(msg):
+    """ the default consumer, prints the message to stdout (using 'print') """
+    sys.stderr.write(str(msg)+"\n")
+
+default_keywordmapper = KeywordMapper()
+
+
+def setconsumer(keywords, consumer):
+    default_keywordmapper.setconsumer(keywords, consumer)
+
+
+def setstate(state):
+    default_keywordmapper.setstate(state)
+
+
+def getstate():
+    return default_keywordmapper.getstate()
+
+#
+# Consumers
+#
+
+
+class File(object):
+    """ log consumer wrapping a file(-like) object """
+    def __init__(self, f):
+        assert hasattr(f, 'write')
+        # assert isinstance(f, file) or not hasattr(f, 'open')
+        self._file = f
+
+    def __call__(self, msg):
+        """ write a message to the log """
+        self._file.write(str(msg) + "\n")
+        if hasattr(self._file, 'flush'):
+            self._file.flush()
+
+
+class Path(object):
+    """ log consumer that opens and writes to a Path """
+    def __init__(self, filename, append=False,
+                 delayed_create=False, buffering=False):
+        self._append = append
+        self._filename = str(filename)
+        self._buffering = buffering
+        if not delayed_create:
+            self._openfile()
+
+    def _openfile(self):
+        mode = self._append and 'a' or 'w'
+        f = open(self._filename, mode)
+        self._file = f
+
+    def __call__(self, msg):
+        """ write a message to the log """
+        if not hasattr(self, "_file"):
+            self._openfile()
+        self._file.write(str(msg) + "\n")
+        if not self._buffering:
+            self._file.flush()
+
+
+def STDOUT(msg):
+    """ consumer that writes to sys.stdout """
+    sys.stdout.write(str(msg)+"\n")
+
+
+def STDERR(msg):
+    """ consumer that writes to sys.stderr """
+    sys.stderr.write(str(msg)+"\n")
+
+
+class Syslog:
+    """ consumer that writes to the syslog daemon """
+
+    def __init__(self, priority=None):
+        if priority is None:
+            priority = self.LOG_INFO
+        self.priority = priority
+
+    def __call__(self, msg):
+        """ write a message to the log """
+        import syslog
+        syslog.syslog(self.priority, str(msg))
+
+
+try:
+    import syslog
+except ImportError:
+    pass
+else:
+    for _prio in "EMERG ALERT CRIT ERR WARNING NOTICE INFO DEBUG".split():
+        _prio = "LOG_" + _prio
+        try:
+            setattr(Syslog, _prio, getattr(syslog, _prio))
+        except AttributeError:
+            pass
Index: venv/Lib/site-packages/py/_io/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_io/__init__.py	(date 1543190977143)
+++ venv/Lib/site-packages/py/_io/__init__.py	(date 1543190977143)
@@ -0,0 +1,1 @@
+""" input/output helping """
Index: venv/Lib/site-packages/py-1.7.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py-1.7.0.dist-info/METADATA	(date 1543190977155)
+++ venv/Lib/site-packages/py-1.7.0.dist-info/METADATA	(date 1543190977155)
@@ -0,0 +1,70 @@
+Metadata-Version: 2.1
+Name: py
+Version: 1.7.0
+Summary: library with cross-python path, ini-parsing, io, code, log facilities
+Home-page: http://py.readthedocs.io/
+Author: holger krekel, Ronny Pfannschmidt, Benjamin Peterson and others
+Author-email: pytest-dev@python.org
+License: MIT license
+Platform: unix
+Platform: linux
+Platform: osx
+Platform: cygwin
+Platform: win32
+Classifier: Development Status :: 6 - Mature
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Topic :: Software Development :: Testing
+Classifier: Topic :: Software Development :: Libraries
+Classifier: Topic :: Utilities
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*
+
+.. image:: https://img.shields.io/pypi/v/py.svg
+    :target: https://pypi.org/project/py
+
+.. image:: https://img.shields.io/conda/vn/conda-forge/py.svg
+    :target: https://anaconda.org/conda-forge/py
+
+.. image:: https://img.shields.io/pypi/pyversions/pytest.svg
+  :target: https://pypi.org/project/py
+
+.. image:: https://img.shields.io/travis/pytest-dev/py.svg
+   :target: https://travis-ci.org/pytest-dev/py
+
+.. image:: https://ci.appveyor.com/api/projects/status/10keglan6uqwj5al/branch/master?svg=true
+   :target: https://ci.appveyor.com/project/pytestbot/py
+
+
+**NOTE**: this library is in **maintenance mode** and should not be used in new code.
+
+The py lib is a Python development support library featuring
+the following tools and modules:
+
+* ``py.path``:  uniform local and svn path objects  -> please use pathlib/pathlib2 instead
+* ``py.apipkg``:  explicit API control and lazy-importing -> please use the standalone package instead
+* ``py.iniconfig``:  easy parsing of .ini files -> please use the standalone package instead
+* ``py.code``: dynamic code generation and introspection (deprecated, moved to ``pytest`` as a implementation detail).
+
+**NOTE**: prior to the 1.4 release this distribution used to
+contain py.test which is now its own package, see http://pytest.org
+
+For questions and more information please visit http://py.readthedocs.org
+
+Bugs and issues: https://github.com/pytest-dev/py
+
+Authors: Holger Krekel and others, 2004-2017
+
+
Index: venv/Lib/site-packages/py/_io/saferepr.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_io/saferepr.py	(date 1543190977170)
+++ venv/Lib/site-packages/py/_io/saferepr.py	(date 1543190977170)
@@ -0,0 +1,71 @@
+import py
+import sys
+
+builtin_repr = repr
+
+reprlib = py.builtin._tryimport('repr', 'reprlib')
+
+class SafeRepr(reprlib.Repr):
+    """ subclass of repr.Repr that limits the resulting size of repr()
+        and includes information on exceptions raised during the call.
+    """
+    def repr(self, x):
+        return self._callhelper(reprlib.Repr.repr, self, x)
+
+    def repr_unicode(self, x, level):
+        # Strictly speaking wrong on narrow builds
+        def repr(u):
+            if "'" not in u:
+                return py.builtin._totext("'%s'") % u
+            elif '"' not in u:
+                return py.builtin._totext('"%s"') % u
+            else:
+                return py.builtin._totext("'%s'") % u.replace("'", r"\'")
+        s = repr(x[:self.maxstring])
+        if len(s) > self.maxstring:
+            i = max(0, (self.maxstring-3)//2)
+            j = max(0, self.maxstring-3-i)
+            s = repr(x[:i] + x[len(x)-j:])
+            s = s[:i] + '...' + s[len(s)-j:]
+        return s
+
+    def repr_instance(self, x, level):
+        return self._callhelper(builtin_repr, x)
+
+    def _callhelper(self, call, x, *args):
+        try:
+            # Try the vanilla repr and make sure that the result is a string
+            s = call(x, *args)
+        except py.builtin._sysex:
+            raise
+        except:
+            cls, e, tb = sys.exc_info()
+            exc_name = getattr(cls, '__name__', 'unknown')
+            try:
+                exc_info = str(e)
+            except py.builtin._sysex:
+                raise
+            except:
+                exc_info = 'unknown'
+            return '<[%s("%s") raised in repr()] %s object at 0x%x>' % (
+                exc_name, exc_info, x.__class__.__name__, id(x))
+        else:
+            if len(s) > self.maxsize:
+                i = max(0, (self.maxsize-3)//2)
+                j = max(0, self.maxsize-3-i)
+                s = s[:i] + '...' + s[len(s)-j:]
+            return s
+
+def saferepr(obj, maxsize=240):
+    """ return a size-limited safe repr-string for the given object.
+    Failing __repr__ functions of user instances will be represented
+    with a short exception info and 'saferepr' generally takes
+    care to never raise exceptions itself.  This function is a wrapper
+    around the Repr/reprlib functionality of the standard 2.6 lib.
+    """
+    # review exception handling
+    srepr = SafeRepr()
+    srepr.maxstring = maxsize
+    srepr.maxsize = maxsize
+    srepr.maxother = 160
+    return srepr.repr(obj)
Index: venv/Lib/site-packages/py-1.7.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py-1.7.0.dist-info/INSTALLER	(date 1543190977179)
+++ venv/Lib/site-packages/py-1.7.0.dist-info/INSTALLER	(date 1543190977179)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/py-1.7.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py-1.7.0.dist-info/top_level.txt	(date 1543190977187)
+++ venv/Lib/site-packages/py-1.7.0.dist-info/top_level.txt	(date 1543190977187)
@@ -0,0 +1,1 @@
+py
Index: venv/Lib/site-packages/more_itertools/tests/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools/tests/__init__.py	(date 1543190975183)
+++ venv/Lib/site-packages/more_itertools/tests/__init__.py	(date 1543190975183)
@@ -0,0 +1,0 @@
Index: venv/Lib/site-packages/py-1.7.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py-1.7.0.dist-info/WHEEL	(date 1543190977200)
+++ venv/Lib/site-packages/py-1.7.0.dist-info/WHEEL	(date 1543190977200)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.32.1)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/pluggy-0.8.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy-0.8.0.dist-info/METADATA	(date 1543190977216)
+++ venv/Lib/site-packages/pluggy-0.8.0.dist-info/METADATA	(date 1543190977216)
@@ -0,0 +1,393 @@
+Metadata-Version: 2.1
+Name: pluggy
+Version: 0.8.0
+Summary: plugin and hook calling mechanisms for python
+Home-page: https://github.com/pytest-dev/pluggy
+Author: Holger Krekel
+Author-email: holger@merlinux.eu
+License: MIT license
+Platform: unix
+Platform: linux
+Platform: osx
+Platform: win32
+Classifier: Development Status :: 4 - Beta
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Topic :: Software Development :: Testing
+Classifier: Topic :: Software Development :: Libraries
+Classifier: Topic :: Utilities
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*
+Provides-Extra: dev
+Requires-Dist: pre-commit; extra == 'dev'
+Requires-Dist: tox; extra == 'dev'
+
+====================================================
+pluggy - A minimalist production ready plugin system
+====================================================
+
+|pypi| |anaconda| |versions| |travis| |appveyor| |gitter| |black|
+
+This is the core framework used by the `pytest`_, `tox`_, and `devpi`_ projects.
+
+Please `read the docs`_ to learn more!
+
+A definitive example
+====================
+.. code-block:: python
+
+    import pluggy
+
+    hookspec = pluggy.HookspecMarker("myproject")
+    hookimpl = pluggy.HookimplMarker("myproject")
+
+
+    class MySpec(object):
+        """A hook specification namespace.
+        """
+
+        @hookspec
+        def myhook(self, arg1, arg2):
+            """My special little hook that you can customize.
+            """
+
+
+    class Plugin_1(object):
+        """A hook implementation namespace.
+        """
+
+        @hookimpl
+        def myhook(self, arg1, arg2):
+            print("inside Plugin_1.myhook()")
+            return arg1 + arg2
+
+
+    class Plugin_2(object):
+        """A 2nd hook implementation namespace.
+        """
+
+        @hookimpl
+        def myhook(self, arg1, arg2):
+            print("inside Plugin_2.myhook()")
+            return arg1 - arg2
+
+
+    # create a manager and add the spec
+    pm = pluggy.PluginManager("myproject")
+    pm.add_hookspecs(MySpec)
+
+    # register plugins
+    pm.register(Plugin_1())
+    pm.register(Plugin_2())
+
+    # call our ``myhook`` hook
+    results = pm.hook.myhook(arg1=1, arg2=2)
+    print(results)
+
+
+.. badges
+
+.. |pypi| image:: https://img.shields.io/pypi/v/pluggy.svg
+    :target: https://pypi.org/pypi/pluggy
+
+.. |versions| image:: https://img.shields.io/pypi/pyversions/pluggy.svg
+    :target: https://pypi.org/pypi/pluggy
+
+.. |travis| image:: https://img.shields.io/travis/pytest-dev/pluggy/master.svg
+    :target: https://travis-ci.org/pytest-dev/pluggy
+
+.. |appveyor| image:: https://img.shields.io/appveyor/ci/pytestbot/pluggy/master.svg
+    :target: https://ci.appveyor.com/project/pytestbot/pluggy
+
+.. |anaconda| image:: https://anaconda.org/conda-forge/pluggy/badges/version.svg
+    :target: https://anaconda.org/conda-forge/pluggy
+
+.. |gitter| image:: https://badges.gitter.im/pytest-dev/pluggy.svg
+    :alt: Join the chat at https://gitter.im/pytest-dev/pluggy
+    :target: https://gitter.im/pytest-dev/pluggy?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge
+
+.. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg
+    :target: https://github.com/ambv/black
+
+.. links
+.. _pytest:
+    http://pytest.org
+.. _tox:
+    https://tox.readthedocs.org
+.. _devpi:
+    http://doc.devpi.net
+.. _read the docs:
+   https://pluggy.readthedocs.io/en/latest/
+
+
+pluggy 0.8.0 (2018-10-15)
+=========================
+
+Features
+--------
+
+- `#177 <https://github.com/pytest-dev/pluggy/issues/177>`_: Add ``get_hookimpls()`` method to hook callers.
+
+
+
+Trivial/Internal Changes
+------------------------
+
+- `#165 <https://github.com/pytest-dev/pluggy/issues/165>`_: Add changelog in long package description and documentation.
+
+
+- `#172 <https://github.com/pytest-dev/pluggy/issues/172>`_: Add a test exemplifying the opt-in nature of spec defined args.
+
+
+- `#57 <https://github.com/pytest-dev/pluggy/issues/57>`_: Encapsulate hook specifications in a type for easier introspection.
+
+
+=========
+Changelog
+=========
+
+.. towncrier release notes start
+
+
+pluggy 0.7.1 (2018-07-28)
+=========================
+
+Deprecations and Removals
+-------------------------
+
+- `#116 <https://github.com/pytest-dev/pluggy/issues/116>`_: Deprecate the ``implprefix`` kwarg to ``PluginManager`` and instead
+  expect users to start using explicit ``HookimplMarker`` everywhere.
+
+
+
+Features
+--------
+
+- `#122 <https://github.com/pytest-dev/pluggy/issues/122>`_: Add ``.plugin`` member to ``PluginValidationError`` to access failing plugin during post-mortem.
+
+
+- `#138 <https://github.com/pytest-dev/pluggy/issues/138>`_: Add per implementation warnings support for hookspecs allowing for both
+  deprecation and future warnings of legacy and (future) experimental hooks
+  respectively.
+
+
+
+Bug Fixes
+---------
+
+- `#110 <https://github.com/pytest-dev/pluggy/issues/110>`_: Fix a bug where ``_HookCaller.call_historic()`` would call the ``proc``
+  arg even when the default is ``None`` resulting in a ``TypeError``.
+
+- `#160 <https://github.com/pytest-dev/pluggy/issues/160>`_: Fix problem when handling ``VersionConflict`` errors when loading setuptools plugins.
+
+
+
+Improved Documentation
+----------------------
+
+- `#123 <https://github.com/pytest-dev/pluggy/issues/123>`_: Document how exceptions are handled and how the hook call loop
+  terminates immediately on the first error which is then delivered
+  to any surrounding wrappers.
+
+
+- `#136 <https://github.com/pytest-dev/pluggy/issues/136>`_: Docs rework including a much better introduction and comprehensive example
+  set for new users. A big thanks goes out to @obestwalter for the great work!
+
+
+
+Trivial/Internal Changes
+------------------------
+
+- `#117 <https://github.com/pytest-dev/pluggy/issues/117>`_: Break up the main monolithic package modules into separate modules by concern
+
+
+- `#131 <https://github.com/pytest-dev/pluggy/issues/131>`_: Automate ``setuptools`` wheels building and PyPi upload using TravisCI.
+
+
+- `#153 <https://github.com/pytest-dev/pluggy/issues/153>`_: Reorganize tests more appropriately by modules relating to each
+  internal component/feature. This is in an effort to avoid (future)
+  duplication and better separation of concerns in the test set.
+
+
+- `#156 <https://github.com/pytest-dev/pluggy/issues/156>`_: Add ``HookImpl.__repr__()`` for better debugging.
+
+
+- `#66 <https://github.com/pytest-dev/pluggy/issues/66>`_: Start using ``towncrier`` and a custom ``tox`` environment to prepare releases!
+
+
+pluggy 0.7.0 (Unreleased)
+=========================
+
+* `#160 <https://github.com/pytest-dev/pluggy/issues/160>`_: We discovered a deployment issue so this version was never released to PyPI, only the tag exists.
+
+pluggy 0.6.0 (2017-11-24)
+=========================
+
+- Add CI testing for the features, release, and master
+  branches of ``pytest`` (PR `#79`_).
+- Document public API for ``_Result`` objects passed to wrappers
+  (PR `#85`_).
+- Document and test hook LIFO ordering (PR `#85`_).
+- Turn warnings into errors in test suite (PR `#89`_).
+- Deprecate ``_Result.result`` (PR `#88`_).
+- Convert ``_Multicall`` to a simple function distinguishing it from
+  the legacy version (PR `#90`_).
+- Resolve E741 errors (PR `#96`_).
+- Test and bug fix for unmarked hook collection (PRs `#97`_ and
+  `#102`_).
+- Drop support for EOL Python 2.6 and 3.3 (PR `#103`_).
+- Fix ``inspect`` based arg introspection on py3.6 (PR `#94`_).
+
+.. _#79: https://github.com/pytest-dev/pluggy/pull/79
+.. _#85: https://github.com/pytest-dev/pluggy/pull/85
+.. _#88: https://github.com/pytest-dev/pluggy/pull/88
+.. _#89: https://github.com/pytest-dev/pluggy/pull/89
+.. _#90: https://github.com/pytest-dev/pluggy/pull/90
+.. _#94: https://github.com/pytest-dev/pluggy/pull/94
+.. _#96: https://github.com/pytest-dev/pluggy/pull/96
+.. _#97: https://github.com/pytest-dev/pluggy/pull/97
+.. _#102: https://github.com/pytest-dev/pluggy/pull/102
+.. _#103: https://github.com/pytest-dev/pluggy/pull/103
+
+
+pluggy 0.5.2 (2017-09-06)
+=========================
+
+- fix bug where ``firstresult`` wrappers were being sent an incorrectly configured
+  ``_Result`` (a list was set instead of a single value). Add tests to check for
+  this as well as ``_Result.force_result()`` behaviour. Thanks to `@tgoodlet`_
+  for the PR `#72`_.
+
+- fix incorrect ``getattr``  of ``DeprecationWarning`` from the ``warnings``
+  module. Thanks to `@nicoddemus`_ for the PR `#77`_.
+
+- hide ``pytest`` tracebacks in certain core routines. Thanks to
+  `@nicoddemus`_ for the PR `#80`_.
+
+.. _#72: https://github.com/pytest-dev/pluggy/pull/72
+.. _#77: https://github.com/pytest-dev/pluggy/pull/77
+.. _#80: https://github.com/pytest-dev/pluggy/pull/80
+
+
+pluggy 0.5.1 (2017-08-29)
+=========================
+
+- fix a bug and add tests for case where ``firstresult`` hooks return
+  ``None`` results. Thanks to `@RonnyPfannschmidt`_ and `@tgoodlet`_
+  for the issue (`#68`_) and PR (`#69`_) respectively.
+
+.. _#69: https://github.com/pytest-dev/pluggy/pull/69
+.. _#68: https://github.com/pytest-dev/pluggy/issues/68
+
+
+pluggy 0.5.0 (2017-08-28)
+=========================
+
+- fix bug where callbacks for historic hooks would not be called for
+  already registered plugins.  Thanks `@vodik`_ for the PR
+  and `@hpk42`_ for further fixes.
+
+- fix `#17`_ by considering only actual functions for hooks
+  this removes the ability to register arbitrary callable objects
+  which at first glance is a reasonable simplification,
+  thanks `@RonnyPfannschmidt`_ for report and pr.
+
+- fix `#19`_: allow registering hookspecs from instances.  The PR from
+  `@tgoodlet`_ also modernized the varnames implementation.
+
+- resolve `#32`_: split up the test set into multiple modules.
+  Thanks to `@RonnyPfannschmidt`_ for the PR and `@tgoodlet`_ for
+  the initial request.
+
+- resolve `#14`_: add full sphinx docs. Thanks to `@tgoodlet`_ for
+  PR `#39`_.
+
+- add hook call mismatch warnings. Thanks to `@tgoodlet`_ for the
+  PR `#42`_.
+
+- resolve `#44`_: move to new-style classes. Thanks to `@MichalTHEDUDE`_
+  for PR `#46`_.
+
+- add baseline benchmarking/speed tests using ``pytest-benchmark``
+  in PR `#54`_.  Thanks to `@tgoodlet`_.
+
+- update the README to showcase the API. Thanks to `@tgoodlet`_ for the
+  issue and PR `#55`_.
+
+- deprecate ``__multicall__`` and add a faster call loop implementation.
+  Thanks to `@tgoodlet`_ for PR `#58`_.
+
+- raise a comprehensible error when a ``hookimpl`` is called with positional
+  args. Thanks to `@RonnyPfannschmidt`_ for the issue and `@tgoodlet`_ for
+  PR `#60`_.
+
+- fix the ``firstresult`` test making it more complete
+  and remove a duplicate of that test. Thanks to `@tgoodlet`_
+  for PR `#62`_.
+
+.. _#62: https://github.com/pytest-dev/pluggy/pull/62
+.. _#60: https://github.com/pytest-dev/pluggy/pull/60
+.. _#58: https://github.com/pytest-dev/pluggy/pull/58
+.. _#55: https://github.com/pytest-dev/pluggy/pull/55
+.. _#54: https://github.com/pytest-dev/pluggy/pull/54
+.. _#46: https://github.com/pytest-dev/pluggy/pull/46
+.. _#44: https://github.com/pytest-dev/pluggy/issues/44
+.. _#42: https://github.com/pytest-dev/pluggy/pull/42
+.. _#39: https://github.com/pytest-dev/pluggy/pull/39
+.. _#32: https://github.com/pytest-dev/pluggy/pull/32
+.. _#19: https://github.com/pytest-dev/pluggy/issues/19
+.. _#17: https://github.com/pytest-dev/pluggy/issues/17
+.. _#14: https://github.com/pytest-dev/pluggy/issues/14
+
+
+pluggy 0.4.0 (2016-09-25)
+=========================
+
+- add ``has_plugin(name)`` method to pluginmanager.  thanks `@nicoddemus`_.
+
+- fix `#11`_: make plugin parsing more resilient against exceptions
+  from ``__getattr__`` functions. Thanks `@nicoddemus`_.
+
+- fix issue `#4`_: specific ``HookCallError`` exception for when a hook call
+  provides not enough arguments.
+
+- better error message when loading setuptools entrypoints fails
+  due to a ``VersionConflict``.  Thanks `@blueyed`_.
+
+.. _#11: https://github.com/pytest-dev/pluggy/issues/11
+.. _#4: https://github.com/pytest-dev/pluggy/issues/4
+
+
+pluggy 0.3.1 (2015-09-17)
+=========================
+
+- avoid using deprecated-in-python3.5 getargspec method. Thanks
+  `@mdboom`_.
+
+
+pluggy 0.3.0 (2015-05-07)
+=========================
+
+initial release
+
+.. contributors
+.. _@hpk42: https://github.com/hpk42
+.. _@tgoodlet: https://github.com/tgoodlet
+.. _@MichalTHEDUDE: https://github.com/MichalTHEDUDE
+.. _@vodik: https://github.com/vodik
+.. _@RonnyPfannschmidt: https://github.com/RonnyPfannschmidt
+.. _@blueyed: https://github.com/blueyed
+.. _@nicoddemus: https://github.com/nicoddemus
+.. _@mdboom: https://github.com/mdboom
+
+
Index: Chapter1/StringCompression.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/StringCompression.py	(date 1543190977224)
+++ Chapter1/StringCompression.py	(date 1543190977224)
@@ -0,0 +1,13 @@
+def compress_string(text: str) -> str:
+    arr = []
+
+    for c in list(text):
+        if len(arr) == 0 or arr[len(arr) - 2] != c:
+            arr.append(c)
+            arr.append(1)
+        else:
+            arr[len(arr) - 1] = arr[len(arr) - 1] + 1
+
+    result = "".join(map(lambda x: str(x), arr))
+
+    return result if len(result) < len(text) else text
Index: venv/Lib/site-packages/more_itertools/tests/test_more.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools/tests/test_more.py	(date 1543190977244)
+++ venv/Lib/site-packages/more_itertools/tests/test_more.py	(date 1543190977244)
@@ -0,0 +1,2074 @@
+from __future__ import division, print_function, unicode_literals
+
+from collections import OrderedDict
+from decimal import Decimal
+from doctest import DocTestSuite
+from fractions import Fraction
+from functools import partial, reduce
+from heapq import merge
+from io import StringIO
+from itertools import (
+    chain,
+    count,
+    groupby,
+    islice,
+    permutations,
+    product,
+    repeat,
+)
+from operator import add, mul, itemgetter
+from unittest import TestCase
+
+from six.moves import filter, map, range, zip
+
+import more_itertools as mi
+
+
+def load_tests(loader, tests, ignore):
+    # Add the doctests
+    tests.addTests(DocTestSuite('more_itertools.more'))
+    return tests
+
+
+class CollateTests(TestCase):
+    """Unit tests for ``collate()``"""
+    # Also accidentally tests peekable, though that could use its own tests
+
+    def test_default(self):
+        """Test with the default `key` function."""
+        iterables = [range(4), range(7), range(3, 6)]
+        self.assertEqual(
+            sorted(reduce(list.__add__, [list(it) for it in iterables])),
+            list(mi.collate(*iterables))
+        )
+
+    def test_key(self):
+        """Test using a custom `key` function."""
+        iterables = [range(5, 0, -1), range(4, 0, -1)]
+        actual = sorted(
+            reduce(list.__add__, [list(it) for it in iterables]), reverse=True
+        )
+        expected = list(mi.collate(*iterables, key=lambda x: -x))
+        self.assertEqual(actual, expected)
+
+    def test_empty(self):
+        """Be nice if passed an empty list of iterables."""
+        self.assertEqual([], list(mi.collate()))
+
+    def test_one(self):
+        """Work when only 1 iterable is passed."""
+        self.assertEqual([0, 1], list(mi.collate(range(2))))
+
+    def test_reverse(self):
+        """Test the `reverse` kwarg."""
+        iterables = [range(4, 0, -1), range(7, 0, -1), range(3, 6, -1)]
+
+        actual = sorted(
+            reduce(list.__add__, [list(it) for it in iterables]), reverse=True
+        )
+        expected = list(mi.collate(*iterables, reverse=True))
+        self.assertEqual(actual, expected)
+
+    def test_alias(self):
+        self.assertNotEqual(merge.__doc__, mi.collate.__doc__)
+        self.assertNotEqual(partial.__doc__, mi.collate.__doc__)
+
+
+class ChunkedTests(TestCase):
+    """Tests for ``chunked()``"""
+
+    def test_even(self):
+        """Test when ``n`` divides evenly into the length of the iterable."""
+        self.assertEqual(
+            list(mi.chunked('ABCDEF', 3)), [['A', 'B', 'C'], ['D', 'E', 'F']]
+        )
+
+    def test_odd(self):
+        """Test when ``n`` does not divide evenly into the length of the
+        iterable.
+
+        """
+        self.assertEqual(
+            list(mi.chunked('ABCDE', 3)), [['A', 'B', 'C'], ['D', 'E']]
+        )
+
+
+class FirstTests(TestCase):
+    """Tests for ``first()``"""
+
+    def test_many(self):
+        """Test that it works on many-item iterables."""
+        # Also try it on a generator expression to make sure it works on
+        # whatever those return, across Python versions.
+        self.assertEqual(mi.first(x for x in range(4)), 0)
+
+    def test_one(self):
+        """Test that it doesn't raise StopIteration prematurely."""
+        self.assertEqual(mi.first([3]), 3)
+
+    def test_empty_stop_iteration(self):
+        """It should raise StopIteration for empty iterables."""
+        self.assertRaises(ValueError, lambda: mi.first([]))
+
+    def test_default(self):
+        """It should return the provided default arg for empty iterables."""
+        self.assertEqual(mi.first([], 'boo'), 'boo')
+
+
+class IterOnlyRange:
+    """User-defined iterable class which only support __iter__.
+
+    It is not specified to inherit ``object``, so indexing on a instance will
+    raise an ``AttributeError`` rather than ``TypeError`` in Python 2.
+
+    >>> r = IterOnlyRange(5)
+    >>> r[0]
+    AttributeError: IterOnlyRange instance has no attribute '__getitem__'
+
+    Note: In Python 3, ``TypeError`` will be raised because ``object`` is
+    inherited implicitly by default.
+
+    >>> r[0]
+    TypeError: 'IterOnlyRange' object does not support indexing
+    """
+    def __init__(self, n):
+        """Set the length of the range."""
+        self.n = n
+
+    def __iter__(self):
+        """Works same as range()."""
+        return iter(range(self.n))
+
+
+class LastTests(TestCase):
+    """Tests for ``last()``"""
+
+    def test_many_nonsliceable(self):
+        """Test that it works on many-item non-slice-able iterables."""
+        # Also try it on a generator expression to make sure it works on
+        # whatever those return, across Python versions.
+        self.assertEqual(mi.last(x for x in range(4)), 3)
+
+    def test_one_nonsliceable(self):
+        """Test that it doesn't raise StopIteration prematurely."""
+        self.assertEqual(mi.last(x for x in range(1)), 0)
+
+    def test_empty_stop_iteration_nonsliceable(self):
+        """It should raise ValueError for empty non-slice-able iterables."""
+        self.assertRaises(ValueError, lambda: mi.last(x for x in range(0)))
+
+    def test_default_nonsliceable(self):
+        """It should return the provided default arg for empty non-slice-able
+        iterables.
+        """
+        self.assertEqual(mi.last((x for x in range(0)), 'boo'), 'boo')
+
+    def test_many_sliceable(self):
+        """Test that it works on many-item slice-able iterables."""
+        self.assertEqual(mi.last([0, 1, 2, 3]), 3)
+
+    def test_one_sliceable(self):
+        """Test that it doesn't raise StopIteration prematurely."""
+        self.assertEqual(mi.last([3]), 3)
+
+    def test_empty_stop_iteration_sliceable(self):
+        """It should raise ValueError for empty slice-able iterables."""
+        self.assertRaises(ValueError, lambda: mi.last([]))
+
+    def test_default_sliceable(self):
+        """It should return the provided default arg for empty slice-able
+        iterables.
+        """
+        self.assertEqual(mi.last([], 'boo'), 'boo')
+
+    def test_dict(self):
+        """last(dic) and last(dic.keys()) should return same result."""
+        dic = {'a': 1, 'b': 2, 'c': 3}
+        self.assertEqual(mi.last(dic), mi.last(dic.keys()))
+
+    def test_ordereddict(self):
+        """last(dic) should return the last key."""
+        od = OrderedDict()
+        od['a'] = 1
+        od['b'] = 2
+        od['c'] = 3
+        self.assertEqual(mi.last(od), 'c')
+
+    def test_customrange(self):
+        """It should work on custom class where [] raises AttributeError."""
+        self.assertEqual(mi.last(IterOnlyRange(5)), 4)
+
+
+class PeekableTests(TestCase):
+    """Tests for ``peekable()`` behavor not incidentally covered by testing
+    ``collate()``
+
+    """
+    def test_peek_default(self):
+        """Make sure passing a default into ``peek()`` works."""
+        p = mi.peekable([])
+        self.assertEqual(p.peek(7), 7)
+
+    def test_truthiness(self):
+        """Make sure a ``peekable`` tests true iff there are items remaining in
+        the iterable.
+
+        """
+        p = mi.peekable([])
+        self.assertFalse(p)
+
+        p = mi.peekable(range(3))
+        self.assertTrue(p)
+
+    def test_simple_peeking(self):
+        """Make sure ``next`` and ``peek`` advance and don't advance the
+        iterator, respectively.
+
+        """
+        p = mi.peekable(range(10))
+        self.assertEqual(next(p), 0)
+        self.assertEqual(p.peek(), 1)
+        self.assertEqual(next(p), 1)
+
+    def test_indexing(self):
+        """
+        Indexing into the peekable shouldn't advance the iterator.
+        """
+        p = mi.peekable('abcdefghijkl')
+
+        # The 0th index is what ``next()`` will return
+        self.assertEqual(p[0], 'a')
+        self.assertEqual(next(p), 'a')
+
+        # Indexing further into the peekable shouldn't advance the itertor
+        self.assertEqual(p[2], 'd')
+        self.assertEqual(next(p), 'b')
+
+        # The 0th index moves up with the iterator; the last index follows
+        self.assertEqual(p[0], 'c')
+        self.assertEqual(p[9], 'l')
+
+        self.assertEqual(next(p), 'c')
+        self.assertEqual(p[8], 'l')
+
+        # Negative indexing should work too
+        self.assertEqual(p[-2], 'k')
+        self.assertEqual(p[-9], 'd')
+        self.assertRaises(IndexError, lambda: p[-10])
+
+    def test_slicing(self):
+        """Slicing the peekable shouldn't advance the iterator."""
+        seq = list('abcdefghijkl')
+        p = mi.peekable(seq)
+
+        # Slicing the peekable should just be like slicing a re-iterable
+        self.assertEqual(p[1:4], seq[1:4])
+
+        # Advancing the iterator moves the slices up also
+        self.assertEqual(next(p), 'a')
+        self.assertEqual(p[1:4], seq[1:][1:4])
+
+        # Implicit starts and stop should work
+        self.assertEqual(p[:5], seq[1:][:5])
+        self.assertEqual(p[:], seq[1:][:])
+
+        # Indexing past the end should work
+        self.assertEqual(p[:100], seq[1:][:100])
+
+        # Steps should work, including negative
+        self.assertEqual(p[::2], seq[1:][::2])
+        self.assertEqual(p[::-1], seq[1:][::-1])
+
+    def test_slicing_reset(self):
+        """Test slicing on a fresh iterable each time"""
+        iterable = ['0', '1', '2', '3', '4', '5']
+        indexes = list(range(-4, len(iterable) + 4)) + [None]
+        steps = [1, 2, 3, 4, -1, -2, -3, 4]
+        for slice_args in product(indexes, indexes, steps):
+            it = iter(iterable)
+            p = mi.peekable(it)
+            next(p)
+            index = slice(*slice_args)
+            actual = p[index]
+            expected = iterable[1:][index]
+            self.assertEqual(actual, expected, slice_args)
+
+    def test_slicing_error(self):
+        iterable = '01234567'
+        p = mi.peekable(iter(iterable))
+
+        # Prime the cache
+        p.peek()
+        old_cache = list(p._cache)
+
+        # Illegal slice
+        with self.assertRaises(ValueError):
+            p[1:-1:0]
+
+        # Neither the cache nor the iteration should be affected
+        self.assertEqual(old_cache, list(p._cache))
+        self.assertEqual(list(p), list(iterable))
+
+    def test_passthrough(self):
+        """Iterating a peekable without using ``peek()`` or ``prepend()``
+        should just give the underlying iterable's elements (a trivial test but
+        useful to set a baseline in case something goes wrong)"""
+        expected = [1, 2, 3, 4, 5]
+        actual = list(mi.peekable(expected))
+        self.assertEqual(actual, expected)
+
+    # prepend() behavior tests
+
+    def test_prepend(self):
+        """Tests intersperesed ``prepend()`` and ``next()`` calls"""
+        it = mi.peekable(range(2))
+        actual = []
+
+        # Test prepend() before next()
+        it.prepend(10)
+        actual += [next(it), next(it)]
+
+        # Test prepend() between next()s
+        it.prepend(11)
+        actual += [next(it), next(it)]
+
+        # Test prepend() after source iterable is consumed
+        it.prepend(12)
+        actual += [next(it)]
+
+        expected = [10, 0, 11, 1, 12]
+        self.assertEqual(actual, expected)
+
+    def test_multi_prepend(self):
+        """Tests prepending multiple items and getting them in proper order"""
+        it = mi.peekable(range(5))
+        actual = [next(it), next(it)]
+        it.prepend(10, 11, 12)
+        it.prepend(20, 21)
+        actual += list(it)
+        expected = [0, 1, 20, 21, 10, 11, 12, 2, 3, 4]
+        self.assertEqual(actual, expected)
+
+    def test_empty(self):
+        """Tests prepending in front of an empty iterable"""
+        it = mi.peekable([])
+        it.prepend(10)
+        actual = list(it)
+        expected = [10]
+        self.assertEqual(actual, expected)
+
+    def test_prepend_truthiness(self):
+        """Tests that ``__bool__()`` or ``__nonzero__()`` works properly
+        with ``prepend()``"""
+        it = mi.peekable(range(5))
+        self.assertTrue(it)
+        actual = list(it)
+        self.assertFalse(it)
+        it.prepend(10)
+        self.assertTrue(it)
+        actual += [next(it)]
+        self.assertFalse(it)
+        expected = [0, 1, 2, 3, 4, 10]
+        self.assertEqual(actual, expected)
+
+    def test_multi_prepend_peek(self):
+        """Tests prepending multiple elements and getting them in reverse order
+        while peeking"""
+        it = mi.peekable(range(5))
+        actual = [next(it), next(it)]
+        self.assertEqual(it.peek(), 2)
+        it.prepend(10, 11, 12)
+        self.assertEqual(it.peek(), 10)
+        it.prepend(20, 21)
+        self.assertEqual(it.peek(), 20)
+        actual += list(it)
+        self.assertFalse(it)
+        expected = [0, 1, 20, 21, 10, 11, 12, 2, 3, 4]
+        self.assertEqual(actual, expected)
+
+    def test_prepend_after_stop(self):
+        """Test resuming iteration after a previous exhaustion"""
+        it = mi.peekable(range(3))
+        self.assertEqual(list(it), [0, 1, 2])
+        self.assertRaises(StopIteration, lambda: next(it))
+        it.prepend(10)
+        self.assertEqual(next(it), 10)
+        self.assertRaises(StopIteration, lambda: next(it))
+
+    def test_prepend_slicing(self):
+        """Tests interaction between prepending and slicing"""
+        seq = list(range(20))
+        p = mi.peekable(seq)
+
+        p.prepend(30, 40, 50)
+        pseq = [30, 40, 50] + seq  # pseq for prepended_seq
+
+        # adapt the specific tests from test_slicing
+        self.assertEqual(p[0], 30)
+        self.assertEqual(p[1:8], pseq[1:8])
+        self.assertEqual(p[1:], pseq[1:])
+        self.assertEqual(p[:5], pseq[:5])
+        self.assertEqual(p[:], pseq[:])
+        self.assertEqual(p[:100], pseq[:100])
+        self.assertEqual(p[::2], pseq[::2])
+        self.assertEqual(p[::-1], pseq[::-1])
+
+    def test_prepend_indexing(self):
+        """Tests interaction between prepending and indexing"""
+        seq = list(range(20))
+        p = mi.peekable(seq)
+
+        p.prepend(30, 40, 50)
+
+        self.assertEqual(p[0], 30)
+        self.assertEqual(next(p), 30)
+        self.assertEqual(p[2], 0)
+        self.assertEqual(next(p), 40)
+        self.assertEqual(p[0], 50)
+        self.assertEqual(p[9], 8)
+        self.assertEqual(next(p), 50)
+        self.assertEqual(p[8], 8)
+        self.assertEqual(p[-2], 18)
+        self.assertEqual(p[-9], 11)
+        self.assertRaises(IndexError, lambda: p[-21])
+
+    def test_prepend_iterable(self):
+        """Tests prepending from an iterable"""
+        it = mi.peekable(range(5))
+        # Don't directly use the range() object to avoid any range-specific
+        # optimizations
+        it.prepend(*(x for x in range(5)))
+        actual = list(it)
+        expected = list(chain(range(5), range(5)))
+        self.assertEqual(actual, expected)
+
+    def test_prepend_many(self):
+        """Tests that prepending a huge number of elements works"""
+        it = mi.peekable(range(5))
+        # Don't directly use the range() object to avoid any range-specific
+        # optimizations
+        it.prepend(*(x for x in range(20000)))
+        actual = list(it)
+        expected = list(chain(range(20000), range(5)))
+        self.assertEqual(actual, expected)
+
+    def test_prepend_reversed(self):
+        """Tests prepending from a reversed iterable"""
+        it = mi.peekable(range(3))
+        it.prepend(*reversed((10, 11, 12)))
+        actual = list(it)
+        expected = [12, 11, 10, 0, 1, 2]
+        self.assertEqual(actual, expected)
+
+
+class ConsumerTests(TestCase):
+    """Tests for ``consumer()``"""
+
+    def test_consumer(self):
+        @mi.consumer
+        def eater():
+            while True:
+                x = yield  # noqa
+
+        e = eater()
+        e.send('hi')  # without @consumer, would raise TypeError
+
+
+class DistinctPermutationsTests(TestCase):
+    def test_distinct_permutations(self):
+        """Make sure the output for ``distinct_permutations()`` is the same as
+        set(permutations(it)).
+
+        """
+        iterable = ['z', 'a', 'a', 'q', 'q', 'q', 'y']
+        test_output = sorted(mi.distinct_permutations(iterable))
+        ref_output = sorted(set(permutations(iterable)))
+        self.assertEqual(test_output, ref_output)
+
+    def test_other_iterables(self):
+        """Make sure ``distinct_permutations()`` accepts a different type of
+        iterables.
+
+        """
+        # a generator
+        iterable = (c for c in ['z', 'a', 'a', 'q', 'q', 'q', 'y'])
+        test_output = sorted(mi.distinct_permutations(iterable))
+        # "reload" it
+        iterable = (c for c in ['z', 'a', 'a', 'q', 'q', 'q', 'y'])
+        ref_output = sorted(set(permutations(iterable)))
+        self.assertEqual(test_output, ref_output)
+
+        # an iterator
+        iterable = iter(['z', 'a', 'a', 'q', 'q', 'q', 'y'])
+        test_output = sorted(mi.distinct_permutations(iterable))
+        # "reload" it
+        iterable = iter(['z', 'a', 'a', 'q', 'q', 'q', 'y'])
+        ref_output = sorted(set(permutations(iterable)))
+        self.assertEqual(test_output, ref_output)
+
+
+class IlenTests(TestCase):
+    def test_ilen(self):
+        """Sanity-checks for ``ilen()``."""
+        # Non-empty
+        self.assertEqual(
+            mi.ilen(filter(lambda x: x % 10 == 0, range(101))), 11
+        )
+
+        # Empty
+        self.assertEqual(mi.ilen((x for x in range(0))), 0)
+
+        # Iterable with __len__
+        self.assertEqual(mi.ilen(list(range(6))), 6)
+
+
+class WithIterTests(TestCase):
+    def test_with_iter(self):
+        s = StringIO('One fish\nTwo fish')
+        initial_words = [line.split()[0] for line in mi.with_iter(s)]
+
+        # Iterable's items should be faithfully represented
+        self.assertEqual(initial_words, ['One', 'Two'])
+        # The file object should be closed
+        self.assertEqual(s.closed, True)
+
+
+class OneTests(TestCase):
+    def test_basic(self):
+        it = iter(['item'])
+        self.assertEqual(mi.one(it), 'item')
+
+    def test_too_short(self):
+        it = iter([])
+        self.assertRaises(ValueError, lambda: mi.one(it))
+        self.assertRaises(IndexError, lambda: mi.one(it, too_short=IndexError))
+
+    def test_too_long(self):
+        it = count()
+        self.assertRaises(ValueError, lambda: mi.one(it))  # burn 0 and 1
+        self.assertEqual(next(it), 2)
+        self.assertRaises(
+            OverflowError, lambda: mi.one(it, too_long=OverflowError)
+        )
+
+
+class IntersperseTest(TestCase):
+    """ Tests for intersperse() """
+
+    def test_even(self):
+        iterable = (x for x in '01')
+        self.assertEqual(
+            list(mi.intersperse(None, iterable)), ['0', None, '1']
+        )
+
+    def test_odd(self):
+        iterable = (x for x in '012')
+        self.assertEqual(
+            list(mi.intersperse(None, iterable)), ['0', None, '1', None, '2']
+        )
+
+    def test_nested(self):
+        element = ('a', 'b')
+        iterable = (x for x in '012')
+        actual = list(mi.intersperse(element, iterable))
+        expected = ['0', ('a', 'b'), '1', ('a', 'b'), '2']
+        self.assertEqual(actual, expected)
+
+    def test_not_iterable(self):
+        self.assertRaises(TypeError, lambda: mi.intersperse('x', 1))
+
+    def test_n(self):
+        for n, element, expected in [
+            (1, '_', ['0', '_', '1', '_', '2', '_', '3', '_', '4', '_', '5']),
+            (2, '_', ['0', '1', '_', '2', '3', '_', '4', '5']),
+            (3, '_', ['0', '1', '2', '_', '3', '4', '5']),
+            (4, '_', ['0', '1', '2', '3', '_', '4', '5']),
+            (5, '_', ['0', '1', '2', '3', '4', '_', '5']),
+            (6, '_', ['0', '1', '2', '3', '4', '5']),
+            (7, '_', ['0', '1', '2', '3', '4', '5']),
+            (3, ['a', 'b'], ['0', '1', '2', ['a', 'b'], '3', '4', '5']),
+        ]:
+            iterable = (x for x in '012345')
+            actual = list(mi.intersperse(element, iterable, n=n))
+            self.assertEqual(actual, expected)
+
+    def test_n_zero(self):
+        self.assertRaises(
+            ValueError, lambda: list(mi.intersperse('x', '012', n=0))
+        )
+
+
+class UniqueToEachTests(TestCase):
+    """Tests for ``unique_to_each()``"""
+
+    def test_all_unique(self):
+        """When all the input iterables are unique the output should match
+        the input."""
+        iterables = [[1, 2], [3, 4, 5], [6, 7, 8]]
+        self.assertEqual(mi.unique_to_each(*iterables), iterables)
+
+    def test_duplicates(self):
+        """When there are duplicates in any of the input iterables that aren't
+        in the rest, those duplicates should be emitted."""
+        iterables = ["mississippi", "missouri"]
+        self.assertEqual(
+            mi.unique_to_each(*iterables), [['p', 'p'], ['o', 'u', 'r']]
+        )
+
+    def test_mixed(self):
+        """When the input iterables contain different types the function should
+        still behave properly"""
+        iterables = ['x', (i for i in range(3)), [1, 2, 3], tuple()]
+        self.assertEqual(mi.unique_to_each(*iterables), [['x'], [0], [3], []])
+
+
+class WindowedTests(TestCase):
+    """Tests for ``windowed()``"""
+
+    def test_basic(self):
+        actual = list(mi.windowed([1, 2, 3, 4, 5], 3))
+        expected = [(1, 2, 3), (2, 3, 4), (3, 4, 5)]
+        self.assertEqual(actual, expected)
+
+    def test_large_size(self):
+        """
+        When the window size is larger than the iterable, and no fill value is
+        given,``None`` should be filled in.
+        """
+        actual = list(mi.windowed([1, 2, 3, 4, 5], 6))
+        expected = [(1, 2, 3, 4, 5, None)]
+        self.assertEqual(actual, expected)
+
+    def test_fillvalue(self):
+        """
+        When sizes don't match evenly, the given fill value should be used.
+        """
+        iterable = [1, 2, 3, 4, 5]
+
+        for n, kwargs, expected in [
+            (6, {}, [(1, 2, 3, 4, 5, '!')]),  # n > len(iterable)
+            (3, {'step': 3}, [(1, 2, 3), (4, 5, '!')]),  # using ``step``
+        ]:
+            actual = list(mi.windowed(iterable, n, fillvalue='!', **kwargs))
+            self.assertEqual(actual, expected)
+
+    def test_zero(self):
+        """When the window size is zero, an empty tuple should be emitted."""
+        actual = list(mi.windowed([1, 2, 3, 4, 5], 0))
+        expected = [tuple()]
+        self.assertEqual(actual, expected)
+
+    def test_negative(self):
+        """When the window size is negative, ValueError should be raised."""
+        with self.assertRaises(ValueError):
+            list(mi.windowed([1, 2, 3, 4, 5], -1))
+
+    def test_step(self):
+        """The window should advance by the number of steps provided"""
+        iterable = [1, 2, 3, 4, 5, 6, 7]
+        for n, step, expected in [
+            (3, 2, [(1, 2, 3), (3, 4, 5), (5, 6, 7)]),  # n > step
+            (3, 3, [(1, 2, 3), (4, 5, 6), (7, None, None)]),  # n == step
+            (3, 4, [(1, 2, 3), (5, 6, 7)]),  # line up nicely
+            (3, 5, [(1, 2, 3), (6, 7, None)]),  # off by one
+            (3, 6, [(1, 2, 3), (7, None, None)]),  # off by two
+            (3, 7, [(1, 2, 3)]),  # step past the end
+            (7, 8, [(1, 2, 3, 4, 5, 6, 7)]),  # step > len(iterable)
+        ]:
+            actual = list(mi.windowed(iterable, n, step=step))
+            self.assertEqual(actual, expected)
+
+        # Step must be greater than or equal to 1
+        with self.assertRaises(ValueError):
+            list(mi.windowed(iterable, 3, step=0))
+
+
+class BucketTests(TestCase):
+    """Tests for ``bucket()``"""
+
+    def test_basic(self):
+        iterable = [10, 20, 30, 11, 21, 31, 12, 22, 23, 33]
+        D = mi.bucket(iterable, key=lambda x: 10 * (x // 10))
+
+        # In-order access
+        self.assertEqual(list(D[10]), [10, 11, 12])
+
+        # Out of order access
+        self.assertEqual(list(D[30]), [30, 31, 33])
+        self.assertEqual(list(D[20]), [20, 21, 22, 23])
+
+        self.assertEqual(list(D[40]), [])  # Nothing in here!
+
+    def test_in(self):
+        iterable = [10, 20, 30, 11, 21, 31, 12, 22, 23, 33]
+        D = mi.bucket(iterable, key=lambda x: 10 * (x // 10))
+
+        self.assertTrue(10 in D)
+        self.assertFalse(40 in D)
+        self.assertTrue(20 in D)
+        self.assertFalse(21 in D)
+
+        # Checking in-ness shouldn't advance the iterator
+        self.assertEqual(next(D[10]), 10)
+
+    def test_validator(self):
+        iterable = count(0)
+        key = lambda x: int(str(x)[0])  # First digit of each number
+        validator = lambda x: 0 < x < 10  # No leading zeros
+        D = mi.bucket(iterable, key, validator=validator)
+        self.assertEqual(mi.take(3, D[1]), [1, 10, 11])
+        self.assertNotIn(0, D)  # Non-valid entries don't return True
+        self.assertNotIn(0, D._cache)  # Don't store non-valid entries
+        self.assertEqual(list(D[0]), [])
+
+
+class SpyTests(TestCase):
+    """Tests for ``spy()``"""
+
+    def test_basic(self):
+        original_iterable = iter('abcdefg')
+        head, new_iterable = mi.spy(original_iterable)
+        self.assertEqual(head, ['a'])
+        self.assertEqual(
+            list(new_iterable), ['a', 'b', 'c', 'd', 'e', 'f', 'g']
+        )
+
+    def test_unpacking(self):
+        original_iterable = iter('abcdefg')
+        (first, second, third), new_iterable = mi.spy(original_iterable, 3)
+        self.assertEqual(first, 'a')
+        self.assertEqual(second, 'b')
+        self.assertEqual(third, 'c')
+        self.assertEqual(
+            list(new_iterable), ['a', 'b', 'c', 'd', 'e', 'f', 'g']
+        )
+
+    def test_too_many(self):
+        original_iterable = iter('abc')
+        head, new_iterable = mi.spy(original_iterable, 4)
+        self.assertEqual(head, ['a', 'b', 'c'])
+        self.assertEqual(list(new_iterable), ['a', 'b', 'c'])
+
+    def test_zero(self):
+        original_iterable = iter('abc')
+        head, new_iterable = mi.spy(original_iterable, 0)
+        self.assertEqual(head, [])
+        self.assertEqual(list(new_iterable), ['a', 'b', 'c'])
+
+
+class InterleaveTests(TestCase):
+    def test_even(self):
+        actual = list(mi.interleave([1, 4, 7], [2, 5, 8], [3, 6, 9]))
+        expected = [1, 2, 3, 4, 5, 6, 7, 8, 9]
+        self.assertEqual(actual, expected)
+
+    def test_short(self):
+        actual = list(mi.interleave([1, 4], [2, 5, 7], [3, 6, 8]))
+        expected = [1, 2, 3, 4, 5, 6]
+        self.assertEqual(actual, expected)
+
+    def test_mixed_types(self):
+        it_list = ['a', 'b', 'c', 'd']
+        it_str = '12345'
+        it_inf = count()
+        actual = list(mi.interleave(it_list, it_str, it_inf))
+        expected = ['a', '1', 0, 'b', '2', 1, 'c', '3', 2, 'd', '4', 3]
+        self.assertEqual(actual, expected)
+
+
+class InterleaveLongestTests(TestCase):
+    def test_even(self):
+        actual = list(mi.interleave_longest([1, 4, 7], [2, 5, 8], [3, 6, 9]))
+        expected = [1, 2, 3, 4, 5, 6, 7, 8, 9]
+        self.assertEqual(actual, expected)
+
+    def test_short(self):
+        actual = list(mi.interleave_longest([1, 4], [2, 5, 7], [3, 6, 8]))
+        expected = [1, 2, 3, 4, 5, 6, 7, 8]
+        self.assertEqual(actual, expected)
+
+    def test_mixed_types(self):
+        it_list = ['a', 'b', 'c', 'd']
+        it_str = '12345'
+        it_gen = (x for x in range(3))
+        actual = list(mi.interleave_longest(it_list, it_str, it_gen))
+        expected = ['a', '1', 0, 'b', '2', 1, 'c', '3', 2, 'd', '4', '5']
+        self.assertEqual(actual, expected)
+
+
+class TestCollapse(TestCase):
+    """Tests for ``collapse()``"""
+
+    def test_collapse(self):
+        l = [[1], 2, [[3], 4], [[[5]]]]
+        self.assertEqual(list(mi.collapse(l)), [1, 2, 3, 4, 5])
+
+    def test_collapse_to_string(self):
+        l = [["s1"], "s2", [["s3"], "s4"], [[["s5"]]]]
+        self.assertEqual(list(mi.collapse(l)), ["s1", "s2", "s3", "s4", "s5"])
+
+    def test_collapse_flatten(self):
+        l = [[1], [2], [[3], 4], [[[5]]]]
+        self.assertEqual(list(mi.collapse(l, levels=1)), list(mi.flatten(l)))
+
+    def test_collapse_to_level(self):
+        l = [[1], 2, [[3], 4], [[[5]]]]
+        self.assertEqual(list(mi.collapse(l, levels=2)), [1, 2, 3, 4, [5]])
+        self.assertEqual(
+            list(mi.collapse(mi.collapse(l, levels=1), levels=1)),
+            list(mi.collapse(l, levels=2))
+        )
+
+    def test_collapse_to_list(self):
+        l = (1, [2], (3, [4, (5,)], 'ab'))
+        actual = list(mi.collapse(l, base_type=list))
+        expected = [1, [2], 3, [4, (5,)], 'ab']
+        self.assertEqual(actual, expected)
+
+
+class SideEffectTests(TestCase):
+    """Tests for ``side_effect()``"""
+
+    def test_individual(self):
+        # The function increments the counter for each call
+        counter = [0]
+
+        def func(arg):
+            counter[0] += 1
+
+        result = list(mi.side_effect(func, range(10)))
+        self.assertEqual(result, list(range(10)))
+        self.assertEqual(counter[0], 10)
+
+    def test_chunked(self):
+        # The function increments the counter for each call
+        counter = [0]
+
+        def func(arg):
+            counter[0] += 1
+
+        result = list(mi.side_effect(func, range(10), 2))
+        self.assertEqual(result, list(range(10)))
+        self.assertEqual(counter[0], 5)
+
+    def test_before_after(self):
+        f = StringIO()
+        collector = []
+
+        def func(item):
+            print(item, file=f)
+            collector.append(f.getvalue())
+
+        def it():
+            yield u'a'
+            yield u'b'
+            raise RuntimeError('kaboom')
+
+        before = lambda: print('HEADER', file=f)
+        after = f.close
+
+        try:
+            mi.consume(mi.side_effect(func, it(), before=before, after=after))
+        except RuntimeError:
+            pass
+
+        # The iterable should have been written to the file
+        self.assertEqual(collector, [u'HEADER\na\n', u'HEADER\na\nb\n'])
+
+        # The file should be closed even though something bad happened
+        self.assertTrue(f.closed)
+
+    def test_before_fails(self):
+        f = StringIO()
+        func = lambda x: print(x, file=f)
+
+        def before():
+            raise RuntimeError('ouch')
+
+        try:
+            mi.consume(
+                mi.side_effect(func, u'abc', before=before, after=f.close)
+            )
+        except RuntimeError:
+            pass
+
+        # The file should be closed even though something bad happened in the
+        # before function
+        self.assertTrue(f.closed)
+
+
+class SlicedTests(TestCase):
+    """Tests for ``sliced()``"""
+
+    def test_even(self):
+        """Test when the length of the sequence is divisible by *n*"""
+        seq = 'ABCDEFGHI'
+        self.assertEqual(list(mi.sliced(seq, 3)), ['ABC', 'DEF', 'GHI'])
+
+    def test_odd(self):
+        """Test when the length of the sequence is not divisible by *n*"""
+        seq = 'ABCDEFGHI'
+        self.assertEqual(list(mi.sliced(seq, 4)), ['ABCD', 'EFGH', 'I'])
+
+    def test_not_sliceable(self):
+        seq = (x for x in 'ABCDEFGHI')
+
+        with self.assertRaises(TypeError):
+            list(mi.sliced(seq, 3))
+
+
+class SplitAtTests(TestCase):
+    """Tests for ``split()``"""
+
+    def comp_with_str_split(self, str_to_split, delim):
+        pred = lambda c: c == delim
+        actual = list(map(''.join, mi.split_at(str_to_split, pred)))
+        expected = str_to_split.split(delim)
+        self.assertEqual(actual, expected)
+
+    def test_seperators(self):
+        test_strs = ['', 'abcba', 'aaabbbcccddd', 'e']
+        for s, delim in product(test_strs, 'abcd'):
+            self.comp_with_str_split(s, delim)
+
+
+class SplitBeforeTest(TestCase):
+    """Tests for ``split_before()``"""
+
+    def test_starts_with_sep(self):
+        actual = list(mi.split_before('xooxoo', lambda c: c == 'x'))
+        expected = [['x', 'o', 'o'], ['x', 'o', 'o']]
+        self.assertEqual(actual, expected)
+
+    def test_ends_with_sep(self):
+        actual = list(mi.split_before('ooxoox', lambda c: c == 'x'))
+        expected = [['o', 'o'], ['x', 'o', 'o'], ['x']]
+        self.assertEqual(actual, expected)
+
+    def test_no_sep(self):
+        actual = list(mi.split_before('ooo', lambda c: c == 'x'))
+        expected = [['o', 'o', 'o']]
+        self.assertEqual(actual, expected)
+
+
+class SplitAfterTest(TestCase):
+    """Tests for ``split_after()``"""
+
+    def test_starts_with_sep(self):
+        actual = list(mi.split_after('xooxoo', lambda c: c == 'x'))
+        expected = [['x'], ['o', 'o', 'x'], ['o', 'o']]
+        self.assertEqual(actual, expected)
+
+    def test_ends_with_sep(self):
+        actual = list(mi.split_after('ooxoox', lambda c: c == 'x'))
+        expected = [['o', 'o', 'x'], ['o', 'o', 'x']]
+        self.assertEqual(actual, expected)
+
+    def test_no_sep(self):
+        actual = list(mi.split_after('ooo', lambda c: c == 'x'))
+        expected = [['o', 'o', 'o']]
+        self.assertEqual(actual, expected)
+
+
+class PaddedTest(TestCase):
+    """Tests for ``padded()``"""
+
+    def test_no_n(self):
+        seq = [1, 2, 3]
+
+        # No fillvalue
+        self.assertEqual(mi.take(5, mi.padded(seq)), [1, 2, 3, None, None])
+
+        # With fillvalue
+        self.assertEqual(
+            mi.take(5, mi.padded(seq, fillvalue='')), [1, 2, 3, '', '']
+        )
+
+    def test_invalid_n(self):
+        self.assertRaises(ValueError, lambda: list(mi.padded([1, 2, 3], n=-1)))
+        self.assertRaises(ValueError, lambda: list(mi.padded([1, 2, 3], n=0)))
+
+    def test_valid_n(self):
+        seq = [1, 2, 3, 4, 5]
+
+        # No need for padding: len(seq) <= n
+        self.assertEqual(list(mi.padded(seq, n=4)), [1, 2, 3, 4, 5])
+        self.assertEqual(list(mi.padded(seq, n=5)), [1, 2, 3, 4, 5])
+
+        # No fillvalue
+        self.assertEqual(
+            list(mi.padded(seq, n=7)), [1, 2, 3, 4, 5, None, None]
+        )
+
+        # With fillvalue
+        self.assertEqual(
+            list(mi.padded(seq, fillvalue='', n=7)), [1, 2, 3, 4, 5, '', '']
+        )
+
+    def test_next_multiple(self):
+        seq = [1, 2, 3, 4, 5, 6]
+
+        # No need for padding: len(seq) % n == 0
+        self.assertEqual(
+            list(mi.padded(seq, n=3, next_multiple=True)), [1, 2, 3, 4, 5, 6]
+        )
+
+        # Padding needed: len(seq) < n
+        self.assertEqual(
+            list(mi.padded(seq, n=8, next_multiple=True)),
+            [1, 2, 3, 4, 5, 6, None, None]
+        )
+
+        # No padding needed: len(seq) == n
+        self.assertEqual(
+            list(mi.padded(seq, n=6, next_multiple=True)), [1, 2, 3, 4, 5, 6]
+        )
+
+        # Padding needed: len(seq) > n
+        self.assertEqual(
+            list(mi.padded(seq, n=4, next_multiple=True)),
+            [1, 2, 3, 4, 5, 6, None, None]
+        )
+
+        # With fillvalue
+        self.assertEqual(
+            list(mi.padded(seq, fillvalue='', n=4, next_multiple=True)),
+            [1, 2, 3, 4, 5, 6, '', '']
+        )
+
+
+class DistributeTest(TestCase):
+    """Tests for distribute()"""
+
+    def test_invalid_n(self):
+        self.assertRaises(ValueError, lambda: mi.distribute(-1, [1, 2, 3]))
+        self.assertRaises(ValueError, lambda: mi.distribute(0, [1, 2, 3]))
+
+    def test_basic(self):
+        iterable = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
+
+        for n, expected in [
+            (1, [iterable]),
+            (2, [[1, 3, 5, 7, 9], [2, 4, 6, 8, 10]]),
+            (3, [[1, 4, 7, 10], [2, 5, 8], [3, 6, 9]]),
+            (10, [[n] for n in range(1, 10 + 1)]),
+        ]:
+            self.assertEqual(
+                [list(x) for x in mi.distribute(n, iterable)], expected
+            )
+
+    def test_large_n(self):
+        iterable = [1, 2, 3, 4]
+        self.assertEqual(
+            [list(x) for x in mi.distribute(6, iterable)],
+            [[1], [2], [3], [4], [], []]
+        )
+
+
+class StaggerTest(TestCase):
+    """Tests for ``stagger()``"""
+
+    def test_default(self):
+        iterable = [0, 1, 2, 3]
+        actual = list(mi.stagger(iterable))
+        expected = [(None, 0, 1), (0, 1, 2), (1, 2, 3)]
+        self.assertEqual(actual, expected)
+
+    def test_offsets(self):
+        iterable = [0, 1, 2, 3]
+        for offsets, expected in [
+            ((-2, 0, 2), [('', 0, 2), ('', 1, 3)]),
+            ((-2, -1), [('', ''), ('', 0), (0, 1), (1, 2), (2, 3)]),
+            ((1, 2), [(1, 2), (2, 3)]),
+        ]:
+            all_groups = mi.stagger(iterable, offsets=offsets, fillvalue='')
+            self.assertEqual(list(all_groups), expected)
+
+    def test_longest(self):
+        iterable = [0, 1, 2, 3]
+        for offsets, expected in [
+            (
+                (-1, 0, 1),
+                [('', 0, 1), (0, 1, 2), (1, 2, 3), (2, 3, ''), (3, '', '')]
+            ),
+            ((-2, -1), [('', ''), ('', 0), (0, 1), (1, 2), (2, 3), (3, '')]),
+            ((1, 2), [(1, 2), (2, 3), (3, '')]),
+        ]:
+            all_groups = mi.stagger(
+                iterable, offsets=offsets, fillvalue='', longest=True
+            )
+            self.assertEqual(list(all_groups), expected)
+
+
+class ZipOffsetTest(TestCase):
+    """Tests for ``zip_offset()``"""
+
+    def test_shortest(self):
+        a_1 = [0, 1, 2, 3]
+        a_2 = [0, 1, 2, 3, 4, 5]
+        a_3 = [0, 1, 2, 3, 4, 5, 6, 7]
+        actual = list(
+            mi.zip_offset(a_1, a_2, a_3, offsets=(-1, 0, 1), fillvalue='')
+        )
+        expected = [('', 0, 1), (0, 1, 2), (1, 2, 3), (2, 3, 4), (3, 4, 5)]
+        self.assertEqual(actual, expected)
+
+    def test_longest(self):
+        a_1 = [0, 1, 2, 3]
+        a_2 = [0, 1, 2, 3, 4, 5]
+        a_3 = [0, 1, 2, 3, 4, 5, 6, 7]
+        actual = list(
+            mi.zip_offset(a_1, a_2, a_3, offsets=(-1, 0, 1), longest=True)
+        )
+        expected = [
+            (None, 0, 1),
+            (0, 1, 2),
+            (1, 2, 3),
+            (2, 3, 4),
+            (3, 4, 5),
+            (None, 5, 6),
+            (None, None, 7),
+        ]
+        self.assertEqual(actual, expected)
+
+    def test_mismatch(self):
+        iterables = [0, 1, 2], [2, 3, 4]
+        offsets = (-1, 0, 1)
+        self.assertRaises(
+            ValueError,
+            lambda: list(mi.zip_offset(*iterables, offsets=offsets))
+        )
+
+
+class SortTogetherTest(TestCase):
+    """Tests for sort_together()"""
+
+    def test_key_list(self):
+        """tests `key_list` including default, iterables include duplicates"""
+        iterables = [
+            ['GA', 'GA', 'GA', 'CT', 'CT', 'CT'],
+            ['May', 'Aug.', 'May', 'June', 'July', 'July'],
+            [97, 20, 100, 70, 100, 20]
+        ]
+
+        self.assertEqual(
+            mi.sort_together(iterables),
+            [
+                ('CT', 'CT', 'CT', 'GA', 'GA', 'GA'),
+                ('June', 'July', 'July', 'May', 'Aug.', 'May'),
+                (70, 100, 20, 97, 20, 100)
+            ]
+        )
+
+        self.assertEqual(
+            mi.sort_together(iterables, key_list=(0, 1)),
+            [
+                ('CT', 'CT', 'CT', 'GA', 'GA', 'GA'),
+                ('July', 'July', 'June', 'Aug.', 'May', 'May'),
+                (100, 20, 70, 20, 97, 100)
+            ]
+        )
+
+        self.assertEqual(
+            mi.sort_together(iterables, key_list=(0, 1, 2)),
+            [
+                ('CT', 'CT', 'CT', 'GA', 'GA', 'GA'),
+                ('July', 'July', 'June', 'Aug.', 'May', 'May'),
+                (20, 100, 70, 20, 97, 100)
+            ]
+        )
+
+        self.assertEqual(
+            mi.sort_together(iterables, key_list=(2,)),
+            [
+                ('GA', 'CT', 'CT', 'GA', 'GA', 'CT'),
+                ('Aug.', 'July', 'June', 'May', 'May', 'July'),
+                (20, 20, 70, 97, 100, 100)
+            ]
+        )
+
+    def test_invalid_key_list(self):
+        """tests `key_list` for indexes not available in `iterables`"""
+        iterables = [
+            ['GA', 'GA', 'GA', 'CT', 'CT', 'CT'],
+            ['May', 'Aug.', 'May', 'June', 'July', 'July'],
+            [97, 20, 100, 70, 100, 20]
+        ]
+
+        self.assertRaises(
+            IndexError, lambda: mi.sort_together(iterables, key_list=(5,))
+        )
+
+    def test_reverse(self):
+        """tests `reverse` to ensure a reverse sort for `key_list` iterables"""
+        iterables = [
+            ['GA', 'GA', 'GA', 'CT', 'CT', 'CT'],
+            ['May', 'Aug.', 'May', 'June', 'July', 'July'],
+            [97, 20, 100, 70, 100, 20]
+        ]
+
+        self.assertEqual(
+            mi.sort_together(iterables, key_list=(0, 1, 2), reverse=True),
+            [('GA', 'GA', 'GA', 'CT', 'CT', 'CT'),
+             ('May', 'May', 'Aug.', 'June', 'July', 'July'),
+             (100, 97, 20, 70, 100, 20)]
+        )
+
+    def test_uneven_iterables(self):
+        """tests trimming of iterables to the shortest length before sorting"""
+        iterables = [['GA', 'GA', 'GA', 'CT', 'CT', 'CT', 'MA'],
+                     ['May', 'Aug.', 'May', 'June', 'July', 'July'],
+                     [97, 20, 100, 70, 100, 20, 0]]
+
+        self.assertEqual(
+            mi.sort_together(iterables),
+            [
+                ('CT', 'CT', 'CT', 'GA', 'GA', 'GA'),
+                ('June', 'July', 'July', 'May', 'Aug.', 'May'),
+                (70, 100, 20, 97, 20, 100)
+            ]
+        )
+
+
+class DivideTest(TestCase):
+    """Tests for divide()"""
+
+    def test_invalid_n(self):
+        self.assertRaises(ValueError, lambda: mi.divide(-1, [1, 2, 3]))
+        self.assertRaises(ValueError, lambda: mi.divide(0, [1, 2, 3]))
+
+    def test_basic(self):
+        iterable = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
+
+        for n, expected in [
+            (1, [iterable]),
+            (2, [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]),
+            (3, [[1, 2, 3, 4], [5, 6, 7], [8, 9, 10]]),
+            (10, [[n] for n in range(1, 10 + 1)]),
+        ]:
+            self.assertEqual(
+                [list(x) for x in mi.divide(n, iterable)], expected
+            )
+
+    def test_large_n(self):
+        iterable = [1, 2, 3, 4]
+        self.assertEqual(
+            [list(x) for x in mi.divide(6, iterable)],
+            [[1], [2], [3], [4], [], []]
+        )
+
+
+class TestAlwaysIterable(TestCase):
+    """Tests for always_iterable()"""
+    def test_single(self):
+        self.assertEqual(list(mi.always_iterable(1)), [1])
+
+    def test_strings(self):
+        for obj in ['foo', b'bar', u'baz']:
+            actual = list(mi.always_iterable(obj))
+            expected = [obj]
+            self.assertEqual(actual, expected)
+
+    def test_base_type(self):
+        dict_obj = {'a': 1, 'b': 2}
+        str_obj = '123'
+
+        # Default: dicts are iterable like they normally are
+        default_actual = list(mi.always_iterable(dict_obj))
+        default_expected = list(dict_obj)
+        self.assertEqual(default_actual, default_expected)
+
+        # Unitary types set: dicts are not iterable
+        custom_actual = list(mi.always_iterable(dict_obj, base_type=dict))
+        custom_expected = [dict_obj]
+        self.assertEqual(custom_actual, custom_expected)
+
+        # With unitary types set, strings are iterable
+        str_actual = list(mi.always_iterable(str_obj, base_type=None))
+        str_expected = list(str_obj)
+        self.assertEqual(str_actual, str_expected)
+
+    def test_iterables(self):
+        self.assertEqual(list(mi.always_iterable([0, 1])), [0, 1])
+        self.assertEqual(
+            list(mi.always_iterable([0, 1], base_type=list)), [[0, 1]]
+        )
+        self.assertEqual(
+            list(mi.always_iterable(iter('foo'))), ['f', 'o', 'o']
+        )
+        self.assertEqual(list(mi.always_iterable([])), [])
+
+    def test_none(self):
+        self.assertEqual(list(mi.always_iterable(None)), [])
+
+    def test_generator(self):
+        def _gen():
+            yield 0
+            yield 1
+
+        self.assertEqual(list(mi.always_iterable(_gen())), [0, 1])
+
+
+class AdjacentTests(TestCase):
+    def test_typical(self):
+        actual = list(mi.adjacent(lambda x: x % 5 == 0, range(10)))
+        expected = [(True, 0), (True, 1), (False, 2), (False, 3), (True, 4),
+                    (True, 5), (True, 6), (False, 7), (False, 8), (False, 9)]
+        self.assertEqual(actual, expected)
+
+    def test_empty_iterable(self):
+        actual = list(mi.adjacent(lambda x: x % 5 == 0, []))
+        expected = []
+        self.assertEqual(actual, expected)
+
+    def test_length_one(self):
+        actual = list(mi.adjacent(lambda x: x % 5 == 0, [0]))
+        expected = [(True, 0)]
+        self.assertEqual(actual, expected)
+
+        actual = list(mi.adjacent(lambda x: x % 5 == 0, [1]))
+        expected = [(False, 1)]
+        self.assertEqual(actual, expected)
+
+    def test_consecutive_true(self):
+        """Test that when the predicate matches multiple consecutive elements
+        it doesn't repeat elements in the output"""
+        actual = list(mi.adjacent(lambda x: x % 5 < 2, range(10)))
+        expected = [(True, 0), (True, 1), (True, 2), (False, 3), (True, 4),
+                    (True, 5), (True, 6), (True, 7), (False, 8), (False, 9)]
+        self.assertEqual(actual, expected)
+
+    def test_distance(self):
+        actual = list(mi.adjacent(lambda x: x % 5 == 0, range(10), distance=2))
+        expected = [(True, 0), (True, 1), (True, 2), (True, 3), (True, 4),
+                    (True, 5), (True, 6), (True, 7), (False, 8), (False, 9)]
+        self.assertEqual(actual, expected)
+
+        actual = list(mi.adjacent(lambda x: x % 5 == 0, range(10), distance=3))
+        expected = [(True, 0), (True, 1), (True, 2), (True, 3), (True, 4),
+                    (True, 5), (True, 6), (True, 7), (True, 8), (False, 9)]
+        self.assertEqual(actual, expected)
+
+    def test_large_distance(self):
+        """Test distance larger than the length of the iterable"""
+        iterable = range(10)
+        actual = list(mi.adjacent(lambda x: x % 5 == 4, iterable, distance=20))
+        expected = list(zip(repeat(True), iterable))
+        self.assertEqual(actual, expected)
+
+        actual = list(mi.adjacent(lambda x: False, iterable, distance=20))
+        expected = list(zip(repeat(False), iterable))
+        self.assertEqual(actual, expected)
+
+    def test_zero_distance(self):
+        """Test that adjacent() reduces to zip+map when distance is 0"""
+        iterable = range(1000)
+        predicate = lambda x: x % 4 == 2
+        actual = mi.adjacent(predicate, iterable, 0)
+        expected = zip(map(predicate, iterable), iterable)
+        self.assertTrue(all(a == e for a, e in zip(actual, expected)))
+
+    def test_negative_distance(self):
+        """Test that adjacent() raises an error with negative distance"""
+        pred = lambda x: x
+        self.assertRaises(
+            ValueError, lambda: mi.adjacent(pred, range(1000), -1)
+        )
+        self.assertRaises(
+            ValueError, lambda: mi.adjacent(pred, range(10), -10)
+        )
+
+    def test_grouping(self):
+        """Test interaction of adjacent() with groupby_transform()"""
+        iterable = mi.adjacent(lambda x: x % 5 == 0, range(10))
+        grouper = mi.groupby_transform(iterable, itemgetter(0), itemgetter(1))
+        actual = [(k, list(g)) for k, g in grouper]
+        expected = [
+            (True, [0, 1]),
+            (False, [2, 3]),
+            (True, [4, 5, 6]),
+            (False, [7, 8, 9]),
+        ]
+        self.assertEqual(actual, expected)
+
+    def test_call_once(self):
+        """Test that the predicate is only called once per item."""
+        already_seen = set()
+        iterable = range(10)
+
+        def predicate(item):
+            self.assertNotIn(item, already_seen)
+            already_seen.add(item)
+            return True
+
+        actual = list(mi.adjacent(predicate, iterable))
+        expected = [(True, x) for x in iterable]
+        self.assertEqual(actual, expected)
+
+
+class GroupByTransformTests(TestCase):
+    def assertAllGroupsEqual(self, groupby1, groupby2):
+        """Compare two groupby objects for equality, both keys and groups."""
+        for a, b in zip(groupby1, groupby2):
+            key1, group1 = a
+            key2, group2 = b
+            self.assertEqual(key1, key2)
+            self.assertListEqual(list(group1), list(group2))
+        self.assertRaises(StopIteration, lambda: next(groupby1))
+        self.assertRaises(StopIteration, lambda: next(groupby2))
+
+    def test_default_funcs(self):
+        """Test that groupby_transform() with default args mimics groupby()"""
+        iterable = [(x // 5, x) for x in range(1000)]
+        actual = mi.groupby_transform(iterable)
+        expected = groupby(iterable)
+        self.assertAllGroupsEqual(actual, expected)
+
+    def test_valuefunc(self):
+        iterable = [(int(x / 5), int(x / 3), x) for x in range(10)]
+
+        # Test the standard usage of grouping one iterable using another's keys
+        grouper = mi.groupby_transform(
+            iterable, keyfunc=itemgetter(0), valuefunc=itemgetter(-1)
+        )
+        actual = [(k, list(g)) for k, g in grouper]
+        expected = [(0, [0, 1, 2, 3, 4]), (1, [5, 6, 7, 8, 9])]
+        self.assertEqual(actual, expected)
+
+        grouper = mi.groupby_transform(
+            iterable, keyfunc=itemgetter(1), valuefunc=itemgetter(-1)
+        )
+        actual = [(k, list(g)) for k, g in grouper]
+        expected = [(0, [0, 1, 2]), (1, [3, 4, 5]), (2, [6, 7, 8]), (3, [9])]
+        self.assertEqual(actual, expected)
+
+        # and now for something a little different
+        d = dict(zip(range(10), 'abcdefghij'))
+        grouper = mi.groupby_transform(
+            range(10), keyfunc=lambda x: x // 5, valuefunc=d.get
+        )
+        actual = [(k, ''.join(g)) for k, g in grouper]
+        expected = [(0, 'abcde'), (1, 'fghij')]
+        self.assertEqual(actual, expected)
+
+    def test_no_valuefunc(self):
+        iterable = range(1000)
+
+        def key(x):
+            return x // 5
+
+        actual = mi.groupby_transform(iterable, key, valuefunc=None)
+        expected = groupby(iterable, key)
+        self.assertAllGroupsEqual(actual, expected)
+
+        actual = mi.groupby_transform(iterable, key)  # default valuefunc
+        expected = groupby(iterable, key)
+        self.assertAllGroupsEqual(actual, expected)
+
+
+class NumericRangeTests(TestCase):
+    def test_basic(self):
+        for args, expected in [
+            ((4,), [0, 1, 2, 3]),
+            ((4.0,), [0.0, 1.0, 2.0, 3.0]),
+            ((1.0, 4), [1.0, 2.0, 3.0]),
+            ((1, 4.0), [1, 2, 3]),
+            ((1.0, 5), [1.0, 2.0, 3.0, 4.0]),
+            ((0, 20, 5), [0, 5, 10, 15]),
+            ((0, 20, 5.0), [0.0, 5.0, 10.0, 15.0]),
+            ((0, 10, 3), [0, 3, 6, 9]),
+            ((0, 10, 3.0), [0.0, 3.0, 6.0, 9.0]),
+            ((0, -5, -1), [0, -1, -2, -3, -4]),
+            ((0.0, -5, -1), [0.0, -1.0, -2.0, -3.0, -4.0]),
+            ((1, 2, Fraction(1, 2)), [Fraction(1, 1), Fraction(3, 2)]),
+            ((0,), []),
+            ((0.0,), []),
+            ((1, 0), []),
+            ((1.0, 0.0), []),
+            ((Fraction(2, 1),), [Fraction(0, 1), Fraction(1, 1)]),
+            ((Decimal('2.0'),), [Decimal('0.0'), Decimal('1.0')]),
+        ]:
+            actual = list(mi.numeric_range(*args))
+            self.assertEqual(actual, expected)
+            self.assertTrue(
+                all(type(a) == type(e) for a, e in zip(actual, expected))
+            )
+
+    def test_arg_count(self):
+        self.assertRaises(TypeError, lambda: list(mi.numeric_range()))
+        self.assertRaises(
+            TypeError, lambda: list(mi.numeric_range(0, 1, 2, 3))
+        )
+
+    def test_zero_step(self):
+        self.assertRaises(
+            ValueError, lambda: list(mi.numeric_range(1, 2, 0))
+        )
+
+
+class CountCycleTests(TestCase):
+    def test_basic(self):
+        expected = [
+            (0, 'a'), (0, 'b'), (0, 'c'),
+            (1, 'a'), (1, 'b'), (1, 'c'),
+            (2, 'a'), (2, 'b'), (2, 'c'),
+        ]
+        for actual in [
+            mi.take(9, mi.count_cycle('abc')),  # n=None
+            list(mi.count_cycle('abc', 3)),  # n=3
+        ]:
+            self.assertEqual(actual, expected)
+
+    def test_empty(self):
+        self.assertEqual(list(mi.count_cycle('')), [])
+        self.assertEqual(list(mi.count_cycle('', 2)), [])
+
+    def test_negative(self):
+        self.assertEqual(list(mi.count_cycle('abc', -3)), [])
+
+
+class LocateTests(TestCase):
+    def test_default_pred(self):
+        iterable = [0, 1, 1, 0, 1, 0, 0]
+        actual = list(mi.locate(iterable))
+        expected = [1, 2, 4]
+        self.assertEqual(actual, expected)
+
+    def test_no_matches(self):
+        iterable = [0, 0, 0]
+        actual = list(mi.locate(iterable))
+        expected = []
+        self.assertEqual(actual, expected)
+
+    def test_custom_pred(self):
+        iterable = ['0', 1, 1, '0', 1, '0', '0']
+        pred = lambda x: x == '0'
+        actual = list(mi.locate(iterable, pred))
+        expected = [0, 3, 5, 6]
+        self.assertEqual(actual, expected)
+
+    def test_window_size(self):
+        iterable = ['0', 1, 1, '0', 1, '0', '0']
+        pred = lambda *args: args == ('0', 1)
+        actual = list(mi.locate(iterable, pred, window_size=2))
+        expected = [0, 3]
+        self.assertEqual(actual, expected)
+
+    def test_window_size_large(self):
+        iterable = [1, 2, 3, 4]
+        pred = lambda a, b, c, d, e: True
+        actual = list(mi.locate(iterable, pred, window_size=5))
+        expected = [0]
+        self.assertEqual(actual, expected)
+
+    def test_window_size_zero(self):
+        iterable = [1, 2, 3, 4]
+        pred = lambda: True
+        with self.assertRaises(ValueError):
+            list(mi.locate(iterable, pred, window_size=0))
+
+
+class StripFunctionTests(TestCase):
+    def test_hashable(self):
+        iterable = list('www.example.com')
+        pred = lambda x: x in set('cmowz.')
+
+        self.assertEqual(list(mi.lstrip(iterable, pred)), list('example.com'))
+        self.assertEqual(list(mi.rstrip(iterable, pred)), list('www.example'))
+        self.assertEqual(list(mi.strip(iterable, pred)), list('example'))
+
+    def test_not_hashable(self):
+        iterable = [
+            list('http://'), list('www'), list('.example'), list('.com')
+        ]
+        pred = lambda x: x in [list('http://'), list('www'), list('.com')]
+
+        self.assertEqual(list(mi.lstrip(iterable, pred)), iterable[2:])
+        self.assertEqual(list(mi.rstrip(iterable, pred)), iterable[:3])
+        self.assertEqual(list(mi.strip(iterable, pred)), iterable[2: 3])
+
+    def test_math(self):
+        iterable = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2]
+        pred = lambda x: x <= 2
+
+        self.assertEqual(list(mi.lstrip(iterable, pred)), iterable[3:])
+        self.assertEqual(list(mi.rstrip(iterable, pred)), iterable[:-3])
+        self.assertEqual(list(mi.strip(iterable, pred)), iterable[3:-3])
+
+
+class IsliceExtendedTests(TestCase):
+    def test_all(self):
+        iterable = ['0', '1', '2', '3', '4', '5']
+        indexes = list(range(-4, len(iterable) + 4)) + [None]
+        steps = [1, 2, 3, 4, -1, -2, -3, 4]
+        for slice_args in product(indexes, indexes, steps):
+            try:
+                actual = list(mi.islice_extended(iterable, *slice_args))
+            except Exception as e:
+                self.fail((slice_args, e))
+
+            expected = iterable[slice(*slice_args)]
+            self.assertEqual(actual, expected, slice_args)
+
+    def test_zero_step(self):
+        with self.assertRaises(ValueError):
+            list(mi.islice_extended([1, 2, 3], 0, 1, 0))
+
+
+class ConsecutiveGroupsTest(TestCase):
+    def test_numbers(self):
+        iterable = [-10, -8, -7, -6, 1, 2, 4, 5, -1, 7]
+        actual = [list(g) for g in mi.consecutive_groups(iterable)]
+        expected = [[-10], [-8, -7, -6], [1, 2], [4, 5], [-1], [7]]
+        self.assertEqual(actual, expected)
+
+    def test_custom_ordering(self):
+        iterable = ['1', '10', '11', '20', '21', '22', '30', '31']
+        ordering = lambda x: int(x)
+        actual = [list(g) for g in mi.consecutive_groups(iterable, ordering)]
+        expected = [['1'], ['10', '11'], ['20', '21', '22'], ['30', '31']]
+        self.assertEqual(actual, expected)
+
+    def test_exotic_ordering(self):
+        iterable = [
+            ('a', 'b', 'c', 'd'),
+            ('a', 'c', 'b', 'd'),
+            ('a', 'c', 'd', 'b'),
+            ('a', 'd', 'b', 'c'),
+            ('d', 'b', 'c', 'a'),
+            ('d', 'c', 'a', 'b'),
+        ]
+        ordering = list(permutations('abcd')).index
+        actual = [list(g) for g in mi.consecutive_groups(iterable, ordering)]
+        expected = [
+            [('a', 'b', 'c', 'd')],
+            [('a', 'c', 'b', 'd'), ('a', 'c', 'd', 'b'), ('a', 'd', 'b', 'c')],
+            [('d', 'b', 'c', 'a'), ('d', 'c', 'a', 'b')],
+        ]
+        self.assertEqual(actual, expected)
+
+
+class DifferenceTest(TestCase):
+    def test_normal(self):
+        iterable = [10, 20, 30, 40, 50]
+        actual = list(mi.difference(iterable))
+        expected = [10, 10, 10, 10, 10]
+        self.assertEqual(actual, expected)
+
+    def test_custom(self):
+        iterable = [10, 20, 30, 40, 50]
+        actual = list(mi.difference(iterable, add))
+        expected = [10, 30, 50, 70, 90]
+        self.assertEqual(actual, expected)
+
+    def test_roundtrip(self):
+        original = list(range(100))
+        accumulated = mi.accumulate(original)
+        actual = list(mi.difference(accumulated))
+        self.assertEqual(actual, original)
+
+    def test_one(self):
+        self.assertEqual(list(mi.difference([0])), [0])
+
+    def test_empty(self):
+        self.assertEqual(list(mi.difference([])), [])
+
+
+class SeekableTest(TestCase):
+    def test_exhaustion_reset(self):
+        iterable = [str(n) for n in range(10)]
+
+        s = mi.seekable(iterable)
+        self.assertEqual(list(s), iterable)  # Normal iteration
+        self.assertEqual(list(s), [])  # Iterable is exhausted
+
+        s.seek(0)
+        self.assertEqual(list(s), iterable)  # Back in action
+
+    def test_partial_reset(self):
+        iterable = [str(n) for n in range(10)]
+
+        s = mi.seekable(iterable)
+        self.assertEqual(mi.take(5, s), iterable[:5])  # Normal iteration
+
+        s.seek(1)
+        self.assertEqual(list(s), iterable[1:])  # Get the rest of the iterable
+
+    def test_forward(self):
+        iterable = [str(n) for n in range(10)]
+
+        s = mi.seekable(iterable)
+        self.assertEqual(mi.take(1, s), iterable[:1])  # Normal iteration
+
+        s.seek(3)  # Skip over index 2
+        self.assertEqual(list(s), iterable[3:])  # Result is similar to slicing
+
+        s.seek(0)  # Back to 0
+        self.assertEqual(list(s), iterable)  # No difference in result
+
+    def test_past_end(self):
+        iterable = [str(n) for n in range(10)]
+
+        s = mi.seekable(iterable)
+        self.assertEqual(mi.take(1, s), iterable[:1])  # Normal iteration
+
+        s.seek(20)
+        self.assertEqual(list(s), [])  # Iterable is exhausted
+
+        s.seek(0)  # Back to 0
+        self.assertEqual(list(s), iterable)  # No difference in result
+
+    def test_elements(self):
+        iterable = map(str, count())
+
+        s = mi.seekable(iterable)
+        mi.take(10, s)
+
+        elements = s.elements()
+        self.assertEqual(
+            [elements[i] for i in range(10)], [str(n) for n in range(10)]
+        )
+        self.assertEqual(len(elements), 10)
+
+        mi.take(10, s)
+        self.assertEqual(list(elements), [str(n) for n in range(20)])
+
+
+class SequenceViewTests(TestCase):
+    def test_init(self):
+        view = mi.SequenceView((1, 2, 3))
+        self.assertEqual(repr(view), "SequenceView((1, 2, 3))")
+        self.assertRaises(TypeError, lambda: mi.SequenceView({}))
+
+    def test_update(self):
+        seq = [1, 2, 3]
+        view = mi.SequenceView(seq)
+        self.assertEqual(len(view), 3)
+        self.assertEqual(repr(view), "SequenceView([1, 2, 3])")
+
+        seq.pop()
+        self.assertEqual(len(view), 2)
+        self.assertEqual(repr(view), "SequenceView([1, 2])")
+
+    def test_indexing(self):
+        seq = ('a', 'b', 'c', 'd', 'e', 'f')
+        view = mi.SequenceView(seq)
+        for i in range(-len(seq), len(seq)):
+            self.assertEqual(view[i], seq[i])
+
+    def test_slicing(self):
+        seq = ('a', 'b', 'c', 'd', 'e', 'f')
+        view = mi.SequenceView(seq)
+        n = len(seq)
+        indexes = list(range(-n - 1, n + 1)) + [None]
+        steps = list(range(-n, n + 1))
+        steps.remove(0)
+        for slice_args in product(indexes, indexes, steps):
+            i = slice(*slice_args)
+            self.assertEqual(view[i], seq[i])
+
+    def test_abc_methods(self):
+        # collections.Sequence should provide all of this functionality
+        seq = ('a', 'b', 'c', 'd', 'e', 'f', 'f')
+        view = mi.SequenceView(seq)
+
+        # __contains__
+        self.assertIn('b', view)
+        self.assertNotIn('g', view)
+
+        # __iter__
+        self.assertEqual(list(iter(view)), list(seq))
+
+        # __reversed__
+        self.assertEqual(list(reversed(view)), list(reversed(seq)))
+
+        # index
+        self.assertEqual(view.index('b'), 1)
+
+        # count
+        self.assertEqual(seq.count('f'), 2)
+
+
+class RunLengthTest(TestCase):
+    def test_encode(self):
+        iterable = (int(str(n)[0]) for n in count(800))
+        actual = mi.take(4, mi.run_length.encode(iterable))
+        expected = [(8, 100), (9, 100), (1, 1000), (2, 1000)]
+        self.assertEqual(actual, expected)
+
+    def test_decode(self):
+        iterable = [('d', 4), ('c', 3), ('b', 2), ('a', 1)]
+        actual = ''.join(mi.run_length.decode(iterable))
+        expected = 'ddddcccbba'
+        self.assertEqual(actual, expected)
+
+
+class ExactlyNTests(TestCase):
+    """Tests for ``exactly_n()``"""
+
+    def test_true(self):
+        """Iterable has ``n`` ``True`` elements"""
+        self.assertTrue(mi.exactly_n([True, False, True], 2))
+        self.assertTrue(mi.exactly_n([1, 1, 1, 0], 3))
+        self.assertTrue(mi.exactly_n([False, False], 0))
+        self.assertTrue(mi.exactly_n(range(100), 10, lambda x: x < 10))
+
+    def test_false(self):
+        """Iterable does not have ``n`` ``True`` elements"""
+        self.assertFalse(mi.exactly_n([True, False, False], 2))
+        self.assertFalse(mi.exactly_n([True, True, False], 1))
+        self.assertFalse(mi.exactly_n([False], 1))
+        self.assertFalse(mi.exactly_n([True], -1))
+        self.assertFalse(mi.exactly_n(repeat(True), 100))
+
+    def test_empty(self):
+        """Return ``True`` if the iterable is empty and ``n`` is 0"""
+        self.assertTrue(mi.exactly_n([], 0))
+        self.assertFalse(mi.exactly_n([], 1))
+
+
+class AlwaysReversibleTests(TestCase):
+    """Tests for ``always_reversible()``"""
+
+    def test_regular_reversed(self):
+        self.assertEqual(list(reversed(range(10))),
+                         list(mi.always_reversible(range(10))))
+        self.assertEqual(list(reversed([1, 2, 3])),
+                         list(mi.always_reversible([1, 2, 3])))
+        self.assertEqual(reversed([1, 2, 3]).__class__,
+                         mi.always_reversible([1, 2, 3]).__class__)
+
+    def test_nonseq_reversed(self):
+        # Create a non-reversible generator from a sequence
+        with self.assertRaises(TypeError):
+            reversed(x for x in range(10))
+
+        self.assertEqual(list(reversed(range(10))),
+                         list(mi.always_reversible(x for x in range(10))))
+        self.assertEqual(list(reversed([1, 2, 3])),
+                         list(mi.always_reversible(x for x in [1, 2, 3])))
+        self.assertNotEqual(reversed((1, 2)).__class__,
+                            mi.always_reversible(x for x in (1, 2)).__class__)
+
+
+class CircularShiftsTests(TestCase):
+    def test_empty(self):
+        # empty iterable -> empty list
+        self.assertEqual(list(mi.circular_shifts([])), [])
+
+    def test_simple_circular_shifts(self):
+        # test the a simple iterator case
+        self.assertEqual(
+            mi.circular_shifts(range(4)),
+            [(0, 1, 2, 3), (1, 2, 3, 0), (2, 3, 0, 1), (3, 0, 1, 2)]
+        )
+
+    def test_duplicates(self):
+        # test non-distinct entries
+        self.assertEqual(
+            mi.circular_shifts([0, 1, 0, 1]),
+            [(0, 1, 0, 1), (1, 0, 1, 0), (0, 1, 0, 1), (1, 0, 1, 0)]
+        )
+
+
+class MakeDecoratorTests(TestCase):
+    def test_basic(self):
+        slicer = mi.make_decorator(islice)
+
+        @slicer(1, 10, 2)
+        def user_function(arg_1, arg_2, kwarg_1=None):
+            self.assertEqual(arg_1, 'arg_1')
+            self.assertEqual(arg_2, 'arg_2')
+            self.assertEqual(kwarg_1, 'kwarg_1')
+            return map(str, count())
+
+        it = user_function('arg_1', 'arg_2', kwarg_1='kwarg_1')
+        actual = list(it)
+        expected = ['1', '3', '5', '7', '9']
+        self.assertEqual(actual, expected)
+
+    def test_result_index(self):
+        def stringify(*args, **kwargs):
+            self.assertEqual(args[0], 'arg_0')
+            iterable = args[1]
+            self.assertEqual(args[2], 'arg_2')
+            self.assertEqual(kwargs['kwarg_1'], 'kwarg_1')
+            return map(str, iterable)
+
+        stringifier = mi.make_decorator(stringify, result_index=1)
+
+        @stringifier('arg_0', 'arg_2', kwarg_1='kwarg_1')
+        def user_function(n):
+            return count(n)
+
+        it = user_function(1)
+        actual = mi.take(5, it)
+        expected = ['1', '2', '3', '4', '5']
+        self.assertEqual(actual, expected)
+
+    def test_wrap_class(self):
+        seeker = mi.make_decorator(mi.seekable)
+
+        @seeker()
+        def user_function(n):
+            return map(str, range(n))
+
+        it = user_function(5)
+        self.assertEqual(list(it), ['0', '1', '2', '3', '4'])
+
+        it.seek(0)
+        self.assertEqual(list(it), ['0', '1', '2', '3', '4'])
+
+
+class MapReduceTests(TestCase):
+    def test_default(self):
+        iterable = (str(x) for x in range(5))
+        keyfunc = lambda x: int(x) // 2
+        actual = sorted(mi.map_reduce(iterable, keyfunc).items())
+        expected = [(0, ['0', '1']), (1, ['2', '3']), (2, ['4'])]
+        self.assertEqual(actual, expected)
+
+    def test_valuefunc(self):
+        iterable = (str(x) for x in range(5))
+        keyfunc = lambda x: int(x) // 2
+        valuefunc = int
+        actual = sorted(mi.map_reduce(iterable, keyfunc, valuefunc).items())
+        expected = [(0, [0, 1]), (1, [2, 3]), (2, [4])]
+        self.assertEqual(actual, expected)
+
+    def test_reducefunc(self):
+        iterable = (str(x) for x in range(5))
+        keyfunc = lambda x: int(x) // 2
+        valuefunc = int
+        reducefunc = lambda value_list: reduce(mul, value_list, 1)
+        actual = sorted(
+            mi.map_reduce(iterable, keyfunc, valuefunc, reducefunc).items()
+        )
+        expected = [(0, 0), (1, 6), (2, 4)]
+        self.assertEqual(actual, expected)
+
+    def test_ret(self):
+        d = mi.map_reduce([1, 0, 2, 0, 1, 0], bool)
+        self.assertEqual(d, {False: [0, 0, 0], True: [1, 2, 1]})
+        self.assertRaises(KeyError, lambda: d[None].append(1))
+
+
+class RlocateTests(TestCase):
+    def test_default_pred(self):
+        iterable = [0, 1, 1, 0, 1, 0, 0]
+        for it in (iterable[:], iter(iterable)):
+            actual = list(mi.rlocate(it))
+            expected = [4, 2, 1]
+            self.assertEqual(actual, expected)
+
+    def test_no_matches(self):
+        iterable = [0, 0, 0]
+        for it in (iterable[:], iter(iterable)):
+            actual = list(mi.rlocate(it))
+            expected = []
+            self.assertEqual(actual, expected)
+
+    def test_custom_pred(self):
+        iterable = ['0', 1, 1, '0', 1, '0', '0']
+        pred = lambda x: x == '0'
+        for it in (iterable[:], iter(iterable)):
+            actual = list(mi.rlocate(it, pred))
+            expected = [6, 5, 3, 0]
+            self.assertEqual(actual, expected)
+
+    def test_efficient_reversal(self):
+        iterable = range(10 ** 10)  # Is efficiently reversible
+        target = 10 ** 10 - 2
+        pred = lambda x: x == target  # Find-able from the right
+        actual = next(mi.rlocate(iterable, pred))
+        self.assertEqual(actual, target)
+
+    def test_window_size(self):
+        iterable = ['0', 1, 1, '0', 1, '0', '0']
+        pred = lambda *args: args == ('0', 1)
+        for it in (iterable, iter(iterable)):
+            actual = list(mi.rlocate(it, pred, window_size=2))
+            expected = [3, 0]
+            self.assertEqual(actual, expected)
+
+    def test_window_size_large(self):
+        iterable = [1, 2, 3, 4]
+        pred = lambda a, b, c, d, e: True
+        for it in (iterable, iter(iterable)):
+            actual = list(mi.rlocate(iterable, pred, window_size=5))
+            expected = [0]
+            self.assertEqual(actual, expected)
+
+    def test_window_size_zero(self):
+        iterable = [1, 2, 3, 4]
+        pred = lambda: True
+        for it in (iterable, iter(iterable)):
+            with self.assertRaises(ValueError):
+                list(mi.locate(iterable, pred, window_size=0))
+
+
+class ReplaceTests(TestCase):
+    def test_basic(self):
+        iterable = range(10)
+        pred = lambda x: x % 2 == 0
+        substitutes = []
+        actual = list(mi.replace(iterable, pred, substitutes))
+        expected = [1, 3, 5, 7, 9]
+        self.assertEqual(actual, expected)
+
+    def test_count(self):
+        iterable = range(10)
+        pred = lambda x: x % 2 == 0
+        substitutes = []
+        actual = list(mi.replace(iterable, pred, substitutes, count=4))
+        expected = [1, 3, 5, 7, 8, 9]
+        self.assertEqual(actual, expected)
+
+    def test_window_size(self):
+        iterable = range(10)
+        pred = lambda *args: args == (0, 1, 2)
+        substitutes = []
+        actual = list(mi.replace(iterable, pred, substitutes, window_size=3))
+        expected = [3, 4, 5, 6, 7, 8, 9]
+        self.assertEqual(actual, expected)
+
+    def test_window_size_end(self):
+        iterable = range(10)
+        pred = lambda *args: args == (7, 8, 9)
+        substitutes = []
+        actual = list(mi.replace(iterable, pred, substitutes, window_size=3))
+        expected = [0, 1, 2, 3, 4, 5, 6]
+        self.assertEqual(actual, expected)
+
+    def test_window_size_count(self):
+        iterable = range(10)
+        pred = lambda *args: (args == (0, 1, 2)) or (args == (7, 8, 9))
+        substitutes = []
+        actual = list(
+            mi.replace(iterable, pred, substitutes, count=1, window_size=3)
+        )
+        expected = [3, 4, 5, 6, 7, 8, 9]
+        self.assertEqual(actual, expected)
+
+    def test_window_size_large(self):
+        iterable = range(4)
+        pred = lambda a, b, c, d, e: True
+        substitutes = [5, 6, 7]
+        actual = list(mi.replace(iterable, pred, substitutes, window_size=5))
+        expected = [5, 6, 7]
+        self.assertEqual(actual, expected)
+
+    def test_window_size_zero(self):
+        iterable = range(10)
+        pred = lambda *args: True
+        substitutes = []
+        with self.assertRaises(ValueError):
+            list(mi.replace(iterable, pred, substitutes, window_size=0))
+
+    def test_iterable_substitutes(self):
+        iterable = range(5)
+        pred = lambda x: x % 2 == 0
+        substitutes = iter('__')
+        actual = list(mi.replace(iterable, pred, substitutes))
+        expected = ['_', '_', 1, '_', '_', 3, '_', '_']
+        self.assertEqual(actual, expected)
Index: Chapter1/Permutation.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/Permutation.py	(date 1543190977256)
+++ Chapter1/Permutation.py	(date 1543190977256)
@@ -0,0 +1,15 @@
+def is_perm(input1: str, input2: str) -> bool:
+    d1 = dict()
+    d2 = dict()
+
+    for c in list(input1.lower()):
+        d1[c] = d1[c] + 1 if c in d1 else 1
+
+    for c in list(input2.lower()):
+        d2[c] = d2[c] + 1 if c in d2 else 1
+
+    for k, v in d1.items():
+        if k not in d2 or d2[k] != v:
+            return False
+
+    return True
Index: Chapter1/tests/test_is_perm.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_is_perm.py	(date 1543190977264)
+++ Chapter1/tests/test_is_perm.py	(date 1543190977264)
@@ -0,0 +1,7 @@
+from Chapter1.Permutation import is_perm
+
+
+def test_is_perm():
+    assert is_perm('Peter', 'repet')
+    assert is_perm('bat', 'tab')
+    assert not is_perm('car', 'bar')
Index: Chapter1/Urlify.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/Urlify.py	(date 1543190977282)
+++ Chapter1/Urlify.py	(date 1543190977282)
@@ -0,0 +1,8 @@
+def urlify(input: str) -> str:
+    arr = []
+    for c in list(input.strip()):
+        if len(c.strip()) == 0:
+            arr.append('%20')
+        else:
+            arr.append(c)
+    return "".join(arr)
Index: Chapter1/tests/test_urlify.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_urlify.py	(date 1543190977294)
+++ Chapter1/tests/test_urlify.py	(date 1543190977294)
@@ -0,0 +1,5 @@
+from Chapter1.Urlify import urlify
+
+
+def test_urlify():
+    assert urlify("Mr John Smith     ") == r"Mr%20John%20Smith"
Index: Chapter1/Palindrome.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/Palindrome.py	(date 1543190977304)
+++ Chapter1/Palindrome.py	(date 1543190977304)
@@ -0,0 +1,13 @@
+def is_palindrome_perm(text: str) -> bool:
+    d = dict()
+
+    for i in list(text):
+        d[i] = d[i] + 1 if i in d else 1
+
+    odd_count = 0
+
+    for k, v in d.items():
+        if len(k) > 0 and v % 2 != 0:
+            odd_count += 1
+
+    return odd_count > 1
Index: Chapter1/tests/test_palindrome.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_palindrome.py	(date 1543190977314)
+++ Chapter1/tests/test_palindrome.py	(date 1543190977314)
@@ -0,0 +1,6 @@
+from Chapter1.Palindrome import is_palindrome_perm
+
+
+def test_is_palindrome_perm():
+    assert is_palindrome_perm("tact coa")
+    assert is_palindrome_perm("coa tact")
Index: Chapter1/tests/test_string_compression.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_string_compression.py	(date 1543190977324)
+++ Chapter1/tests/test_string_compression.py	(date 1543190977324)
@@ -0,0 +1,9 @@
+from Chapter1.StringCompression import compress_string
+
+
+def test_compress_string():
+    assert compress_string("aabcccccaaa") == "a2b1c5a3"
+
+
+def test_compress_string_no_compress():
+    assert compress_string("abc") == "abc"
Index: Chapter1/RotateMatrix.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/RotateMatrix.py	(date 1543190975296)
+++ Chapter1/RotateMatrix.py	(date 1543190975296)
@@ -0,0 +1,6 @@
+from typing import List
+
+
+def rotate_matrix(arr: List[List[int]]) -> List[List[int]]:
+    # (0,0), (0,1), (1,0), (1,1)
+    pass
Index: Chapter1/SetToZero.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/SetToZero.py	(date 1543190975312)
+++ Chapter1/SetToZero.py	(date 1543190975312)
@@ -0,0 +1,24 @@
+from typing import List
+
+
+def set_to_zero(input_array: List[int]) -> List[int]:
+    copy = input_array[:]
+    row = []
+    col = []
+
+    for r in enumerate(input_array):
+        print(f"r:{r}")
+        for c in enumerate(r[-1]):
+            print(f"c:{c}")
+            if c[-1] == 0:
+                if r[0] not in row:
+                    row.append(r[0])
+                if c[0] not in col:
+                    col.append(c[0])
+
+    for r in enumerate(copy):
+        for c in enumerate(r[-1]):
+            if r[0] in row or c[0] in col:
+                copy[r[0]][c[0]] = 0
+
+    return copy
Index: Chapter1/tests/test_set_to_zero.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_set_to_zero.py	(date 1543190975321)
+++ Chapter1/tests/test_set_to_zero.py	(date 1543190975321)
@@ -0,0 +1,7 @@
+from Chapter1.SetToZero import set_to_zero
+
+
+def test_set_to_zero():
+    arr = [[0, 1, 1], [1, 1, 1], [1, 1, 0]]
+    result = [[0, 0, 0], [0, 1, 0], [0, 0, 0]]
+    assert set_to_zero(arr) == result
Index: Chapter1/StringRotation.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/StringRotation.py	(date 1543190975333)
+++ Chapter1/StringRotation.py	(date 1543190975333)
@@ -0,0 +1,6 @@
+def is_rotation(input1, input2):
+    d = []
+    for i in range(1, len(input1)):
+        d.append(input1[-i:] + input1[0:-i])
+
+    return input2 in d
Index: Chapter1/tests/test_string_rotation.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Chapter1/tests/test_string_rotation.py	(date 1543190975343)
+++ Chapter1/tests/test_string_rotation.py	(date 1543190975343)
@@ -0,0 +1,5 @@
+from Chapter1.StringRotation import is_rotation
+
+
+def test_is_string_rotation():
+    assert is_rotation("waterbottle", "erbottlewat")
Index: venv/Lib/site-packages/more_itertools/tests/test_recipes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools/tests/test_recipes.py	(date 1543190975357)
+++ venv/Lib/site-packages/more_itertools/tests/test_recipes.py	(date 1543190975357)
@@ -0,0 +1,616 @@
+from doctest import DocTestSuite
+from unittest import TestCase
+
+from itertools import combinations
+from six.moves import range
+
+import more_itertools as mi
+
+
+def load_tests(loader, tests, ignore):
+    # Add the doctests
+    tests.addTests(DocTestSuite('more_itertools.recipes'))
+    return tests
+
+
+class AccumulateTests(TestCase):
+    """Tests for ``accumulate()``"""
+
+    def test_empty(self):
+        """Test that an empty input returns an empty output"""
+        self.assertEqual(list(mi.accumulate([])), [])
+
+    def test_default(self):
+        """Test accumulate with the default function (addition)"""
+        self.assertEqual(list(mi.accumulate([1, 2, 3])), [1, 3, 6])
+
+    def test_bogus_function(self):
+        """Test accumulate with an invalid function"""
+        with self.assertRaises(TypeError):
+            list(mi.accumulate([1, 2, 3], func=lambda x: x))
+
+    def test_custom_function(self):
+        """Test accumulate with a custom function"""
+        self.assertEqual(
+            list(mi.accumulate((1, 2, 3, 2, 1), func=max)), [1, 2, 3, 3, 3]
+        )
+
+
+class TakeTests(TestCase):
+    """Tests for ``take()``"""
+
+    def test_simple_take(self):
+        """Test basic usage"""
+        t = mi.take(5, range(10))
+        self.assertEqual(t, [0, 1, 2, 3, 4])
+
+    def test_null_take(self):
+        """Check the null case"""
+        t = mi.take(0, range(10))
+        self.assertEqual(t, [])
+
+    def test_negative_take(self):
+        """Make sure taking negative items results in a ValueError"""
+        self.assertRaises(ValueError, lambda: mi.take(-3, range(10)))
+
+    def test_take_too_much(self):
+        """Taking more than an iterator has remaining should return what the
+        iterator has remaining.
+
+        """
+        t = mi.take(10, range(5))
+        self.assertEqual(t, [0, 1, 2, 3, 4])
+
+
+class TabulateTests(TestCase):
+    """Tests for ``tabulate()``"""
+
+    def test_simple_tabulate(self):
+        """Test the happy path"""
+        t = mi.tabulate(lambda x: x)
+        f = tuple([next(t) for _ in range(3)])
+        self.assertEqual(f, (0, 1, 2))
+
+    def test_count(self):
+        """Ensure tabulate accepts specific count"""
+        t = mi.tabulate(lambda x: 2 * x, -1)
+        f = (next(t), next(t), next(t))
+        self.assertEqual(f, (-2, 0, 2))
+
+
+class TailTests(TestCase):
+    """Tests for ``tail()``"""
+
+    def test_greater(self):
+        """Length of iterable is greather than requested tail"""
+        self.assertEqual(list(mi.tail(3, 'ABCDEFG')), ['E', 'F', 'G'])
+
+    def test_equal(self):
+        """Length of iterable is equal to the requested tail"""
+        self.assertEqual(
+            list(mi.tail(7, 'ABCDEFG')), ['A', 'B', 'C', 'D', 'E', 'F', 'G']
+        )
+
+    def test_less(self):
+        """Length of iterable is less than requested tail"""
+        self.assertEqual(
+            list(mi.tail(8, 'ABCDEFG')), ['A', 'B', 'C', 'D', 'E', 'F', 'G']
+        )
+
+
+class ConsumeTests(TestCase):
+    """Tests for ``consume()``"""
+
+    def test_sanity(self):
+        """Test basic functionality"""
+        r = (x for x in range(10))
+        mi.consume(r, 3)
+        self.assertEqual(3, next(r))
+
+    def test_null_consume(self):
+        """Check the null case"""
+        r = (x for x in range(10))
+        mi.consume(r, 0)
+        self.assertEqual(0, next(r))
+
+    def test_negative_consume(self):
+        """Check that negative consumsion throws an error"""
+        r = (x for x in range(10))
+        self.assertRaises(ValueError, lambda: mi.consume(r, -1))
+
+    def test_total_consume(self):
+        """Check that iterator is totally consumed by default"""
+        r = (x for x in range(10))
+        mi.consume(r)
+        self.assertRaises(StopIteration, lambda: next(r))
+
+
+class NthTests(TestCase):
+    """Tests for ``nth()``"""
+
+    def test_basic(self):
+        """Make sure the nth item is returned"""
+        l = range(10)
+        for i, v in enumerate(l):
+            self.assertEqual(mi.nth(l, i), v)
+
+    def test_default(self):
+        """Ensure a default value is returned when nth item not found"""
+        l = range(3)
+        self.assertEqual(mi.nth(l, 100, "zebra"), "zebra")
+
+    def test_negative_item_raises(self):
+        """Ensure asking for a negative item raises an exception"""
+        self.assertRaises(ValueError, lambda: mi.nth(range(10), -3))
+
+
+class AllEqualTests(TestCase):
+    """Tests for ``all_equal()``"""
+
+    def test_true(self):
+        """Everything is equal"""
+        self.assertTrue(mi.all_equal('aaaaaa'))
+        self.assertTrue(mi.all_equal([0, 0, 0, 0]))
+
+    def test_false(self):
+        """Not everything is equal"""
+        self.assertFalse(mi.all_equal('aaaaab'))
+        self.assertFalse(mi.all_equal([0, 0, 0, 1]))
+
+    def test_tricky(self):
+        """Not everything is identical, but everything is equal"""
+        items = [1, complex(1, 0), 1.0]
+        self.assertTrue(mi.all_equal(items))
+
+    def test_empty(self):
+        """Return True if the iterable is empty"""
+        self.assertTrue(mi.all_equal(''))
+        self.assertTrue(mi.all_equal([]))
+
+    def test_one(self):
+        """Return True if the iterable is singular"""
+        self.assertTrue(mi.all_equal('0'))
+        self.assertTrue(mi.all_equal([0]))
+
+
+class QuantifyTests(TestCase):
+    """Tests for ``quantify()``"""
+
+    def test_happy_path(self):
+        """Make sure True count is returned"""
+        q = [True, False, True]
+        self.assertEqual(mi.quantify(q), 2)
+
+    def test_custom_predicate(self):
+        """Ensure non-default predicates return as expected"""
+        q = range(10)
+        self.assertEqual(mi.quantify(q, lambda x: x % 2 == 0), 5)
+
+
+class PadnoneTests(TestCase):
+    """Tests for ``padnone()``"""
+
+    def test_happy_path(self):
+        """wrapper iterator should return None indefinitely"""
+        r = range(2)
+        p = mi.padnone(r)
+        self.assertEqual([0, 1, None, None], [next(p) for _ in range(4)])
+
+
+class NcyclesTests(TestCase):
+    """Tests for ``nyclces()``"""
+
+    def test_happy_path(self):
+        """cycle a sequence three times"""
+        r = ["a", "b", "c"]
+        n = mi.ncycles(r, 3)
+        self.assertEqual(
+            ["a", "b", "c", "a", "b", "c", "a", "b", "c"],
+            list(n)
+        )
+
+    def test_null_case(self):
+        """asking for 0 cycles should return an empty iterator"""
+        n = mi.ncycles(range(100), 0)
+        self.assertRaises(StopIteration, lambda: next(n))
+
+    def test_pathalogical_case(self):
+        """asking for negative cycles should return an empty iterator"""
+        n = mi.ncycles(range(100), -10)
+        self.assertRaises(StopIteration, lambda: next(n))
+
+
+class DotproductTests(TestCase):
+    """Tests for ``dotproduct()``'"""
+
+    def test_happy_path(self):
+        """simple dotproduct example"""
+        self.assertEqual(400, mi.dotproduct([10, 10], [20, 20]))
+
+
+class FlattenTests(TestCase):
+    """Tests for ``flatten()``"""
+
+    def test_basic_usage(self):
+        """ensure list of lists is flattened one level"""
+        f = [[0, 1, 2], [3, 4, 5]]
+        self.assertEqual(list(range(6)), list(mi.flatten(f)))
+
+    def test_single_level(self):
+        """ensure list of lists is flattened only one level"""
+        f = [[0, [1, 2]], [[3, 4], 5]]
+        self.assertEqual([0, [1, 2], [3, 4], 5], list(mi.flatten(f)))
+
+
+class RepeatfuncTests(TestCase):
+    """Tests for ``repeatfunc()``"""
+
+    def test_simple_repeat(self):
+        """test simple repeated functions"""
+        r = mi.repeatfunc(lambda: 5)
+        self.assertEqual([5, 5, 5, 5, 5], [next(r) for _ in range(5)])
+
+    def test_finite_repeat(self):
+        """ensure limited repeat when times is provided"""
+        r = mi.repeatfunc(lambda: 5, times=5)
+        self.assertEqual([5, 5, 5, 5, 5], list(r))
+
+    def test_added_arguments(self):
+        """ensure arguments are applied to the function"""
+        r = mi.repeatfunc(lambda x: x, 2, 3)
+        self.assertEqual([3, 3], list(r))
+
+    def test_null_times(self):
+        """repeat 0 should return an empty iterator"""
+        r = mi.repeatfunc(range, 0, 3)
+        self.assertRaises(StopIteration, lambda: next(r))
+
+
+class PairwiseTests(TestCase):
+    """Tests for ``pairwise()``"""
+
+    def test_base_case(self):
+        """ensure an iterable will return pairwise"""
+        p = mi.pairwise([1, 2, 3])
+        self.assertEqual([(1, 2), (2, 3)], list(p))
+
+    def test_short_case(self):
+        """ensure an empty iterator if there's not enough values to pair"""
+        p = mi.pairwise("a")
+        self.assertRaises(StopIteration, lambda: next(p))
+
+
+class GrouperTests(TestCase):
+    """Tests for ``grouper()``"""
+
+    def test_even(self):
+        """Test when group size divides evenly into the length of
+        the iterable.
+
+        """
+        self.assertEqual(
+            list(mi.grouper(3, 'ABCDEF')), [('A', 'B', 'C'), ('D', 'E', 'F')]
+        )
+
+    def test_odd(self):
+        """Test when group size does not divide evenly into the length of the
+        iterable.
+
+        """
+        self.assertEqual(
+            list(mi.grouper(3, 'ABCDE')), [('A', 'B', 'C'), ('D', 'E', None)]
+        )
+
+    def test_fill_value(self):
+        """Test that the fill value is used to pad the final group"""
+        self.assertEqual(
+            list(mi.grouper(3, 'ABCDE', 'x')),
+            [('A', 'B', 'C'), ('D', 'E', 'x')]
+        )
+
+
+class RoundrobinTests(TestCase):
+    """Tests for ``roundrobin()``"""
+
+    def test_even_groups(self):
+        """Ensure ordered output from evenly populated iterables"""
+        self.assertEqual(
+            list(mi.roundrobin('ABC', [1, 2, 3], range(3))),
+            ['A', 1, 0, 'B', 2, 1, 'C', 3, 2]
+        )
+
+    def test_uneven_groups(self):
+        """Ensure ordered output from unevenly populated iterables"""
+        self.assertEqual(
+            list(mi.roundrobin('ABCD', [1, 2], range(0))),
+            ['A', 1, 'B', 2, 'C', 'D']
+        )
+
+
+class PartitionTests(TestCase):
+    """Tests for ``partition()``"""
+
+    def test_bool(self):
+        """Test when pred() returns a boolean"""
+        lesser, greater = mi.partition(lambda x: x > 5, range(10))
+        self.assertEqual(list(lesser), [0, 1, 2, 3, 4, 5])
+        self.assertEqual(list(greater), [6, 7, 8, 9])
+
+    def test_arbitrary(self):
+        """Test when pred() returns an integer"""
+        divisibles, remainders = mi.partition(lambda x: x % 3, range(10))
+        self.assertEqual(list(divisibles), [0, 3, 6, 9])
+        self.assertEqual(list(remainders), [1, 2, 4, 5, 7, 8])
+
+
+class PowersetTests(TestCase):
+    """Tests for ``powerset()``"""
+
+    def test_combinatorics(self):
+        """Ensure a proper enumeration"""
+        p = mi.powerset([1, 2, 3])
+        self.assertEqual(
+            list(p),
+            [(), (1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]
+        )
+
+
+class UniqueEverseenTests(TestCase):
+    """Tests for ``unique_everseen()``"""
+
+    def test_everseen(self):
+        """ensure duplicate elements are ignored"""
+        u = mi.unique_everseen('AAAABBBBCCDAABBB')
+        self.assertEqual(
+            ['A', 'B', 'C', 'D'],
+            list(u)
+        )
+
+    def test_custom_key(self):
+        """ensure the custom key comparison works"""
+        u = mi.unique_everseen('aAbACCc', key=str.lower)
+        self.assertEqual(list('abC'), list(u))
+
+    def test_unhashable(self):
+        """ensure things work for unhashable items"""
+        iterable = ['a', [1, 2, 3], [1, 2, 3], 'a']
+        u = mi.unique_everseen(iterable)
+        self.assertEqual(list(u), ['a', [1, 2, 3]])
+
+    def test_unhashable_key(self):
+        """ensure things work for unhashable items with a custom key"""
+        iterable = ['a', [1, 2, 3], [1, 2, 3], 'a']
+        u = mi.unique_everseen(iterable, key=lambda x: x)
+        self.assertEqual(list(u), ['a', [1, 2, 3]])
+
+
+class UniqueJustseenTests(TestCase):
+    """Tests for ``unique_justseen()``"""
+
+    def test_justseen(self):
+        """ensure only last item is remembered"""
+        u = mi.unique_justseen('AAAABBBCCDABB')
+        self.assertEqual(list('ABCDAB'), list(u))
+
+    def test_custom_key(self):
+        """ensure the custom key comparison works"""
+        u = mi.unique_justseen('AABCcAD', str.lower)
+        self.assertEqual(list('ABCAD'), list(u))
+
+
+class IterExceptTests(TestCase):
+    """Tests for ``iter_except()``"""
+
+    def test_exact_exception(self):
+        """ensure the exact specified exception is caught"""
+        l = [1, 2, 3]
+        i = mi.iter_except(l.pop, IndexError)
+        self.assertEqual(list(i), [3, 2, 1])
+
+    def test_generic_exception(self):
+        """ensure the generic exception can be caught"""
+        l = [1, 2]
+        i = mi.iter_except(l.pop, Exception)
+        self.assertEqual(list(i), [2, 1])
+
+    def test_uncaught_exception_is_raised(self):
+        """ensure a non-specified exception is raised"""
+        l = [1, 2, 3]
+        i = mi.iter_except(l.pop, KeyError)
+        self.assertRaises(IndexError, lambda: list(i))
+
+    def test_first(self):
+        """ensure first is run before the function"""
+        l = [1, 2, 3]
+        f = lambda: 25
+        i = mi.iter_except(l.pop, IndexError, f)
+        self.assertEqual(list(i), [25, 3, 2, 1])
+
+
+class FirstTrueTests(TestCase):
+    """Tests for ``first_true()``"""
+
+    def test_something_true(self):
+        """Test with no keywords"""
+        self.assertEqual(mi.first_true(range(10)), 1)
+
+    def test_nothing_true(self):
+        """Test default return value."""
+        self.assertEqual(mi.first_true([0, 0, 0]), False)
+
+    def test_default(self):
+        """Test with a default keyword"""
+        self.assertEqual(mi.first_true([0, 0, 0], default='!'), '!')
+
+    def test_pred(self):
+        """Test with a custom predicate"""
+        self.assertEqual(
+            mi.first_true([2, 4, 6], pred=lambda x: x % 3 == 0), 6
+        )
+
+
+class RandomProductTests(TestCase):
+    """Tests for ``random_product()``
+
+    Since random.choice() has different results with the same seed across
+    python versions 2.x and 3.x, these tests use highly probably events to
+    create predictable outcomes across platforms.
+    """
+
+    def test_simple_lists(self):
+        """Ensure that one item is chosen from each list in each pair.
+        Also ensure that each item from each list eventually appears in
+        the chosen combinations.
+
+        Odds are roughly 1 in 7.1 * 10e16 that one item from either list will
+        not be chosen after 100 samplings of one item from each list. Just to
+        be safe, better use a known random seed, too.
+
+        """
+        nums = [1, 2, 3]
+        lets = ['a', 'b', 'c']
+        n, m = zip(*[mi.random_product(nums, lets) for _ in range(100)])
+        n, m = set(n), set(m)
+        self.assertEqual(n, set(nums))
+        self.assertEqual(m, set(lets))
+        self.assertEqual(len(n), len(nums))
+        self.assertEqual(len(m), len(lets))
+
+    def test_list_with_repeat(self):
+        """ensure multiple items are chosen, and that they appear to be chosen
+        from one list then the next, in proper order.
+
+        """
+        nums = [1, 2, 3]
+        lets = ['a', 'b', 'c']
+        r = list(mi.random_product(nums, lets, repeat=100))
+        self.assertEqual(2 * 100, len(r))
+        n, m = set(r[::2]), set(r[1::2])
+        self.assertEqual(n, set(nums))
+        self.assertEqual(m, set(lets))
+        self.assertEqual(len(n), len(nums))
+        self.assertEqual(len(m), len(lets))
+
+
+class RandomPermutationTests(TestCase):
+    """Tests for ``random_permutation()``"""
+
+    def test_full_permutation(self):
+        """ensure every item from the iterable is returned in a new ordering
+
+        15 elements have a 1 in 1.3 * 10e12 of appearing in sorted order, so
+        we fix a seed value just to be sure.
+
+        """
+        i = range(15)
+        r = mi.random_permutation(i)
+        self.assertEqual(set(i), set(r))
+        if i == r:
+            raise AssertionError("Values were not permuted")
+
+    def test_partial_permutation(self):
+        """ensure all returned items are from the iterable, that the returned
+        permutation is of the desired length, and that all items eventually
+        get returned.
+
+        Sampling 100 permutations of length 5 from a set of 15 leaves a
+        (2/3)^100 chance that an item will not be chosen. Multiplied by 15
+        items, there is a 1 in 2.6e16 chance that at least 1 item will not
+        show up in the resulting output. Using a random seed will fix that.
+
+        """
+        items = range(15)
+        item_set = set(items)
+        all_items = set()
+        for _ in range(100):
+            permutation = mi.random_permutation(items, 5)
+            self.assertEqual(len(permutation), 5)
+            permutation_set = set(permutation)
+            self.assertLessEqual(permutation_set, item_set)
+            all_items |= permutation_set
+        self.assertEqual(all_items, item_set)
+
+
+class RandomCombinationTests(TestCase):
+    """Tests for ``random_combination()``"""
+
+    def test_psuedorandomness(self):
+        """ensure different subsets of the iterable get returned over many
+        samplings of random combinations"""
+        items = range(15)
+        all_items = set()
+        for _ in range(50):
+            combination = mi.random_combination(items, 5)
+            all_items |= set(combination)
+        self.assertEqual(all_items, set(items))
+
+    def test_no_replacement(self):
+        """ensure that elements are sampled without replacement"""
+        items = range(15)
+        for _ in range(50):
+            combination = mi.random_combination(items, len(items))
+            self.assertEqual(len(combination), len(set(combination)))
+        self.assertRaises(
+            ValueError, lambda: mi.random_combination(items, len(items) + 1)
+        )
+
+
+class RandomCombinationWithReplacementTests(TestCase):
+    """Tests for ``random_combination_with_replacement()``"""
+
+    def test_replacement(self):
+        """ensure that elements are sampled with replacement"""
+        items = range(5)
+        combo = mi.random_combination_with_replacement(items, len(items) * 2)
+        self.assertEqual(2 * len(items), len(combo))
+        if len(set(combo)) == len(combo):
+            raise AssertionError("Combination contained no duplicates")
+
+    def test_pseudorandomness(self):
+        """ensure different subsets of the iterable get returned over many
+        samplings of random combinations"""
+        items = range(15)
+        all_items = set()
+        for _ in range(50):
+            combination = mi.random_combination_with_replacement(items, 5)
+            all_items |= set(combination)
+        self.assertEqual(all_items, set(items))
+
+
+class NthCombinationTests(TestCase):
+    def test_basic(self):
+        iterable = 'abcdefg'
+        r = 4
+        for index, expected in enumerate(combinations(iterable, r)):
+            actual = mi.nth_combination(iterable, r, index)
+            self.assertEqual(actual, expected)
+
+    def test_long(self):
+        actual = mi.nth_combination(range(180), 4, 2000000)
+        expected = (2, 12, 35, 126)
+        self.assertEqual(actual, expected)
+
+    def test_invalid_r(self):
+        for r in (-1, 3):
+            with self.assertRaises(ValueError):
+                mi.nth_combination([], r, 0)
+
+    def test_invalid_index(self):
+        with self.assertRaises(IndexError):
+            mi.nth_combination('abcdefg', 3, -36)
+
+
+class PrependTests(TestCase):
+    def test_basic(self):
+        value = 'a'
+        iterator = iter('bcdefg')
+        actual = list(mi.prepend(value, iterator))
+        expected = list('abcdefg')
+        self.assertEqual(actual, expected)
+
+    def test_multiple(self):
+        value = 'ab'
+        iterator = iter('cdefg')
+        actual = tuple(mi.prepend(value, iterator))
+        expected = ('ab',) + tuple('cdefg')
+        self.assertEqual(actual, expected)
Index: venv/Lib/site-packages/more_itertools/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools/__init__.py	(date 1543190975367)
+++ venv/Lib/site-packages/more_itertools/__init__.py	(date 1543190975367)
@@ -0,0 +1,2 @@
+from more_itertools.more import *  # noqa
+from more_itertools.recipes import *  # noqa
Index: venv/Lib/site-packages/more_itertools/recipes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools/recipes.py	(date 1543190975380)
+++ venv/Lib/site-packages/more_itertools/recipes.py	(date 1543190975380)
@@ -0,0 +1,565 @@
+"""Imported from the recipes section of the itertools documentation.
+
+All functions taken from the recipes section of the itertools library docs
+[1]_.
+Some backward-compatible usability improvements have been made.
+
+.. [1] http://docs.python.org/library/itertools.html#recipes
+
+"""
+from collections import deque
+from itertools import (
+    chain, combinations, count, cycle, groupby, islice, repeat, starmap, tee
+)
+import operator
+from random import randrange, sample, choice
+
+from six import PY2
+from six.moves import filter, filterfalse, map, range, zip, zip_longest
+
+__all__ = [
+    'accumulate',
+    'all_equal',
+    'consume',
+    'dotproduct',
+    'first_true',
+    'flatten',
+    'grouper',
+    'iter_except',
+    'ncycles',
+    'nth',
+    'nth_combination',
+    'padnone',
+    'pairwise',
+    'partition',
+    'powerset',
+    'prepend',
+    'quantify',
+    'random_combination_with_replacement',
+    'random_combination',
+    'random_permutation',
+    'random_product',
+    'repeatfunc',
+    'roundrobin',
+    'tabulate',
+    'tail',
+    'take',
+    'unique_everseen',
+    'unique_justseen',
+]
+
+
+def accumulate(iterable, func=operator.add):
+    """
+    Return an iterator whose items are the accumulated results of a function
+    (specified by the optional *func* argument) that takes two arguments.
+    By default, returns accumulated sums with :func:`operator.add`.
+
+        >>> list(accumulate([1, 2, 3, 4, 5]))  # Running sum
+        [1, 3, 6, 10, 15]
+        >>> list(accumulate([1, 2, 3], func=operator.mul))  # Running product
+        [1, 2, 6]
+        >>> list(accumulate([0, 1, -1, 2, 3, 2], func=max))  # Running maximum
+        [0, 1, 1, 2, 3, 3]
+
+    This function is available in the ``itertools`` module for Python 3.2 and
+    greater.
+
+    """
+    it = iter(iterable)
+    try:
+        total = next(it)
+    except StopIteration:
+        return
+    else:
+        yield total
+
+    for element in it:
+        total = func(total, element)
+        yield total
+
+
+def take(n, iterable):
+    """Return first *n* items of the iterable as a list.
+
+        >>> take(3, range(10))
+        [0, 1, 2]
+        >>> take(5, range(3))
+        [0, 1, 2]
+
+    Effectively a short replacement for ``next`` based iterator consumption
+    when you want more than one item, but less than the whole iterator.
+
+    """
+    return list(islice(iterable, n))
+
+
+def tabulate(function, start=0):
+    """Return an iterator over the results of ``func(start)``,
+    ``func(start + 1)``, ``func(start + 2)``...
+
+    *func* should be a function that accepts one integer argument.
+
+    If *start* is not specified it defaults to 0. It will be incremented each
+    time the iterator is advanced.
+
+        >>> square = lambda x: x ** 2
+        >>> iterator = tabulate(square, -3)
+        >>> take(4, iterator)
+        [9, 4, 1, 0]
+
+    """
+    return map(function, count(start))
+
+
+def tail(n, iterable):
+    """Return an iterator over the last *n* items of *iterable*.
+
+        >>> t = tail(3, 'ABCDEFG')
+        >>> list(t)
+        ['E', 'F', 'G']
+
+    """
+    return iter(deque(iterable, maxlen=n))
+
+
+def consume(iterator, n=None):
+    """Advance *iterable* by *n* steps. If *n* is ``None``, consume it
+    entirely.
+
+    Efficiently exhausts an iterator without returning values. Defaults to
+    consuming the whole iterator, but an optional second argument may be
+    provided to limit consumption.
+
+        >>> i = (x for x in range(10))
+        >>> next(i)
+        0
+        >>> consume(i, 3)
+        >>> next(i)
+        4
+        >>> consume(i)
+        >>> next(i)
+        Traceback (most recent call last):
+          File "<stdin>", line 1, in <module>
+        StopIteration
+
+    If the iterator has fewer items remaining than the provided limit, the
+    whole iterator will be consumed.
+
+        >>> i = (x for x in range(3))
+        >>> consume(i, 5)
+        >>> next(i)
+        Traceback (most recent call last):
+          File "<stdin>", line 1, in <module>
+        StopIteration
+
+    """
+    # Use functions that consume iterators at C speed.
+    if n is None:
+        # feed the entire iterator into a zero-length deque
+        deque(iterator, maxlen=0)
+    else:
+        # advance to the empty slice starting at position n
+        next(islice(iterator, n, n), None)
+
+
+def nth(iterable, n, default=None):
+    """Returns the nth item or a default value.
+
+        >>> l = range(10)
+        >>> nth(l, 3)
+        3
+        >>> nth(l, 20, "zebra")
+        'zebra'
+
+    """
+    return next(islice(iterable, n, None), default)
+
+
+def all_equal(iterable):
+    """
+    Returns ``True`` if all the elements are equal to each other.
+
+        >>> all_equal('aaaa')
+        True
+        >>> all_equal('aaab')
+        False
+
+    """
+    g = groupby(iterable)
+    return next(g, True) and not next(g, False)
+
+
+def quantify(iterable, pred=bool):
+    """Return the how many times the predicate is true.
+
+        >>> quantify([True, False, True])
+        2
+
+    """
+    return sum(map(pred, iterable))
+
+
+def padnone(iterable):
+    """Returns the sequence of elements and then returns ``None`` indefinitely.
+
+        >>> take(5, padnone(range(3)))
+        [0, 1, 2, None, None]
+
+    Useful for emulating the behavior of the built-in :func:`map` function.
+
+    See also :func:`padded`.
+
+    """
+    return chain(iterable, repeat(None))
+
+
+def ncycles(iterable, n):
+    """Returns the sequence elements *n* times
+
+        >>> list(ncycles(["a", "b"], 3))
+        ['a', 'b', 'a', 'b', 'a', 'b']
+
+    """
+    return chain.from_iterable(repeat(tuple(iterable), n))
+
+
+def dotproduct(vec1, vec2):
+    """Returns the dot product of the two iterables.
+
+        >>> dotproduct([10, 10], [20, 20])
+        400
+
+    """
+    return sum(map(operator.mul, vec1, vec2))
+
+
+def flatten(listOfLists):
+    """Return an iterator flattening one level of nesting in a list of lists.
+
+        >>> list(flatten([[0, 1], [2, 3]]))
+        [0, 1, 2, 3]
+
+    See also :func:`collapse`, which can flatten multiple levels of nesting.
+
+    """
+    return chain.from_iterable(listOfLists)
+
+
+def repeatfunc(func, times=None, *args):
+    """Call *func* with *args* repeatedly, returning an iterable over the
+    results.
+
+    If *times* is specified, the iterable will terminate after that many
+    repetitions:
+
+        >>> from operator import add
+        >>> times = 4
+        >>> args = 3, 5
+        >>> list(repeatfunc(add, times, *args))
+        [8, 8, 8, 8]
+
+    If *times* is ``None`` the iterable will not terminate:
+
+        >>> from random import randrange
+        >>> times = None
+        >>> args = 1, 11
+        >>> take(6, repeatfunc(randrange, times, *args))  # doctest:+SKIP
+        [2, 4, 8, 1, 8, 4]
+
+    """
+    if times is None:
+        return starmap(func, repeat(args))
+    return starmap(func, repeat(args, times))
+
+
+def pairwise(iterable):
+    """Returns an iterator of paired items, overlapping, from the original
+
+        >>> take(4, pairwise(count()))
+        [(0, 1), (1, 2), (2, 3), (3, 4)]
+
+    """
+    a, b = tee(iterable)
+    next(b, None)
+    return zip(a, b)
+
+
+def grouper(n, iterable, fillvalue=None):
+    """Collect data into fixed-length chunks or blocks.
+
+        >>> list(grouper(3, 'ABCDEFG', 'x'))
+        [('A', 'B', 'C'), ('D', 'E', 'F'), ('G', 'x', 'x')]
+
+    """
+    args = [iter(iterable)] * n
+    return zip_longest(fillvalue=fillvalue, *args)
+
+
+def roundrobin(*iterables):
+    """Yields an item from each iterable, alternating between them.
+
+        >>> list(roundrobin('ABC', 'D', 'EF'))
+        ['A', 'D', 'E', 'B', 'F', 'C']
+
+    This function produces the same output as :func:`interleave_longest`, but
+    may perform better for some inputs (in particular when the number of
+    iterables is small).
+
+    """
+    # Recipe credited to George Sakkis
+    pending = len(iterables)
+    if PY2:
+        nexts = cycle(iter(it).next for it in iterables)
+    else:
+        nexts = cycle(iter(it).__next__ for it in iterables)
+    while pending:
+        try:
+            for next in nexts:
+                yield next()
+        except StopIteration:
+            pending -= 1
+            nexts = cycle(islice(nexts, pending))
+
+
+def partition(pred, iterable):
+    """
+    Returns a 2-tuple of iterables derived from the input iterable.
+    The first yields the items that have ``pred(item) == False``.
+    The second yields the items that have ``pred(item) == True``.
+
+        >>> is_odd = lambda x: x % 2 != 0
+        >>> iterable = range(10)
+        >>> even_items, odd_items = partition(is_odd, iterable)
+        >>> list(even_items), list(odd_items)
+        ([0, 2, 4, 6, 8], [1, 3, 5, 7, 9])
+
+    """
+    # partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9
+    t1, t2 = tee(iterable)
+    return filterfalse(pred, t1), filter(pred, t2)
+
+
+def powerset(iterable):
+    """Yields all possible subsets of the iterable.
+
+        >>> list(powerset([1,2,3]))
+        [(), (1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]
+
+    """
+    s = list(iterable)
+    return chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
+
+
+def unique_everseen(iterable, key=None):
+    """
+    Yield unique elements, preserving order.
+
+        >>> list(unique_everseen('AAAABBBCCDAABBB'))
+        ['A', 'B', 'C', 'D']
+        >>> list(unique_everseen('ABBCcAD', str.lower))
+        ['A', 'B', 'C', 'D']
+
+    Sequences with a mix of hashable and unhashable items can be used.
+    The function will be slower (i.e., `O(n^2)`) for unhashable items.
+
+    """
+    seenset = set()
+    seenset_add = seenset.add
+    seenlist = []
+    seenlist_add = seenlist.append
+    if key is None:
+        for element in iterable:
+            try:
+                if element not in seenset:
+                    seenset_add(element)
+                    yield element
+            except TypeError:
+                if element not in seenlist:
+                    seenlist_add(element)
+                    yield element
+    else:
+        for element in iterable:
+            k = key(element)
+            try:
+                if k not in seenset:
+                    seenset_add(k)
+                    yield element
+            except TypeError:
+                if k not in seenlist:
+                    seenlist_add(k)
+                    yield element
+
+
+def unique_justseen(iterable, key=None):
+    """Yields elements in order, ignoring serial duplicates
+
+        >>> list(unique_justseen('AAAABBBCCDAABBB'))
+        ['A', 'B', 'C', 'D', 'A', 'B']
+        >>> list(unique_justseen('ABBCcAD', str.lower))
+        ['A', 'B', 'C', 'A', 'D']
+
+    """
+    return map(next, map(operator.itemgetter(1), groupby(iterable, key)))
+
+
+def iter_except(func, exception, first=None):
+    """Yields results from a function repeatedly until an exception is raised.
+
+    Converts a call-until-exception interface to an iterator interface.
+    Like ``iter(func, sentinel)``, but uses an exception instead of a sentinel
+    to end the loop.
+
+        >>> l = [0, 1, 2]
+        >>> list(iter_except(l.pop, IndexError))
+        [2, 1, 0]
+
+    """
+    try:
+        if first is not None:
+            yield first()
+        while 1:
+            yield func()
+    except exception:
+        pass
+
+
+def first_true(iterable, default=False, pred=None):
+    """
+    Returns the first true value in the iterable.
+
+    If no true value is found, returns *default*
+
+    If *pred* is not None, returns the first item for which
+    ``pred(item) == True`` .
+
+        >>> first_true(range(10))
+        1
+        >>> first_true(range(10), pred=lambda x: x > 5)
+        6
+        >>> first_true(range(10), default='missing', pred=lambda x: x > 9)
+        'missing'
+
+    """
+    return next(filter(pred, iterable), default)
+
+
+def random_product(*args, **kwds):
+    """Draw an item at random from each of the input iterables.
+
+        >>> random_product('abc', range(4), 'XYZ')  # doctest:+SKIP
+        ('c', 3, 'Z')
+
+    If *repeat* is provided as a keyword argument, that many items will be
+    drawn from each iterable.
+
+        >>> random_product('abcd', range(4), repeat=2)  # doctest:+SKIP
+        ('a', 2, 'd', 3)
+
+    This equivalent to taking a random selection from
+    ``itertools.product(*args, **kwarg)``.
+
+    """
+    pools = [tuple(pool) for pool in args] * kwds.get('repeat', 1)
+    return tuple(choice(pool) for pool in pools)
+
+
+def random_permutation(iterable, r=None):
+    """Return a random *r* length permutation of the elements in *iterable*.
+
+    If *r* is not specified or is ``None``, then *r* defaults to the length of
+    *iterable*.
+
+        >>> random_permutation(range(5))  # doctest:+SKIP
+        (3, 4, 0, 1, 2)
+
+    This equivalent to taking a random selection from
+    ``itertools.permutations(iterable, r)``.
+
+    """
+    pool = tuple(iterable)
+    r = len(pool) if r is None else r
+    return tuple(sample(pool, r))
+
+
+def random_combination(iterable, r):
+    """Return a random *r* length subsequence of the elements in *iterable*.
+
+        >>> random_combination(range(5), 3)  # doctest:+SKIP
+        (2, 3, 4)
+
+    This equivalent to taking a random selection from
+    ``itertools.combinations(iterable, r)``.
+
+    """
+    pool = tuple(iterable)
+    n = len(pool)
+    indices = sorted(sample(range(n), r))
+    return tuple(pool[i] for i in indices)
+
+
+def random_combination_with_replacement(iterable, r):
+    """Return a random *r* length subsequence of elements in *iterable*,
+    allowing individual elements to be repeated.
+
+        >>> random_combination_with_replacement(range(3), 5) # doctest:+SKIP
+        (0, 0, 1, 2, 2)
+
+    This equivalent to taking a random selection from
+    ``itertools.combinations_with_replacement(iterable, r)``.
+
+    """
+    pool = tuple(iterable)
+    n = len(pool)
+    indices = sorted(randrange(n) for i in range(r))
+    return tuple(pool[i] for i in indices)
+
+
+def nth_combination(iterable, r, index):
+    """Equivalent to ``list(combinations(iterable, r))[index]``.
+
+    The subsequences of *iterable* that are of length *r* can be ordered
+    lexicographically. :func:`nth_combination` computes the subsequence at
+    sort position *index* directly, without computing the previous
+    subsequences.
+
+    """
+    pool = tuple(iterable)
+    n = len(pool)
+    if (r < 0) or (r > n):
+        raise ValueError
+
+    c = 1
+    k = min(r, n - r)
+    for i in range(1, k + 1):
+        c = c * (n - k + i) // i
+
+    if index < 0:
+        index += c
+
+    if (index < 0) or (index >= c):
+        raise IndexError
+
+    result = []
+    while r:
+        c, n, r = c * r // n, n - 1, r - 1
+        while index >= c:
+            index -= c
+            c, n = c * (n - r) // n, n - 1
+        result.append(pool[-1 - n])
+
+    return tuple(result)
+
+
+def prepend(value, iterator):
+    """Yield *value*, followed by the elements in *iterator*.
+
+        >>> value = '0'
+        >>> iterator = ['1', '2', '3']
+        >>> list(prepend(value, iterator))
+        ['0', '1', '2', '3']
+
+    To prepend multiple values, see :func:`itertools.chain`.
+
+    """
+    return chain([value], iterator)
Index: venv/Lib/site-packages/six-1.11.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six-1.11.0.dist-info/top_level.txt	(date 1543190975389)
+++ venv/Lib/site-packages/six-1.11.0.dist-info/top_level.txt	(date 1543190975389)
@@ -0,0 +1,1 @@
+six
Index: venv/Lib/site-packages/more_itertools/more.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools/more.py	(date 1543190975418)
+++ venv/Lib/site-packages/more_itertools/more.py	(date 1543190975418)
@@ -0,0 +1,2211 @@
+from __future__ import print_function
+
+from collections import Counter, defaultdict, deque
+from functools import partial, wraps
+from heapq import merge
+from itertools import (
+    chain,
+    compress,
+    count,
+    cycle,
+    dropwhile,
+    groupby,
+    islice,
+    repeat,
+    starmap,
+    takewhile,
+    tee
+)
+from operator import itemgetter, lt, gt, sub
+from sys import maxsize, version_info
+try:
+    from collections.abc import Sequence
+except ImportError:
+    from collections import Sequence
+
+from six import binary_type, string_types, text_type
+from six.moves import filter, map, range, zip, zip_longest
+
+from .recipes import consume, flatten, take
+
+__all__ = [
+    'adjacent',
+    'always_iterable',
+    'always_reversible',
+    'bucket',
+    'chunked',
+    'circular_shifts',
+    'collapse',
+    'collate',
+    'consecutive_groups',
+    'consumer',
+    'count_cycle',
+    'difference',
+    'distinct_permutations',
+    'distribute',
+    'divide',
+    'exactly_n',
+    'first',
+    'groupby_transform',
+    'ilen',
+    'interleave_longest',
+    'interleave',
+    'intersperse',
+    'islice_extended',
+    'iterate',
+    'last',
+    'locate',
+    'lstrip',
+    'make_decorator',
+    'map_reduce',
+    'numeric_range',
+    'one',
+    'padded',
+    'peekable',
+    'replace',
+    'rlocate',
+    'rstrip',
+    'run_length',
+    'seekable',
+    'SequenceView',
+    'side_effect',
+    'sliced',
+    'sort_together',
+    'split_at',
+    'split_after',
+    'split_before',
+    'spy',
+    'stagger',
+    'strip',
+    'unique_to_each',
+    'windowed',
+    'with_iter',
+    'zip_offset',
+]
+
+_marker = object()
+
+
+def chunked(iterable, n):
+    """Break *iterable* into lists of length *n*:
+
+        >>> list(chunked([1, 2, 3, 4, 5, 6], 3))
+        [[1, 2, 3], [4, 5, 6]]
+
+    If the length of *iterable* is not evenly divisible by *n*, the last
+    returned list will be shorter:
+
+        >>> list(chunked([1, 2, 3, 4, 5, 6, 7, 8], 3))
+        [[1, 2, 3], [4, 5, 6], [7, 8]]
+
+    To use a fill-in value instead, see the :func:`grouper` recipe.
+
+    :func:`chunked` is useful for splitting up a computation on a large number
+    of keys into batches, to be pickled and sent off to worker processes. One
+    example is operations on rows in MySQL, which does not implement
+    server-side cursors properly and would otherwise load the entire dataset
+    into RAM on the client.
+
+    """
+    return iter(partial(take, n, iter(iterable)), [])
+
+
+def first(iterable, default=_marker):
+    """Return the first item of *iterable*, or *default* if *iterable* is
+    empty.
+
+        >>> first([0, 1, 2, 3])
+        0
+        >>> first([], 'some default')
+        'some default'
+
+    If *default* is not provided and there are no items in the iterable,
+    raise ``ValueError``.
+
+    :func:`first` is useful when you have a generator of expensive-to-retrieve
+    values and want any arbitrary one. It is marginally shorter than
+    ``next(iter(iterable), default)``.
+
+    """
+    try:
+        return next(iter(iterable))
+    except StopIteration:
+        # I'm on the edge about raising ValueError instead of StopIteration. At
+        # the moment, ValueError wins, because the caller could conceivably
+        # want to do something different with flow control when I raise the
+        # exception, and it's weird to explicitly catch StopIteration.
+        if default is _marker:
+            raise ValueError('first() was called on an empty iterable, and no '
+                             'default value was provided.')
+        return default
+
+
+def last(iterable, default=_marker):
+    """Return the last item of *iterable*, or *default* if *iterable* is
+    empty.
+
+        >>> last([0, 1, 2, 3])
+        3
+        >>> last([], 'some default')
+        'some default'
+
+    If *default* is not provided and there are no items in the iterable,
+    raise ``ValueError``.
+    """
+    try:
+        try:
+            # Try to access the last item directly
+            return iterable[-1]
+        except (TypeError, AttributeError, KeyError):
+            # If not slice-able, iterate entirely using length-1 deque
+            return deque(iterable, maxlen=1)[0]
+    except IndexError:  # If the iterable was empty
+        if default is _marker:
+            raise ValueError('last() was called on an empty iterable, and no '
+                             'default value was provided.')
+        return default
+
+
+class peekable(object):
+    """Wrap an iterator to allow lookahead and prepending elements.
+
+    Call :meth:`peek` on the result to get the value that will be returned
+    by :func:`next`. This won't advance the iterator:
+
+        >>> p = peekable(['a', 'b'])
+        >>> p.peek()
+        'a'
+        >>> next(p)
+        'a'
+
+    Pass :meth:`peek` a default value to return that instead of raising
+    ``StopIteration`` when the iterator is exhausted.
+
+        >>> p = peekable([])
+        >>> p.peek('hi')
+        'hi'
+
+    peekables also offer a :meth:`prepend` method, which "inserts" items
+    at the head of the iterable:
+
+        >>> p = peekable([1, 2, 3])
+        >>> p.prepend(10, 11, 12)
+        >>> next(p)
+        10
+        >>> p.peek()
+        11
+        >>> list(p)
+        [11, 12, 1, 2, 3]
+
+    peekables can be indexed. Index 0 is the item that will be returned by
+    :func:`next`, index 1 is the item after that, and so on:
+    The values up to the given index will be cached.
+
+        >>> p = peekable(['a', 'b', 'c', 'd'])
+        >>> p[0]
+        'a'
+        >>> p[1]
+        'b'
+        >>> next(p)
+        'a'
+
+    Negative indexes are supported, but be aware that they will cache the
+    remaining items in the source iterator, which may require significant
+    storage.
+
+    To check whether a peekable is exhausted, check its truth value:
+
+        >>> p = peekable(['a', 'b'])
+        >>> if p:  # peekable has items
+        ...     list(p)
+        ['a', 'b']
+        >>> if not p:  # peekable is exhaused
+        ...     list(p)
+        []
+
+    """
+    def __init__(self, iterable):
+        self._it = iter(iterable)
+        self._cache = deque()
+
+    def __iter__(self):
+        return self
+
+    def __bool__(self):
+        try:
+            self.peek()
+        except StopIteration:
+            return False
+        return True
+
+    def __nonzero__(self):
+        # For Python 2 compatibility
+        return self.__bool__()
+
+    def peek(self, default=_marker):
+        """Return the item that will be next returned from ``next()``.
+
+        Return ``default`` if there are no items left. If ``default`` is not
+        provided, raise ``StopIteration``.
+
+        """
+        if not self._cache:
+            try:
+                self._cache.append(next(self._it))
+            except StopIteration:
+                if default is _marker:
+                    raise
+                return default
+        return self._cache[0]
+
+    def prepend(self, *items):
+        """Stack up items to be the next ones returned from ``next()`` or
+        ``self.peek()``. The items will be returned in
+        first in, first out order::
+
+            >>> p = peekable([1, 2, 3])
+            >>> p.prepend(10, 11, 12)
+            >>> next(p)
+            10
+            >>> list(p)
+            [11, 12, 1, 2, 3]
+
+        It is possible, by prepending items, to "resurrect" a peekable that
+        previously raised ``StopIteration``.
+
+            >>> p = peekable([])
+            >>> next(p)
+            Traceback (most recent call last):
+              ...
+            StopIteration
+            >>> p.prepend(1)
+            >>> next(p)
+            1
+            >>> next(p)
+            Traceback (most recent call last):
+              ...
+            StopIteration
+
+        """
+        self._cache.extendleft(reversed(items))
+
+    def __next__(self):
+        if self._cache:
+            return self._cache.popleft()
+
+        return next(self._it)
+
+    next = __next__  # For Python 2 compatibility
+
+    def _get_slice(self, index):
+        # Normalize the slice's arguments
+        step = 1 if (index.step is None) else index.step
+        if step > 0:
+            start = 0 if (index.start is None) else index.start
+            stop = maxsize if (index.stop is None) else index.stop
+        elif step < 0:
+            start = -1 if (index.start is None) else index.start
+            stop = (-maxsize - 1) if (index.stop is None) else index.stop
+        else:
+            raise ValueError('slice step cannot be zero')
+
+        # If either the start or stop index is negative, we'll need to cache
+        # the rest of the iterable in order to slice from the right side.
+        if (start < 0) or (stop < 0):
+            self._cache.extend(self._it)
+        # Otherwise we'll need to find the rightmost index and cache to that
+        # point.
+        else:
+            n = min(max(start, stop) + 1, maxsize)
+            cache_len = len(self._cache)
+            if n >= cache_len:
+                self._cache.extend(islice(self._it, n - cache_len))
+
+        return list(self._cache)[index]
+
+    def __getitem__(self, index):
+        if isinstance(index, slice):
+            return self._get_slice(index)
+
+        cache_len = len(self._cache)
+        if index < 0:
+            self._cache.extend(self._it)
+        elif index >= cache_len:
+            self._cache.extend(islice(self._it, index + 1 - cache_len))
+
+        return self._cache[index]
+
+
+def _collate(*iterables, **kwargs):
+    """Helper for ``collate()``, called when the user is using the ``reverse``
+    or ``key`` keyword arguments on Python versions below 3.5.
+
+    """
+    key = kwargs.pop('key', lambda a: a)
+    reverse = kwargs.pop('reverse', False)
+
+    min_or_max = partial(max if reverse else min, key=itemgetter(0))
+    peekables = [peekable(it) for it in iterables]
+    peekables = [p for p in peekables if p]  # Kill empties.
+    while peekables:
+        _, p = min_or_max((key(p.peek()), p) for p in peekables)
+        yield next(p)
+        peekables = [x for x in peekables if x]
+
+
+def collate(*iterables, **kwargs):
+    """Return a sorted merge of the items from each of several already-sorted
+    *iterables*.
+
+        >>> list(collate('ACDZ', 'AZ', 'JKL'))
+        ['A', 'A', 'C', 'D', 'J', 'K', 'L', 'Z', 'Z']
+
+    Works lazily, keeping only the next value from each iterable in memory. Use
+    :func:`collate` to, for example, perform a n-way mergesort of items that
+    don't fit in memory.
+
+    If a *key* function is specified, the iterables will be sorted according
+    to its result:
+
+        >>> key = lambda s: int(s)  # Sort by numeric value, not by string
+        >>> list(collate(['1', '10'], ['2', '11'], key=key))
+        ['1', '2', '10', '11']
+
+
+    If the *iterables* are sorted in descending order, set *reverse* to
+    ``True``:
+
+        >>> list(collate([5, 3, 1], [4, 2, 0], reverse=True))
+        [5, 4, 3, 2, 1, 0]
+
+    If the elements of the passed-in iterables are out of order, you might get
+    unexpected results.
+
+    On Python 2.7, this function delegates to :func:`heapq.merge` if neither
+    of the keyword arguments are specified. On Python 3.5+, this function
+    is an alias for :func:`heapq.merge`.
+
+    """
+    if not kwargs:
+        return merge(*iterables)
+
+    return _collate(*iterables, **kwargs)
+
+
+# If using Python version 3.5 or greater, heapq.merge() will be faster than
+# collate - use that instead.
+if version_info >= (3, 5, 0):
+    _collate_docstring = collate.__doc__
+    collate = partial(merge)
+    collate.__doc__ = _collate_docstring
+
+
+def consumer(func):
+    """Decorator that automatically advances a PEP-342-style "reverse iterator"
+    to its first yield point so you don't have to call ``next()`` on it
+    manually.
+
+        >>> @consumer
+        ... def tally():
+        ...     i = 0
+        ...     while True:
+        ...         print('Thing number %s is %s.' % (i, (yield)))
+        ...         i += 1
+        ...
+        >>> t = tally()
+        >>> t.send('red')
+        Thing number 0 is red.
+        >>> t.send('fish')
+        Thing number 1 is fish.
+
+    Without the decorator, you would have to call ``next(t)`` before
+    ``t.send()`` could be used.
+
+    """
+    @wraps(func)
+    def wrapper(*args, **kwargs):
+        gen = func(*args, **kwargs)
+        next(gen)
+        return gen
+    return wrapper
+
+
+def ilen(iterable):
+    """Return the number of items in *iterable*.
+
+        >>> ilen(x for x in range(1000000) if x % 3 == 0)
+        333334
+
+    This consumes the iterable, so handle with care.
+
+    """
+    # maxlen=1 only stores the last item in the deque
+    d = deque(enumerate(iterable, 1), maxlen=1)
+    # since we started enumerate at 1,
+    # the first item of the last pair will be the length of the iterable
+    # (assuming there were items)
+    return d[0][0] if d else 0
+
+
+def iterate(func, start):
+    """Return ``start``, ``func(start)``, ``func(func(start))``, ...
+
+        >>> from itertools import islice
+        >>> list(islice(iterate(lambda x: 2*x, 1), 10))
+        [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
+
+    """
+    while True:
+        yield start
+        start = func(start)
+
+
+def with_iter(context_manager):
+    """Wrap an iterable in a ``with`` statement, so it closes once exhausted.
+
+    For example, this will close the file when the iterator is exhausted::
+
+        upper_lines = (line.upper() for line in with_iter(open('foo')))
+
+    Any context manager which returns an iterable is a candidate for
+    ``with_iter``.
+
+    """
+    with context_manager as iterable:
+        for item in iterable:
+            yield item
+
+
+def one(iterable, too_short=None, too_long=None):
+    """Return the first item from *iterable*, which is expected to contain only
+    that item. Raise an exception if *iterable* is empty or has more than one
+    item.
+
+    :func:`one` is useful for ensuring that an iterable contains only one item.
+    For example, it can be used to retrieve the result of a database query
+    that is expected to return a single row.
+
+    If *iterable* is empty, ``ValueError`` will be raised. You may specify a
+    different exception with the *too_short* keyword:
+
+        >>> it = []
+        >>> one(it)  # doctest: +IGNORE_EXCEPTION_DETAIL
+        Traceback (most recent call last):
+        ...
+        ValueError: too many items in iterable (expected 1)'
+        >>> too_short = IndexError('too few items')
+        >>> one(it, too_short=too_short)  # doctest: +IGNORE_EXCEPTION_DETAIL
+        Traceback (most recent call last):
+        ...
+        IndexError: too few items
+
+    Similarly, if *iterable* contains more than one item, ``ValueError`` will
+    be raised. You may specify a different exception with the *too_long*
+    keyword:
+
+        >>> it = ['too', 'many']
+        >>> one(it)  # doctest: +IGNORE_EXCEPTION_DETAIL
+        Traceback (most recent call last):
+        ...
+        ValueError: too many items in iterable (expected 1)'
+        >>> too_long = RuntimeError
+        >>> one(it, too_long=too_long)  # doctest: +IGNORE_EXCEPTION_DETAIL
+        Traceback (most recent call last):
+        ...
+        RuntimeError
+
+    Note that :func:`one` attempts to advance *iterable* twice to ensure there
+    is only one item. If there is more than one, both items will be discarded.
+    See :func:`spy` or :func:`peekable` to check iterable contents less
+    destructively.
+
+    """
+    it = iter(iterable)
+
+    try:
+        value = next(it)
+    except StopIteration:
+        raise too_short or ValueError('too few items in iterable (expected 1)')
+
+    try:
+        next(it)
+    except StopIteration:
+        pass
+    else:
+        raise too_long or ValueError('too many items in iterable (expected 1)')
+
+    return value
+
+
+def distinct_permutations(iterable):
+    """Yield successive distinct permutations of the elements in *iterable*.
+
+        >>> sorted(distinct_permutations([1, 0, 1]))
+        [(0, 1, 1), (1, 0, 1), (1, 1, 0)]
+
+    Equivalent to ``set(permutations(iterable))``, except duplicates are not
+    generated and thrown away. For larger input sequences this is much more
+    efficient.
+
+    Duplicate permutations arise when there are duplicated elements in the
+    input iterable. The number of items returned is
+    `n! / (x_1! * x_2! * ... * x_n!)`, where `n` is the total number of
+    items input, and each `x_i` is the count of a distinct item in the input
+    sequence.
+
+    """
+    def perm_unique_helper(item_counts, perm, i):
+        """Internal helper function
+
+        :arg item_counts: Stores the unique items in ``iterable`` and how many
+            times they are repeated
+        :arg perm: The permutation that is being built for output
+        :arg i: The index of the permutation being modified
+
+        The output permutations are built up recursively; the distinct items
+        are placed until their repetitions are exhausted.
+        """
+        if i < 0:
+            yield tuple(perm)
+        else:
+            for item in item_counts:
+                if item_counts[item] <= 0:
+                    continue
+                perm[i] = item
+                item_counts[item] -= 1
+                for x in perm_unique_helper(item_counts, perm, i - 1):
+                    yield x
+                item_counts[item] += 1
+
+    item_counts = Counter(iterable)
+    length = sum(item_counts.values())
+
+    return perm_unique_helper(item_counts, [None] * length, length - 1)
+
+
+def intersperse(e, iterable, n=1):
+    """Intersperse filler element *e* among the items in *iterable*, leaving
+    *n* items between each filler element.
+
+        >>> list(intersperse('!', [1, 2, 3, 4, 5]))
+        [1, '!', 2, '!', 3, '!', 4, '!', 5]
+
+        >>> list(intersperse(None, [1, 2, 3, 4, 5], n=2))
+        [1, 2, None, 3, 4, None, 5]
+
+    """
+    if n == 0:
+        raise ValueError('n must be > 0')
+    elif n == 1:
+        # interleave(repeat(e), iterable) -> e, x_0, e, e, x_1, e, x_2...
+        # islice(..., 1, None) -> x_0, e, e, x_1, e, x_2...
+        return islice(interleave(repeat(e), iterable), 1, None)
+    else:
+        # interleave(filler, chunks) -> [e], [x_0, x_1], [e], [x_2, x_3]...
+        # islice(..., 1, None) -> [x_0, x_1], [e], [x_2, x_3]...
+        # flatten(...) -> x_0, x_1, e, x_2, x_3...
+        filler = repeat([e])
+        chunks = chunked(iterable, n)
+        return flatten(islice(interleave(filler, chunks), 1, None))
+
+
+def unique_to_each(*iterables):
+    """Return the elements from each of the input iterables that aren't in the
+    other input iterables.
+
+    For example, suppose you have a set of packages, each with a set of
+    dependencies::
+
+        {'pkg_1': {'A', 'B'}, 'pkg_2': {'B', 'C'}, 'pkg_3': {'B', 'D'}}
+
+    If you remove one package, which dependencies can also be removed?
+
+    If ``pkg_1`` is removed, then ``A`` is no longer necessary - it is not
+    associated with ``pkg_2`` or ``pkg_3``. Similarly, ``C`` is only needed for
+    ``pkg_2``, and ``D`` is only needed for ``pkg_3``::
+
+        >>> unique_to_each({'A', 'B'}, {'B', 'C'}, {'B', 'D'})
+        [['A'], ['C'], ['D']]
+
+    If there are duplicates in one input iterable that aren't in the others
+    they will be duplicated in the output. Input order is preserved::
+
+        >>> unique_to_each("mississippi", "missouri")
+        [['p', 'p'], ['o', 'u', 'r']]
+
+    It is assumed that the elements of each iterable are hashable.
+
+    """
+    pool = [list(it) for it in iterables]
+    counts = Counter(chain.from_iterable(map(set, pool)))
+    uniques = {element for element in counts if counts[element] == 1}
+    return [list(filter(uniques.__contains__, it)) for it in pool]
+
+
+def windowed(seq, n, fillvalue=None, step=1):
+    """Return a sliding window of width *n* over the given iterable.
+
+        >>> all_windows = windowed([1, 2, 3, 4, 5], 3)
+        >>> list(all_windows)
+        [(1, 2, 3), (2, 3, 4), (3, 4, 5)]
+
+    When the window is larger than the iterable, *fillvalue* is used in place
+    of missing values::
+
+        >>> list(windowed([1, 2, 3], 4))
+        [(1, 2, 3, None)]
+
+    Each window will advance in increments of *step*:
+
+        >>> list(windowed([1, 2, 3, 4, 5, 6], 3, fillvalue='!', step=2))
+        [(1, 2, 3), (3, 4, 5), (5, 6, '!')]
+
+    """
+    if n < 0:
+        raise ValueError('n must be >= 0')
+    if n == 0:
+        yield tuple()
+        return
+    if step < 1:
+        raise ValueError('step must be >= 1')
+
+    it = iter(seq)
+    window = deque([], n)
+    append = window.append
+
+    # Initial deque fill
+    for _ in range(n):
+        append(next(it, fillvalue))
+    yield tuple(window)
+
+    # Appending new items to the right causes old items to fall off the left
+    i = 0
+    for item in it:
+        append(item)
+        i = (i + 1) % step
+        if i % step == 0:
+            yield tuple(window)
+
+    # If there are items from the iterable in the window, pad with the given
+    # value and emit them.
+    if (i % step) and (step - i < n):
+        for _ in range(step - i):
+            append(fillvalue)
+        yield tuple(window)
+
+
+class bucket(object):
+    """Wrap *iterable* and return an object that buckets it iterable into
+    child iterables based on a *key* function.
+
+        >>> iterable = ['a1', 'b1', 'c1', 'a2', 'b2', 'c2', 'b3']
+        >>> s = bucket(iterable, key=lambda x: x[0])
+        >>> a_iterable = s['a']
+        >>> next(a_iterable)
+        'a1'
+        >>> next(a_iterable)
+        'a2'
+        >>> list(s['b'])
+        ['b1', 'b2', 'b3']
+
+    The original iterable will be advanced and its items will be cached until
+    they are used by the child iterables. This may require significant storage.
+
+    By default, attempting to select a bucket to which no items belong  will
+    exhaust the iterable and cache all values.
+    If you specify a *validator* function, selected buckets will instead be
+    checked against it.
+
+        >>> from itertools import count
+        >>> it = count(1, 2)  # Infinite sequence of odd numbers
+        >>> key = lambda x: x % 10  # Bucket by last digit
+        >>> validator = lambda x: x in {1, 3, 5, 7, 9}  # Odd digits only
+        >>> s = bucket(it, key=key, validator=validator)
+        >>> 2 in s
+        False
+        >>> list(s[2])
+        []
+
+    """
+    def __init__(self, iterable, key, validator=None):
+        self._it = iter(iterable)
+        self._key = key
+        self._cache = defaultdict(deque)
+        self._validator = validator or (lambda x: True)
+
+    def __contains__(self, value):
+        if not self._validator(value):
+            return False
+
+        try:
+            item = next(self[value])
+        except StopIteration:
+            return False
+        else:
+            self._cache[value].appendleft(item)
+
+        return True
+
+    def _get_values(self, value):
+        """
+        Helper to yield items from the parent iterator that match *value*.
+        Items that don't match are stored in the local cache as they
+        are encountered.
+        """
+        while True:
+            # If we've cached some items that match the target value, emit
+            # the first one and evict it from the cache.
+            if self._cache[value]:
+                yield self._cache[value].popleft()
+            # Otherwise we need to advance the parent iterator to search for
+            # a matching item, caching the rest.
+            else:
+                while True:
+                    try:
+                        item = next(self._it)
+                    except StopIteration:
+                        return
+                    item_value = self._key(item)
+                    if item_value == value:
+                        yield item
+                        break
+                    elif self._validator(item_value):
+                        self._cache[item_value].append(item)
+
+    def __getitem__(self, value):
+        if not self._validator(value):
+            return iter(())
+
+        return self._get_values(value)
+
+
+def spy(iterable, n=1):
+    """Return a 2-tuple with a list containing the first *n* elements of
+    *iterable*, and an iterator with the same items as *iterable*.
+    This allows you to "look ahead" at the items in the iterable without
+    advancing it.
+
+    There is one item in the list by default:
+
+        >>> iterable = 'abcdefg'
+        >>> head, iterable = spy(iterable)
+        >>> head
+        ['a']
+        >>> list(iterable)
+        ['a', 'b', 'c', 'd', 'e', 'f', 'g']
+
+    You may use unpacking to retrieve items instead of lists:
+
+        >>> (head,), iterable = spy('abcdefg')
+        >>> head
+        'a'
+        >>> (first, second), iterable = spy('abcdefg', 2)
+        >>> first
+        'a'
+        >>> second
+        'b'
+
+    The number of items requested can be larger than the number of items in
+    the iterable:
+
+        >>> iterable = [1, 2, 3, 4, 5]
+        >>> head, iterable = spy(iterable, 10)
+        >>> head
+        [1, 2, 3, 4, 5]
+        >>> list(iterable)
+        [1, 2, 3, 4, 5]
+
+    """
+    it = iter(iterable)
+    head = take(n, it)
+
+    return head, chain(head, it)
+
+
+def interleave(*iterables):
+    """Return a new iterable yielding from each iterable in turn,
+    until the shortest is exhausted.
+
+        >>> list(interleave([1, 2, 3], [4, 5], [6, 7, 8]))
+        [1, 4, 6, 2, 5, 7]
+
+    For a version that doesn't terminate after the shortest iterable is
+    exhausted, see :func:`interleave_longest`.
+
+    """
+    return chain.from_iterable(zip(*iterables))
+
+
+def interleave_longest(*iterables):
+    """Return a new iterable yielding from each iterable in turn,
+    skipping any that are exhausted.
+
+        >>> list(interleave_longest([1, 2, 3], [4, 5], [6, 7, 8]))
+        [1, 4, 6, 2, 5, 7, 3, 8]
+
+    This function produces the same output as :func:`roundrobin`, but may
+    perform better for some inputs (in particular when the number of iterables
+    is large).
+
+    """
+    i = chain.from_iterable(zip_longest(*iterables, fillvalue=_marker))
+    return (x for x in i if x is not _marker)
+
+
+def collapse(iterable, base_type=None, levels=None):
+    """Flatten an iterable with multiple levels of nesting (e.g., a list of
+    lists of tuples) into non-iterable types.
+
+        >>> iterable = [(1, 2), ([3, 4], [[5], [6]])]
+        >>> list(collapse(iterable))
+        [1, 2, 3, 4, 5, 6]
+
+    String types are not considered iterable and will not be collapsed.
+    To avoid collapsing other types, specify *base_type*:
+
+        >>> iterable = ['ab', ('cd', 'ef'), ['gh', 'ij']]
+        >>> list(collapse(iterable, base_type=tuple))
+        ['ab', ('cd', 'ef'), 'gh', 'ij']
+
+    Specify *levels* to stop flattening after a certain level:
+
+    >>> iterable = [('a', ['b']), ('c', ['d'])]
+    >>> list(collapse(iterable))  # Fully flattened
+    ['a', 'b', 'c', 'd']
+    >>> list(collapse(iterable, levels=1))  # Only one level flattened
+    ['a', ['b'], 'c', ['d']]
+
+    """
+    def walk(node, level):
+        if (
+            ((levels is not None) and (level > levels)) or
+            isinstance(node, string_types) or
+            ((base_type is not None) and isinstance(node, base_type))
+        ):
+            yield node
+            return
+
+        try:
+            tree = iter(node)
+        except TypeError:
+            yield node
+            return
+        else:
+            for child in tree:
+                for x in walk(child, level + 1):
+                    yield x
+
+    for x in walk(iterable, 0):
+        yield x
+
+
+def side_effect(func, iterable, chunk_size=None, before=None, after=None):
+    """Invoke *func* on each item in *iterable* (or on each *chunk_size* group
+    of items) before yielding the item.
+
+    `func` must be a function that takes a single argument. Its return value
+    will be discarded.
+
+    *before* and *after* are optional functions that take no arguments. They
+    will be executed before iteration starts and after it ends, respectively.
+
+    `side_effect` can be used for logging, updating progress bars, or anything
+    that is not functionally "pure."
+
+    Emitting a status message:
+
+        >>> from more_itertools import consume
+        >>> func = lambda item: print('Received {}'.format(item))
+        >>> consume(side_effect(func, range(2)))
+        Received 0
+        Received 1
+
+    Operating on chunks of items:
+
+        >>> pair_sums = []
+        >>> func = lambda chunk: pair_sums.append(sum(chunk))
+        >>> list(side_effect(func, [0, 1, 2, 3, 4, 5], 2))
+        [0, 1, 2, 3, 4, 5]
+        >>> list(pair_sums)
+        [1, 5, 9]
+
+    Writing to a file-like object:
+
+        >>> from io import StringIO
+        >>> from more_itertools import consume
+        >>> f = StringIO()
+        >>> func = lambda x: print(x, file=f)
+        >>> before = lambda: print(u'HEADER', file=f)
+        >>> after = f.close
+        >>> it = [u'a', u'b', u'c']
+        >>> consume(side_effect(func, it, before=before, after=after))
+        >>> f.closed
+        True
+
+    """
+    try:
+        if before is not None:
+            before()
+
+        if chunk_size is None:
+            for item in iterable:
+                func(item)
+                yield item
+        else:
+            for chunk in chunked(iterable, chunk_size):
+                func(chunk)
+                for item in chunk:
+                    yield item
+    finally:
+        if after is not None:
+            after()
+
+
+def sliced(seq, n):
+    """Yield slices of length *n* from the sequence *seq*.
+
+        >>> list(sliced((1, 2, 3, 4, 5, 6), 3))
+        [(1, 2, 3), (4, 5, 6)]
+
+    If the length of the sequence is not divisible by the requested slice
+    length, the last slice will be shorter.
+
+        >>> list(sliced((1, 2, 3, 4, 5, 6, 7, 8), 3))
+        [(1, 2, 3), (4, 5, 6), (7, 8)]
+
+    This function will only work for iterables that support slicing.
+    For non-sliceable iterables, see :func:`chunked`.
+
+    """
+    return takewhile(bool, (seq[i: i + n] for i in count(0, n)))
+
+
+def split_at(iterable, pred):
+    """Yield lists of items from *iterable*, where each list is delimited by
+    an item where callable *pred* returns ``True``. The lists do not include
+    the delimiting items.
+
+        >>> list(split_at('abcdcba', lambda x: x == 'b'))
+        [['a'], ['c', 'd', 'c'], ['a']]
+
+        >>> list(split_at(range(10), lambda n: n % 2 == 1))
+        [[0], [2], [4], [6], [8], []]
+    """
+    buf = []
+    for item in iterable:
+        if pred(item):
+            yield buf
+            buf = []
+        else:
+            buf.append(item)
+    yield buf
+
+
+def split_before(iterable, pred):
+    """Yield lists of items from *iterable*, where each list starts with an
+    item where callable *pred* returns ``True``:
+
+        >>> list(split_before('OneTwo', lambda s: s.isupper()))
+        [['O', 'n', 'e'], ['T', 'w', 'o']]
+
+        >>> list(split_before(range(10), lambda n: n % 3 == 0))
+        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
+
+    """
+    buf = []
+    for item in iterable:
+        if pred(item) and buf:
+            yield buf
+            buf = []
+        buf.append(item)
+    yield buf
+
+
+def split_after(iterable, pred):
+    """Yield lists of items from *iterable*, where each list ends with an
+    item where callable *pred* returns ``True``:
+
+        >>> list(split_after('one1two2', lambda s: s.isdigit()))
+        [['o', 'n', 'e', '1'], ['t', 'w', 'o', '2']]
+
+        >>> list(split_after(range(10), lambda n: n % 3 == 0))
+        [[0], [1, 2, 3], [4, 5, 6], [7, 8, 9]]
+
+    """
+    buf = []
+    for item in iterable:
+        buf.append(item)
+        if pred(item) and buf:
+            yield buf
+            buf = []
+    if buf:
+        yield buf
+
+
+def padded(iterable, fillvalue=None, n=None, next_multiple=False):
+    """Yield the elements from *iterable*, followed by *fillvalue*, such that
+    at least *n* items are emitted.
+
+        >>> list(padded([1, 2, 3], '?', 5))
+        [1, 2, 3, '?', '?']
+
+    If *next_multiple* is ``True``, *fillvalue* will be emitted until the
+    number of items emitted is a multiple of *n*::
+
+        >>> list(padded([1, 2, 3, 4], n=3, next_multiple=True))
+        [1, 2, 3, 4, None, None]
+
+    If *n* is ``None``, *fillvalue* will be emitted indefinitely.
+
+    """
+    it = iter(iterable)
+    if n is None:
+        for item in chain(it, repeat(fillvalue)):
+            yield item
+    elif n < 1:
+        raise ValueError('n must be at least 1')
+    else:
+        item_count = 0
+        for item in it:
+            yield item
+            item_count += 1
+
+        remaining = (n - item_count) % n if next_multiple else n - item_count
+        for _ in range(remaining):
+            yield fillvalue
+
+
+def distribute(n, iterable):
+    """Distribute the items from *iterable* among *n* smaller iterables.
+
+        >>> group_1, group_2 = distribute(2, [1, 2, 3, 4, 5, 6])
+        >>> list(group_1)
+        [1, 3, 5]
+        >>> list(group_2)
+        [2, 4, 6]
+
+    If the length of *iterable* is not evenly divisible by *n*, then the
+    length of the returned iterables will not be identical:
+
+        >>> children = distribute(3, [1, 2, 3, 4, 5, 6, 7])
+        >>> [list(c) for c in children]
+        [[1, 4, 7], [2, 5], [3, 6]]
+
+    If the length of *iterable* is smaller than *n*, then the last returned
+    iterables will be empty:
+
+        >>> children = distribute(5, [1, 2, 3])
+        >>> [list(c) for c in children]
+        [[1], [2], [3], [], []]
+
+    This function uses :func:`itertools.tee` and may require significant
+    storage. If you need the order items in the smaller iterables to match the
+    original iterable, see :func:`divide`.
+
+    """
+    if n < 1:
+        raise ValueError('n must be at least 1')
+
+    children = tee(iterable, n)
+    return [islice(it, index, None, n) for index, it in enumerate(children)]
+
+
+def stagger(iterable, offsets=(-1, 0, 1), longest=False, fillvalue=None):
+    """Yield tuples whose elements are offset from *iterable*.
+    The amount by which the `i`-th item in each tuple is offset is given by
+    the `i`-th item in *offsets*.
+
+        >>> list(stagger([0, 1, 2, 3]))
+        [(None, 0, 1), (0, 1, 2), (1, 2, 3)]
+        >>> list(stagger(range(8), offsets=(0, 2, 4)))
+        [(0, 2, 4), (1, 3, 5), (2, 4, 6), (3, 5, 7)]
+
+    By default, the sequence will end when the final element of a tuple is the
+    last item in the iterable. To continue until the first element of a tuple
+    is the last item in the iterable, set *longest* to ``True``::
+
+        >>> list(stagger([0, 1, 2, 3], longest=True))
+        [(None, 0, 1), (0, 1, 2), (1, 2, 3), (2, 3, None), (3, None, None)]
+
+    By default, ``None`` will be used to replace offsets beyond the end of the
+    sequence. Specify *fillvalue* to use some other value.
+
+    """
+    children = tee(iterable, len(offsets))
+
+    return zip_offset(
+        *children, offsets=offsets, longest=longest, fillvalue=fillvalue
+    )
+
+
+def zip_offset(*iterables, **kwargs):
+    """``zip`` the input *iterables* together, but offset the `i`-th iterable
+    by the `i`-th item in *offsets*.
+
+        >>> list(zip_offset('0123', 'abcdef', offsets=(0, 1)))
+        [('0', 'b'), ('1', 'c'), ('2', 'd'), ('3', 'e')]
+
+    This can be used as a lightweight alternative to SciPy or pandas to analyze
+    data sets in which somes series have a lead or lag relationship.
+
+    By default, the sequence will end when the shortest iterable is exhausted.
+    To continue until the longest iterable is exhausted, set *longest* to
+    ``True``.
+
+        >>> list(zip_offset('0123', 'abcdef', offsets=(0, 1), longest=True))
+        [('0', 'b'), ('1', 'c'), ('2', 'd'), ('3', 'e'), (None, 'f')]
+
+    By default, ``None`` will be used to replace offsets beyond the end of the
+    sequence. Specify *fillvalue* to use some other value.
+
+    """
+    offsets = kwargs['offsets']
+    longest = kwargs.get('longest', False)
+    fillvalue = kwargs.get('fillvalue', None)
+
+    if len(iterables) != len(offsets):
+        raise ValueError("Number of iterables and offsets didn't match")
+
+    staggered = []
+    for it, n in zip(iterables, offsets):
+        if n < 0:
+            staggered.append(chain(repeat(fillvalue, -n), it))
+        elif n > 0:
+            staggered.append(islice(it, n, None))
+        else:
+            staggered.append(it)
+
+    if longest:
+        return zip_longest(*staggered, fillvalue=fillvalue)
+
+    return zip(*staggered)
+
+
+def sort_together(iterables, key_list=(0,), reverse=False):
+    """Return the input iterables sorted together, with *key_list* as the
+    priority for sorting. All iterables are trimmed to the length of the
+    shortest one.
+
+    This can be used like the sorting function in a spreadsheet. If each
+    iterable represents a column of data, the key list determines which
+    columns are used for sorting.
+
+    By default, all iterables are sorted using the ``0``-th iterable::
+
+        >>> iterables = [(4, 3, 2, 1), ('a', 'b', 'c', 'd')]
+        >>> sort_together(iterables)
+        [(1, 2, 3, 4), ('d', 'c', 'b', 'a')]
+
+    Set a different key list to sort according to another iterable.
+    Specifying mutliple keys dictates how ties are broken::
+
+        >>> iterables = [(3, 1, 2), (0, 1, 0), ('c', 'b', 'a')]
+        >>> sort_together(iterables, key_list=(1, 2))
+        [(2, 3, 1), (0, 0, 1), ('a', 'c', 'b')]
+
+    Set *reverse* to ``True`` to sort in descending order.
+
+        >>> sort_together([(1, 2, 3), ('c', 'b', 'a')], reverse=True)
+        [(3, 2, 1), ('a', 'b', 'c')]
+
+    """
+    return list(zip(*sorted(zip(*iterables),
+                            key=itemgetter(*key_list),
+                            reverse=reverse)))
+
+
+def divide(n, iterable):
+    """Divide the elements from *iterable* into *n* parts, maintaining
+    order.
+
+        >>> group_1, group_2 = divide(2, [1, 2, 3, 4, 5, 6])
+        >>> list(group_1)
+        [1, 2, 3]
+        >>> list(group_2)
+        [4, 5, 6]
+
+    If the length of *iterable* is not evenly divisible by *n*, then the
+    length of the returned iterables will not be identical:
+
+        >>> children = divide(3, [1, 2, 3, 4, 5, 6, 7])
+        >>> [list(c) for c in children]
+        [[1, 2, 3], [4, 5], [6, 7]]
+
+    If the length of the iterable is smaller than n, then the last returned
+    iterables will be empty:
+
+        >>> children = divide(5, [1, 2, 3])
+        >>> [list(c) for c in children]
+        [[1], [2], [3], [], []]
+
+    This function will exhaust the iterable before returning and may require
+    significant storage. If order is not important, see :func:`distribute`,
+    which does not first pull the iterable into memory.
+
+    """
+    if n < 1:
+        raise ValueError('n must be at least 1')
+
+    seq = tuple(iterable)
+    q, r = divmod(len(seq), n)
+
+    ret = []
+    for i in range(n):
+        start = (i * q) + (i if i < r else r)
+        stop = ((i + 1) * q) + (i + 1 if i + 1 < r else r)
+        ret.append(iter(seq[start:stop]))
+
+    return ret
+
+
+def always_iterable(obj, base_type=(text_type, binary_type)):
+    """If *obj* is iterable, return an iterator over its items::
+
+        >>> obj = (1, 2, 3)
+        >>> list(always_iterable(obj))
+        [1, 2, 3]
+
+    If *obj* is not iterable, return a one-item iterable containing *obj*::
+
+        >>> obj = 1
+        >>> list(always_iterable(obj))
+        [1]
+
+    If *obj* is ``None``, return an empty iterable:
+
+        >>> obj = None
+        >>> list(always_iterable(None))
+        []
+
+    By default, binary and text strings are not considered iterable::
+
+        >>> obj = 'foo'
+        >>> list(always_iterable(obj))
+        ['foo']
+
+    If *base_type* is set, objects for which ``isinstance(obj, base_type)``
+    returns ``True`` won't be considered iterable.
+
+        >>> obj = {'a': 1}
+        >>> list(always_iterable(obj))  # Iterate over the dict's keys
+        ['a']
+        >>> list(always_iterable(obj, base_type=dict))  # Treat dicts as a unit
+        [{'a': 1}]
+
+    Set *base_type* to ``None`` to avoid any special handling and treat objects
+    Python considers iterable as iterable:
+
+        >>> obj = 'foo'
+        >>> list(always_iterable(obj, base_type=None))
+        ['f', 'o', 'o']
+    """
+    if obj is None:
+        return iter(())
+
+    if (base_type is not None) and isinstance(obj, base_type):
+        return iter((obj,))
+
+    try:
+        return iter(obj)
+    except TypeError:
+        return iter((obj,))
+
+
+def adjacent(predicate, iterable, distance=1):
+    """Return an iterable over `(bool, item)` tuples where the `item` is
+    drawn from *iterable* and the `bool` indicates whether
+    that item satisfies the *predicate* or is adjacent to an item that does.
+
+    For example, to find whether items are adjacent to a ``3``::
+
+        >>> list(adjacent(lambda x: x == 3, range(6)))
+        [(False, 0), (False, 1), (True, 2), (True, 3), (True, 4), (False, 5)]
+
+    Set *distance* to change what counts as adjacent. For example, to find
+    whether items are two places away from a ``3``:
+
+        >>> list(adjacent(lambda x: x == 3, range(6), distance=2))
+        [(False, 0), (True, 1), (True, 2), (True, 3), (True, 4), (True, 5)]
+
+    This is useful for contextualizing the results of a search function.
+    For example, a code comparison tool might want to identify lines that
+    have changed, but also surrounding lines to give the viewer of the diff
+    context.
+
+    The predicate function will only be called once for each item in the
+    iterable.
+
+    See also :func:`groupby_transform`, which can be used with this function
+    to group ranges of items with the same `bool` value.
+
+    """
+    # Allow distance=0 mainly for testing that it reproduces results with map()
+    if distance < 0:
+        raise ValueError('distance must be at least 0')
+
+    i1, i2 = tee(iterable)
+    padding = [False] * distance
+    selected = chain(padding, map(predicate, i1), padding)
+    adjacent_to_selected = map(any, windowed(selected, 2 * distance + 1))
+    return zip(adjacent_to_selected, i2)
+
+
+def groupby_transform(iterable, keyfunc=None, valuefunc=None):
+    """An extension of :func:`itertools.groupby` that transforms the values of
+    *iterable* after grouping them.
+    *keyfunc* is a function used to compute a grouping key for each item.
+    *valuefunc* is a function for transforming the items after grouping.
+
+        >>> iterable = 'AaaABbBCcA'
+        >>> keyfunc = lambda x: x.upper()
+        >>> valuefunc = lambda x: x.lower()
+        >>> grouper = groupby_transform(iterable, keyfunc, valuefunc)
+        >>> [(k, ''.join(g)) for k, g in grouper]
+        [('A', 'aaaa'), ('B', 'bbb'), ('C', 'cc'), ('A', 'a')]
+
+    *keyfunc* and *valuefunc* default to identity functions if they are not
+    specified.
+
+    :func:`groupby_transform` is useful when grouping elements of an iterable
+    using a separate iterable as the key. To do this, :func:`zip` the iterables
+    and pass a *keyfunc* that extracts the first element and a *valuefunc*
+    that extracts the second element::
+
+        >>> from operator import itemgetter
+        >>> keys = [0, 0, 1, 1, 1, 2, 2, 2, 3]
+        >>> values = 'abcdefghi'
+        >>> iterable = zip(keys, values)
+        >>> grouper = groupby_transform(iterable, itemgetter(0), itemgetter(1))
+        >>> [(k, ''.join(g)) for k, g in grouper]
+        [(0, 'ab'), (1, 'cde'), (2, 'fgh'), (3, 'i')]
+
+    Note that the order of items in the iterable is significant.
+    Only adjacent items are grouped together, so if you don't want any
+    duplicate groups, you should sort the iterable by the key function.
+
+    """
+    valuefunc = (lambda x: x) if valuefunc is None else valuefunc
+    return ((k, map(valuefunc, g)) for k, g in groupby(iterable, keyfunc))
+
+
+def numeric_range(*args):
+    """An extension of the built-in ``range()`` function whose arguments can
+    be any orderable numeric type.
+
+    With only *stop* specified, *start* defaults to ``0`` and *step*
+    defaults to ``1``. The output items will match the type of *stop*:
+
+        >>> list(numeric_range(3.5))
+        [0.0, 1.0, 2.0, 3.0]
+
+    With only *start* and *stop* specified, *step* defaults to ``1``. The
+    output items will match the type of *start*:
+
+        >>> from decimal import Decimal
+        >>> start = Decimal('2.1')
+        >>> stop = Decimal('5.1')
+        >>> list(numeric_range(start, stop))
+        [Decimal('2.1'), Decimal('3.1'), Decimal('4.1')]
+
+    With *start*, *stop*, and *step*  specified the output items will match
+    the type of ``start + step``:
+
+        >>> from fractions import Fraction
+        >>> start = Fraction(1, 2)  # Start at 1/2
+        >>> stop = Fraction(5, 2)  # End at 5/2
+        >>> step = Fraction(1, 2)  # Count by 1/2
+        >>> list(numeric_range(start, stop, step))
+        [Fraction(1, 2), Fraction(1, 1), Fraction(3, 2), Fraction(2, 1)]
+
+    If *step* is zero, ``ValueError`` is raised. Negative steps are supported:
+
+        >>> list(numeric_range(3, -1, -1.0))
+        [3.0, 2.0, 1.0, 0.0]
+
+    Be aware of the limitations of floating point numbers; the representation
+    of the yielded numbers may be surprising.
+
+    """
+    argc = len(args)
+    if argc == 1:
+        stop, = args
+        start = type(stop)(0)
+        step = 1
+    elif argc == 2:
+        start, stop = args
+        step = 1
+    elif argc == 3:
+        start, stop, step = args
+    else:
+        err_msg = 'numeric_range takes at most 3 arguments, got {}'
+        raise TypeError(err_msg.format(argc))
+
+    values = (start + (step * n) for n in count())
+    if step > 0:
+        return takewhile(partial(gt, stop), values)
+    elif step < 0:
+        return takewhile(partial(lt, stop), values)
+    else:
+        raise ValueError('numeric_range arg 3 must not be zero')
+
+
+def count_cycle(iterable, n=None):
+    """Cycle through the items from *iterable* up to *n* times, yielding
+    the number of completed cycles along with each item. If *n* is omitted the
+    process repeats indefinitely.
+
+    >>> list(count_cycle('AB', 3))
+    [(0, 'A'), (0, 'B'), (1, 'A'), (1, 'B'), (2, 'A'), (2, 'B')]
+
+    """
+    iterable = tuple(iterable)
+    if not iterable:
+        return iter(())
+    counter = count() if n is None else range(n)
+    return ((i, item) for i in counter for item in iterable)
+
+
+def locate(iterable, pred=bool, window_size=None):
+    """Yield the index of each item in *iterable* for which *pred* returns
+    ``True``.
+
+    *pred* defaults to :func:`bool`, which will select truthy items:
+
+        >>> list(locate([0, 1, 1, 0, 1, 0, 0]))
+        [1, 2, 4]
+
+    Set *pred* to a custom function to, e.g., find the indexes for a particular
+    item.
+
+        >>> list(locate(['a', 'b', 'c', 'b'], lambda x: x == 'b'))
+        [1, 3]
+
+    If *window_size* is given, then the *pred* function will be called with
+    that many items. This enables searching for sub-sequences:
+
+        >>> iterable = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]
+        >>> pred = lambda *args: args == (1, 2, 3)
+        >>> list(locate(iterable, pred=pred, window_size=3))
+        [1, 5, 9]
+
+    Use with :func:`seekable` to find indexes and then retrieve the associated
+    items:
+
+        >>> from itertools import count
+        >>> from more_itertools import seekable
+        >>> source = (3 * n + 1 if (n % 2) else n // 2 for n in count())
+        >>> it = seekable(source)
+        >>> pred = lambda x: x > 100
+        >>> indexes = locate(it, pred=pred)
+        >>> i = next(indexes)
+        >>> it.seek(i)
+        >>> next(it)
+        106
+
+    """
+    if window_size is None:
+        return compress(count(), map(pred, iterable))
+
+    if window_size < 1:
+        raise ValueError('window size must be at least 1')
+
+    it = windowed(iterable, window_size, fillvalue=_marker)
+    return compress(count(), starmap(pred, it))
+
+
+def lstrip(iterable, pred):
+    """Yield the items from *iterable*, but strip any from the beginning
+    for which *pred* returns ``True``.
+
+    For example, to remove a set of items from the start of an iterable:
+
+        >>> iterable = (None, False, None, 1, 2, None, 3, False, None)
+        >>> pred = lambda x: x in {None, False, ''}
+        >>> list(lstrip(iterable, pred))
+        [1, 2, None, 3, False, None]
+
+    This function is analogous to to :func:`str.lstrip`, and is essentially
+    an wrapper for :func:`itertools.dropwhile`.
+
+    """
+    return dropwhile(pred, iterable)
+
+
+def rstrip(iterable, pred):
+    """Yield the items from *iterable*, but strip any from the end
+    for which *pred* returns ``True``.
+
+    For example, to remove a set of items from the end of an iterable:
+
+        >>> iterable = (None, False, None, 1, 2, None, 3, False, None)
+        >>> pred = lambda x: x in {None, False, ''}
+        >>> list(rstrip(iterable, pred))
+        [None, False, None, 1, 2, None, 3]
+
+    This function is analogous to :func:`str.rstrip`.
+
+    """
+    cache = []
+    cache_append = cache.append
+    for x in iterable:
+        if pred(x):
+            cache_append(x)
+        else:
+            for y in cache:
+                yield y
+            del cache[:]
+            yield x
+
+
+def strip(iterable, pred):
+    """Yield the items from *iterable*, but strip any from the
+    beginning and end for which *pred* returns ``True``.
+
+    For example, to remove a set of items from both ends of an iterable:
+
+        >>> iterable = (None, False, None, 1, 2, None, 3, False, None)
+        >>> pred = lambda x: x in {None, False, ''}
+        >>> list(strip(iterable, pred))
+        [1, 2, None, 3]
+
+    This function is analogous to :func:`str.strip`.
+
+    """
+    return rstrip(lstrip(iterable, pred), pred)
+
+
+def islice_extended(iterable, *args):
+    """An extension of :func:`itertools.islice` that supports negative values
+    for *stop*, *start*, and *step*.
+
+        >>> iterable = iter('abcdefgh')
+        >>> list(islice_extended(iterable, -4, -1))
+        ['e', 'f', 'g']
+
+    Slices with negative values require some caching of *iterable*, but this
+    function takes care to minimize the amount of memory required.
+
+    For example, you can use a negative step with an infinite iterator:
+
+        >>> from itertools import count
+        >>> list(islice_extended(count(), 110, 99, -2))
+        [110, 108, 106, 104, 102, 100]
+
+    """
+    s = slice(*args)
+    start = s.start
+    stop = s.stop
+    if s.step == 0:
+        raise ValueError('step argument must be a non-zero integer or None.')
+    step = s.step or 1
+
+    it = iter(iterable)
+
+    if step > 0:
+        start = 0 if (start is None) else start
+
+        if (start < 0):
+            # Consume all but the last -start items
+            cache = deque(enumerate(it, 1), maxlen=-start)
+            len_iter = cache[-1][0] if cache else 0
+
+            # Adjust start to be positive
+            i = max(len_iter + start, 0)
+
+            # Adjust stop to be positive
+            if stop is None:
+                j = len_iter
+            elif stop >= 0:
+                j = min(stop, len_iter)
+            else:
+                j = max(len_iter + stop, 0)
+
+            # Slice the cache
+            n = j - i
+            if n <= 0:
+                return
+
+            for index, item in islice(cache, 0, n, step):
+                yield item
+        elif (stop is not None) and (stop < 0):
+            # Advance to the start position
+            next(islice(it, start, start), None)
+
+            # When stop is negative, we have to carry -stop items while
+            # iterating
+            cache = deque(islice(it, -stop), maxlen=-stop)
+
+            for index, item in enumerate(it):
+                cached_item = cache.popleft()
+                if index % step == 0:
+                    yield cached_item
+                cache.append(item)
+        else:
+            # When both start and stop are positive we have the normal case
+            for item in islice(it, start, stop, step):
+                yield item
+    else:
+        start = -1 if (start is None) else start
+
+        if (stop is not None) and (stop < 0):
+            # Consume all but the last items
+            n = -stop - 1
+            cache = deque(enumerate(it, 1), maxlen=n)
+            len_iter = cache[-1][0] if cache else 0
+
+            # If start and stop are both negative they are comparable and
+            # we can just slice. Otherwise we can adjust start to be negative
+            # and then slice.
+            if start < 0:
+                i, j = start, stop
+            else:
+                i, j = min(start - len_iter, -1), None
+
+            for index, item in list(cache)[i:j:step]:
+                yield item
+        else:
+            # Advance to the stop position
+            if stop is not None:
+                m = stop + 1
+                next(islice(it, m, m), None)
+
+            # stop is positive, so if start is negative they are not comparable
+            # and we need the rest of the items.
+            if start < 0:
+                i = start
+                n = None
+            # stop is None and start is positive, so we just need items up to
+            # the start index.
+            elif stop is None:
+                i = None
+                n = start + 1
+            # Both stop and start are positive, so they are comparable.
+            else:
+                i = None
+                n = start - stop
+                if n <= 0:
+                    return
+
+            cache = list(islice(it, n))
+
+            for item in cache[i::step]:
+                yield item
+
+
+def always_reversible(iterable):
+    """An extension of :func:`reversed` that supports all iterables, not
+    just those which implement the ``Reversible`` or ``Sequence`` protocols.
+
+        >>> print(*always_reversible(x for x in range(3)))
+        2 1 0
+
+    If the iterable is already reversible, this function returns the
+    result of :func:`reversed()`. If the iterable is not reversible,
+    this function will cache the remaining items in the iterable and
+    yield them in reverse order, which may require significant storage.
+    """
+    try:
+        return reversed(iterable)
+    except TypeError:
+        return reversed(list(iterable))
+
+
+def consecutive_groups(iterable, ordering=lambda x: x):
+    """Yield groups of consecutive items using :func:`itertools.groupby`.
+    The *ordering* function determines whether two items are adjacent by
+    returning their position.
+
+    By default, the ordering function is the identity function. This is
+    suitable for finding runs of numbers:
+
+        >>> iterable = [1, 10, 11, 12, 20, 30, 31, 32, 33, 40]
+        >>> for group in consecutive_groups(iterable):
+        ...     print(list(group))
+        [1]
+        [10, 11, 12]
+        [20]
+        [30, 31, 32, 33]
+        [40]
+
+    For finding runs of adjacent letters, try using the :meth:`index` method
+    of a string of letters:
+
+        >>> from string import ascii_lowercase
+        >>> iterable = 'abcdfgilmnop'
+        >>> ordering = ascii_lowercase.index
+        >>> for group in consecutive_groups(iterable, ordering):
+        ...     print(list(group))
+        ['a', 'b', 'c', 'd']
+        ['f', 'g']
+        ['i']
+        ['l', 'm', 'n', 'o', 'p']
+
+    """
+    for k, g in groupby(
+        enumerate(iterable), key=lambda x: x[0] - ordering(x[1])
+    ):
+        yield map(itemgetter(1), g)
+
+
+def difference(iterable, func=sub):
+    """By default, compute the first difference of *iterable* using
+    :func:`operator.sub`.
+
+        >>> iterable = [0, 1, 3, 6, 10]
+        >>> list(difference(iterable))
+        [0, 1, 2, 3, 4]
+
+    This is the opposite of :func:`accumulate`'s default behavior:
+
+        >>> from more_itertools import accumulate
+        >>> iterable = [0, 1, 2, 3, 4]
+        >>> list(accumulate(iterable))
+        [0, 1, 3, 6, 10]
+        >>> list(difference(accumulate(iterable)))
+        [0, 1, 2, 3, 4]
+
+    By default *func* is :func:`operator.sub`, but other functions can be
+    specified. They will be applied as follows::
+
+        A, B, C, D, ... --> A, func(B, A), func(C, B), func(D, C), ...
+
+    For example, to do progressive division:
+
+        >>> iterable = [1, 2, 6, 24, 120]  # Factorial sequence
+        >>> func = lambda x, y: x // y
+        >>> list(difference(iterable, func))
+        [1, 2, 3, 4, 5]
+
+    """
+    a, b = tee(iterable)
+    try:
+        item = next(b)
+    except StopIteration:
+        return iter([])
+    return chain([item], map(lambda x: func(x[1], x[0]), zip(a, b)))
+
+
+class SequenceView(Sequence):
+    """Return a read-only view of the sequence object *target*.
+
+    :class:`SequenceView` objects are analagous to Python's built-in
+    "dictionary view" types. They provide a dynamic view of a sequence's items,
+    meaning that when the sequence updates, so does the view.
+
+        >>> seq = ['0', '1', '2']
+        >>> view = SequenceView(seq)
+        >>> view
+        SequenceView(['0', '1', '2'])
+        >>> seq.append('3')
+        >>> view
+        SequenceView(['0', '1', '2', '3'])
+
+    Sequence views support indexing, slicing, and length queries. They act
+    like the underlying sequence, except they don't allow assignment:
+
+        >>> view[1]
+        '1'
+        >>> view[1:-1]
+        ['1', '2']
+        >>> len(view)
+        4
+
+    Sequence views are useful as an alternative to copying, as they don't
+    require (much) extra storage.
+
+    """
+    def __init__(self, target):
+        if not isinstance(target, Sequence):
+            raise TypeError
+        self._target = target
+
+    def __getitem__(self, index):
+        return self._target[index]
+
+    def __len__(self):
+        return len(self._target)
+
+    def __repr__(self):
+        return '{}({})'.format(self.__class__.__name__, repr(self._target))
+
+
+class seekable(object):
+    """Wrap an iterator to allow for seeking backward and forward. This
+    progressively caches the items in the source iterable so they can be
+    re-visited.
+
+    Call :meth:`seek` with an index to seek to that position in the source
+    iterable.
+
+    To "reset" an iterator, seek to ``0``:
+
+        >>> from itertools import count
+        >>> it = seekable((str(n) for n in count()))
+        >>> next(it), next(it), next(it)
+        ('0', '1', '2')
+        >>> it.seek(0)
+        >>> next(it), next(it), next(it)
+        ('0', '1', '2')
+        >>> next(it)
+        '3'
+
+    You can also seek forward:
+
+        >>> it = seekable((str(n) for n in range(20)))
+        >>> it.seek(10)
+        >>> next(it)
+        '10'
+        >>> it.seek(20)  # Seeking past the end of the source isn't a problem
+        >>> list(it)
+        []
+        >>> it.seek(0)  # Resetting works even after hitting the end
+        >>> next(it), next(it), next(it)
+        ('0', '1', '2')
+
+    The cache grows as the source iterable progresses, so beware of wrapping
+    very large or infinite iterables.
+
+    You may view the contents of the cache with the :meth:`elements` method.
+    That returns a :class:`SequenceView`, a view that updates automatically:
+
+        >>> it = seekable((str(n) for n in range(10)))
+        >>> next(it), next(it), next(it)
+        ('0', '1', '2')
+        >>> elements = it.elements()
+        >>> elements
+        SequenceView(['0', '1', '2'])
+        >>> next(it)
+        '3'
+        >>> elements
+        SequenceView(['0', '1', '2', '3'])
+
+    """
+
+    def __init__(self, iterable):
+        self._source = iter(iterable)
+        self._cache = []
+        self._index = None
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        if self._index is not None:
+            try:
+                item = self._cache[self._index]
+            except IndexError:
+                self._index = None
+            else:
+                self._index += 1
+                return item
+
+        item = next(self._source)
+        self._cache.append(item)
+        return item
+
+    next = __next__
+
+    def elements(self):
+        return SequenceView(self._cache)
+
+    def seek(self, index):
+        self._index = index
+        remainder = index - len(self._cache)
+        if remainder > 0:
+            consume(self, remainder)
+
+
+class run_length(object):
+    """
+    :func:`run_length.encode` compresses an iterable with run-length encoding.
+    It yields groups of repeated items with the count of how many times they
+    were repeated:
+
+        >>> uncompressed = 'abbcccdddd'
+        >>> list(run_length.encode(uncompressed))
+        [('a', 1), ('b', 2), ('c', 3), ('d', 4)]
+
+    :func:`run_length.decode` decompresses an iterable that was previously
+    compressed with run-length encoding. It yields the items of the
+    decompressed iterable:
+
+        >>> compressed = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]
+        >>> list(run_length.decode(compressed))
+        ['a', 'b', 'b', 'c', 'c', 'c', 'd', 'd', 'd', 'd']
+
+    """
+
+    @staticmethod
+    def encode(iterable):
+        return ((k, ilen(g)) for k, g in groupby(iterable))
+
+    @staticmethod
+    def decode(iterable):
+        return chain.from_iterable(repeat(k, n) for k, n in iterable)
+
+
+def exactly_n(iterable, n, predicate=bool):
+    """Return ``True`` if exactly ``n`` items in the iterable are ``True``
+    according to the *predicate* function.
+
+        >>> exactly_n([True, True, False], 2)
+        True
+        >>> exactly_n([True, True, False], 1)
+        False
+        >>> exactly_n([0, 1, 2, 3, 4, 5], 3, lambda x: x < 3)
+        True
+
+    The iterable will be advanced until ``n + 1`` truthy items are encountered,
+    so avoid calling it on infinite iterables.
+
+    """
+    return len(take(n + 1, filter(predicate, iterable))) == n
+
+
+def circular_shifts(iterable):
+    """Return a list of circular shifts of *iterable*.
+
+        >>> circular_shifts(range(4))
+        [(0, 1, 2, 3), (1, 2, 3, 0), (2, 3, 0, 1), (3, 0, 1, 2)]
+    """
+    lst = list(iterable)
+    return take(len(lst), windowed(cycle(lst), len(lst)))
+
+
+def make_decorator(wrapping_func, result_index=0):
+    """Return a decorator version of *wrapping_func*, which is a function that
+    modifies an iterable. *result_index* is the position in that function's
+    signature where the iterable goes.
+
+    This lets you use itertools on the "production end," i.e. at function
+    definition. This can augment what the function returns without changing the
+    function's code.
+
+    For example, to produce a decorator version of :func:`chunked`:
+
+        >>> from more_itertools import chunked
+        >>> chunker = make_decorator(chunked, result_index=0)
+        >>> @chunker(3)
+        ... def iter_range(n):
+        ...     return iter(range(n))
+        ...
+        >>> list(iter_range(9))
+        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
+
+    To only allow truthy items to be returned:
+
+        >>> truth_serum = make_decorator(filter, result_index=1)
+        >>> @truth_serum(bool)
+        ... def boolean_test():
+        ...     return [0, 1, '', ' ', False, True]
+        ...
+        >>> list(boolean_test())
+        [1, ' ', True]
+
+    The :func:`peekable` and :func:`seekable` wrappers make for practical
+    decorators:
+
+        >>> from more_itertools import peekable
+        >>> peekable_function = make_decorator(peekable)
+        >>> @peekable_function()
+        ... def str_range(*args):
+        ...     return (str(x) for x in range(*args))
+        ...
+        >>> it = str_range(1, 20, 2)
+        >>> next(it), next(it), next(it)
+        ('1', '3', '5')
+        >>> it.peek()
+        '7'
+        >>> next(it)
+        '7'
+
+    """
+    # See https://sites.google.com/site/bbayles/index/decorator_factory for
+    # notes on how this works.
+    def decorator(*wrapping_args, **wrapping_kwargs):
+        def outer_wrapper(f):
+            def inner_wrapper(*args, **kwargs):
+                result = f(*args, **kwargs)
+                wrapping_args_ = list(wrapping_args)
+                wrapping_args_.insert(result_index, result)
+                return wrapping_func(*wrapping_args_, **wrapping_kwargs)
+
+            return inner_wrapper
+
+        return outer_wrapper
+
+    return decorator
+
+
+def map_reduce(iterable, keyfunc, valuefunc=None, reducefunc=None):
+    """Return a dictionary that maps the items in *iterable* to categories
+    defined by *keyfunc*, transforms them with *valuefunc*, and
+    then summarizes them by category with *reducefunc*.
+
+    *valuefunc* defaults to the identity function if it is unspecified.
+    If *reducefunc* is unspecified, no summarization takes place:
+
+        >>> keyfunc = lambda x: x.upper()
+        >>> result = map_reduce('abbccc', keyfunc)
+        >>> sorted(result.items())
+        [('A', ['a']), ('B', ['b', 'b']), ('C', ['c', 'c', 'c'])]
+
+    Specifying *valuefunc* transforms the categorized items:
+
+        >>> keyfunc = lambda x: x.upper()
+        >>> valuefunc = lambda x: 1
+        >>> result = map_reduce('abbccc', keyfunc, valuefunc)
+        >>> sorted(result.items())
+        [('A', [1]), ('B', [1, 1]), ('C', [1, 1, 1])]
+
+    Specifying *reducefunc* summarizes the categorized items:
+
+        >>> keyfunc = lambda x: x.upper()
+        >>> valuefunc = lambda x: 1
+        >>> reducefunc = sum
+        >>> result = map_reduce('abbccc', keyfunc, valuefunc, reducefunc)
+        >>> sorted(result.items())
+        [('A', 1), ('B', 2), ('C', 3)]
+
+    You may want to filter the input iterable before applying the map/reduce
+    procedure:
+
+        >>> all_items = range(30)
+        >>> items = [x for x in all_items if 10 <= x <= 20]  # Filter
+        >>> keyfunc = lambda x: x % 2  # Evens map to 0; odds to 1
+        >>> categories = map_reduce(items, keyfunc=keyfunc)
+        >>> sorted(categories.items())
+        [(0, [10, 12, 14, 16, 18, 20]), (1, [11, 13, 15, 17, 19])]
+        >>> summaries = map_reduce(items, keyfunc=keyfunc, reducefunc=sum)
+        >>> sorted(summaries.items())
+        [(0, 90), (1, 75)]
+
+    Note that all items in the iterable are gathered into a list before the
+    summarization step, which may require significant storage.
+
+    The returned object is a :obj:`collections.defaultdict` with the
+    ``default_factory`` set to ``None``, such that it behaves like a normal
+    dictionary.
+
+    """
+    valuefunc = (lambda x: x) if (valuefunc is None) else valuefunc
+
+    ret = defaultdict(list)
+    for item in iterable:
+        key = keyfunc(item)
+        value = valuefunc(item)
+        ret[key].append(value)
+
+    if reducefunc is not None:
+        for key, value_list in ret.items():
+            ret[key] = reducefunc(value_list)
+
+    ret.default_factory = None
+    return ret
+
+
+def rlocate(iterable, pred=bool, window_size=None):
+    """Yield the index of each item in *iterable* for which *pred* returns
+    ``True``, starting from the right and moving left.
+
+    *pred* defaults to :func:`bool`, which will select truthy items:
+
+        >>> list(rlocate([0, 1, 1, 0, 1, 0, 0]))  # Truthy at 1, 2, and 4
+        [4, 2, 1]
+
+    Set *pred* to a custom function to, e.g., find the indexes for a particular
+    item:
+
+        >>> iterable = iter('abcb')
+        >>> pred = lambda x: x == 'b'
+        >>> list(rlocate(iterable, pred))
+        [3, 1]
+
+    If *window_size* is given, then the *pred* function will be called with
+    that many items. This enables searching for sub-sequences:
+
+        >>> iterable = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]
+        >>> pred = lambda *args: args == (1, 2, 3)
+        >>> list(rlocate(iterable, pred=pred, window_size=3))
+        [9, 5, 1]
+
+    Beware, this function won't return anything for infinite iterables.
+    If *iterable* is reversible, ``rlocate`` will reverse it and search from
+    the right. Otherwise, it will search from the left and return the results
+    in reverse order.
+
+    See :func:`locate` to for other example applications.
+
+    """
+    if window_size is None:
+        try:
+            len_iter = len(iterable)
+            return (
+                len_iter - i - 1 for i in locate(reversed(iterable), pred)
+            )
+        except TypeError:
+            pass
+
+    return reversed(list(locate(iterable, pred, window_size)))
+
+
+def replace(iterable, pred, substitutes, count=None, window_size=1):
+    """Yield the items from *iterable*, replacing the items for which *pred*
+    returns ``True`` with the items from the iterable *substitutes*.
+
+        >>> iterable = [1, 1, 0, 1, 1, 0, 1, 1]
+        >>> pred = lambda x: x == 0
+        >>> substitutes = (2, 3)
+        >>> list(replace(iterable, pred, substitutes))
+        [1, 1, 2, 3, 1, 1, 2, 3, 1, 1]
+
+    If *count* is given, the number of replacements will be limited:
+
+        >>> iterable = [1, 1, 0, 1, 1, 0, 1, 1, 0]
+        >>> pred = lambda x: x == 0
+        >>> substitutes = [None]
+        >>> list(replace(iterable, pred, substitutes, count=2))
+        [1, 1, None, 1, 1, None, 1, 1, 0]
+
+    Use *window_size* to control the number of items passed as arguments to
+    *pred*. This allows for locating and replacing subsequences.
+
+        >>> iterable = [0, 1, 2, 5, 0, 1, 2, 5]
+        >>> window_size = 3
+        >>> pred = lambda *args: args == (0, 1, 2)  # 3 items passed to pred
+        >>> substitutes = [3, 4] # Splice in these items
+        >>> list(replace(iterable, pred, substitutes, window_size=window_size))
+        [3, 4, 5, 3, 4, 5]
+
+    """
+    if window_size < 1:
+        raise ValueError('window_size must be at least 1')
+
+    # Save the substitutes iterable, since it's used more than once
+    substitutes = tuple(substitutes)
+
+    # Add padding such that the number of windows matches the length of the
+    # iterable
+    it = chain(iterable, [_marker] * (window_size - 1))
+    windows = windowed(it, window_size)
+
+    n = 0
+    for w in windows:
+        # If the current window matches our predicate (and we haven't hit
+        # our maximum number of replacements), splice in the substitutes
+        # and then consume the following windows that overlap with this one.
+        # For example, if the iterable is (0, 1, 2, 3, 4...)
+        # and the window size is 2, we have (0, 1), (1, 2), (2, 3)...
+        # If the predicate matches on (0, 1), we need to zap (0, 1) and (1, 2)
+        if pred(*w):
+            if (count is None) or (n < count):
+                n += 1
+                for s in substitutes:
+                    yield s
+                consume(windows, window_size - 1)
+                continue
+
+        # If there was no match (or we've reached the replacement limit),
+        # yield the first item from the window.
+        if w and (w[0] is not _marker):
+            yield w[0]
Index: venv/Lib/site-packages/six-1.11.0.dist-info/metadata.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six-1.11.0.dist-info/metadata.json	(date 1543190975430)
+++ venv/Lib/site-packages/six-1.11.0.dist-info/metadata.json	(date 1543190975430)
@@ -0,0 +1,1 @@
+{"classifiers": ["Programming Language :: Python :: 2", "Programming Language :: Python :: 3", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Topic :: Software Development :: Libraries", "Topic :: Utilities"], "extensions": {"python.details": {"contacts": [{"email": "benjamin@python.org", "name": "Benjamin Peterson", "role": "author"}], "document_names": {"description": "DESCRIPTION.rst"}, "project_urls": {"Home": "http://pypi.python.org/pypi/six/"}}}, "generator": "bdist_wheel (0.29.0)", "license": "MIT", "metadata_version": "2.0", "name": "six", "summary": "Python 2 and 3 compatibility utilities", "test_requires": [{"requires": ["pytest"]}], "version": "1.11.0"}
\ No newline at end of file
Index: venv/Lib/site-packages/six-1.11.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six-1.11.0.dist-info/WHEEL	(date 1543190974553)
+++ venv/Lib/site-packages/six-1.11.0.dist-info/WHEEL	(date 1543190974553)
@@ -0,0 +1,0 @@
Index: venv/Lib/site-packages/_pytest/assertion/rewrite.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/assertion/rewrite.py	(date 1543190975445)
+++ venv/Lib/site-packages/_pytest/assertion/rewrite.py	(date 1543190975445)
@@ -0,0 +1,1035 @@
+"""Rewrite assertion AST to produce nice error messages"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import ast
+import errno
+import imp
+import itertools
+import marshal
+import os
+import re
+import string
+import struct
+import sys
+import types
+
+import atomicwrites
+import py
+import six
+
+from _pytest.assertion import util
+from _pytest.compat import spec_from_file_location
+from _pytest.pathlib import fnmatch_ex
+from _pytest.pathlib import PurePath
+
+# pytest caches rewritten pycs in __pycache__.
+if hasattr(imp, "get_tag"):
+    PYTEST_TAG = imp.get_tag() + "-PYTEST"
+else:
+    if hasattr(sys, "pypy_version_info"):
+        impl = "pypy"
+    elif sys.platform == "java":
+        impl = "jython"
+    else:
+        impl = "cpython"
+    ver = sys.version_info
+    PYTEST_TAG = "%s-%s%s-PYTEST" % (impl, ver[0], ver[1])
+    del ver, impl
+
+PYC_EXT = ".py" + (__debug__ and "c" or "o")
+PYC_TAIL = "." + PYTEST_TAG + PYC_EXT
+
+ASCII_IS_DEFAULT_ENCODING = sys.version_info[0] < 3
+
+if sys.version_info >= (3, 5):
+    ast_Call = ast.Call
+else:
+
+    def ast_Call(a, b, c):
+        return ast.Call(a, b, c, None, None)
+
+
+class AssertionRewritingHook(object):
+    """PEP302 Import hook which rewrites asserts."""
+
+    def __init__(self, config):
+        self.config = config
+        self.fnpats = config.getini("python_files")
+        self.session = None
+        self.modules = {}
+        self._rewritten_names = set()
+        self._register_with_pkg_resources()
+        self._must_rewrite = set()
+        # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,
+        # which might result in infinite recursion (#3506)
+        self._writing_pyc = False
+        self._basenames_to_check_rewrite = {"conftest"}
+        self._marked_for_rewrite_cache = {}
+        self._session_paths_checked = False
+
+    def set_session(self, session):
+        self.session = session
+        self._session_paths_checked = False
+
+    def _imp_find_module(self, name, path=None):
+        """Indirection so we can mock calls to find_module originated from the hook during testing"""
+        return imp.find_module(name, path)
+
+    def find_module(self, name, path=None):
+        if self._writing_pyc:
+            return None
+        state = self.config._assertstate
+        if self._early_rewrite_bailout(name, state):
+            return None
+        state.trace("find_module called for: %s" % name)
+        names = name.rsplit(".", 1)
+        lastname = names[-1]
+        pth = None
+        if path is not None:
+            # Starting with Python 3.3, path is a _NamespacePath(), which
+            # causes problems if not converted to list.
+            path = list(path)
+            if len(path) == 1:
+                pth = path[0]
+        if pth is None:
+            try:
+                fd, fn, desc = self._imp_find_module(lastname, path)
+            except ImportError:
+                return None
+            if fd is not None:
+                fd.close()
+            tp = desc[2]
+            if tp == imp.PY_COMPILED:
+                if hasattr(imp, "source_from_cache"):
+                    try:
+                        fn = imp.source_from_cache(fn)
+                    except ValueError:
+                        # Python 3 doesn't like orphaned but still-importable
+                        # .pyc files.
+                        fn = fn[:-1]
+                else:
+                    fn = fn[:-1]
+            elif tp != imp.PY_SOURCE:
+                # Don't know what this is.
+                return None
+        else:
+            fn = os.path.join(pth, name.rpartition(".")[2] + ".py")
+
+        fn_pypath = py.path.local(fn)
+        if not self._should_rewrite(name, fn_pypath, state):
+            return None
+
+        self._rewritten_names.add(name)
+
+        # The requested module looks like a test file, so rewrite it. This is
+        # the most magical part of the process: load the source, rewrite the
+        # asserts, and load the rewritten source. We also cache the rewritten
+        # module code in a special pyc. We must be aware of the possibility of
+        # concurrent pytest processes rewriting and loading pycs. To avoid
+        # tricky race conditions, we maintain the following invariant: The
+        # cached pyc is always a complete, valid pyc. Operations on it must be
+        # atomic. POSIX's atomic rename comes in handy.
+        write = not sys.dont_write_bytecode
+        cache_dir = os.path.join(fn_pypath.dirname, "__pycache__")
+        if write:
+            try:
+                os.mkdir(cache_dir)
+            except OSError:
+                e = sys.exc_info()[1].errno
+                if e == errno.EEXIST:
+                    # Either the __pycache__ directory already exists (the
+                    # common case) or it's blocked by a non-dir node. In the
+                    # latter case, we'll ignore it in _write_pyc.
+                    pass
+                elif e in [errno.ENOENT, errno.ENOTDIR]:
+                    # One of the path components was not a directory, likely
+                    # because we're in a zip file.
+                    write = False
+                elif e in [errno.EACCES, errno.EROFS, errno.EPERM]:
+                    state.trace("read only directory: %r" % fn_pypath.dirname)
+                    write = False
+                else:
+                    raise
+        cache_name = fn_pypath.basename[:-3] + PYC_TAIL
+        pyc = os.path.join(cache_dir, cache_name)
+        # Notice that even if we're in a read-only directory, I'm going
+        # to check for a cached pyc. This may not be optimal...
+        co = _read_pyc(fn_pypath, pyc, state.trace)
+        if co is None:
+            state.trace("rewriting %r" % (fn,))
+            source_stat, co = _rewrite_test(self.config, fn_pypath)
+            if co is None:
+                # Probably a SyntaxError in the test.
+                return None
+            if write:
+                self._writing_pyc = True
+                try:
+                    _write_pyc(state, co, source_stat, pyc)
+                finally:
+                    self._writing_pyc = False
+        else:
+            state.trace("found cached rewritten pyc for %r" % (fn,))
+        self.modules[name] = co, pyc
+        return self
+
+    def _early_rewrite_bailout(self, name, state):
+        """
+        This is a fast way to get out of rewriting modules. Profiling has
+        shown that the call to imp.find_module (inside of the find_module
+        from this class) is a major slowdown, so, this method tries to
+        filter what we're sure won't be rewritten before getting to it.
+        """
+        if self.session is not None and not self._session_paths_checked:
+            self._session_paths_checked = True
+            for path in self.session._initialpaths:
+                # Make something as c:/projects/my_project/path.py ->
+                #     ['c:', 'projects', 'my_project', 'path.py']
+                parts = str(path).split(os.path.sep)
+                # add 'path' to basenames to be checked.
+                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])
+
+        # Note: conftest already by default in _basenames_to_check_rewrite.
+        parts = name.split(".")
+        if parts[-1] in self._basenames_to_check_rewrite:
+            return False
+
+        # For matching the name it must be as if it was a filename.
+        path = PurePath(os.path.sep.join(parts) + ".py")
+
+        for pat in self.fnpats:
+            # if the pattern contains subdirectories ("tests/**.py" for example) we can't bail out based
+            # on the name alone because we need to match against the full path
+            if os.path.dirname(pat):
+                return False
+            if fnmatch_ex(pat, path):
+                return False
+
+        if self._is_marked_for_rewrite(name, state):
+            return False
+
+        state.trace("early skip of rewriting module: %s" % (name,))
+        return True
+
+    def _should_rewrite(self, name, fn_pypath, state):
+        # always rewrite conftest files
+        fn = str(fn_pypath)
+        if fn_pypath.basename == "conftest.py":
+            state.trace("rewriting conftest file: %r" % (fn,))
+            return True
+
+        if self.session is not None:
+            if self.session.isinitpath(fn):
+                state.trace("matched test file (was specified on cmdline): %r" % (fn,))
+                return True
+
+        # modules not passed explicitly on the command line are only
+        # rewritten if they match the naming convention for test files
+        for pat in self.fnpats:
+            if fn_pypath.fnmatch(pat):
+                state.trace("matched test file %r" % (fn,))
+                return True
+
+        return self._is_marked_for_rewrite(name, state)
+
+    def _is_marked_for_rewrite(self, name, state):
+        try:
+            return self._marked_for_rewrite_cache[name]
+        except KeyError:
+            for marked in self._must_rewrite:
+                if name == marked or name.startswith(marked + "."):
+                    state.trace("matched marked file %r (from %r)" % (name, marked))
+                    self._marked_for_rewrite_cache[name] = True
+                    return True
+
+            self._marked_for_rewrite_cache[name] = False
+            return False
+
+    def mark_rewrite(self, *names):
+        """Mark import names as needing to be rewritten.
+
+        The named module or package as well as any nested modules will
+        be rewritten on import.
+        """
+        already_imported = (
+            set(names).intersection(sys.modules).difference(self._rewritten_names)
+        )
+        for name in already_imported:
+            if not AssertionRewriter.is_rewrite_disabled(
+                sys.modules[name].__doc__ or ""
+            ):
+                self._warn_already_imported(name)
+        self._must_rewrite.update(names)
+        self._marked_for_rewrite_cache.clear()
+
+    def _warn_already_imported(self, name):
+        from _pytest.warning_types import PytestWarning
+        from _pytest.warnings import _issue_config_warning
+
+        _issue_config_warning(
+            PytestWarning("Module already imported so cannot be rewritten: %s" % name),
+            self.config,
+        )
+
+    def load_module(self, name):
+        co, pyc = self.modules.pop(name)
+        if name in sys.modules:
+            # If there is an existing module object named 'fullname' in
+            # sys.modules, the loader must use that existing module. (Otherwise,
+            # the reload() builtin will not work correctly.)
+            mod = sys.modules[name]
+        else:
+            # I wish I could just call imp.load_compiled here, but __file__ has to
+            # be set properly. In Python 3.2+, this all would be handled correctly
+            # by load_compiled.
+            mod = sys.modules[name] = imp.new_module(name)
+        try:
+            mod.__file__ = co.co_filename
+            # Normally, this attribute is 3.2+.
+            mod.__cached__ = pyc
+            mod.__loader__ = self
+            # Normally, this attribute is 3.4+
+            mod.__spec__ = spec_from_file_location(name, co.co_filename, loader=self)
+            six.exec_(co, mod.__dict__)
+        except:  # noqa
+            if name in sys.modules:
+                del sys.modules[name]
+            raise
+        return sys.modules[name]
+
+    def is_package(self, name):
+        try:
+            fd, fn, desc = self._imp_find_module(name)
+        except ImportError:
+            return False
+        if fd is not None:
+            fd.close()
+        tp = desc[2]
+        return tp == imp.PKG_DIRECTORY
+
+    @classmethod
+    def _register_with_pkg_resources(cls):
+        """
+        Ensure package resources can be loaded from this loader. May be called
+        multiple times, as the operation is idempotent.
+        """
+        try:
+            import pkg_resources
+
+            # access an attribute in case a deferred importer is present
+            pkg_resources.__name__
+        except ImportError:
+            return
+
+        # Since pytest tests are always located in the file system, the
+        #  DefaultProvider is appropriate.
+        pkg_resources.register_loader_type(cls, pkg_resources.DefaultProvider)
+
+    def get_data(self, pathname):
+        """Optional PEP302 get_data API.
+        """
+        with open(pathname, "rb") as f:
+            return f.read()
+
+
+def _write_pyc(state, co, source_stat, pyc):
+    # Technically, we don't have to have the same pyc format as
+    # (C)Python, since these "pycs" should never be seen by builtin
+    # import. However, there's little reason deviate, and I hope
+    # sometime to be able to use imp.load_compiled to load them. (See
+    # the comment in load_module above.)
+    try:
+        with atomicwrites.atomic_write(pyc, mode="wb", overwrite=True) as fp:
+            fp.write(imp.get_magic())
+            mtime = int(source_stat.mtime)
+            size = source_stat.size & 0xFFFFFFFF
+            fp.write(struct.pack("<ll", mtime, size))
+            fp.write(marshal.dumps(co))
+    except EnvironmentError as e:
+        state.trace("error writing pyc file at %s: errno=%s" % (pyc, e.errno))
+        # we ignore any failure to write the cache file
+        # there are many reasons, permission-denied, __pycache__ being a
+        # file etc.
+        return False
+    return True
+
+
+RN = "\r\n".encode("utf-8")
+N = "\n".encode("utf-8")
+
+cookie_re = re.compile(r"^[ \t\f]*#.*coding[:=][ \t]*[-\w.]+")
+BOM_UTF8 = "\xef\xbb\xbf"
+
+
+def _rewrite_test(config, fn):
+    """Try to read and rewrite *fn* and return the code object."""
+    state = config._assertstate
+    try:
+        stat = fn.stat()
+        source = fn.read("rb")
+    except EnvironmentError:
+        return None, None
+    if ASCII_IS_DEFAULT_ENCODING:
+        # ASCII is the default encoding in Python 2. Without a coding
+        # declaration, Python 2 will complain about any bytes in the file
+        # outside the ASCII range. Sadly, this behavior does not extend to
+        # compile() or ast.parse(), which prefer to interpret the bytes as
+        # latin-1. (At least they properly handle explicit coding cookies.) To
+        # preserve this error behavior, we could force ast.parse() to use ASCII
+        # as the encoding by inserting a coding cookie. Unfortunately, that
+        # messes up line numbers. Thus, we have to check ourselves if anything
+        # is outside the ASCII range in the case no encoding is explicitly
+        # declared. For more context, see issue #269. Yay for Python 3 which
+        # gets this right.
+        end1 = source.find("\n")
+        end2 = source.find("\n", end1 + 1)
+        if (
+            not source.startswith(BOM_UTF8)
+            and cookie_re.match(source[0:end1]) is None
+            and cookie_re.match(source[end1 + 1 : end2]) is None
+        ):
+            if hasattr(state, "_indecode"):
+                # encodings imported us again, so don't rewrite.
+                return None, None
+            state._indecode = True
+            try:
+                try:
+                    source.decode("ascii")
+                except UnicodeDecodeError:
+                    # Let it fail in real import.
+                    return None, None
+            finally:
+                del state._indecode
+    try:
+        tree = ast.parse(source, filename=fn.strpath)
+    except SyntaxError:
+        # Let this pop up again in the real import.
+        state.trace("failed to parse: %r" % (fn,))
+        return None, None
+    rewrite_asserts(tree, fn, config)
+    try:
+        co = compile(tree, fn.strpath, "exec", dont_inherit=True)
+    except SyntaxError:
+        # It's possible that this error is from some bug in the
+        # assertion rewriting, but I don't know of a fast way to tell.
+        state.trace("failed to compile: %r" % (fn,))
+        return None, None
+    return stat, co
+
+
+def _read_pyc(source, pyc, trace=lambda x: None):
+    """Possibly read a pytest pyc containing rewritten code.
+
+    Return rewritten code if successful or None if not.
+    """
+    try:
+        fp = open(pyc, "rb")
+    except IOError:
+        return None
+    with fp:
+        try:
+            mtime = int(source.mtime())
+            size = source.size()
+            data = fp.read(12)
+        except EnvironmentError as e:
+            trace("_read_pyc(%s): EnvironmentError %s" % (source, e))
+            return None
+        # Check for invalid or out of date pyc file.
+        if (
+            len(data) != 12
+            or data[:4] != imp.get_magic()
+            or struct.unpack("<ll", data[4:]) != (mtime, size)
+        ):
+            trace("_read_pyc(%s): invalid or out of date pyc" % source)
+            return None
+        try:
+            co = marshal.load(fp)
+        except Exception as e:
+            trace("_read_pyc(%s): marshal.load error %s" % (source, e))
+            return None
+        if not isinstance(co, types.CodeType):
+            trace("_read_pyc(%s): not a code object" % source)
+            return None
+        return co
+
+
+def rewrite_asserts(mod, module_path=None, config=None):
+    """Rewrite the assert statements in mod."""
+    AssertionRewriter(module_path, config).run(mod)
+
+
+def _saferepr(obj):
+    """Get a safe repr of an object for assertion error messages.
+
+    The assertion formatting (util.format_explanation()) requires
+    newlines to be escaped since they are a special character for it.
+    Normally assertion.util.format_explanation() does this but for a
+    custom repr it is possible to contain one of the special escape
+    sequences, especially '\n{' and '\n}' are likely to be present in
+    JSON reprs.
+
+    """
+    r = py.io.saferepr(obj)
+    # only occurs in python2.x, repr must return text in python3+
+    if isinstance(r, bytes):
+        # Represent unprintable bytes as `\x##`
+        r = u"".join(
+            u"\\x{:x}".format(ord(c)) if c not in string.printable else c.decode()
+            for c in r
+        )
+    return r.replace(u"\n", u"\\n")
+
+
+from _pytest.assertion.util import format_explanation as _format_explanation  # noqa
+
+
+def _format_assertmsg(obj):
+    """Format the custom assertion message given.
+
+    For strings this simply replaces newlines with '\n~' so that
+    util.format_explanation() will preserve them instead of escaping
+    newlines.  For other objects py.io.saferepr() is used first.
+
+    """
+    # reprlib appears to have a bug which means that if a string
+    # contains a newline it gets escaped, however if an object has a
+    # .__repr__() which contains newlines it does not get escaped.
+    # However in either case we want to preserve the newline.
+    replaces = [(u"\n", u"\n~"), (u"%", u"%%")]
+    if not isinstance(obj, six.string_types):
+        obj = py.io.saferepr(obj)
+        replaces.append((u"\\n", u"\n~"))
+
+    if isinstance(obj, bytes):
+        replaces = [(r1.encode(), r2.encode()) for r1, r2 in replaces]
+
+    for r1, r2 in replaces:
+        obj = obj.replace(r1, r2)
+
+    return obj
+
+
+def _should_repr_global_name(obj):
+    return not hasattr(obj, "__name__") and not callable(obj)
+
+
+def _format_boolop(explanations, is_or):
+    explanation = "(" + (is_or and " or " or " and ").join(explanations) + ")"
+    if isinstance(explanation, six.text_type):
+        return explanation.replace(u"%", u"%%")
+    else:
+        return explanation.replace(b"%", b"%%")
+
+
+def _call_reprcompare(ops, results, expls, each_obj):
+    for i, res, expl in zip(range(len(ops)), results, expls):
+        try:
+            done = not res
+        except Exception:
+            done = True
+        if done:
+            break
+    if util._reprcompare is not None:
+        custom = util._reprcompare(ops[i], each_obj[i], each_obj[i + 1])
+        if custom is not None:
+            return custom
+    return expl
+
+
+unary_map = {ast.Not: "not %s", ast.Invert: "~%s", ast.USub: "-%s", ast.UAdd: "+%s"}
+
+binop_map = {
+    ast.BitOr: "|",
+    ast.BitXor: "^",
+    ast.BitAnd: "&",
+    ast.LShift: "<<",
+    ast.RShift: ">>",
+    ast.Add: "+",
+    ast.Sub: "-",
+    ast.Mult: "*",
+    ast.Div: "/",
+    ast.FloorDiv: "//",
+    ast.Mod: "%%",  # escaped for string formatting
+    ast.Eq: "==",
+    ast.NotEq: "!=",
+    ast.Lt: "<",
+    ast.LtE: "<=",
+    ast.Gt: ">",
+    ast.GtE: ">=",
+    ast.Pow: "**",
+    ast.Is: "is",
+    ast.IsNot: "is not",
+    ast.In: "in",
+    ast.NotIn: "not in",
+}
+# Python 3.5+ compatibility
+try:
+    binop_map[ast.MatMult] = "@"
+except AttributeError:
+    pass
+
+# Python 3.4+ compatibility
+if hasattr(ast, "NameConstant"):
+    _NameConstant = ast.NameConstant
+else:
+
+    def _NameConstant(c):
+        return ast.Name(str(c), ast.Load())
+
+
+def set_location(node, lineno, col_offset):
+    """Set node location information recursively."""
+
+    def _fix(node, lineno, col_offset):
+        if "lineno" in node._attributes:
+            node.lineno = lineno
+        if "col_offset" in node._attributes:
+            node.col_offset = col_offset
+        for child in ast.iter_child_nodes(node):
+            _fix(child, lineno, col_offset)
+
+    _fix(node, lineno, col_offset)
+    return node
+
+
+class AssertionRewriter(ast.NodeVisitor):
+    """Assertion rewriting implementation.
+
+    The main entrypoint is to call .run() with an ast.Module instance,
+    this will then find all the assert statements and rewrite them to
+    provide intermediate values and a detailed assertion error.  See
+    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html
+    for an overview of how this works.
+
+    The entry point here is .run() which will iterate over all the
+    statements in an ast.Module and for each ast.Assert statement it
+    finds call .visit() with it.  Then .visit_Assert() takes over and
+    is responsible for creating new ast statements to replace the
+    original assert statement: it rewrites the test of an assertion
+    to provide intermediate values and replace it with an if statement
+    which raises an assertion error with a detailed explanation in
+    case the expression is false.
+
+    For this .visit_Assert() uses the visitor pattern to visit all the
+    AST nodes of the ast.Assert.test field, each visit call returning
+    an AST node and the corresponding explanation string.  During this
+    state is kept in several instance attributes:
+
+    :statements: All the AST statements which will replace the assert
+       statement.
+
+    :variables: This is populated by .variable() with each variable
+       used by the statements so that they can all be set to None at
+       the end of the statements.
+
+    :variable_counter: Counter to create new unique variables needed
+       by statements.  Variables are created using .variable() and
+       have the form of "@py_assert0".
+
+    :on_failure: The AST statements which will be executed if the
+       assertion test fails.  This is the code which will construct
+       the failure message and raises the AssertionError.
+
+    :explanation_specifiers: A dict filled by .explanation_param()
+       with %-formatting placeholders and their corresponding
+       expressions to use in the building of an assertion message.
+       This is used by .pop_format_context() to build a message.
+
+    :stack: A stack of the explanation_specifiers dicts maintained by
+       .push_format_context() and .pop_format_context() which allows
+       to build another %-formatted string while already building one.
+
+    This state is reset on every new assert statement visited and used
+    by the other visitors.
+
+    """
+
+    def __init__(self, module_path, config):
+        super(AssertionRewriter, self).__init__()
+        self.module_path = module_path
+        self.config = config
+
+    def run(self, mod):
+        """Find all assert statements in *mod* and rewrite them."""
+        if not mod.body:
+            # Nothing to do.
+            return
+        # Insert some special imports at the top of the module but after any
+        # docstrings and __future__ imports.
+        aliases = [
+            ast.alias(py.builtin.builtins.__name__, "@py_builtins"),
+            ast.alias("_pytest.assertion.rewrite", "@pytest_ar"),
+        ]
+        doc = getattr(mod, "docstring", None)
+        expect_docstring = doc is None
+        if doc is not None and self.is_rewrite_disabled(doc):
+            return
+        pos = 0
+        lineno = 1
+        for item in mod.body:
+            if (
+                expect_docstring
+                and isinstance(item, ast.Expr)
+                and isinstance(item.value, ast.Str)
+            ):
+                doc = item.value.s
+                if self.is_rewrite_disabled(doc):
+                    return
+                expect_docstring = False
+            elif (
+                not isinstance(item, ast.ImportFrom)
+                or item.level > 0
+                or item.module != "__future__"
+            ):
+                lineno = item.lineno
+                break
+            pos += 1
+        else:
+            lineno = item.lineno
+        imports = [
+            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases
+        ]
+        mod.body[pos:pos] = imports
+        # Collect asserts.
+        nodes = [mod]
+        while nodes:
+            node = nodes.pop()
+            for name, field in ast.iter_fields(node):
+                if isinstance(field, list):
+                    new = []
+                    for i, child in enumerate(field):
+                        if isinstance(child, ast.Assert):
+                            # Transform assert.
+                            new.extend(self.visit(child))
+                        else:
+                            new.append(child)
+                            if isinstance(child, ast.AST):
+                                nodes.append(child)
+                    setattr(node, name, new)
+                elif (
+                    isinstance(field, ast.AST)
+                    # Don't recurse into expressions as they can't contain
+                    # asserts.
+                    and not isinstance(field, ast.expr)
+                ):
+                    nodes.append(field)
+
+    @staticmethod
+    def is_rewrite_disabled(docstring):
+        return "PYTEST_DONT_REWRITE" in docstring
+
+    def variable(self):
+        """Get a new variable."""
+        # Use a character invalid in python identifiers to avoid clashing.
+        name = "@py_assert" + str(next(self.variable_counter))
+        self.variables.append(name)
+        return name
+
+    def assign(self, expr):
+        """Give *expr* a name."""
+        name = self.variable()
+        self.statements.append(ast.Assign([ast.Name(name, ast.Store())], expr))
+        return ast.Name(name, ast.Load())
+
+    def display(self, expr):
+        """Call py.io.saferepr on the expression."""
+        return self.helper("saferepr", expr)
+
+    def helper(self, name, *args):
+        """Call a helper in this module."""
+        py_name = ast.Name("@pytest_ar", ast.Load())
+        attr = ast.Attribute(py_name, "_" + name, ast.Load())
+        return ast_Call(attr, list(args), [])
+
+    def builtin(self, name):
+        """Return the builtin called *name*."""
+        builtin_name = ast.Name("@py_builtins", ast.Load())
+        return ast.Attribute(builtin_name, name, ast.Load())
+
+    def explanation_param(self, expr):
+        """Return a new named %-formatting placeholder for expr.
+
+        This creates a %-formatting placeholder for expr in the
+        current formatting context, e.g. ``%(py0)s``.  The placeholder
+        and expr are placed in the current format context so that it
+        can be used on the next call to .pop_format_context().
+
+        """
+        specifier = "py" + str(next(self.variable_counter))
+        self.explanation_specifiers[specifier] = expr
+        return "%(" + specifier + ")s"
+
+    def push_format_context(self):
+        """Create a new formatting context.
+
+        The format context is used for when an explanation wants to
+        have a variable value formatted in the assertion message.  In
+        this case the value required can be added using
+        .explanation_param().  Finally .pop_format_context() is used
+        to format a string of %-formatted values as added by
+        .explanation_param().
+
+        """
+        self.explanation_specifiers = {}
+        self.stack.append(self.explanation_specifiers)
+
+    def pop_format_context(self, expl_expr):
+        """Format the %-formatted string with current format context.
+
+        The expl_expr should be an ast.Str instance constructed from
+        the %-placeholders created by .explanation_param().  This will
+        add the required code to format said string to .on_failure and
+        return the ast.Name instance of the formatted string.
+
+        """
+        current = self.stack.pop()
+        if self.stack:
+            self.explanation_specifiers = self.stack[-1]
+        keys = [ast.Str(key) for key in current.keys()]
+        format_dict = ast.Dict(keys, list(current.values()))
+        form = ast.BinOp(expl_expr, ast.Mod(), format_dict)
+        name = "@py_format" + str(next(self.variable_counter))
+        self.on_failure.append(ast.Assign([ast.Name(name, ast.Store())], form))
+        return ast.Name(name, ast.Load())
+
+    def generic_visit(self, node):
+        """Handle expressions we don't have custom code for."""
+        assert isinstance(node, ast.expr)
+        res = self.assign(node)
+        return res, self.explanation_param(self.display(res))
+
+    def visit_Assert(self, assert_):
+        """Return the AST statements to replace the ast.Assert instance.
+
+        This rewrites the test of an assertion to provide
+        intermediate values and replace it with an if statement which
+        raises an assertion error with a detailed explanation in case
+        the expression is false.
+
+        """
+        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:
+            from _pytest.warning_types import PytestWarning
+            import warnings
+
+            warnings.warn_explicit(
+                PytestWarning("assertion is always true, perhaps remove parentheses?"),
+                category=None,
+                filename=str(self.module_path),
+                lineno=assert_.lineno,
+            )
+
+        self.statements = []
+        self.variables = []
+        self.variable_counter = itertools.count()
+        self.stack = []
+        self.on_failure = []
+        self.push_format_context()
+        # Rewrite assert into a bunch of statements.
+        top_condition, explanation = self.visit(assert_.test)
+        # Create failure message.
+        body = self.on_failure
+        negation = ast.UnaryOp(ast.Not(), top_condition)
+        self.statements.append(ast.If(negation, body, []))
+        if assert_.msg:
+            assertmsg = self.helper("format_assertmsg", assert_.msg)
+            explanation = "\n>assert " + explanation
+        else:
+            assertmsg = ast.Str("")
+            explanation = "assert " + explanation
+        template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))
+        msg = self.pop_format_context(template)
+        fmt = self.helper("format_explanation", msg)
+        err_name = ast.Name("AssertionError", ast.Load())
+        exc = ast_Call(err_name, [fmt], [])
+        if sys.version_info[0] >= 3:
+            raise_ = ast.Raise(exc, None)
+        else:
+            raise_ = ast.Raise(exc, None, None)
+        body.append(raise_)
+        # Clear temporary variables by setting them to None.
+        if self.variables:
+            variables = [ast.Name(name, ast.Store()) for name in self.variables]
+            clear = ast.Assign(variables, _NameConstant(None))
+            self.statements.append(clear)
+        # Fix line numbers.
+        for stmt in self.statements:
+            set_location(stmt, assert_.lineno, assert_.col_offset)
+        return self.statements
+
+    def visit_Name(self, name):
+        # Display the repr of the name if it's a local variable or
+        # _should_repr_global_name() thinks it's acceptable.
+        locs = ast_Call(self.builtin("locals"), [], [])
+        inlocs = ast.Compare(ast.Str(name.id), [ast.In()], [locs])
+        dorepr = self.helper("should_repr_global_name", name)
+        test = ast.BoolOp(ast.Or(), [inlocs, dorepr])
+        expr = ast.IfExp(test, self.display(name), ast.Str(name.id))
+        return name, self.explanation_param(expr)
+
+    def visit_BoolOp(self, boolop):
+        res_var = self.variable()
+        expl_list = self.assign(ast.List([], ast.Load()))
+        app = ast.Attribute(expl_list, "append", ast.Load())
+        is_or = int(isinstance(boolop.op, ast.Or))
+        body = save = self.statements
+        fail_save = self.on_failure
+        levels = len(boolop.values) - 1
+        self.push_format_context()
+        # Process each operand, short-circuting if needed.
+        for i, v in enumerate(boolop.values):
+            if i:
+                fail_inner = []
+                # cond is set in a prior loop iteration below
+                self.on_failure.append(ast.If(cond, fail_inner, []))  # noqa
+                self.on_failure = fail_inner
+            self.push_format_context()
+            res, expl = self.visit(v)
+            body.append(ast.Assign([ast.Name(res_var, ast.Store())], res))
+            expl_format = self.pop_format_context(ast.Str(expl))
+            call = ast_Call(app, [expl_format], [])
+            self.on_failure.append(ast.Expr(call))
+            if i < levels:
+                cond = res
+                if is_or:
+                    cond = ast.UnaryOp(ast.Not(), cond)
+                inner = []
+                self.statements.append(ast.If(cond, inner, []))
+                self.statements = body = inner
+        self.statements = save
+        self.on_failure = fail_save
+        expl_template = self.helper("format_boolop", expl_list, ast.Num(is_or))
+        expl = self.pop_format_context(expl_template)
+        return ast.Name(res_var, ast.Load()), self.explanation_param(expl)
+
+    def visit_UnaryOp(self, unary):
+        pattern = unary_map[unary.op.__class__]
+        operand_res, operand_expl = self.visit(unary.operand)
+        res = self.assign(ast.UnaryOp(unary.op, operand_res))
+        return res, pattern % (operand_expl,)
+
+    def visit_BinOp(self, binop):
+        symbol = binop_map[binop.op.__class__]
+        left_expr, left_expl = self.visit(binop.left)
+        right_expr, right_expl = self.visit(binop.right)
+        explanation = "(%s %s %s)" % (left_expl, symbol, right_expl)
+        res = self.assign(ast.BinOp(left_expr, binop.op, right_expr))
+        return res, explanation
+
+    def visit_Call_35(self, call):
+        """
+        visit `ast.Call` nodes on Python3.5 and after
+        """
+        new_func, func_expl = self.visit(call.func)
+        arg_expls = []
+        new_args = []
+        new_kwargs = []
+        for arg in call.args:
+            res, expl = self.visit(arg)
+            arg_expls.append(expl)
+            new_args.append(res)
+        for keyword in call.keywords:
+            res, expl = self.visit(keyword.value)
+            new_kwargs.append(ast.keyword(keyword.arg, res))
+            if keyword.arg:
+                arg_expls.append(keyword.arg + "=" + expl)
+            else:  # **args have `arg` keywords with an .arg of None
+                arg_expls.append("**" + expl)
+
+        expl = "%s(%s)" % (func_expl, ", ".join(arg_expls))
+        new_call = ast.Call(new_func, new_args, new_kwargs)
+        res = self.assign(new_call)
+        res_expl = self.explanation_param(self.display(res))
+        outer_expl = "%s\n{%s = %s\n}" % (res_expl, res_expl, expl)
+        return res, outer_expl
+
+    def visit_Starred(self, starred):
+        # From Python 3.5, a Starred node can appear in a function call
+        res, expl = self.visit(starred.value)
+        return starred, "*" + expl
+
+    def visit_Call_legacy(self, call):
+        """
+        visit `ast.Call nodes on 3.4 and below`
+        """
+        new_func, func_expl = self.visit(call.func)
+        arg_expls = []
+        new_args = []
+        new_kwargs = []
+        new_star = new_kwarg = None
+        for arg in call.args:
+            res, expl = self.visit(arg)
+            new_args.append(res)
+            arg_expls.append(expl)
+        for keyword in call.keywords:
+            res, expl = self.visit(keyword.value)
+            new_kwargs.append(ast.keyword(keyword.arg, res))
+            arg_expls.append(keyword.arg + "=" + expl)
+        if call.starargs:
+            new_star, expl = self.visit(call.starargs)
+            arg_expls.append("*" + expl)
+        if call.kwargs:
+            new_kwarg, expl = self.visit(call.kwargs)
+            arg_expls.append("**" + expl)
+        expl = "%s(%s)" % (func_expl, ", ".join(arg_expls))
+        new_call = ast.Call(new_func, new_args, new_kwargs, new_star, new_kwarg)
+        res = self.assign(new_call)
+        res_expl = self.explanation_param(self.display(res))
+        outer_expl = "%s\n{%s = %s\n}" % (res_expl, res_expl, expl)
+        return res, outer_expl
+
+    # ast.Call signature changed on 3.5,
+    # conditionally change  which methods is named
+    # visit_Call depending on Python version
+    if sys.version_info >= (3, 5):
+        visit_Call = visit_Call_35
+    else:
+        visit_Call = visit_Call_legacy
+
+    def visit_Attribute(self, attr):
+        if not isinstance(attr.ctx, ast.Load):
+            return self.generic_visit(attr)
+        value, value_expl = self.visit(attr.value)
+        res = self.assign(ast.Attribute(value, attr.attr, ast.Load()))
+        res_expl = self.explanation_param(self.display(res))
+        pat = "%s\n{%s = %s.%s\n}"
+        expl = pat % (res_expl, res_expl, value_expl, attr.attr)
+        return res, expl
+
+    def visit_Compare(self, comp):
+        self.push_format_context()
+        left_res, left_expl = self.visit(comp.left)
+        if isinstance(comp.left, (ast.Compare, ast.BoolOp)):
+            left_expl = "({})".format(left_expl)
+        res_variables = [self.variable() for i in range(len(comp.ops))]
+        load_names = [ast.Name(v, ast.Load()) for v in res_variables]
+        store_names = [ast.Name(v, ast.Store()) for v in res_variables]
+        it = zip(range(len(comp.ops)), comp.ops, comp.comparators)
+        expls = []
+        syms = []
+        results = [left_res]
+        for i, op, next_operand in it:
+            next_res, next_expl = self.visit(next_operand)
+            if isinstance(next_operand, (ast.Compare, ast.BoolOp)):
+                next_expl = "({})".format(next_expl)
+            results.append(next_res)
+            sym = binop_map[op.__class__]
+            syms.append(ast.Str(sym))
+            expl = "%s %s %s" % (left_expl, sym, next_expl)
+            expls.append(ast.Str(expl))
+            res_expr = ast.Compare(left_res, [op], [next_res])
+            self.statements.append(ast.Assign([store_names[i]], res_expr))
+            left_res, left_expl = next_res, next_expl
+        # Use pytest.assertion.util._reprcompare if that's available.
+        expl_call = self.helper(
+            "call_reprcompare",
+            ast.Tuple(syms, ast.Load()),
+            ast.Tuple(load_names, ast.Load()),
+            ast.Tuple(expls, ast.Load()),
+            ast.Tuple(results, ast.Load()),
+        )
+        if len(comp.ops) > 1:
+            res = ast.BoolOp(ast.And(), load_names)
+        else:
+            res = load_names[0]
+        return res, self.explanation_param(self.pop_format_context(expl_call))
Index: venv/Lib/site-packages/more_itertools-4.3.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools-4.3.0.dist-info/METADATA	(date 1543190974557)
+++ venv/Lib/site-packages/more_itertools-4.3.0.dist-info/METADATA	(date 1543190974557)
@@ -0,0 +1,0 @@
Index: venv/Lib/site-packages/_pytest/assertion/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/assertion/__init__.py	(date 1543190975459)
+++ venv/Lib/site-packages/_pytest/assertion/__init__.py	(date 1543190975459)
@@ -0,0 +1,155 @@
+"""
+support for presenting detailed information in failing assertions.
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import sys
+
+import six
+
+from _pytest.assertion import rewrite
+from _pytest.assertion import truncate
+from _pytest.assertion import util
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("debugconfig")
+    group.addoption(
+        "--assert",
+        action="store",
+        dest="assertmode",
+        choices=("rewrite", "plain"),
+        default="rewrite",
+        metavar="MODE",
+        help="""Control assertion debugging tools.  'plain'
+                            performs no assertion debugging.  'rewrite'
+                            (the default) rewrites assert statements in
+                            test modules on import to provide assert
+                            expression information.""",
+    )
+
+
+def register_assert_rewrite(*names):
+    """Register one or more module names to be rewritten on import.
+
+    This function will make sure that this module or all modules inside
+    the package will get their assert statements rewritten.
+    Thus you should make sure to call this before the module is
+    actually imported, usually in your __init__.py if you are a plugin
+    using a package.
+
+    :raise TypeError: if the given module names are not strings.
+    """
+    for name in names:
+        if not isinstance(name, str):
+            msg = "expected module names as *args, got {0} instead"
+            raise TypeError(msg.format(repr(names)))
+    for hook in sys.meta_path:
+        if isinstance(hook, rewrite.AssertionRewritingHook):
+            importhook = hook
+            break
+    else:
+        importhook = DummyRewriteHook()
+    importhook.mark_rewrite(*names)
+
+
+class DummyRewriteHook(object):
+    """A no-op import hook for when rewriting is disabled."""
+
+    def mark_rewrite(self, *names):
+        pass
+
+
+class AssertionState(object):
+    """State for the assertion plugin."""
+
+    def __init__(self, config, mode):
+        self.mode = mode
+        self.trace = config.trace.root.get("assertion")
+        self.hook = None
+
+
+def install_importhook(config):
+    """Try to install the rewrite hook, raise SystemError if it fails."""
+    # Jython has an AST bug that make the assertion rewriting hook malfunction.
+    if sys.platform.startswith("java"):
+        raise SystemError("rewrite not supported")
+
+    config._assertstate = AssertionState(config, "rewrite")
+    config._assertstate.hook = hook = rewrite.AssertionRewritingHook(config)
+    sys.meta_path.insert(0, hook)
+    config._assertstate.trace("installed rewrite import hook")
+
+    def undo():
+        hook = config._assertstate.hook
+        if hook is not None and hook in sys.meta_path:
+            sys.meta_path.remove(hook)
+
+    config.add_cleanup(undo)
+    return hook
+
+
+def pytest_collection(session):
+    # this hook is only called when test modules are collected
+    # so for example not in the master process of pytest-xdist
+    # (which does not collect test modules)
+    assertstate = getattr(session.config, "_assertstate", None)
+    if assertstate:
+        if assertstate.hook is not None:
+            assertstate.hook.set_session(session)
+
+
+def pytest_runtest_setup(item):
+    """Setup the pytest_assertrepr_compare hook
+
+    The newinterpret and rewrite modules will use util._reprcompare if
+    it exists to use custom reporting via the
+    pytest_assertrepr_compare hook.  This sets up this custom
+    comparison for the test.
+    """
+
+    def callbinrepr(op, left, right):
+        """Call the pytest_assertrepr_compare hook and prepare the result
+
+        This uses the first result from the hook and then ensures the
+        following:
+        * Overly verbose explanations are truncated unless configured otherwise
+          (eg. if running in verbose mode).
+        * Embedded newlines are escaped to help util.format_explanation()
+          later.
+        * If the rewrite mode is used embedded %-characters are replaced
+          to protect later % formatting.
+
+        The result can be formatted by util.format_explanation() for
+        pretty printing.
+        """
+        hook_result = item.ihook.pytest_assertrepr_compare(
+            config=item.config, op=op, left=left, right=right
+        )
+        for new_expl in hook_result:
+            if new_expl:
+                new_expl = truncate.truncate_if_required(new_expl, item)
+                new_expl = [line.replace("\n", "\\n") for line in new_expl]
+                res = six.text_type("\n~").join(new_expl)
+                if item.config.getvalue("assertmode") == "rewrite":
+                    res = res.replace("%", "%%")
+                return res
+
+    util._reprcompare = callbinrepr
+
+
+def pytest_runtest_teardown(item):
+    util._reprcompare = None
+
+
+def pytest_sessionfinish(session):
+    assertstate = getattr(session.config, "_assertstate", None)
+    if assertstate:
+        if assertstate.hook is not None:
+            assertstate.hook.set_session(None)
+
+
+# Expose this plugin's implementation for the pytest_assertrepr_compare hook
+pytest_assertrepr_compare = util.assertrepr_compare
Index: venv/Lib/site-packages/more_itertools-4.3.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools-4.3.0.dist-info/INSTALLER	(date 1543190974565)
+++ venv/Lib/site-packages/more_itertools-4.3.0.dist-info/INSTALLER	(date 1543190974565)
@@ -0,0 +1,0 @@
Index: venv/Lib/site-packages/_pytest/assertion/truncate.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/assertion/truncate.py	(date 1543190975471)
+++ venv/Lib/site-packages/_pytest/assertion/truncate.py	(date 1543190975471)
@@ -0,0 +1,102 @@
+"""
+Utilities for truncating assertion output.
+
+Current default behaviour is to truncate assertion explanations at
+~8 terminal lines, unless running in "-vv" mode or running on CI.
+"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+
+import six
+
+
+DEFAULT_MAX_LINES = 8
+DEFAULT_MAX_CHARS = 8 * 80
+USAGE_MSG = "use '-vv' to show"
+
+
+def truncate_if_required(explanation, item, max_length=None):
+    """
+    Truncate this assertion explanation if the given test item is eligible.
+    """
+    if _should_truncate_item(item):
+        return _truncate_explanation(explanation)
+    return explanation
+
+
+def _should_truncate_item(item):
+    """
+    Whether or not this test item is eligible for truncation.
+    """
+    verbose = item.config.option.verbose
+    return verbose < 2 and not _running_on_ci()
+
+
+def _running_on_ci():
+    """Check if we're currently running on a CI system."""
+    env_vars = ["CI", "BUILD_NUMBER"]
+    return any(var in os.environ for var in env_vars)
+
+
+def _truncate_explanation(input_lines, max_lines=None, max_chars=None):
+    """
+    Truncate given list of strings that makes up the assertion explanation.
+
+    Truncates to either 8 lines, or 640 characters - whichever the input reaches
+    first. The remaining lines will be replaced by a usage message.
+    """
+
+    if max_lines is None:
+        max_lines = DEFAULT_MAX_LINES
+    if max_chars is None:
+        max_chars = DEFAULT_MAX_CHARS
+
+    # Check if truncation required
+    input_char_count = len("".join(input_lines))
+    if len(input_lines) <= max_lines and input_char_count <= max_chars:
+        return input_lines
+
+    # Truncate first to max_lines, and then truncate to max_chars if max_chars
+    # is exceeded.
+    truncated_explanation = input_lines[:max_lines]
+    truncated_explanation = _truncate_by_char_count(truncated_explanation, max_chars)
+
+    # Add ellipsis to final line
+    truncated_explanation[-1] = truncated_explanation[-1] + "..."
+
+    # Append useful message to explanation
+    truncated_line_count = len(input_lines) - len(truncated_explanation)
+    truncated_line_count += 1  # Account for the part-truncated final line
+    msg = "...Full output truncated"
+    if truncated_line_count == 1:
+        msg += " ({} line hidden)".format(truncated_line_count)
+    else:
+        msg += " ({} lines hidden)".format(truncated_line_count)
+    msg += ", {}".format(USAGE_MSG)
+    truncated_explanation.extend([six.text_type(""), six.text_type(msg)])
+    return truncated_explanation
+
+
+def _truncate_by_char_count(input_lines, max_chars):
+    # Check if truncation required
+    if len("".join(input_lines)) <= max_chars:
+        return input_lines
+
+    # Find point at which input length exceeds total allowed length
+    iterated_char_count = 0
+    for iterated_index, input_line in enumerate(input_lines):
+        if iterated_char_count + len(input_line) > max_chars:
+            break
+        iterated_char_count += len(input_line)
+
+    # Create truncated explanation with modified final line
+    truncated_result = input_lines[:iterated_index]
+    final_line = input_lines[iterated_index]
+    if final_line:
+        final_line_truncate_point = max_chars - iterated_char_count
+        final_line = final_line[:final_line_truncate_point]
+    truncated_result.append(final_line)
+    return truncated_result
Index: venv/Lib/site-packages/_pytest/assertion/util.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/assertion/util.py	(date 1543190975481)
+++ venv/Lib/site-packages/_pytest/assertion/util.py	(date 1543190975481)
@@ -0,0 +1,334 @@
+"""Utilities for assertion debugging"""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import pprint
+
+import py
+import six
+
+import _pytest._code
+from ..compat import Sequence
+
+# The _reprcompare attribute on the util module is used by the new assertion
+# interpretation code and assertion rewriter to detect this plugin was
+# loaded and in turn call the hooks defined here as part of the
+# DebugInterpreter.
+_reprcompare = None
+
+
+# the re-encoding is needed for python2 repr
+# with non-ascii characters (see issue 877 and 1379)
+def ecu(s):
+    if isinstance(s, bytes):
+        return s.decode("UTF-8", "replace")
+    else:
+        return s
+
+
+def format_explanation(explanation):
+    """This formats an explanation
+
+    Normally all embedded newlines are escaped, however there are
+    three exceptions: \n{, \n} and \n~.  The first two are intended
+    cover nested explanations, see function and attribute explanations
+    for examples (.visit_Call(), visit_Attribute()).  The last one is
+    for when one explanation needs to span multiple lines, e.g. when
+    displaying diffs.
+    """
+    explanation = ecu(explanation)
+    lines = _split_explanation(explanation)
+    result = _format_lines(lines)
+    return u"\n".join(result)
+
+
+def _split_explanation(explanation):
+    """Return a list of individual lines in the explanation
+
+    This will return a list of lines split on '\n{', '\n}' and '\n~'.
+    Any other newlines will be escaped and appear in the line as the
+    literal '\n' characters.
+    """
+    raw_lines = (explanation or u"").split("\n")
+    lines = [raw_lines[0]]
+    for values in raw_lines[1:]:
+        if values and values[0] in ["{", "}", "~", ">"]:
+            lines.append(values)
+        else:
+            lines[-1] += "\\n" + values
+    return lines
+
+
+def _format_lines(lines):
+    """Format the individual lines
+
+    This will replace the '{', '}' and '~' characters of our mini
+    formatting language with the proper 'where ...', 'and ...' and ' +
+    ...' text, taking care of indentation along the way.
+
+    Return a list of formatted lines.
+    """
+    result = lines[:1]
+    stack = [0]
+    stackcnt = [0]
+    for line in lines[1:]:
+        if line.startswith("{"):
+            if stackcnt[-1]:
+                s = u"and   "
+            else:
+                s = u"where "
+            stack.append(len(result))
+            stackcnt[-1] += 1
+            stackcnt.append(0)
+            result.append(u" +" + u"  " * (len(stack) - 1) + s + line[1:])
+        elif line.startswith("}"):
+            stack.pop()
+            stackcnt.pop()
+            result[stack[-1]] += line[1:]
+        else:
+            assert line[0] in ["~", ">"]
+            stack[-1] += 1
+            indent = len(stack) if line.startswith("~") else len(stack) - 1
+            result.append(u"  " * indent + line[1:])
+    assert len(stack) == 1
+    return result
+
+
+# Provide basestring in python3
+try:
+    basestring = basestring
+except NameError:
+    basestring = str
+
+
+def assertrepr_compare(config, op, left, right):
+    """Return specialised explanations for some operators/operands"""
+    width = 80 - 15 - len(op) - 2  # 15 chars indentation, 1 space around op
+    left_repr = py.io.saferepr(left, maxsize=int(width // 2))
+    right_repr = py.io.saferepr(right, maxsize=width - len(left_repr))
+
+    summary = u"%s %s %s" % (ecu(left_repr), op, ecu(right_repr))
+
+    def issequence(x):
+        return isinstance(x, Sequence) and not isinstance(x, basestring)
+
+    def istext(x):
+        return isinstance(x, basestring)
+
+    def isdict(x):
+        return isinstance(x, dict)
+
+    def isset(x):
+        return isinstance(x, (set, frozenset))
+
+    def isiterable(obj):
+        try:
+            iter(obj)
+            return not istext(obj)
+        except TypeError:
+            return False
+
+    verbose = config.getoption("verbose")
+    explanation = None
+    try:
+        if op == "==":
+            if istext(left) and istext(right):
+                explanation = _diff_text(left, right, verbose)
+            else:
+                if issequence(left) and issequence(right):
+                    explanation = _compare_eq_sequence(left, right, verbose)
+                elif isset(left) and isset(right):
+                    explanation = _compare_eq_set(left, right, verbose)
+                elif isdict(left) and isdict(right):
+                    explanation = _compare_eq_dict(left, right, verbose)
+                if isiterable(left) and isiterable(right):
+                    expl = _compare_eq_iterable(left, right, verbose)
+                    if explanation is not None:
+                        explanation.extend(expl)
+                    else:
+                        explanation = expl
+        elif op == "not in":
+            if istext(left) and istext(right):
+                explanation = _notin_text(left, right, verbose)
+    except Exception:
+        explanation = [
+            u"(pytest_assertion plugin: representation of details failed.  "
+            u"Probably an object has a faulty __repr__.)",
+            six.text_type(_pytest._code.ExceptionInfo()),
+        ]
+
+    if not explanation:
+        return None
+
+    return [summary] + explanation
+
+
+def _diff_text(left, right, verbose=False):
+    """Return the explanation for the diff between text or bytes
+
+    Unless --verbose is used this will skip leading and trailing
+    characters which are identical to keep the diff minimal.
+
+    If the input are bytes they will be safely converted to text.
+    """
+    from difflib import ndiff
+
+    explanation = []
+
+    def escape_for_readable_diff(binary_text):
+        """
+        Ensures that the internal string is always valid unicode, converting any bytes safely to valid unicode.
+        This is done using repr() which then needs post-processing to fix the encompassing quotes and un-escape
+        newlines and carriage returns (#429).
+        """
+        r = six.text_type(repr(binary_text)[1:-1])
+        r = r.replace(r"\n", "\n")
+        r = r.replace(r"\r", "\r")
+        return r
+
+    if isinstance(left, bytes):
+        left = escape_for_readable_diff(left)
+    if isinstance(right, bytes):
+        right = escape_for_readable_diff(right)
+    if not verbose:
+        i = 0  # just in case left or right has zero length
+        for i in range(min(len(left), len(right))):
+            if left[i] != right[i]:
+                break
+        if i > 42:
+            i -= 10  # Provide some context
+            explanation = [
+                u"Skipping %s identical leading characters in diff, use -v to show" % i
+            ]
+            left = left[i:]
+            right = right[i:]
+        if len(left) == len(right):
+            for i in range(len(left)):
+                if left[-i] != right[-i]:
+                    break
+            if i > 42:
+                i -= 10  # Provide some context
+                explanation += [
+                    u"Skipping {} identical trailing "
+                    u"characters in diff, use -v to show".format(i)
+                ]
+                left = left[:-i]
+                right = right[:-i]
+    keepends = True
+    if left.isspace() or right.isspace():
+        left = repr(str(left))
+        right = repr(str(right))
+        explanation += [u"Strings contain only whitespace, escaping them using repr()"]
+    explanation += [
+        line.strip("\n")
+        for line in ndiff(left.splitlines(keepends), right.splitlines(keepends))
+    ]
+    return explanation
+
+
+def _compare_eq_iterable(left, right, verbose=False):
+    if not verbose:
+        return [u"Use -v to get the full diff"]
+    # dynamic import to speedup pytest
+    import difflib
+
+    try:
+        left_formatting = pprint.pformat(left).splitlines()
+        right_formatting = pprint.pformat(right).splitlines()
+        explanation = [u"Full diff:"]
+    except Exception:
+        # hack: PrettyPrinter.pformat() in python 2 fails when formatting items that can't be sorted(), ie, calling
+        # sorted() on a list would raise. See issue #718.
+        # As a workaround, the full diff is generated by using the repr() string of each item of each container.
+        left_formatting = sorted(repr(x) for x in left)
+        right_formatting = sorted(repr(x) for x in right)
+        explanation = [u"Full diff (fallback to calling repr on each item):"]
+    explanation.extend(
+        line.strip() for line in difflib.ndiff(left_formatting, right_formatting)
+    )
+    return explanation
+
+
+def _compare_eq_sequence(left, right, verbose=False):
+    explanation = []
+    for i in range(min(len(left), len(right))):
+        if left[i] != right[i]:
+            explanation += [u"At index %s diff: %r != %r" % (i, left[i], right[i])]
+            break
+    if len(left) > len(right):
+        explanation += [
+            u"Left contains more items, first extra item: %s"
+            % py.io.saferepr(left[len(right)])
+        ]
+    elif len(left) < len(right):
+        explanation += [
+            u"Right contains more items, first extra item: %s"
+            % py.io.saferepr(right[len(left)])
+        ]
+    return explanation
+
+
+def _compare_eq_set(left, right, verbose=False):
+    explanation = []
+    diff_left = left - right
+    diff_right = right - left
+    if diff_left:
+        explanation.append(u"Extra items in the left set:")
+        for item in diff_left:
+            explanation.append(py.io.saferepr(item))
+    if diff_right:
+        explanation.append(u"Extra items in the right set:")
+        for item in diff_right:
+            explanation.append(py.io.saferepr(item))
+    return explanation
+
+
+def _compare_eq_dict(left, right, verbose=False):
+    explanation = []
+    common = set(left).intersection(set(right))
+    same = {k: left[k] for k in common if left[k] == right[k]}
+    if same and verbose < 2:
+        explanation += [u"Omitting %s identical items, use -vv to show" % len(same)]
+    elif same:
+        explanation += [u"Common items:"]
+        explanation += pprint.pformat(same).splitlines()
+    diff = {k for k in common if left[k] != right[k]}
+    if diff:
+        explanation += [u"Differing items:"]
+        for k in diff:
+            explanation += [
+                py.io.saferepr({k: left[k]}) + " != " + py.io.saferepr({k: right[k]})
+            ]
+    extra_left = set(left) - set(right)
+    if extra_left:
+        explanation.append(u"Left contains more items:")
+        explanation.extend(
+            pprint.pformat({k: left[k] for k in extra_left}).splitlines()
+        )
+    extra_right = set(right) - set(left)
+    if extra_right:
+        explanation.append(u"Right contains more items:")
+        explanation.extend(
+            pprint.pformat({k: right[k] for k in extra_right}).splitlines()
+        )
+    return explanation
+
+
+def _notin_text(term, text, verbose=False):
+    index = text.find(term)
+    head = text[:index]
+    tail = text[index + len(term) :]
+    correct_text = head + tail
+    diff = _diff_text(correct_text, text, verbose)
+    newdiff = [u"%s is contained here:" % py.io.saferepr(term, maxsize=42)]
+    for line in diff:
+        if line.startswith(u"Skipping"):
+            continue
+        if line.startswith(u"- "):
+            continue
+        if line.startswith(u"+ "):
+            newdiff.append(u"  " + line[2:])
+        else:
+            newdiff.append(line)
+    return newdiff
Index: venv/Lib/site-packages/_pytest/config/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/config/__init__.py	(date 1543190975493)
+++ venv/Lib/site-packages/_pytest/config/__init__.py	(date 1543190975493)
@@ -0,0 +1,1054 @@
+""" command line options, ini-file and conftest.py processing. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import argparse
+import copy
+import inspect
+import os
+import shlex
+import sys
+import types
+import warnings
+from distutils.version import LooseVersion
+
+import py
+import six
+from pluggy import HookimplMarker
+from pluggy import HookspecMarker
+from pluggy import PluginManager
+
+import _pytest._code
+import _pytest.assertion
+import _pytest.hookspec  # the extension point definitions
+from .exceptions import PrintHelp
+from .exceptions import UsageError
+from .findpaths import determine_setup
+from .findpaths import exists
+from _pytest._code import ExceptionInfo
+from _pytest._code import filter_traceback
+from _pytest.compat import lru_cache
+from _pytest.compat import safe_str
+from _pytest.outcomes import Skipped
+
+hookimpl = HookimplMarker("pytest")
+hookspec = HookspecMarker("pytest")
+
+
+class ConftestImportFailure(Exception):
+    def __init__(self, path, excinfo):
+        Exception.__init__(self, path, excinfo)
+        self.path = path
+        self.excinfo = excinfo
+
+
+def main(args=None, plugins=None):
+    """ return exit code, after performing an in-process test run.
+
+    :arg args: list of command line arguments.
+
+    :arg plugins: list of plugin objects to be auto-registered during
+                  initialization.
+    """
+    from _pytest.main import EXIT_USAGEERROR
+
+    try:
+        try:
+            config = _prepareconfig(args, plugins)
+        except ConftestImportFailure as e:
+            exc_info = ExceptionInfo(e.excinfo)
+            tw = py.io.TerminalWriter(sys.stderr)
+            tw.line(
+                "ImportError while loading conftest '{e.path}'.".format(e=e), red=True
+            )
+            exc_info.traceback = exc_info.traceback.filter(filter_traceback)
+            exc_repr = (
+                exc_info.getrepr(style="short", chain=False)
+                if exc_info.traceback
+                else exc_info.exconly()
+            )
+            formatted_tb = safe_str(exc_repr)
+            for line in formatted_tb.splitlines():
+                tw.line(line.rstrip(), red=True)
+            return 4
+        else:
+            try:
+                return config.hook.pytest_cmdline_main(config=config)
+            finally:
+                config._ensure_unconfigure()
+    except UsageError as e:
+        tw = py.io.TerminalWriter(sys.stderr)
+        for msg in e.args:
+            tw.line("ERROR: {}\n".format(msg), red=True)
+        return EXIT_USAGEERROR
+
+
+class cmdline(object):  # compatibility namespace
+    main = staticmethod(main)
+
+
+def filename_arg(path, optname):
+    """ Argparse type validator for filename arguments.
+
+    :path: path of filename
+    :optname: name of the option
+    """
+    if os.path.isdir(path):
+        raise UsageError("{} must be a filename, given: {}".format(optname, path))
+    return path
+
+
+def directory_arg(path, optname):
+    """Argparse type validator for directory arguments.
+
+    :path: path of directory
+    :optname: name of the option
+    """
+    if not os.path.isdir(path):
+        raise UsageError("{} must be a directory, given: {}".format(optname, path))
+    return path
+
+
+default_plugins = (
+    "mark",
+    "main",
+    "terminal",
+    "runner",
+    "python",
+    "fixtures",
+    "debugging",
+    "unittest",
+    "capture",
+    "skipping",
+    "tmpdir",
+    "monkeypatch",
+    "recwarn",
+    "pastebin",
+    "helpconfig",
+    "nose",
+    "assertion",
+    "junitxml",
+    "resultlog",
+    "doctest",
+    "cacheprovider",
+    "freeze_support",
+    "setuponly",
+    "setupplan",
+    "stepwise",
+    "warnings",
+    "logging",
+)
+
+
+builtin_plugins = set(default_plugins)
+builtin_plugins.add("pytester")
+
+
+def get_config():
+    # subsequent calls to main will create a fresh instance
+    pluginmanager = PytestPluginManager()
+    config = Config(pluginmanager)
+    for spec in default_plugins:
+        pluginmanager.import_plugin(spec)
+    return config
+
+
+def get_plugin_manager():
+    """
+    Obtain a new instance of the
+    :py:class:`_pytest.config.PytestPluginManager`, with default plugins
+    already loaded.
+
+    This function can be used by integration with other tools, like hooking
+    into pytest to run tests into an IDE.
+    """
+    return get_config().pluginmanager
+
+
+def _prepareconfig(args=None, plugins=None):
+    warning = None
+    if args is None:
+        args = sys.argv[1:]
+    elif isinstance(args, py.path.local):
+        args = [str(args)]
+    elif not isinstance(args, (tuple, list)):
+        if not isinstance(args, str):
+            raise ValueError("not a string or argument list: %r" % (args,))
+        args = shlex.split(args, posix=sys.platform != "win32")
+        from _pytest import deprecated
+
+        warning = deprecated.MAIN_STR_ARGS
+    config = get_config()
+    pluginmanager = config.pluginmanager
+    try:
+        if plugins:
+            for plugin in plugins:
+                if isinstance(plugin, six.string_types):
+                    pluginmanager.consider_pluginarg(plugin)
+                else:
+                    pluginmanager.register(plugin)
+        if warning:
+            from _pytest.warnings import _issue_config_warning
+
+            _issue_config_warning(warning, config=config)
+        return pluginmanager.hook.pytest_cmdline_parse(
+            pluginmanager=pluginmanager, args=args
+        )
+    except BaseException:
+        config._ensure_unconfigure()
+        raise
+
+
+class PytestPluginManager(PluginManager):
+    """
+    Overwrites :py:class:`pluggy.PluginManager <pluggy.PluginManager>` to add pytest-specific
+    functionality:
+
+    * loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and
+      ``pytest_plugins`` global variables found in plugins being loaded;
+    * ``conftest.py`` loading during start-up;
+    """
+
+    def __init__(self):
+        super(PytestPluginManager, self).__init__("pytest")
+        self._conftest_plugins = set()
+
+        # state related to local conftest plugins
+        self._dirpath2confmods = {}
+        self._conftestpath2mod = {}
+        self._confcutdir = None
+        self._noconftest = False
+        self._duplicatepaths = set()
+
+        self.add_hookspecs(_pytest.hookspec)
+        self.register(self)
+        if os.environ.get("PYTEST_DEBUG"):
+            err = sys.stderr
+            encoding = getattr(err, "encoding", "utf8")
+            try:
+                err = py.io.dupfile(err, encoding=encoding)
+            except Exception:
+                pass
+            self.trace.root.setwriter(err.write)
+            self.enable_tracing()
+
+        # Config._consider_importhook will set a real object if required.
+        self.rewrite_hook = _pytest.assertion.DummyRewriteHook()
+        # Used to know when we are importing conftests after the pytest_configure stage
+        self._configured = False
+
+    def addhooks(self, module_or_class):
+        """
+        .. deprecated:: 2.8
+
+        Use :py:meth:`pluggy.PluginManager.add_hookspecs <PluginManager.add_hookspecs>`
+        instead.
+        """
+        warning = dict(
+            code="I2",
+            fslocation=_pytest._code.getfslineno(sys._getframe(1)),
+            nodeid=None,
+            message="use pluginmanager.add_hookspecs instead of "
+            "deprecated addhooks() method.",
+        )
+        self._warn(warning)
+        return self.add_hookspecs(module_or_class)
+
+    def parse_hookimpl_opts(self, plugin, name):
+        # pytest hooks are always prefixed with pytest_
+        # so we avoid accessing possibly non-readable attributes
+        # (see issue #1073)
+        if not name.startswith("pytest_"):
+            return
+        # ignore some historic special names which can not be hooks anyway
+        if name == "pytest_plugins" or name.startswith("pytest_funcarg__"):
+            return
+
+        method = getattr(plugin, name)
+        opts = super(PytestPluginManager, self).parse_hookimpl_opts(plugin, name)
+
+        # consider only actual functions for hooks (#3775)
+        if not inspect.isroutine(method):
+            return
+
+        # collect unmarked hooks as long as they have the `pytest_' prefix
+        if opts is None and name.startswith("pytest_"):
+            opts = {}
+
+        if opts is not None:
+            for name in ("tryfirst", "trylast", "optionalhook", "hookwrapper"):
+                opts.setdefault(name, hasattr(method, name))
+        return opts
+
+    def parse_hookspec_opts(self, module_or_class, name):
+        opts = super(PytestPluginManager, self).parse_hookspec_opts(
+            module_or_class, name
+        )
+        if opts is None:
+            method = getattr(module_or_class, name)
+            if name.startswith("pytest_"):
+                opts = {
+                    "firstresult": hasattr(method, "firstresult"),
+                    "historic": hasattr(method, "historic"),
+                }
+        return opts
+
+    def register(self, plugin, name=None):
+        if name in ["pytest_catchlog", "pytest_capturelog"]:
+            self._warn(
+                "{} plugin has been merged into the core, "
+                "please remove it from your requirements.".format(
+                    name.replace("_", "-")
+                )
+            )
+            return
+        ret = super(PytestPluginManager, self).register(plugin, name)
+        if ret:
+            self.hook.pytest_plugin_registered.call_historic(
+                kwargs=dict(plugin=plugin, manager=self)
+            )
+
+            if isinstance(plugin, types.ModuleType):
+                self.consider_module(plugin)
+        return ret
+
+    def getplugin(self, name):
+        # support deprecated naming because plugins (xdist e.g.) use it
+        return self.get_plugin(name)
+
+    def hasplugin(self, name):
+        """Return True if the plugin with the given name is registered."""
+        return bool(self.get_plugin(name))
+
+    def pytest_configure(self, config):
+        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)
+        # we should remove tryfirst/trylast as markers
+        config.addinivalue_line(
+            "markers",
+            "tryfirst: mark a hook implementation function such that the "
+            "plugin machinery will try to call it first/as early as possible.",
+        )
+        config.addinivalue_line(
+            "markers",
+            "trylast: mark a hook implementation function such that the "
+            "plugin machinery will try to call it last/as late as possible.",
+        )
+        self._configured = True
+
+    def _warn(self, message):
+        kwargs = (
+            message
+            if isinstance(message, dict)
+            else {"code": "I1", "message": message, "fslocation": None, "nodeid": None}
+        )
+        self.hook.pytest_logwarning.call_historic(kwargs=kwargs)
+
+    #
+    # internal API for local conftest plugin handling
+    #
+    def _set_initial_conftests(self, namespace):
+        """ load initial conftest files given a preparsed "namespace".
+            As conftest files may add their own command line options
+            which have arguments ('--my-opt somepath') we might get some
+            false positives.  All builtin and 3rd party plugins will have
+            been loaded, however, so common options will not confuse our logic
+            here.
+        """
+        current = py.path.local()
+        self._confcutdir = (
+            current.join(namespace.confcutdir, abs=True)
+            if namespace.confcutdir
+            else None
+        )
+        self._noconftest = namespace.noconftest
+        self._using_pyargs = namespace.pyargs
+        testpaths = namespace.file_or_dir
+        foundanchor = False
+        for path in testpaths:
+            path = str(path)
+            # remove node-id syntax
+            i = path.find("::")
+            if i != -1:
+                path = path[:i]
+            anchor = current.join(path, abs=1)
+            if exists(anchor):  # we found some file object
+                self._try_load_conftest(anchor)
+                foundanchor = True
+        if not foundanchor:
+            self._try_load_conftest(current)
+
+    def _try_load_conftest(self, anchor):
+        self._getconftestmodules(anchor)
+        # let's also consider test* subdirs
+        if anchor.check(dir=1):
+            for x in anchor.listdir("test*"):
+                if x.check(dir=1):
+                    self._getconftestmodules(x)
+
+    @lru_cache(maxsize=128)
+    def _getconftestmodules(self, path):
+        if self._noconftest:
+            return []
+
+        if path.isfile():
+            directory = path.dirpath()
+        else:
+            directory = path
+
+        if six.PY2:  # py2 is not using lru_cache.
+            try:
+                return self._dirpath2confmods[directory]
+            except KeyError:
+                pass
+
+        # XXX these days we may rather want to use config.rootdir
+        # and allow users to opt into looking into the rootdir parent
+        # directories instead of requiring to specify confcutdir
+        clist = []
+        for parent in directory.realpath().parts():
+            if self._confcutdir and self._confcutdir.relto(parent):
+                continue
+            conftestpath = parent.join("conftest.py")
+            if conftestpath.isfile():
+                mod = self._importconftest(conftestpath)
+                clist.append(mod)
+        self._dirpath2confmods[directory] = clist
+        return clist
+
+    def _rget_with_confmod(self, name, path):
+        modules = self._getconftestmodules(path)
+        for mod in reversed(modules):
+            try:
+                return mod, getattr(mod, name)
+            except AttributeError:
+                continue
+        raise KeyError(name)
+
+    def _importconftest(self, conftestpath):
+        try:
+            return self._conftestpath2mod[conftestpath]
+        except KeyError:
+            pkgpath = conftestpath.pypkgpath()
+            if pkgpath is None:
+                _ensure_removed_sysmodule(conftestpath.purebasename)
+            try:
+                mod = conftestpath.pyimport()
+                if (
+                    hasattr(mod, "pytest_plugins")
+                    and self._configured
+                    and not self._using_pyargs
+                ):
+                    from _pytest.deprecated import (
+                        PYTEST_PLUGINS_FROM_NON_TOP_LEVEL_CONFTEST
+                    )
+
+                    warnings.warn_explicit(
+                        PYTEST_PLUGINS_FROM_NON_TOP_LEVEL_CONFTEST,
+                        category=None,
+                        filename=str(conftestpath),
+                        lineno=0,
+                    )
+            except Exception:
+                raise ConftestImportFailure(conftestpath, sys.exc_info())
+
+            self._conftest_plugins.add(mod)
+            self._conftestpath2mod[conftestpath] = mod
+            dirpath = conftestpath.dirpath()
+            if dirpath in self._dirpath2confmods:
+                for path, mods in self._dirpath2confmods.items():
+                    if path and path.relto(dirpath) or path == dirpath:
+                        assert mod not in mods
+                        mods.append(mod)
+            self.trace("loaded conftestmodule %r" % (mod))
+            self.consider_conftest(mod)
+            return mod
+
+    #
+    # API for bootstrapping plugin loading
+    #
+    #
+
+    def consider_preparse(self, args):
+        for opt1, opt2 in zip(args, args[1:]):
+            if opt1 == "-p":
+                self.consider_pluginarg(opt2)
+
+    def consider_pluginarg(self, arg):
+        if arg.startswith("no:"):
+            name = arg[3:]
+            # PR #4304 : remove stepwise if cacheprovider is blocked
+            if name == "cacheprovider":
+                self.set_blocked("stepwise")
+                self.set_blocked("pytest_stepwise")
+
+            self.set_blocked(name)
+            if not name.startswith("pytest_"):
+                self.set_blocked("pytest_" + name)
+        else:
+            self.import_plugin(arg)
+
+    def consider_conftest(self, conftestmodule):
+        self.register(conftestmodule, name=conftestmodule.__file__)
+
+    def consider_env(self):
+        self._import_plugin_specs(os.environ.get("PYTEST_PLUGINS"))
+
+    def consider_module(self, mod):
+        self._import_plugin_specs(getattr(mod, "pytest_plugins", []))
+
+    def _import_plugin_specs(self, spec):
+        plugins = _get_plugin_specs_as_list(spec)
+        for import_spec in plugins:
+            self.import_plugin(import_spec)
+
+    def import_plugin(self, modname):
+        # most often modname refers to builtin modules, e.g. "pytester",
+        # "terminal" or "capture".  Those plugins are registered under their
+        # basename for historic purposes but must be imported with the
+        # _pytest prefix.
+        assert isinstance(modname, (six.text_type, str)), (
+            "module name as text required, got %r" % modname
+        )
+        modname = str(modname)
+        if self.is_blocked(modname) or self.get_plugin(modname) is not None:
+            return
+        if modname in builtin_plugins:
+            importspec = "_pytest." + modname
+        else:
+            importspec = modname
+        self.rewrite_hook.mark_rewrite(importspec)
+        try:
+            __import__(importspec)
+        except ImportError as e:
+            new_exc_type = ImportError
+            new_exc_message = 'Error importing plugin "%s": %s' % (
+                modname,
+                safe_str(e.args[0]),
+            )
+            new_exc = new_exc_type(new_exc_message)
+
+            six.reraise(new_exc_type, new_exc, sys.exc_info()[2])
+
+        except Skipped as e:
+            self._warn("skipped plugin %r: %s" % ((modname, e.msg)))
+        else:
+            mod = sys.modules[importspec]
+            self.register(mod, modname)
+
+
+def _get_plugin_specs_as_list(specs):
+    """
+    Parses a list of "plugin specs" and returns a list of plugin names.
+
+    Plugin specs can be given as a list of strings separated by "," or already as a list/tuple in
+    which case it is returned as a list. Specs can also be `None` in which case an
+    empty list is returned.
+    """
+    if specs is not None:
+        if isinstance(specs, str):
+            specs = specs.split(",") if specs else []
+        if not isinstance(specs, (list, tuple)):
+            raise UsageError(
+                "Plugin specs must be a ','-separated string or a "
+                "list/tuple of strings for plugin names. Given: %r" % specs
+            )
+        return list(specs)
+    return []
+
+
+def _ensure_removed_sysmodule(modname):
+    try:
+        del sys.modules[modname]
+    except KeyError:
+        pass
+
+
+class Notset(object):
+    def __repr__(self):
+        return "<NOTSET>"
+
+
+notset = Notset()
+
+
+def _iter_rewritable_modules(package_files):
+    for fn in package_files:
+        is_simple_module = "/" not in fn and fn.endswith(".py")
+        is_package = fn.count("/") == 1 and fn.endswith("__init__.py")
+        if is_simple_module:
+            module_name, _ = os.path.splitext(fn)
+            yield module_name
+        elif is_package:
+            package_name = os.path.dirname(fn)
+            yield package_name
+
+
+class Config(object):
+    """ access to configuration values, pluginmanager and plugin hooks.  """
+
+    def __init__(self, pluginmanager):
+        #: access to command line option as attributes.
+        #: (deprecated), use :py:func:`getoption() <_pytest.config.Config.getoption>` instead
+        self.option = argparse.Namespace()
+        from .argparsing import Parser, FILE_OR_DIR
+
+        _a = FILE_OR_DIR
+        self._parser = Parser(
+            usage="%%(prog)s [options] [%s] [%s] [...]" % (_a, _a),
+            processopt=self._processopt,
+        )
+        #: a pluginmanager instance
+        self.pluginmanager = pluginmanager
+        self.trace = self.pluginmanager.trace.root.get("config")
+        self.hook = self.pluginmanager.hook
+        self._inicache = {}
+        self._override_ini = ()
+        self._opt2dest = {}
+        self._cleanup = []
+        self._warn = self.pluginmanager._warn
+        self.pluginmanager.register(self, "pytestconfig")
+        self._configured = False
+
+        def do_setns(dic):
+            import pytest
+
+            setns(pytest, dic)
+
+        self.hook.pytest_namespace.call_historic(do_setns, {})
+        self.hook.pytest_addoption.call_historic(kwargs=dict(parser=self._parser))
+
+    def add_cleanup(self, func):
+        """ Add a function to be called when the config object gets out of
+        use (usually coninciding with pytest_unconfigure)."""
+        self._cleanup.append(func)
+
+    def _do_configure(self):
+        assert not self._configured
+        self._configured = True
+        self.hook.pytest_configure.call_historic(kwargs=dict(config=self))
+
+    def _ensure_unconfigure(self):
+        if self._configured:
+            self._configured = False
+            self.hook.pytest_unconfigure(config=self)
+            self.hook.pytest_configure._call_history = []
+        while self._cleanup:
+            fin = self._cleanup.pop()
+            fin()
+
+    def warn(self, code, message, fslocation=None, nodeid=None):
+        """
+        .. deprecated:: 3.8
+
+            Use :py:func:`warnings.warn` or :py:func:`warnings.warn_explicit` directly instead.
+
+        Generate a warning for this test session.
+        """
+        from _pytest.warning_types import RemovedInPytest4Warning
+
+        if isinstance(fslocation, (tuple, list)) and len(fslocation) > 2:
+            filename, lineno = fslocation[:2]
+        else:
+            filename = "unknown file"
+            lineno = 0
+        msg = "config.warn has been deprecated, use warnings.warn instead"
+        if nodeid:
+            msg = "{}: {}".format(nodeid, msg)
+        warnings.warn_explicit(
+            RemovedInPytest4Warning(msg),
+            category=None,
+            filename=filename,
+            lineno=lineno,
+        )
+        self.hook.pytest_logwarning.call_historic(
+            kwargs=dict(
+                code=code, message=message, fslocation=fslocation, nodeid=nodeid
+            )
+        )
+
+    def get_terminal_writer(self):
+        return self.pluginmanager.get_plugin("terminalreporter")._tw
+
+    def pytest_cmdline_parse(self, pluginmanager, args):
+        # REF1 assert self == pluginmanager.config, (self, pluginmanager.config)
+        self.parse(args)
+        return self
+
+    def notify_exception(self, excinfo, option=None):
+        if option and option.fulltrace:
+            style = "long"
+        else:
+            style = "native"
+        excrepr = excinfo.getrepr(
+            funcargs=True, showlocals=getattr(option, "showlocals", False), style=style
+        )
+        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)
+        if not any(res):
+            for line in str(excrepr).split("\n"):
+                sys.stderr.write("INTERNALERROR> %s\n" % line)
+                sys.stderr.flush()
+
+    def cwd_relative_nodeid(self, nodeid):
+        # nodeid's are relative to the rootpath, compute relative to cwd
+        if self.invocation_dir != self.rootdir:
+            fullpath = self.rootdir.join(nodeid)
+            nodeid = self.invocation_dir.bestrelpath(fullpath)
+        return nodeid
+
+    @classmethod
+    def fromdictargs(cls, option_dict, args):
+        """ constructor useable for subprocesses. """
+        config = get_config()
+        config.option.__dict__.update(option_dict)
+        config.parse(args, addopts=False)
+        for x in config.option.plugins:
+            config.pluginmanager.consider_pluginarg(x)
+        return config
+
+    def _processopt(self, opt):
+        for name in opt._short_opts + opt._long_opts:
+            self._opt2dest[name] = opt.dest
+
+        if hasattr(opt, "default") and opt.dest:
+            if not hasattr(self.option, opt.dest):
+                setattr(self.option, opt.dest, opt.default)
+
+    @hookimpl(trylast=True)
+    def pytest_load_initial_conftests(self, early_config):
+        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)
+
+    def _initini(self, args):
+        ns, unknown_args = self._parser.parse_known_and_unknown_args(
+            args, namespace=copy.copy(self.option)
+        )
+        r = determine_setup(
+            ns.inifilename,
+            ns.file_or_dir + unknown_args,
+            rootdir_cmd_arg=ns.rootdir or None,
+            config=self,
+        )
+        self.rootdir, self.inifile, self.inicfg = r
+        self._parser.extra_info["rootdir"] = self.rootdir
+        self._parser.extra_info["inifile"] = self.inifile
+        self.invocation_dir = py.path.local()
+        self._parser.addini("addopts", "extra command line options", "args")
+        self._parser.addini("minversion", "minimally required pytest version")
+        self._override_ini = ns.override_ini or ()
+
+    def _consider_importhook(self, args):
+        """Install the PEP 302 import hook if using assertion rewriting.
+
+        Needs to parse the --assert=<mode> option from the commandline
+        and find all the installed plugins to mark them for rewriting
+        by the importhook.
+        """
+        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)
+        mode = ns.assertmode
+        if mode == "rewrite":
+            try:
+                hook = _pytest.assertion.install_importhook(self)
+            except SystemError:
+                mode = "plain"
+            else:
+                self._mark_plugins_for_rewrite(hook)
+        _warn_about_missing_assertion(mode)
+
+    def _mark_plugins_for_rewrite(self, hook):
+        """
+        Given an importhook, mark for rewrite any top-level
+        modules or packages in the distribution package for
+        all pytest plugins.
+        """
+        import pkg_resources
+
+        self.pluginmanager.rewrite_hook = hook
+
+        if os.environ.get("PYTEST_DISABLE_PLUGIN_AUTOLOAD"):
+            # We don't autoload from setuptools entry points, no need to continue.
+            return
+
+        # 'RECORD' available for plugins installed normally (pip install)
+        # 'SOURCES.txt' available for plugins installed in dev mode (pip install -e)
+        # for installed plugins 'SOURCES.txt' returns an empty list, and vice-versa
+        # so it shouldn't be an issue
+        metadata_files = "RECORD", "SOURCES.txt"
+
+        package_files = (
+            entry.split(",")[0]
+            for entrypoint in pkg_resources.iter_entry_points("pytest11")
+            for metadata in metadata_files
+            for entry in entrypoint.dist._get_metadata(metadata)
+        )
+
+        for name in _iter_rewritable_modules(package_files):
+            hook.mark_rewrite(name)
+
+    def _preparse(self, args, addopts=True):
+        if addopts:
+            args[:] = shlex.split(os.environ.get("PYTEST_ADDOPTS", "")) + args
+        self._initini(args)
+        if addopts:
+            args[:] = self.getini("addopts") + args
+        self._checkversion()
+        self._consider_importhook(args)
+        self.pluginmanager.consider_preparse(args)
+        if not os.environ.get("PYTEST_DISABLE_PLUGIN_AUTOLOAD"):
+            # Don't autoload from setuptools entry point. Only explicitly specified
+            # plugins are going to be loaded.
+            self.pluginmanager.load_setuptools_entrypoints("pytest11")
+        self.pluginmanager.consider_env()
+        self.known_args_namespace = ns = self._parser.parse_known_args(
+            args, namespace=copy.copy(self.option)
+        )
+        if self.known_args_namespace.confcutdir is None and self.inifile:
+            confcutdir = py.path.local(self.inifile).dirname
+            self.known_args_namespace.confcutdir = confcutdir
+        try:
+            self.hook.pytest_load_initial_conftests(
+                early_config=self, args=args, parser=self._parser
+            )
+        except ConftestImportFailure:
+            e = sys.exc_info()[1]
+            if ns.help or ns.version:
+                # we don't want to prevent --help/--version to work
+                # so just let is pass and print a warning at the end
+                self._warn("could not load initial conftests (%s)\n" % e.path)
+            else:
+                raise
+
+    def _checkversion(self):
+        import pytest
+
+        minver = self.inicfg.get("minversion", None)
+        if minver:
+            if LooseVersion(minver) > LooseVersion(pytest.__version__):
+                raise pytest.UsageError(
+                    "%s:%d: requires pytest-%s, actual pytest-%s'"
+                    % (
+                        self.inicfg.config.path,
+                        self.inicfg.lineof("minversion"),
+                        minver,
+                        pytest.__version__,
+                    )
+                )
+
+    def parse(self, args, addopts=True):
+        # parse given cmdline arguments into this config object.
+        assert not hasattr(
+            self, "args"
+        ), "can only parse cmdline args at most once per Config object"
+        self._origargs = args
+        self.hook.pytest_addhooks.call_historic(
+            kwargs=dict(pluginmanager=self.pluginmanager)
+        )
+        self._preparse(args, addopts=addopts)
+        # XXX deprecated hook:
+        self.hook.pytest_cmdline_preparse(config=self, args=args)
+        self._parser.after_preparse = True
+        try:
+            args = self._parser.parse_setoption(
+                args, self.option, namespace=self.option
+            )
+            if not args:
+                if self.invocation_dir == self.rootdir:
+                    args = [
+                        str(self.invocation_dir.join(x, abs=True))
+                        for x in self.getini("testpaths")
+                    ]
+                if not args:
+                    args = [str(self.invocation_dir)]
+            self.args = args
+        except PrintHelp:
+            pass
+
+    def addinivalue_line(self, name, line):
+        """ add a line to an ini-file option. The option must have been
+        declared but might not yet be set in which case the line becomes the
+        the first line in its value. """
+        x = self.getini(name)
+        assert isinstance(x, list)
+        x.append(line)  # modifies the cached list inline
+
+    def getini(self, name):
+        """ return configuration value from an :ref:`ini file <inifiles>`. If the
+        specified name hasn't been registered through a prior
+        :py:func:`parser.addini <_pytest.config.Parser.addini>`
+        call (usually from a plugin), a ValueError is raised. """
+        try:
+            return self._inicache[name]
+        except KeyError:
+            self._inicache[name] = val = self._getini(name)
+            return val
+
+    def _getini(self, name):
+        try:
+            description, type, default = self._parser._inidict[name]
+        except KeyError:
+            raise ValueError("unknown configuration value: %r" % (name,))
+        value = self._get_override_ini_value(name)
+        if value is None:
+            try:
+                value = self.inicfg[name]
+            except KeyError:
+                if default is not None:
+                    return default
+                if type is None:
+                    return ""
+                return []
+        if type == "pathlist":
+            dp = py.path.local(self.inicfg.config.path).dirpath()
+            values = []
+            for relpath in shlex.split(value):
+                values.append(dp.join(relpath, abs=True))
+            return values
+        elif type == "args":
+            return shlex.split(value)
+        elif type == "linelist":
+            return [t for t in map(lambda x: x.strip(), value.split("\n")) if t]
+        elif type == "bool":
+            return bool(_strtobool(value.strip()))
+        else:
+            assert type is None
+            return value
+
+    def _getconftest_pathlist(self, name, path):
+        try:
+            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)
+        except KeyError:
+            return None
+        modpath = py.path.local(mod.__file__).dirpath()
+        values = []
+        for relroot in relroots:
+            if not isinstance(relroot, py.path.local):
+                relroot = relroot.replace("/", py.path.local.sep)
+                relroot = modpath.join(relroot, abs=True)
+            values.append(relroot)
+        return values
+
+    def _get_override_ini_value(self, name):
+        value = None
+        # override_ini is a list of "ini=value" options
+        # always use the last item if multiple values are set for same ini-name,
+        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2
+        for ini_config in self._override_ini:
+            try:
+                key, user_ini_value = ini_config.split("=", 1)
+            except ValueError:
+                raise UsageError("-o/--override-ini expects option=value style.")
+            else:
+                if key == name:
+                    value = user_ini_value
+        return value
+
+    def getoption(self, name, default=notset, skip=False):
+        """ return command line option value.
+
+        :arg name: name of the option.  You may also specify
+            the literal ``--OPT`` option instead of the "dest" option name.
+        :arg default: default value if no option of that name exists.
+        :arg skip: if True raise pytest.skip if option does not exists
+            or has a None value.
+        """
+        name = self._opt2dest.get(name, name)
+        try:
+            val = getattr(self.option, name)
+            if val is None and skip:
+                raise AttributeError(name)
+            return val
+        except AttributeError:
+            if default is not notset:
+                return default
+            if skip:
+                import pytest
+
+                pytest.skip("no %r option found" % (name,))
+            raise ValueError("no option named %r" % (name,))
+
+    def getvalue(self, name, path=None):
+        """ (deprecated, use getoption()) """
+        return self.getoption(name)
+
+    def getvalueorskip(self, name, path=None):
+        """ (deprecated, use getoption(skip=True)) """
+        return self.getoption(name, skip=True)
+
+
+def _assertion_supported():
+    try:
+        assert False
+    except AssertionError:
+        return True
+    else:
+        return False
+
+
+def _warn_about_missing_assertion(mode):
+    if not _assertion_supported():
+        if mode == "plain":
+            sys.stderr.write(
+                "WARNING: ASSERTIONS ARE NOT EXECUTED"
+                " and FAILING TESTS WILL PASS.  Are you"
+                " using python -O?"
+            )
+        else:
+            sys.stderr.write(
+                "WARNING: assertions not in test modules or"
+                " plugins will be ignored"
+                " because assert statements are not executed "
+                "by the underlying Python interpreter "
+                "(are you using python -O?)\n"
+            )
+
+
+def setns(obj, dic):
+    import pytest
+
+    for name, value in dic.items():
+        if isinstance(value, dict):
+            mod = getattr(obj, name, None)
+            if mod is None:
+                modname = "pytest.%s" % name
+                mod = types.ModuleType(modname)
+                sys.modules[modname] = mod
+                mod.__all__ = []
+                setattr(obj, name, mod)
+            obj.__all__.append(name)
+            setns(mod, value)
+        else:
+            setattr(obj, name, value)
+            obj.__all__.append(name)
+            # if obj != pytest:
+            #    pytest.__all__.append(name)
+            setattr(pytest, name, value)
+
+
+def create_terminal_writer(config, *args, **kwargs):
+    """Create a TerminalWriter instance configured according to the options
+    in the config object. Every code which requires a TerminalWriter object
+    and has access to a config object should use this function.
+    """
+    tw = py.io.TerminalWriter(*args, **kwargs)
+    if config.option.color == "yes":
+        tw.hasmarkup = True
+    if config.option.color == "no":
+        tw.hasmarkup = False
+    return tw
+
+
+def _strtobool(val):
+    """Convert a string representation of truth to true (1) or false (0).
+
+    True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
+    are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
+    'val' is anything else.
+
+    .. note:: copied from distutils.util
+    """
+    val = val.lower()
+    if val in ("y", "yes", "t", "true", "on", "1"):
+        return 1
+    elif val in ("n", "no", "f", "false", "off", "0"):
+        return 0
+    else:
+        raise ValueError("invalid truth value %r" % (val,))
Index: venv/Lib/site-packages/_pytest/config/findpaths.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/config/findpaths.py	(date 1543190975503)
+++ venv/Lib/site-packages/_pytest/config/findpaths.py	(date 1543190975503)
@@ -0,0 +1,148 @@
+import os
+
+import py
+
+from .exceptions import UsageError
+
+
+def exists(path, ignore=EnvironmentError):
+    try:
+        return path.check()
+    except ignore:
+        return False
+
+
+def getcfg(args, config=None):
+    """
+    Search the list of arguments for a valid ini-file for pytest,
+    and return a tuple of (rootdir, inifile, cfg-dict).
+
+    note: config is optional and used only to issue warnings explicitly (#2891).
+    """
+    from _pytest.deprecated import CFG_PYTEST_SECTION
+
+    inibasenames = ["pytest.ini", "tox.ini", "setup.cfg"]
+    args = [x for x in args if not str(x).startswith("-")]
+    if not args:
+        args = [py.path.local()]
+    for arg in args:
+        arg = py.path.local(arg)
+        for base in arg.parts(reverse=True):
+            for inibasename in inibasenames:
+                p = base.join(inibasename)
+                if exists(p):
+                    iniconfig = py.iniconfig.IniConfig(p)
+                    if "pytest" in iniconfig.sections:
+                        if inibasename == "setup.cfg" and config is not None:
+                            from _pytest.warnings import _issue_config_warning
+                            from _pytest.warning_types import RemovedInPytest4Warning
+
+                            _issue_config_warning(
+                                RemovedInPytest4Warning(
+                                    CFG_PYTEST_SECTION.format(filename=inibasename)
+                                ),
+                                config=config,
+                            )
+                        return base, p, iniconfig["pytest"]
+                    if (
+                        inibasename == "setup.cfg"
+                        and "tool:pytest" in iniconfig.sections
+                    ):
+                        return base, p, iniconfig["tool:pytest"]
+                    elif inibasename == "pytest.ini":
+                        # allowed to be empty
+                        return base, p, {}
+    return None, None, None
+
+
+def get_common_ancestor(paths):
+    common_ancestor = None
+    for path in paths:
+        if not path.exists():
+            continue
+        if common_ancestor is None:
+            common_ancestor = path
+        else:
+            if path.relto(common_ancestor) or path == common_ancestor:
+                continue
+            elif common_ancestor.relto(path):
+                common_ancestor = path
+            else:
+                shared = path.common(common_ancestor)
+                if shared is not None:
+                    common_ancestor = shared
+    if common_ancestor is None:
+        common_ancestor = py.path.local()
+    elif common_ancestor.isfile():
+        common_ancestor = common_ancestor.dirpath()
+    return common_ancestor
+
+
+def get_dirs_from_args(args):
+    def is_option(x):
+        return str(x).startswith("-")
+
+    def get_file_part_from_node_id(x):
+        return str(x).split("::")[0]
+
+    def get_dir_from_path(path):
+        if path.isdir():
+            return path
+        return py.path.local(path.dirname)
+
+    # These look like paths but may not exist
+    possible_paths = (
+        py.path.local(get_file_part_from_node_id(arg))
+        for arg in args
+        if not is_option(arg)
+    )
+
+    return [get_dir_from_path(path) for path in possible_paths if path.exists()]
+
+
+def determine_setup(inifile, args, rootdir_cmd_arg=None, config=None):
+    dirs = get_dirs_from_args(args)
+    if inifile:
+        iniconfig = py.iniconfig.IniConfig(inifile)
+        is_cfg_file = str(inifile).endswith(".cfg")
+        sections = ["tool:pytest", "pytest"] if is_cfg_file else ["pytest"]
+        for section in sections:
+            try:
+                inicfg = iniconfig[section]
+                if is_cfg_file and section == "pytest" and config is not None:
+                    from _pytest.deprecated import CFG_PYTEST_SECTION
+                    from _pytest.warnings import _issue_config_warning
+
+                    # TODO: [pytest] section in *.cfg files is deprecated. Need refactoring once
+                    # the deprecation expires.
+                    _issue_config_warning(
+                        CFG_PYTEST_SECTION.format(filename=str(inifile)), config
+                    )
+                break
+            except KeyError:
+                inicfg = None
+        rootdir = get_common_ancestor(dirs)
+    else:
+        ancestor = get_common_ancestor(dirs)
+        rootdir, inifile, inicfg = getcfg([ancestor], config=config)
+        if rootdir is None:
+            for rootdir in ancestor.parts(reverse=True):
+                if rootdir.join("setup.py").exists():
+                    break
+            else:
+                rootdir, inifile, inicfg = getcfg(dirs, config=config)
+                if rootdir is None:
+                    rootdir = get_common_ancestor([py.path.local(), ancestor])
+                    is_fs_root = os.path.splitdrive(str(rootdir))[1] == "/"
+                    if is_fs_root:
+                        rootdir = ancestor
+    if rootdir_cmd_arg:
+        rootdir_abs_path = py.path.local(os.path.expandvars(rootdir_cmd_arg))
+        if not os.path.isdir(str(rootdir_abs_path)):
+            raise UsageError(
+                "Directory '{}' not found. Check your '--rootdir' option.".format(
+                    rootdir_abs_path
+                )
+            )
+        rootdir = rootdir_abs_path
+    return rootdir, inifile, inicfg or {}
Index: venv/Lib/site-packages/_pytest/config/argparsing.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/config/argparsing.py	(date 1543190975515)
+++ venv/Lib/site-packages/_pytest/config/argparsing.py	(date 1543190975515)
@@ -0,0 +1,409 @@
+import argparse
+import sys as _sys
+import warnings
+from gettext import gettext as _
+
+import py
+import six
+
+from ..main import EXIT_USAGEERROR
+
+FILE_OR_DIR = "file_or_dir"
+
+
+class Parser(object):
+    """ Parser for command line arguments and ini-file values.
+
+    :ivar extra_info: dict of generic param -> value to display in case
+        there's an error processing the command line arguments.
+    """
+
+    def __init__(self, usage=None, processopt=None):
+        self._anonymous = OptionGroup("custom options", parser=self)
+        self._groups = []
+        self._processopt = processopt
+        self._usage = usage
+        self._inidict = {}
+        self._ininames = []
+        self.extra_info = {}
+
+    def processoption(self, option):
+        if self._processopt:
+            if option.dest:
+                self._processopt(option)
+
+    def getgroup(self, name, description="", after=None):
+        """ get (or create) a named option Group.
+
+        :name: name of the option group.
+        :description: long description for --help output.
+        :after: name of other group, used for ordering --help output.
+
+        The returned group object has an ``addoption`` method with the same
+        signature as :py:func:`parser.addoption
+        <_pytest.config.Parser.addoption>` but will be shown in the
+        respective group in the output of ``pytest. --help``.
+        """
+        for group in self._groups:
+            if group.name == name:
+                return group
+        group = OptionGroup(name, description, parser=self)
+        i = 0
+        for i, grp in enumerate(self._groups):
+            if grp.name == after:
+                break
+        self._groups.insert(i + 1, group)
+        return group
+
+    def addoption(self, *opts, **attrs):
+        """ register a command line option.
+
+        :opts: option names, can be short or long options.
+        :attrs: same attributes which the ``add_option()`` function of the
+           `argparse library
+           <http://docs.python.org/2/library/argparse.html>`_
+           accepts.
+
+        After command line parsing options are available on the pytest config
+        object via ``config.option.NAME`` where ``NAME`` is usually set
+        by passing a ``dest`` attribute, for example
+        ``addoption("--long", dest="NAME", ...)``.
+        """
+        self._anonymous.addoption(*opts, **attrs)
+
+    def parse(self, args, namespace=None):
+        from _pytest._argcomplete import try_argcomplete
+
+        self.optparser = self._getparser()
+        try_argcomplete(self.optparser)
+        args = [str(x) if isinstance(x, py.path.local) else x for x in args]
+        return self.optparser.parse_args(args, namespace=namespace)
+
+    def _getparser(self):
+        from _pytest._argcomplete import filescompleter
+
+        optparser = MyOptionParser(self, self.extra_info)
+        groups = self._groups + [self._anonymous]
+        for group in groups:
+            if group.options:
+                desc = group.description or group.name
+                arggroup = optparser.add_argument_group(desc)
+                for option in group.options:
+                    n = option.names()
+                    a = option.attrs()
+                    arggroup.add_argument(*n, **a)
+        # bash like autocompletion for dirs (appending '/')
+        optparser.add_argument(FILE_OR_DIR, nargs="*").completer = filescompleter
+        return optparser
+
+    def parse_setoption(self, args, option, namespace=None):
+        parsedoption = self.parse(args, namespace=namespace)
+        for name, value in parsedoption.__dict__.items():
+            setattr(option, name, value)
+        return getattr(parsedoption, FILE_OR_DIR)
+
+    def parse_known_args(self, args, namespace=None):
+        """parses and returns a namespace object with known arguments at this
+        point.
+        """
+        return self.parse_known_and_unknown_args(args, namespace=namespace)[0]
+
+    def parse_known_and_unknown_args(self, args, namespace=None):
+        """parses and returns a namespace object with known arguments, and
+        the remaining arguments unknown at this point.
+        """
+        optparser = self._getparser()
+        args = [str(x) if isinstance(x, py.path.local) else x for x in args]
+        return optparser.parse_known_args(args, namespace=namespace)
+
+    def addini(self, name, help, type=None, default=None):
+        """ register an ini-file option.
+
+        :name: name of the ini-variable
+        :type: type of the variable, can be ``pathlist``, ``args``, ``linelist``
+               or ``bool``.
+        :default: default value if no ini-file option exists but is queried.
+
+        The value of ini-variables can be retrieved via a call to
+        :py:func:`config.getini(name) <_pytest.config.Config.getini>`.
+        """
+        assert type in (None, "pathlist", "args", "linelist", "bool")
+        self._inidict[name] = (help, type, default)
+        self._ininames.append(name)
+
+
+class ArgumentError(Exception):
+    """
+    Raised if an Argument instance is created with invalid or
+    inconsistent arguments.
+    """
+
+    def __init__(self, msg, option):
+        self.msg = msg
+        self.option_id = str(option)
+
+    def __str__(self):
+        if self.option_id:
+            return "option %s: %s" % (self.option_id, self.msg)
+        else:
+            return self.msg
+
+
+class Argument(object):
+    """class that mimics the necessary behaviour of optparse.Option
+
+    it's currently a least effort implementation
+    and ignoring choices and integer prefixes
+    https://docs.python.org/3/library/optparse.html#optparse-standard-option-types
+    """
+
+    _typ_map = {"int": int, "string": str, "float": float, "complex": complex}
+
+    def __init__(self, *names, **attrs):
+        """store parms in private vars for use in add_argument"""
+        self._attrs = attrs
+        self._short_opts = []
+        self._long_opts = []
+        self.dest = attrs.get("dest")
+        if "%default" in (attrs.get("help") or ""):
+            warnings.warn(
+                'pytest now uses argparse. "%default" should be'
+                ' changed to "%(default)s" ',
+                DeprecationWarning,
+                stacklevel=3,
+            )
+        try:
+            typ = attrs["type"]
+        except KeyError:
+            pass
+        else:
+            # this might raise a keyerror as well, don't want to catch that
+            if isinstance(typ, six.string_types):
+                if typ == "choice":
+                    warnings.warn(
+                        "`type` argument to addoption() is the string %r."
+                        " For choices this is optional and can be omitted, "
+                        " but when supplied should be a type (for example `str` or `int`)."
+                        " (options: %s)" % (typ, names),
+                        DeprecationWarning,
+                        stacklevel=4,
+                    )
+                    # argparse expects a type here take it from
+                    # the type of the first element
+                    attrs["type"] = type(attrs["choices"][0])
+                else:
+                    warnings.warn(
+                        "`type` argument to addoption() is the string %r, "
+                        " but when supplied should be a type (for example `str` or `int`)."
+                        " (options: %s)" % (typ, names),
+                        DeprecationWarning,
+                        stacklevel=4,
+                    )
+                    attrs["type"] = Argument._typ_map[typ]
+                # used in test_parseopt -> test_parse_defaultgetter
+                self.type = attrs["type"]
+            else:
+                self.type = typ
+        try:
+            # attribute existence is tested in Config._processopt
+            self.default = attrs["default"]
+        except KeyError:
+            pass
+        self._set_opt_strings(names)
+        if not self.dest:
+            if self._long_opts:
+                self.dest = self._long_opts[0][2:].replace("-", "_")
+            else:
+                try:
+                    self.dest = self._short_opts[0][1:]
+                except IndexError:
+                    raise ArgumentError("need a long or short option", self)
+
+    def names(self):
+        return self._short_opts + self._long_opts
+
+    def attrs(self):
+        # update any attributes set by processopt
+        attrs = "default dest help".split()
+        if self.dest:
+            attrs.append(self.dest)
+        for attr in attrs:
+            try:
+                self._attrs[attr] = getattr(self, attr)
+            except AttributeError:
+                pass
+        if self._attrs.get("help"):
+            a = self._attrs["help"]
+            a = a.replace("%default", "%(default)s")
+            # a = a.replace('%prog', '%(prog)s')
+            self._attrs["help"] = a
+        return self._attrs
+
+    def _set_opt_strings(self, opts):
+        """directly from optparse
+
+        might not be necessary as this is passed to argparse later on"""
+        for opt in opts:
+            if len(opt) < 2:
+                raise ArgumentError(
+                    "invalid option string %r: "
+                    "must be at least two characters long" % opt,
+                    self,
+                )
+            elif len(opt) == 2:
+                if not (opt[0] == "-" and opt[1] != "-"):
+                    raise ArgumentError(
+                        "invalid short option string %r: "
+                        "must be of the form -x, (x any non-dash char)" % opt,
+                        self,
+                    )
+                self._short_opts.append(opt)
+            else:
+                if not (opt[0:2] == "--" and opt[2] != "-"):
+                    raise ArgumentError(
+                        "invalid long option string %r: "
+                        "must start with --, followed by non-dash" % opt,
+                        self,
+                    )
+                self._long_opts.append(opt)
+
+    def __repr__(self):
+        args = []
+        if self._short_opts:
+            args += ["_short_opts: " + repr(self._short_opts)]
+        if self._long_opts:
+            args += ["_long_opts: " + repr(self._long_opts)]
+        args += ["dest: " + repr(self.dest)]
+        if hasattr(self, "type"):
+            args += ["type: " + repr(self.type)]
+        if hasattr(self, "default"):
+            args += ["default: " + repr(self.default)]
+        return "Argument({})".format(", ".join(args))
+
+
+class OptionGroup(object):
+    def __init__(self, name, description="", parser=None):
+        self.name = name
+        self.description = description
+        self.options = []
+        self.parser = parser
+
+    def addoption(self, *optnames, **attrs):
+        """ add an option to this group.
+
+        if a shortened version of a long option is specified it will
+        be suppressed in the help. addoption('--twowords', '--two-words')
+        results in help showing '--two-words' only, but --twowords gets
+        accepted **and** the automatic destination is in args.twowords
+        """
+        conflict = set(optnames).intersection(
+            name for opt in self.options for name in opt.names()
+        )
+        if conflict:
+            raise ValueError("option names %s already added" % conflict)
+        option = Argument(*optnames, **attrs)
+        self._addoption_instance(option, shortupper=False)
+
+    def _addoption(self, *optnames, **attrs):
+        option = Argument(*optnames, **attrs)
+        self._addoption_instance(option, shortupper=True)
+
+    def _addoption_instance(self, option, shortupper=False):
+        if not shortupper:
+            for opt in option._short_opts:
+                if opt[0] == "-" and opt[1].islower():
+                    raise ValueError("lowercase shortoptions reserved")
+        if self.parser:
+            self.parser.processoption(option)
+        self.options.append(option)
+
+
+class MyOptionParser(argparse.ArgumentParser):
+    def __init__(self, parser, extra_info=None):
+        if not extra_info:
+            extra_info = {}
+        self._parser = parser
+        argparse.ArgumentParser.__init__(
+            self,
+            usage=parser._usage,
+            add_help=False,
+            formatter_class=DropShorterLongHelpFormatter,
+        )
+        # extra_info is a dict of (param -> value) to display if there's
+        # an usage error to provide more contextual information to the user
+        self.extra_info = extra_info
+
+    def error(self, message):
+        """error(message: string)
+
+        Prints a usage message incorporating the message to stderr and
+        exits.
+        Overrides the method in parent class to change exit code"""
+        self.print_usage(_sys.stderr)
+        args = {"prog": self.prog, "message": message}
+        self.exit(EXIT_USAGEERROR, _("%(prog)s: error: %(message)s\n") % args)
+
+    def parse_args(self, args=None, namespace=None):
+        """allow splitting of positional arguments"""
+        args, argv = self.parse_known_args(args, namespace)
+        if argv:
+            for arg in argv:
+                if arg and arg[0] == "-":
+                    lines = ["unrecognized arguments: %s" % (" ".join(argv))]
+                    for k, v in sorted(self.extra_info.items()):
+                        lines.append("  %s: %s" % (k, v))
+                    self.error("\n".join(lines))
+            getattr(args, FILE_OR_DIR).extend(argv)
+        return args
+
+
+class DropShorterLongHelpFormatter(argparse.HelpFormatter):
+    """shorten help for long options that differ only in extra hyphens
+
+    - collapse **long** options that are the same except for extra hyphens
+    - special action attribute map_long_option allows surpressing additional
+      long options
+    - shortcut if there are only two options and one of them is a short one
+    - cache result on action object as this is called at least 2 times
+    """
+
+    def _format_action_invocation(self, action):
+        orgstr = argparse.HelpFormatter._format_action_invocation(self, action)
+        if orgstr and orgstr[0] != "-":  # only optional arguments
+            return orgstr
+        res = getattr(action, "_formatted_action_invocation", None)
+        if res:
+            return res
+        options = orgstr.split(", ")
+        if len(options) == 2 and (len(options[0]) == 2 or len(options[1]) == 2):
+            # a shortcut for '-h, --help' or '--abc', '-a'
+            action._formatted_action_invocation = orgstr
+            return orgstr
+        return_list = []
+        option_map = getattr(action, "map_long_option", {})
+        if option_map is None:
+            option_map = {}
+        short_long = {}
+        for option in options:
+            if len(option) == 2 or option[2] == " ":
+                continue
+            if not option.startswith("--"):
+                raise ArgumentError(
+                    'long optional argument without "--": [%s]' % (option), self
+                )
+            xxoption = option[2:]
+            if xxoption.split()[0] not in option_map:
+                shortened = xxoption.replace("-", "")
+                if shortened not in short_long or len(short_long[shortened]) < len(
+                    xxoption
+                ):
+                    short_long[shortened] = xxoption
+        # now short_long has been filled out to the longest with dashes
+        # **and** we keep the right option ordering from add_argument
+        for option in options:
+            if len(option) == 2 or option[2] == " ":
+                return_list.append(option)
+            if option[2:] == short_long.get(option.replace("-", "")):
+                return_list.append(option.replace(" ", "=", 1))
+        action._formatted_action_invocation = ", ".join(return_list)
+        return action._formatted_action_invocation
Index: venv/Lib/site-packages/more_itertools-4.3.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools-4.3.0.dist-info/top_level.txt	(date 1543190975524)
+++ venv/Lib/site-packages/more_itertools-4.3.0.dist-info/top_level.txt	(date 1543190975524)
@@ -0,0 +1,1 @@
+more_itertools
Index: venv/Lib/site-packages/more_itertools-4.3.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/more_itertools-4.3.0.dist-info/WHEEL	(date 1543190975533)
+++ venv/Lib/site-packages/more_itertools-4.3.0.dist-info/WHEEL	(date 1543190975533)
@@ -0,0 +1,5 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.31.1)
+Root-Is-Purelib: true
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/atomicwrites/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/atomicwrites/__init__.py	(date 1543190975545)
+++ venv/Lib/site-packages/atomicwrites/__init__.py	(date 1543190975545)
@@ -0,0 +1,214 @@
+import contextlib
+import io
+import os
+import sys
+import tempfile
+
+try:
+    import fcntl
+except ImportError:
+    fcntl = None
+
+__version__ = '1.2.1'
+
+
+PY2 = sys.version_info[0] == 2
+
+text_type = unicode if PY2 else str  # noqa
+
+
+def _path_to_unicode(x):
+    if not isinstance(x, text_type):
+        return x.decode(sys.getfilesystemencoding())
+    return x
+
+
+DEFAULT_MODE = "wb" if PY2 else "w"
+
+
+_proper_fsync = os.fsync
+
+
+if sys.platform != 'win32':
+    if hasattr(fcntl, 'F_FULLFSYNC'):
+        def _proper_fsync(fd):
+            # https://lists.apple.com/archives/darwin-dev/2005/Feb/msg00072.html
+            # https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man2/fsync.2.html
+            # https://github.com/untitaker/python-atomicwrites/issues/6
+            fcntl.fcntl(fd, fcntl.F_FULLFSYNC)
+
+    def _sync_directory(directory):
+        # Ensure that filenames are written to disk
+        fd = os.open(directory, 0)
+        try:
+            _proper_fsync(fd)
+        finally:
+            os.close(fd)
+
+    def _replace_atomic(src, dst):
+        os.rename(src, dst)
+        _sync_directory(os.path.normpath(os.path.dirname(dst)))
+
+    def _move_atomic(src, dst):
+        os.link(src, dst)
+        os.unlink(src)
+
+        src_dir = os.path.normpath(os.path.dirname(src))
+        dst_dir = os.path.normpath(os.path.dirname(dst))
+        _sync_directory(dst_dir)
+        if src_dir != dst_dir:
+            _sync_directory(src_dir)
+else:
+    from ctypes import windll, WinError
+
+    _MOVEFILE_REPLACE_EXISTING = 0x1
+    _MOVEFILE_WRITE_THROUGH = 0x8
+    _windows_default_flags = _MOVEFILE_WRITE_THROUGH
+
+    def _handle_errors(rv):
+        if not rv:
+            raise WinError()
+
+    def _replace_atomic(src, dst):
+        _handle_errors(windll.kernel32.MoveFileExW(
+            _path_to_unicode(src), _path_to_unicode(dst),
+            _windows_default_flags | _MOVEFILE_REPLACE_EXISTING
+        ))
+
+    def _move_atomic(src, dst):
+        _handle_errors(windll.kernel32.MoveFileExW(
+            _path_to_unicode(src), _path_to_unicode(dst),
+            _windows_default_flags
+        ))
+
+
+def replace_atomic(src, dst):
+    '''
+    Move ``src`` to ``dst``. If ``dst`` exists, it will be silently
+    overwritten.
+
+    Both paths must reside on the same filesystem for the operation to be
+    atomic.
+    '''
+    return _replace_atomic(src, dst)
+
+
+def move_atomic(src, dst):
+    '''
+    Move ``src`` to ``dst``. There might a timewindow where both filesystem
+    entries exist. If ``dst`` already exists, :py:exc:`FileExistsError` will be
+    raised.
+
+    Both paths must reside on the same filesystem for the operation to be
+    atomic.
+    '''
+    return _move_atomic(src, dst)
+
+
+class AtomicWriter(object):
+    '''
+    A helper class for performing atomic writes. Usage::
+
+        with AtomicWriter(path).open() as f:
+            f.write(...)
+
+    :param path: The destination filepath. May or may not exist.
+    :param mode: The filemode for the temporary file. This defaults to `wb` in
+        Python 2 and `w` in Python 3.
+    :param overwrite: If set to false, an error is raised if ``path`` exists.
+        Errors are only raised after the file has been written to.  Either way,
+        the operation is atomic.
+
+    If you need further control over the exact behavior, you are encouraged to
+    subclass.
+    '''
+
+    def __init__(self, path, mode=DEFAULT_MODE, overwrite=False,
+                 **open_kwargs):
+        if 'a' in mode:
+            raise ValueError(
+                'Appending to an existing file is not supported, because that '
+                'would involve an expensive `copy`-operation to a temporary '
+                'file. Open the file in normal `w`-mode and copy explicitly '
+                'if that\'s what you\'re after.'
+            )
+        if 'x' in mode:
+            raise ValueError('Use the `overwrite`-parameter instead.')
+        if 'w' not in mode:
+            raise ValueError('AtomicWriters can only be written to.')
+
+        self._path = path
+        self._mode = mode
+        self._overwrite = overwrite
+        self._open_kwargs = open_kwargs
+
+    def open(self):
+        '''
+        Open the temporary file.
+        '''
+        return self._open(self.get_fileobject)
+
+    @contextlib.contextmanager
+    def _open(self, get_fileobject):
+        f = None  # make sure f exists even if get_fileobject() fails
+        try:
+            success = False
+            with get_fileobject(**self._open_kwargs) as f:
+                yield f
+                self.sync(f)
+            self.commit(f)
+            success = True
+        finally:
+            if not success:
+                try:
+                    self.rollback(f)
+                except Exception:
+                    pass
+
+    def get_fileobject(self, dir=None, **kwargs):
+        '''Return the temporary file to use.'''
+        if dir is None:
+            dir = os.path.normpath(os.path.dirname(self._path))
+        descriptor, name = tempfile.mkstemp(dir=dir)
+        # io.open() will take either the descriptor or the name, but we need
+        # the name later for commit()/replace_atomic() and couldn't find a way
+        # to get the filename from the descriptor.
+        os.close(descriptor)
+        kwargs['mode'] = self._mode
+        kwargs['file'] = name
+        return io.open(**kwargs)
+
+    def sync(self, f):
+        '''responsible for clearing as many file caches as possible before
+        commit'''
+        f.flush()
+        _proper_fsync(f.fileno())
+
+    def commit(self, f):
+        '''Move the temporary file to the target location.'''
+        if self._overwrite:
+            replace_atomic(f.name, self._path)
+        else:
+            move_atomic(f.name, self._path)
+
+    def rollback(self, f):
+        '''Clean up all temporary resources.'''
+        os.unlink(f.name)
+
+
+def atomic_write(path, writer_cls=AtomicWriter, **cls_kwargs):
+    '''
+    Simple atomic writes. This wraps :py:class:`AtomicWriter`::
+
+        with atomic_write(path) as f:
+            f.write(...)
+
+    :param path: The target path to write to.
+    :param writer_cls: The writer class to use. This parameter is useful if you
+        subclassed :py:class:`AtomicWriter` to change some behavior and want to
+        use that new subclass.
+
+    Additional keyword arguments are passed to the writer class. See
+    :py:class:`AtomicWriter`.
+    '''
+    return writer_cls(path, **cls_kwargs).open()
Index: venv/Lib/site-packages/colorama/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama/__init__.py	(date 1543190975554)
+++ venv/Lib/site-packages/colorama/__init__.py	(date 1543190975554)
@@ -0,0 +1,6 @@
+# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
+from .initialise import init, deinit, reinit, colorama_text
+from .ansi import Fore, Back, Style, Cursor
+from .ansitowin32 import AnsiToWin32
+
+__version__ = '0.4.0'
Index: venv/Lib/site-packages/colorama/initialise.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama/initialise.py	(date 1543190975567)
+++ venv/Lib/site-packages/colorama/initialise.py	(date 1543190975567)
@@ -0,0 +1,80 @@
+# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
+import atexit
+import contextlib
+import sys
+
+from .ansitowin32 import AnsiToWin32
+
+
+orig_stdout = None
+orig_stderr = None
+
+wrapped_stdout = None
+wrapped_stderr = None
+
+atexit_done = False
+
+
+def reset_all():
+    if AnsiToWin32 is not None:    # Issue #74: objects might become None at exit
+        AnsiToWin32(orig_stdout).reset_all()
+
+
+def init(autoreset=False, convert=None, strip=None, wrap=True):
+
+    if not wrap and any([autoreset, convert, strip]):
+        raise ValueError('wrap=False conflicts with any other arg=True')
+
+    global wrapped_stdout, wrapped_stderr
+    global orig_stdout, orig_stderr
+
+    orig_stdout = sys.stdout
+    orig_stderr = sys.stderr
+
+    if sys.stdout is None:
+        wrapped_stdout = None
+    else:
+        sys.stdout = wrapped_stdout = \
+            wrap_stream(orig_stdout, convert, strip, autoreset, wrap)
+    if sys.stderr is None:
+        wrapped_stderr = None
+    else:
+        sys.stderr = wrapped_stderr = \
+            wrap_stream(orig_stderr, convert, strip, autoreset, wrap)
+
+    global atexit_done
+    if not atexit_done:
+        atexit.register(reset_all)
+        atexit_done = True
+
+
+def deinit():
+    if orig_stdout is not None:
+        sys.stdout = orig_stdout
+    if orig_stderr is not None:
+        sys.stderr = orig_stderr
+
+
+@contextlib.contextmanager
+def colorama_text(*args, **kwargs):
+    init(*args, **kwargs)
+    try:
+        yield
+    finally:
+        deinit()
+
+
+def reinit():
+    if wrapped_stdout is not None:
+        sys.stdout = wrapped_stdout
+    if wrapped_stderr is not None:
+        sys.stderr = wrapped_stderr
+
+
+def wrap_stream(stream, convert, strip, autoreset, wrap):
+    if wrap:
+        wrapper = AnsiToWin32(stream,
+            convert=convert, strip=strip, autoreset=autoreset)
+        if wrapper.should_wrap():
+            stream = wrapper.stream
+    return stream
Index: venv/Lib/site-packages/colorama/win32.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama/win32.py	(date 1543190975578)
+++ venv/Lib/site-packages/colorama/win32.py	(date 1543190975578)
@@ -0,0 +1,152 @@
+# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
+
+# from winbase.h
+STDOUT = -11
+STDERR = -12
+
+try:
+    import ctypes
+    from ctypes import LibraryLoader
+    windll = LibraryLoader(ctypes.WinDLL)
+    from ctypes import wintypes
+except (AttributeError, ImportError):
+    windll = None
+    SetConsoleTextAttribute = lambda *_: None
+    winapi_test = lambda *_: None
+else:
+    from ctypes import byref, Structure, c_char, POINTER
+
+    COORD = wintypes._COORD
+
+    class CONSOLE_SCREEN_BUFFER_INFO(Structure):
+        """struct in wincon.h."""
+        _fields_ = [
+            ("dwSize", COORD),
+            ("dwCursorPosition", COORD),
+            ("wAttributes", wintypes.WORD),
+            ("srWindow", wintypes.SMALL_RECT),
+            ("dwMaximumWindowSize", COORD),
+        ]
+        def __str__(self):
+            return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % (
+                self.dwSize.Y, self.dwSize.X
+                , self.dwCursorPosition.Y, self.dwCursorPosition.X
+                , self.wAttributes
+                , self.srWindow.Top, self.srWindow.Left, self.srWindow.Bottom, self.srWindow.Right
+                , self.dwMaximumWindowSize.Y, self.dwMaximumWindowSize.X
+            )
+
+    _GetStdHandle = windll.kernel32.GetStdHandle
+    _GetStdHandle.argtypes = [
+        wintypes.DWORD,
+    ]
+    _GetStdHandle.restype = wintypes.HANDLE
+
+    _GetConsoleScreenBufferInfo = windll.kernel32.GetConsoleScreenBufferInfo
+    _GetConsoleScreenBufferInfo.argtypes = [
+        wintypes.HANDLE,
+        POINTER(CONSOLE_SCREEN_BUFFER_INFO),
+    ]
+    _GetConsoleScreenBufferInfo.restype = wintypes.BOOL
+
+    _SetConsoleTextAttribute = windll.kernel32.SetConsoleTextAttribute
+    _SetConsoleTextAttribute.argtypes = [
+        wintypes.HANDLE,
+        wintypes.WORD,
+    ]
+    _SetConsoleTextAttribute.restype = wintypes.BOOL
+
+    _SetConsoleCursorPosition = windll.kernel32.SetConsoleCursorPosition
+    _SetConsoleCursorPosition.argtypes = [
+        wintypes.HANDLE,
+        COORD,
+    ]
+    _SetConsoleCursorPosition.restype = wintypes.BOOL
+
+    _FillConsoleOutputCharacterA = windll.kernel32.FillConsoleOutputCharacterA
+    _FillConsoleOutputCharacterA.argtypes = [
+        wintypes.HANDLE,
+        c_char,
+        wintypes.DWORD,
+        COORD,
+        POINTER(wintypes.DWORD),
+    ]
+    _FillConsoleOutputCharacterA.restype = wintypes.BOOL
+
+    _FillConsoleOutputAttribute = windll.kernel32.FillConsoleOutputAttribute
+    _FillConsoleOutputAttribute.argtypes = [
+        wintypes.HANDLE,
+        wintypes.WORD,
+        wintypes.DWORD,
+        COORD,
+        POINTER(wintypes.DWORD),
+    ]
+    _FillConsoleOutputAttribute.restype = wintypes.BOOL
+
+    _SetConsoleTitleW = windll.kernel32.SetConsoleTitleW
+    _SetConsoleTitleW.argtypes = [
+        wintypes.LPCWSTR
+    ]
+    _SetConsoleTitleW.restype = wintypes.BOOL
+
+    def _winapi_test(handle):
+        csbi = CONSOLE_SCREEN_BUFFER_INFO()
+        success = _GetConsoleScreenBufferInfo(
+            handle, byref(csbi))
+        return bool(success)
+
+    def winapi_test():
+        return any(_winapi_test(h) for h in
+                   (_GetStdHandle(STDOUT), _GetStdHandle(STDERR)))
+
+    def GetConsoleScreenBufferInfo(stream_id=STDOUT):
+        handle = _GetStdHandle(stream_id)
+        csbi = CONSOLE_SCREEN_BUFFER_INFO()
+        success = _GetConsoleScreenBufferInfo(
+            handle, byref(csbi))
+        return csbi
+
+    def SetConsoleTextAttribute(stream_id, attrs):
+        handle = _GetStdHandle(stream_id)
+        return _SetConsoleTextAttribute(handle, attrs)
+
+    def SetConsoleCursorPosition(stream_id, position, adjust=True):
+        position = COORD(*position)
+        # If the position is out of range, do nothing.
+        if position.Y <= 0 or position.X <= 0:
+            return
+        # Adjust for Windows' SetConsoleCursorPosition:
+        #    1. being 0-based, while ANSI is 1-based.
+        #    2. expecting (x,y), while ANSI uses (y,x).
+        adjusted_position = COORD(position.Y - 1, position.X - 1)
+        if adjust:
+            # Adjust for viewport's scroll position
+            sr = GetConsoleScreenBufferInfo(STDOUT).srWindow
+            adjusted_position.Y += sr.Top
+            adjusted_position.X += sr.Left
+        # Resume normal processing
+        handle = _GetStdHandle(stream_id)
+        return _SetConsoleCursorPosition(handle, adjusted_position)
+
+    def FillConsoleOutputCharacter(stream_id, char, length, start):
+        handle = _GetStdHandle(stream_id)
+        char = c_char(char.encode())
+        length = wintypes.DWORD(length)
+        num_written = wintypes.DWORD(0)
+        # Note that this is hard-coded for ANSI (vs wide) bytes.
+        success = _FillConsoleOutputCharacterA(
+            handle, char, length, start, byref(num_written))
+        return num_written.value
+
+    def FillConsoleOutputAttribute(stream_id, attr, length, start):
+        ''' FillConsoleOutputAttribute( hConsole, csbi.wAttributes, dwConSize, coordScreen, &cCharsWritten )'''
+        handle = _GetStdHandle(stream_id)
+        attribute = wintypes.WORD(attr)
+        length = wintypes.DWORD(length)
+        num_written = wintypes.DWORD(0)
+        # Note that this is hard-coded for ANSI (vs wide) bytes.
+        return _FillConsoleOutputAttribute(
+            handle, attribute, length, start, byref(num_written))
+
+    def SetConsoleTitle(title):
+        return _SetConsoleTitleW(title)
Index: venv/Lib/site-packages/colorama/winterm.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama/winterm.py	(date 1543190975588)
+++ venv/Lib/site-packages/colorama/winterm.py	(date 1543190975588)
@@ -0,0 +1,169 @@
+# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
+from . import win32
+
+
+# from wincon.h
+class WinColor(object):
+    BLACK   = 0
+    BLUE    = 1
+    GREEN   = 2
+    CYAN    = 3
+    RED     = 4
+    MAGENTA = 5
+    YELLOW  = 6
+    GREY    = 7
+
+# from wincon.h
+class WinStyle(object):
+    NORMAL              = 0x00 # dim text, dim background
+    BRIGHT              = 0x08 # bright text, dim background
+    BRIGHT_BACKGROUND   = 0x80 # dim text, bright background
+
+class WinTerm(object):
+
+    def __init__(self):
+        self._default = win32.GetConsoleScreenBufferInfo(win32.STDOUT).wAttributes
+        self.set_attrs(self._default)
+        self._default_fore = self._fore
+        self._default_back = self._back
+        self._default_style = self._style
+        # In order to emulate LIGHT_EX in windows, we borrow the BRIGHT style.
+        # So that LIGHT_EX colors and BRIGHT style do not clobber each other,
+        # we track them separately, since LIGHT_EX is overwritten by Fore/Back
+        # and BRIGHT is overwritten by Style codes.
+        self._light = 0
+
+    def get_attrs(self):
+        return self._fore + self._back * 16 + (self._style | self._light)
+
+    def set_attrs(self, value):
+        self._fore = value & 7
+        self._back = (value >> 4) & 7
+        self._style = value & (WinStyle.BRIGHT | WinStyle.BRIGHT_BACKGROUND)
+
+    def reset_all(self, on_stderr=None):
+        self.set_attrs(self._default)
+        self.set_console(attrs=self._default)
+        self._light = 0
+
+    def fore(self, fore=None, light=False, on_stderr=False):
+        if fore is None:
+            fore = self._default_fore
+        self._fore = fore
+        # Emulate LIGHT_EX with BRIGHT Style
+        if light:
+            self._light |= WinStyle.BRIGHT
+        else:
+            self._light &= ~WinStyle.BRIGHT
+        self.set_console(on_stderr=on_stderr)
+
+    def back(self, back=None, light=False, on_stderr=False):
+        if back is None:
+            back = self._default_back
+        self._back = back
+        # Emulate LIGHT_EX with BRIGHT_BACKGROUND Style
+        if light:
+            self._light |= WinStyle.BRIGHT_BACKGROUND
+        else:
+            self._light &= ~WinStyle.BRIGHT_BACKGROUND
+        self.set_console(on_stderr=on_stderr)
+
+    def style(self, style=None, on_stderr=False):
+        if style is None:
+            style = self._default_style
+        self._style = style
+        self.set_console(on_stderr=on_stderr)
+
+    def set_console(self, attrs=None, on_stderr=False):
+        if attrs is None:
+            attrs = self.get_attrs()
+        handle = win32.STDOUT
+        if on_stderr:
+            handle = win32.STDERR
+        win32.SetConsoleTextAttribute(handle, attrs)
+
+    def get_position(self, handle):
+        position = win32.GetConsoleScreenBufferInfo(handle).dwCursorPosition
+        # Because Windows coordinates are 0-based,
+        # and win32.SetConsoleCursorPosition expects 1-based.
+        position.X += 1
+        position.Y += 1
+        return position
+
+    def set_cursor_position(self, position=None, on_stderr=False):
+        if position is None:
+            # I'm not currently tracking the position, so there is no default.
+            # position = self.get_position()
+            return
+        handle = win32.STDOUT
+        if on_stderr:
+            handle = win32.STDERR
+        win32.SetConsoleCursorPosition(handle, position)
+
+    def cursor_adjust(self, x, y, on_stderr=False):
+        handle = win32.STDOUT
+        if on_stderr:
+            handle = win32.STDERR
+        position = self.get_position(handle)
+        adjusted_position = (position.Y + y, position.X + x)
+        win32.SetConsoleCursorPosition(handle, adjusted_position, adjust=False)
+
+    def erase_screen(self, mode=0, on_stderr=False):
+        # 0 should clear from the cursor to the end of the screen.
+        # 1 should clear from the cursor to the beginning of the screen.
+        # 2 should clear the entire screen, and move cursor to (1,1)
+        handle = win32.STDOUT
+        if on_stderr:
+            handle = win32.STDERR
+        csbi = win32.GetConsoleScreenBufferInfo(handle)
+        # get the number of character cells in the current buffer
+        cells_in_screen = csbi.dwSize.X * csbi.dwSize.Y
+        # get number of character cells before current cursor position
+        cells_before_cursor = csbi.dwSize.X * csbi.dwCursorPosition.Y + csbi.dwCursorPosition.X
+        if mode == 0:
+            from_coord = csbi.dwCursorPosition
+            cells_to_erase = cells_in_screen - cells_before_cursor
+        elif mode == 1:
+            from_coord = win32.COORD(0, 0)
+            cells_to_erase = cells_before_cursor
+        elif mode == 2:
+            from_coord = win32.COORD(0, 0)
+            cells_to_erase = cells_in_screen
+        else:
+            # invalid mode
+            return
+        # fill the entire screen with blanks
+        win32.FillConsoleOutputCharacter(handle, ' ', cells_to_erase, from_coord)
+        # now set the buffer's attributes accordingly
+        win32.FillConsoleOutputAttribute(handle, self.get_attrs(), cells_to_erase, from_coord)
+        if mode == 2:
+            # put the cursor where needed
+            win32.SetConsoleCursorPosition(handle, (1, 1))
+
+    def erase_line(self, mode=0, on_stderr=False):
+        # 0 should clear from the cursor to the end of the line.
+        # 1 should clear from the cursor to the beginning of the line.
+        # 2 should clear the entire line.
+        handle = win32.STDOUT
+        if on_stderr:
+            handle = win32.STDERR
+        csbi = win32.GetConsoleScreenBufferInfo(handle)
+        if mode == 0:
+            from_coord = csbi.dwCursorPosition
+            cells_to_erase = csbi.dwSize.X - csbi.dwCursorPosition.X
+        elif mode == 1:
+            from_coord = win32.COORD(0, csbi.dwCursorPosition.Y)
+            cells_to_erase = csbi.dwCursorPosition.X
+        elif mode == 2:
+            from_coord = win32.COORD(0, csbi.dwCursorPosition.Y)
+            cells_to_erase = csbi.dwSize.X
+        else:
+            # invalid mode
+            return
+        # fill the entire screen with blanks
+        win32.FillConsoleOutputCharacter(handle, ' ', cells_to_erase, from_coord)
+        # now set the buffer's attributes accordingly
+        win32.FillConsoleOutputAttribute(handle, self.get_attrs(), cells_to_erase, from_coord)
+
+    def set_title(self, title):
+        win32.SetConsoleTitle(title)
Index: venv/Lib/site-packages/colorama/ansitowin32.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama/ansitowin32.py	(date 1543190975599)
+++ venv/Lib/site-packages/colorama/ansitowin32.py	(date 1543190975599)
@@ -0,0 +1,249 @@
+# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
+import re
+import sys
+import os
+
+from .ansi import AnsiFore, AnsiBack, AnsiStyle, Style
+from .winterm import WinTerm, WinColor, WinStyle
+from .win32 import windll, winapi_test
+
+
+winterm = None
+if windll is not None:
+    winterm = WinTerm()
+
+
+class StreamWrapper(object):
+    '''
+    Wraps a stream (such as stdout), acting as a transparent proxy for all
+    attribute access apart from method 'write()', which is delegated to our
+    Converter instance.
+    '''
+    def __init__(self, wrapped, converter):
+        # double-underscore everything to prevent clashes with names of
+        # attributes on the wrapped stream object.
+        self.__wrapped = wrapped
+        self.__convertor = converter
+
+    def __getattr__(self, name):
+        return getattr(self.__wrapped, name)
+
+    def __enter__(self, *args, **kwargs):
+        # special method lookup bypasses __getattr__/__getattribute__, see
+        # https://stackoverflow.com/questions/12632894/why-doesnt-getattr-work-with-exit
+        # thus, contextlib magic methods are not proxied via __getattr__
+        return self.__wrapped.__enter__(*args, **kwargs)
+
+    def __exit__(self, *args, **kwargs):
+        return self.__wrapped.__exit__(*args, **kwargs)
+
+    def write(self, text):
+        self.__convertor.write(text)
+
+    def isatty(self):
+        stream = self.__wrapped
+        if 'PYCHARM_HOSTED' in os.environ:
+            if stream is not None and (stream is sys.__stdout__ or stream is sys.__stderr__):
+                return True
+        return (hasattr(stream, 'isatty') and stream.isatty())
+
+    @property
+    def closed(self):
+        stream = self.__wrapped
+        return not hasattr(stream, 'closed') or stream.closed
+
+
+class AnsiToWin32(object):
+    '''
+    Implements a 'write()' method which, on Windows, will strip ANSI character
+    sequences from the text, and if outputting to a tty, will convert them into
+    win32 function calls.
+    '''
+    ANSI_CSI_RE = re.compile('\001?\033\\[((?:\\d|;)*)([a-zA-Z])\002?')   # Control Sequence Introducer
+    ANSI_OSC_RE = re.compile('\001?\033\\]((?:.|;)*?)(\x07)\002?')        # Operating System Command
+
+    def __init__(self, wrapped, convert=None, strip=None, autoreset=False):
+        # The wrapped stream (normally sys.stdout or sys.stderr)
+        self.wrapped = wrapped
+
+        # should we reset colors to defaults after every .write()
+        self.autoreset = autoreset
+
+        # create the proxy wrapping our output stream
+        self.stream = StreamWrapper(wrapped, self)
+
+        on_windows = os.name == 'nt'
+        # We test if the WinAPI works, because even if we are on Windows
+        # we may be using a terminal that doesn't support the WinAPI
+        # (e.g. Cygwin Terminal). In this case it's up to the terminal
+        # to support the ANSI codes.
+        conversion_supported = on_windows and winapi_test()
+
+        # should we strip ANSI sequences from our output?
+        if strip is None:
+            strip = conversion_supported or (not self.stream.closed and not self.stream.isatty())
+        self.strip = strip
+
+        # should we should convert ANSI sequences into win32 calls?
+        if convert is None:
+            convert = conversion_supported and not self.stream.closed and self.stream.isatty()
+        self.convert = convert
+
+        # dict of ansi codes to win32 functions and parameters
+        self.win32_calls = self.get_win32_calls()
+
+        # are we wrapping stderr?
+        self.on_stderr = self.wrapped is sys.stderr
+
+    def should_wrap(self):
+        '''
+        True if this class is actually needed. If false, then the output
+        stream will not be affected, nor will win32 calls be issued, so
+        wrapping stdout is not actually required. This will generally be
+        False on non-Windows platforms, unless optional functionality like
+        autoreset has been requested using kwargs to init()
+        '''
+        return self.convert or self.strip or self.autoreset
+
+    def get_win32_calls(self):
+        if self.convert and winterm:
+            return {
+                AnsiStyle.RESET_ALL: (winterm.reset_all, ),
+                AnsiStyle.BRIGHT: (winterm.style, WinStyle.BRIGHT),
+                AnsiStyle.DIM: (winterm.style, WinStyle.NORMAL),
+                AnsiStyle.NORMAL: (winterm.style, WinStyle.NORMAL),
+                AnsiFore.BLACK: (winterm.fore, WinColor.BLACK),
+                AnsiFore.RED: (winterm.fore, WinColor.RED),
+                AnsiFore.GREEN: (winterm.fore, WinColor.GREEN),
+                AnsiFore.YELLOW: (winterm.fore, WinColor.YELLOW),
+                AnsiFore.BLUE: (winterm.fore, WinColor.BLUE),
+                AnsiFore.MAGENTA: (winterm.fore, WinColor.MAGENTA),
+                AnsiFore.CYAN: (winterm.fore, WinColor.CYAN),
+                AnsiFore.WHITE: (winterm.fore, WinColor.GREY),
+                AnsiFore.RESET: (winterm.fore, ),
+                AnsiFore.LIGHTBLACK_EX: (winterm.fore, WinColor.BLACK, True),
+                AnsiFore.LIGHTRED_EX: (winterm.fore, WinColor.RED, True),
+                AnsiFore.LIGHTGREEN_EX: (winterm.fore, WinColor.GREEN, True),
+                AnsiFore.LIGHTYELLOW_EX: (winterm.fore, WinColor.YELLOW, True),
+                AnsiFore.LIGHTBLUE_EX: (winterm.fore, WinColor.BLUE, True),
+                AnsiFore.LIGHTMAGENTA_EX: (winterm.fore, WinColor.MAGENTA, True),
+                AnsiFore.LIGHTCYAN_EX: (winterm.fore, WinColor.CYAN, True),
+                AnsiFore.LIGHTWHITE_EX: (winterm.fore, WinColor.GREY, True),
+                AnsiBack.BLACK: (winterm.back, WinColor.BLACK),
+                AnsiBack.RED: (winterm.back, WinColor.RED),
+                AnsiBack.GREEN: (winterm.back, WinColor.GREEN),
+                AnsiBack.YELLOW: (winterm.back, WinColor.YELLOW),
+                AnsiBack.BLUE: (winterm.back, WinColor.BLUE),
+                AnsiBack.MAGENTA: (winterm.back, WinColor.MAGENTA),
+                AnsiBack.CYAN: (winterm.back, WinColor.CYAN),
+                AnsiBack.WHITE: (winterm.back, WinColor.GREY),
+                AnsiBack.RESET: (winterm.back, ),
+                AnsiBack.LIGHTBLACK_EX: (winterm.back, WinColor.BLACK, True),
+                AnsiBack.LIGHTRED_EX: (winterm.back, WinColor.RED, True),
+                AnsiBack.LIGHTGREEN_EX: (winterm.back, WinColor.GREEN, True),
+                AnsiBack.LIGHTYELLOW_EX: (winterm.back, WinColor.YELLOW, True),
+                AnsiBack.LIGHTBLUE_EX: (winterm.back, WinColor.BLUE, True),
+                AnsiBack.LIGHTMAGENTA_EX: (winterm.back, WinColor.MAGENTA, True),
+                AnsiBack.LIGHTCYAN_EX: (winterm.back, WinColor.CYAN, True),
+                AnsiBack.LIGHTWHITE_EX: (winterm.back, WinColor.GREY, True),
+            }
+        return dict()
+
+    def write(self, text):
+        if self.strip or self.convert:
+            self.write_and_convert(text)
+        else:
+            self.wrapped.write(text)
+            self.wrapped.flush()
+        if self.autoreset:
+            self.reset_all()
+
+
+    def reset_all(self):
+        if self.convert:
+            self.call_win32('m', (0,))
+        elif not self.strip and not self.stream.closed:
+            self.wrapped.write(Style.RESET_ALL)
+
+
+    def write_and_convert(self, text):
+        '''
+        Write the given text to our wrapped stream, stripping any ANSI
+        sequences from the text, and optionally converting them into win32
+        calls.
+        '''
+        cursor = 0
+        text = self.convert_osc(text)
+        for match in self.ANSI_CSI_RE.finditer(text):
+            start, end = match.span()
+            self.write_plain_text(text, cursor, start)
+            self.convert_ansi(*match.groups())
+            cursor = end
+        self.write_plain_text(text, cursor, len(text))
+
+
+    def write_plain_text(self, text, start, end):
+        if start < end:
+            self.wrapped.write(text[start:end])
+            self.wrapped.flush()
+
+
+    def convert_ansi(self, paramstring, command):
+        if self.convert:
+            params = self.extract_params(command, paramstring)
+            self.call_win32(command, params)
+
+
+    def extract_params(self, command, paramstring):
+        if command in 'Hf':
+            params = tuple(int(p) if len(p) != 0 else 1 for p in paramstring.split(';'))
+            while len(params) < 2:
+                # defaults:
+                params = params + (1,)
+        else:
+            params = tuple(int(p) for p in paramstring.split(';') if len(p) != 0)
+            if len(params) == 0:
+                # defaults:
+                if command in 'JKm':
+                    params = (0,)
+                elif command in 'ABCD':
+                    params = (1,)
+
+        return params
+
+
+    def call_win32(self, command, params):
+        if command == 'm':
+            for param in params:
+                if param in self.win32_calls:
+                    func_args = self.win32_calls[param]
+                    func = func_args[0]
+                    args = func_args[1:]
+                    kwargs = dict(on_stderr=self.on_stderr)
+                    func(*args, **kwargs)
+        elif command in 'J':
+            winterm.erase_screen(params[0], on_stderr=self.on_stderr)
+        elif command in 'K':
+            winterm.erase_line(params[0], on_stderr=self.on_stderr)
+        elif command in 'Hf':     # cursor position - absolute
+            winterm.set_cursor_position(params, on_stderr=self.on_stderr)
+        elif command in 'ABCD':   # cursor position - relative
+            n = params[0]
+            # A - up, B - down, C - forward, D - back
+            x, y = {'A': (0, -n), 'B': (0, n), 'C': (n, 0), 'D': (-n, 0)}[command]
+            winterm.cursor_adjust(x, y, on_stderr=self.on_stderr)
+
+
+    def convert_osc(self, text):
+        for match in self.ANSI_OSC_RE.finditer(text):
+            start, end = match.span()
+            text = text[:start] + text[end:]
+            paramstring, command = match.groups()
+            if command in '\x07':       # \x07 = BEL
+                params = paramstring.split(";")
+                # 0 - change title and icon (we will only change title)
+                # 1 - change icon (we don't support this)
+                # 2 - change title
+                if params[0] in '02':
+                    winterm.set_title(params[1])
+        return text
Index: venv/Lib/site-packages/colorama/ansi.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/colorama/ansi.py	(date 1543190975607)
+++ venv/Lib/site-packages/colorama/ansi.py	(date 1543190975607)
@@ -0,0 +1,102 @@
+# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
+'''
+This module generates ANSI character codes to printing colors to terminals.
+See: http://en.wikipedia.org/wiki/ANSI_escape_code
+'''
+
+CSI = '\033['
+OSC = '\033]'
+BEL = '\007'
+
+
+def code_to_chars(code):
+    return CSI + str(code) + 'm'
+
+def set_title(title):
+    return OSC + '2;' + title + BEL
+
+def clear_screen(mode=2):
+    return CSI + str(mode) + 'J'
+
+def clear_line(mode=2):
+    return CSI + str(mode) + 'K'
+
+
+class AnsiCodes(object):
+    def __init__(self):
+        # the subclasses declare class attributes which are numbers.
+        # Upon instantiation we define instance attributes, which are the same
+        # as the class attributes but wrapped with the ANSI escape sequence
+        for name in dir(self):
+            if not name.startswith('_'):
+                value = getattr(self, name)
+                setattr(self, name, code_to_chars(value))
+
+
+class AnsiCursor(object):
+    def UP(self, n=1):
+        return CSI + str(n) + 'A'
+    def DOWN(self, n=1):
+        return CSI + str(n) + 'B'
+    def FORWARD(self, n=1):
+        return CSI + str(n) + 'C'
+    def BACK(self, n=1):
+        return CSI + str(n) + 'D'
+    def POS(self, x=1, y=1):
+        return CSI + str(y) + ';' + str(x) + 'H'
+
+
+class AnsiFore(AnsiCodes):
+    BLACK           = 30
+    RED             = 31
+    GREEN           = 32
+    YELLOW          = 33
+    BLUE            = 34
+    MAGENTA         = 35
+    CYAN            = 36
+    WHITE           = 37
+    RESET           = 39
+
+    # These are fairly well supported, but not part of the standard.
+    LIGHTBLACK_EX   = 90
+    LIGHTRED_EX     = 91
+    LIGHTGREEN_EX   = 92
+    LIGHTYELLOW_EX  = 93
+    LIGHTBLUE_EX    = 94
+    LIGHTMAGENTA_EX = 95
+    LIGHTCYAN_EX    = 96
+    LIGHTWHITE_EX   = 97
+
+
+class AnsiBack(AnsiCodes):
+    BLACK           = 40
+    RED             = 41
+    GREEN           = 42
+    YELLOW          = 43
+    BLUE            = 44
+    MAGENTA         = 45
+    CYAN            = 46
+    WHITE           = 47
+    RESET           = 49
+
+    # These are fairly well supported, but not part of the standard.
+    LIGHTBLACK_EX   = 100
+    LIGHTRED_EX     = 101
+    LIGHTGREEN_EX   = 102
+    LIGHTYELLOW_EX  = 103
+    LIGHTBLUE_EX    = 104
+    LIGHTMAGENTA_EX = 105
+    LIGHTCYAN_EX    = 106
+    LIGHTWHITE_EX   = 107
+
+
+class AnsiStyle(AnsiCodes):
+    BRIGHT    = 1
+    DIM       = 2
+    NORMAL    = 22
+    RESET_ALL = 0
+
+Fore   = AnsiFore()
+Back   = AnsiBack()
+Style  = AnsiStyle()
+Cursor = AnsiCursor()
Index: venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/METADATA	(date 1543190975619)
+++ venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/METADATA	(date 1543190975619)
@@ -0,0 +1,144 @@
+Metadata-Version: 2.1
+Name: atomicwrites
+Version: 1.2.1
+Summary: Atomic file writes.
+Home-page: https://github.com/untitaker/python-atomicwrites
+Author: Markus Unterwaditzer
+Author-email: markus@unterwaditzer.net
+License: MIT
+Platform: UNKNOWN
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*
+
+===================
+python-atomicwrites
+===================
+
+.. image:: https://travis-ci.org/untitaker/python-atomicwrites.svg?branch=master
+    :target: https://travis-ci.org/untitaker/python-atomicwrites
+
+.. image:: https://ci.appveyor.com/api/projects/status/vadc4le3c27to59x/branch/master?svg=true
+   :target: https://ci.appveyor.com/project/untitaker/python-atomicwrites/branch/master
+
+Atomic file writes.
+
+.. code-block:: python
+
+    from atomicwrites import atomic_write
+
+    with atomic_write('foo.txt', overwrite=True) as f:
+        f.write('Hello world.')
+        # "foo.txt" doesn't exist yet.
+
+    # Now it does.
+
+
+Features that distinguish it from other similar libraries (see `Alternatives and Credit`_):
+
+- Race-free assertion that the target file doesn't yet exist. This can be
+  controlled with the ``overwrite`` parameter.
+
+- Windows support, although not well-tested. The MSDN resources are not very
+  explicit about which operations are atomic. I'm basing my assumptions off `a
+  comment
+  <https://social.msdn.microsoft.com/Forums/windowsdesktop/en-US/449bb49d-8acc-48dc-a46f-0760ceddbfc3/movefileexmovefilereplaceexisting-ntfs-same-volume-atomic?forum=windowssdk#a239bc26-eaf0-4920-9f21-440bd2be9cc8>`_
+  by `Doug Crook
+  <https://social.msdn.microsoft.com/Profile/doug%20e.%20cook>`_, who appears
+  to be a Microsoft employee:
+
+      FAQ: Is MoveFileEx atomic
+      Frequently asked question: Is MoveFileEx atomic if the existing and new
+      files are both on the same drive?
+
+      The simple answer is "usually, but in some cases it will silently fall-back
+      to a non-atomic method, so don't count on it".
+
+      The implementation of MoveFileEx looks something like this: [...]
+
+      The problem is if the rename fails, you might end up with a CopyFile, which
+      is definitely not atomic.
+
+      If you really need atomic-or-nothing, you can try calling
+      NtSetInformationFile, which is unsupported but is much more likely to be
+      atomic. 
+
+- Simple high-level API that wraps a very flexible class-based API.
+
+- Consistent error handling across platforms.
+
+
+How it works
+============
+
+It uses a temporary file in the same directory as the given path. This ensures
+that the temporary file resides on the same filesystem.
+
+The temporary file will then be atomically moved to the target location: On
+POSIX, it will use ``rename`` if files should be overwritten, otherwise a
+combination of ``link`` and ``unlink``. On Windows, it uses MoveFileEx_ through
+stdlib's ``ctypes`` with the appropriate flags.
+
+Note that with ``link`` and ``unlink``, there's a timewindow where the file
+might be available under two entries in the filesystem: The name of the
+temporary file, and the name of the target file.
+
+Also note that the permissions of the target file may change this way. In some
+situations a ``chmod`` can be issued without any concurrency problems, but
+since that is not always the case, this library doesn't do it by itself.
+
+.. _MoveFileEx: https://msdn.microsoft.com/en-us/library/windows/desktop/aa365240%28v=vs.85%29.aspx
+
+fsync
+-----
+
+On POSIX, ``fsync`` is invoked on the temporary file after it is written (to
+flush file content and metadata), and on the parent directory after the file is
+moved (to flush filename).
+
+``fsync`` does not take care of disks' internal buffers, but there don't seem
+to be any standard POSIX APIs for that. On OS X, ``fcntl`` is used with
+``F_FULLFSYNC`` instead of ``fsync`` for that reason.
+
+On Windows, `_commit <https://msdn.microsoft.com/en-us/library/17618685.aspx>`_
+is used, but there are no guarantees about disk internal buffers.
+
+Alternatives and Credit
+=======================
+
+Atomicwrites is directly inspired by the following libraries (and shares a
+minimal amount of code):
+
+- The Trac project's `utility functions
+  <http://www.edgewall.org/docs/tags-trac-0.11.7/epydoc/trac.util-pysrc.html>`_,
+  also used in `Werkzeug <http://werkzeug.pocoo.org/>`_ and
+  `mitsuhiko/python-atomicfile
+  <https://github.com/mitsuhiko/python-atomicfile>`_. The idea to use
+  ``ctypes`` instead of ``PyWin32`` originated there.
+
+- `abarnert/fatomic <https://github.com/abarnert/fatomic>`_. Windows support
+  (based on ``PyWin32``) was originally taken from there.
+
+Other alternatives to atomicwrites include:
+
+- `sashka/atomicfile <https://github.com/sashka/atomicfile>`_. Originally I
+  considered using that, but at the time it was lacking a lot of features I
+  needed (Windows support, overwrite-parameter, overriding behavior through
+  subclassing).
+
+- The `Boltons library collection <https://github.com/mahmoud/boltons>`_
+  features a class for atomic file writes, which seems to have a very similar
+  ``overwrite`` parameter. It is lacking Windows support though.
+
+License
+=======
+
+Licensed under the MIT, see ``LICENSE``.
+
+
Index: venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/INSTALLER	(date 1543190975627)
+++ venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/INSTALLER	(date 1543190975627)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/pluggy-0.8.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy-0.8.0.dist-info/INSTALLER	(date 1543190975639)
+++ venv/Lib/site-packages/pluggy-0.8.0.dist-info/INSTALLER	(date 1543190975639)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/top_level.txt	(date 1543190975647)
+++ venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/top_level.txt	(date 1543190975647)
@@ -0,0 +1,1 @@
+atomicwrites
Index: venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/WHEEL	(date 1543190975659)
+++ venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/WHEEL	(date 1543190975659)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.31.1)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/six-1.11.0.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six-1.11.0.dist-info/METADATA	(date 1543190975671)
+++ venv/Lib/site-packages/six-1.11.0.dist-info/METADATA	(date 1543190975671)
@@ -0,0 +1,43 @@
+Metadata-Version: 2.0
+Name: six
+Version: 1.11.0
+Summary: Python 2 and 3 compatibility utilities
+Home-page: http://pypi.python.org/pypi/six/
+Author: Benjamin Peterson
+Author-email: benjamin@python.org
+License: MIT
+Platform: UNKNOWN
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 3
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Topic :: Software Development :: Libraries
+Classifier: Topic :: Utilities
+
+.. image:: http://img.shields.io/pypi/v/six.svg
+   :target: https://pypi.python.org/pypi/six
+
+.. image:: https://travis-ci.org/benjaminp/six.svg?branch=master
+    :target: https://travis-ci.org/benjaminp/six
+
+.. image:: http://img.shields.io/badge/license-MIT-green.svg
+   :target: https://github.com/benjaminp/six/blob/master/LICENSE
+
+Six is a Python 2 and 3 compatibility library.  It provides utility functions
+for smoothing over the differences between the Python versions with the goal of
+writing Python code that is compatible on both Python versions.  See the
+documentation for more information on what is provided.
+
+Six supports every Python version since 2.6.  It is contained in only one Python
+file, so it can be easily copied into your project. (The copyright and license
+notice must be retained.)
+
+Online documentation is at http://six.rtfd.org.
+
+Bugs can be reported to https://github.com/benjaminp/six.  The code can also
+be found there.
+
+For questions about six or porting in general, email the python-porting mailing
+list: https://mail.python.org/mailman/listinfo/python-porting
+
+
Index: venv/Lib/site-packages/six-1.11.0.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/six-1.11.0.dist-info/INSTALLER	(date 1543190975679)
+++ venv/Lib/site-packages/six-1.11.0.dist-info/INSTALLER	(date 1543190975679)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/pluggy-0.8.0.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy-0.8.0.dist-info/top_level.txt	(date 1543190975693)
+++ venv/Lib/site-packages/pluggy-0.8.0.dist-info/top_level.txt	(date 1543190975693)
@@ -0,0 +1,1 @@
+pluggy
Index: venv/Lib/site-packages/pluggy-0.8.0.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/pluggy-0.8.0.dist-info/WHEEL	(date 1543190975700)
+++ venv/Lib/site-packages/pluggy-0.8.0.dist-info/WHEEL	(date 1543190975700)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.32.1)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/attr/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/__init__.py	(date 1543190975712)
+++ venv/Lib/site-packages/attr/__init__.py	(date 1543190975712)
@@ -0,0 +1,65 @@
+from __future__ import absolute_import, division, print_function
+
+from functools import partial
+
+from . import converters, exceptions, filters, validators
+from ._config import get_run_validators, set_run_validators
+from ._funcs import asdict, assoc, astuple, evolve, has
+from ._make import (
+    NOTHING,
+    Attribute,
+    Factory,
+    attrib,
+    attrs,
+    fields,
+    fields_dict,
+    make_class,
+    validate,
+)
+
+
+__version__ = "18.2.0"
+
+__title__ = "attrs"
+__description__ = "Classes Without Boilerplate"
+__url__ = "https://www.attrs.org/"
+__uri__ = __url__
+__doc__ = __description__ + " <" + __uri__ + ">"
+
+__author__ = "Hynek Schlawack"
+__email__ = "hs@ox.cx"
+
+__license__ = "MIT"
+__copyright__ = "Copyright (c) 2015 Hynek Schlawack"
+
+
+s = attributes = attrs
+ib = attr = attrib
+dataclass = partial(attrs, auto_attribs=True)  # happy Easter ;)
+
+__all__ = [
+    "Attribute",
+    "Factory",
+    "NOTHING",
+    "asdict",
+    "assoc",
+    "astuple",
+    "attr",
+    "attrib",
+    "attributes",
+    "attrs",
+    "converters",
+    "evolve",
+    "exceptions",
+    "fields",
+    "fields_dict",
+    "filters",
+    "get_run_validators",
+    "has",
+    "ib",
+    "make_class",
+    "s",
+    "set_run_validators",
+    "validate",
+    "validators",
+]
Index: venv/Lib/site-packages/attr/validators.pyi
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/validators.pyi	(date 1543190975720)
+++ venv/Lib/site-packages/attr/validators.pyi	(date 1543190975720)
@@ -0,0 +1,14 @@
+from typing import Container, List, Union, TypeVar, Type, Any, Optional, Tuple
+from . import _ValidatorType
+
+_T = TypeVar("_T")
+
+def instance_of(
+    type: Union[Tuple[Type[_T], ...], Type[_T]]
+) -> _ValidatorType[_T]: ...
+def provides(interface: Any) -> _ValidatorType[Any]: ...
+def optional(
+    validator: Union[_ValidatorType[_T], List[_ValidatorType[_T]]]
+) -> _ValidatorType[Optional[_T]]: ...
+def in_(options: Container[_T]) -> _ValidatorType[_T]: ...
+def and_(*validators: _ValidatorType[_T]) -> _ValidatorType[_T]: ...
Index: venv/Lib/site-packages/attr/filters.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/attr/filters.py	(date 1543190975732)
+++ venv/Lib/site-packages/attr/filters.py	(date 1543190975732)
@@ -0,0 +1,52 @@
+"""
+Commonly useful filters for :func:`attr.asdict`.
+"""
+
+from __future__ import absolute_import, division, print_function
+
+from ._compat import isclass
+from ._make import Attribute
+
+
+def _split_what(what):
+    """
+    Returns a tuple of `frozenset`s of classes and attributes.
+    """
+    return (
+        frozenset(cls for cls in what if isclass(cls)),
+        frozenset(cls for cls in what if isinstance(cls, Attribute)),
+    )
+
+
+def include(*what):
+    """
+    Whitelist *what*.
+
+    :param what: What to whitelist.
+    :type what: :class:`list` of :class:`type` or :class:`attr.Attribute`\\ s
+
+    :rtype: :class:`callable`
+    """
+    cls, attrs = _split_what(what)
+
+    def include_(attribute, value):
+        return value.__class__ in cls or attribute in attrs
+
+    return include_
+
+
+def exclude(*what):
+    """
+    Blacklist *what*.
+
+    :param what: What to blacklist.
+    :type what: :class:`list` of classes or :class:`attr.Attribute`\\ s.
+
+    :rtype: :class:`callable`
+    """
+    cls, attrs = _split_what(what)
+
+    def exclude_(attribute, value):
+        return value.__class__ not in cls and attribute not in attrs
+
+    return exclude_
Index: venv/Lib/site-packages/_pytest/_code/source.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/_code/source.py	(date 1543190975740)
+++ venv/Lib/site-packages/_pytest/_code/source.py	(date 1543190975740)
@@ -0,0 +1,328 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import ast
+import inspect
+import linecache
+import sys
+import textwrap
+import tokenize
+import warnings
+from ast import PyCF_ONLY_AST as _AST_FLAG
+from bisect import bisect_right
+
+import py
+import six
+
+
+class Source(object):
+    """ an immutable object holding a source code fragment,
+        possibly deindenting it.
+    """
+
+    _compilecounter = 0
+
+    def __init__(self, *parts, **kwargs):
+        self.lines = lines = []
+        de = kwargs.get("deindent", True)
+        for part in parts:
+            if not part:
+                partlines = []
+            elif isinstance(part, Source):
+                partlines = part.lines
+            elif isinstance(part, (tuple, list)):
+                partlines = [x.rstrip("\n") for x in part]
+            elif isinstance(part, six.string_types):
+                partlines = part.split("\n")
+            else:
+                partlines = getsource(part, deindent=de).lines
+            if de:
+                partlines = deindent(partlines)
+            lines.extend(partlines)
+
+    def __eq__(self, other):
+        try:
+            return self.lines == other.lines
+        except AttributeError:
+            if isinstance(other, str):
+                return str(self) == other
+            return False
+
+    __hash__ = None
+
+    def __getitem__(self, key):
+        if isinstance(key, int):
+            return self.lines[key]
+        else:
+            if key.step not in (None, 1):
+                raise IndexError("cannot slice a Source with a step")
+            newsource = Source()
+            newsource.lines = self.lines[key.start : key.stop]
+            return newsource
+
+    def __len__(self):
+        return len(self.lines)
+
+    def strip(self):
+        """ return new source object with trailing
+            and leading blank lines removed.
+        """
+        start, end = 0, len(self)
+        while start < end and not self.lines[start].strip():
+            start += 1
+        while end > start and not self.lines[end - 1].strip():
+            end -= 1
+        source = Source()
+        source.lines[:] = self.lines[start:end]
+        return source
+
+    def putaround(self, before="", after="", indent=" " * 4):
+        """ return a copy of the source object with
+            'before' and 'after' wrapped around it.
+        """
+        before = Source(before)
+        after = Source(after)
+        newsource = Source()
+        lines = [(indent + line) for line in self.lines]
+        newsource.lines = before.lines + lines + after.lines
+        return newsource
+
+    def indent(self, indent=" " * 4):
+        """ return a copy of the source object with
+            all lines indented by the given indent-string.
+        """
+        newsource = Source()
+        newsource.lines = [(indent + line) for line in self.lines]
+        return newsource
+
+    def getstatement(self, lineno):
+        """ return Source statement which contains the
+            given linenumber (counted from 0).
+        """
+        start, end = self.getstatementrange(lineno)
+        return self[start:end]
+
+    def getstatementrange(self, lineno):
+        """ return (start, end) tuple which spans the minimal
+            statement region which containing the given lineno.
+        """
+        if not (0 <= lineno < len(self)):
+            raise IndexError("lineno out of range")
+        ast, start, end = getstatementrange_ast(lineno, self)
+        return start, end
+
+    def deindent(self):
+        """return a new source object deindented."""
+        newsource = Source()
+        newsource.lines[:] = deindent(self.lines)
+        return newsource
+
+    def isparseable(self, deindent=True):
+        """ return True if source is parseable, heuristically
+            deindenting it by default.
+        """
+        from parser import suite as syntax_checker
+
+        if deindent:
+            source = str(self.deindent())
+        else:
+            source = str(self)
+        try:
+            # compile(source+'\n', "x", "exec")
+            syntax_checker(source + "\n")
+        except KeyboardInterrupt:
+            raise
+        except Exception:
+            return False
+        else:
+            return True
+
+    def __str__(self):
+        return "\n".join(self.lines)
+
+    def compile(
+        self, filename=None, mode="exec", flag=0, dont_inherit=0, _genframe=None
+    ):
+        """ return compiled code object. if filename is None
+            invent an artificial filename which displays
+            the source/line position of the caller frame.
+        """
+        if not filename or py.path.local(filename).check(file=0):
+            if _genframe is None:
+                _genframe = sys._getframe(1)  # the caller
+            fn, lineno = _genframe.f_code.co_filename, _genframe.f_lineno
+            base = "<%d-codegen " % self._compilecounter
+            self.__class__._compilecounter += 1
+            if not filename:
+                filename = base + "%s:%d>" % (fn, lineno)
+            else:
+                filename = base + "%r %s:%d>" % (filename, fn, lineno)
+        source = "\n".join(self.lines) + "\n"
+        try:
+            co = compile(source, filename, mode, flag)
+        except SyntaxError:
+            ex = sys.exc_info()[1]
+            # re-represent syntax errors from parsing python strings
+            msglines = self.lines[: ex.lineno]
+            if ex.offset:
+                msglines.append(" " * ex.offset + "^")
+            msglines.append("(code was compiled probably from here: %s)" % filename)
+            newex = SyntaxError("\n".join(msglines))
+            newex.offset = ex.offset
+            newex.lineno = ex.lineno
+            newex.text = ex.text
+            raise newex
+        else:
+            if flag & _AST_FLAG:
+                return co
+            lines = [(x + "\n") for x in self.lines]
+            linecache.cache[filename] = (1, None, lines, filename)
+            return co
+
+
+#
+# public API shortcut functions
+#
+
+
+def compile_(source, filename=None, mode="exec", flags=0, dont_inherit=0):
+    """ compile the given source to a raw code object,
+        and maintain an internal cache which allows later
+        retrieval of the source code for the code object
+        and any recursively created code objects.
+    """
+    if isinstance(source, ast.AST):
+        # XXX should Source support having AST?
+        return compile(source, filename, mode, flags, dont_inherit)
+    _genframe = sys._getframe(1)  # the caller
+    s = Source(source)
+    co = s.compile(filename, mode, flags, _genframe=_genframe)
+    return co
+
+
+def getfslineno(obj):
+    """ Return source location (path, lineno) for the given object.
+    If the source cannot be determined return ("", -1)
+    """
+    from .code import Code
+
+    try:
+        code = Code(obj)
+    except TypeError:
+        try:
+            fn = inspect.getsourcefile(obj) or inspect.getfile(obj)
+        except TypeError:
+            return "", -1
+
+        fspath = fn and py.path.local(fn) or None
+        lineno = -1
+        if fspath:
+            try:
+                _, lineno = findsource(obj)
+            except IOError:
+                pass
+    else:
+        fspath = code.path
+        lineno = code.firstlineno
+    assert isinstance(lineno, int)
+    return fspath, lineno
+
+
+#
+# helper functions
+#
+
+
+def findsource(obj):
+    try:
+        sourcelines, lineno = inspect.findsource(obj)
+    except py.builtin._sysex:
+        raise
+    except:  # noqa
+        return None, -1
+    source = Source()
+    source.lines = [line.rstrip() for line in sourcelines]
+    return source, lineno
+
+
+def getsource(obj, **kwargs):
+    from .code import getrawcode
+
+    obj = getrawcode(obj)
+    try:
+        strsrc = inspect.getsource(obj)
+    except IndentationError:
+        strsrc = '"Buggy python version consider upgrading, cannot get source"'
+    assert isinstance(strsrc, str)
+    return Source(strsrc, **kwargs)
+
+
+def deindent(lines):
+    return textwrap.dedent("\n".join(lines)).splitlines()
+
+
+def get_statement_startend2(lineno, node):
+    import ast
+
+    # flatten all statements and except handlers into one lineno-list
+    # AST's line numbers start indexing at 1
+    values = []
+    for x in ast.walk(node):
+        if isinstance(x, (ast.stmt, ast.ExceptHandler)):
+            values.append(x.lineno - 1)
+            for name in ("finalbody", "orelse"):
+                val = getattr(x, name, None)
+                if val:
+                    # treat the finally/orelse part as its own statement
+                    values.append(val[0].lineno - 1 - 1)
+    values.sort()
+    insert_index = bisect_right(values, lineno)
+    start = values[insert_index - 1]
+    if insert_index >= len(values):
+        end = None
+    else:
+        end = values[insert_index]
+    return start, end
+
+
+def getstatementrange_ast(lineno, source, assertion=False, astnode=None):
+    if astnode is None:
+        content = str(source)
+        # See #4260:
+        # don't produce duplicate warnings when compiling source to find ast
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore")
+            astnode = compile(content, "source", "exec", _AST_FLAG)
+
+    start, end = get_statement_startend2(lineno, astnode)
+    # we need to correct the end:
+    # - ast-parsing strips comments
+    # - there might be empty lines
+    # - we might have lesser indented code blocks at the end
+    if end is None:
+        end = len(source.lines)
+
+    if end > start + 1:
+        # make sure we don't span differently indented code blocks
+        # by using the BlockFinder helper used which inspect.getsource() uses itself
+        block_finder = inspect.BlockFinder()
+        # if we start with an indented line, put blockfinder to "started" mode
+        block_finder.started = source.lines[start][0].isspace()
+        it = ((x + "\n") for x in source.lines[start:end])
+        try:
+            for tok in tokenize.generate_tokens(lambda: next(it)):
+                block_finder.tokeneater(*tok)
+        except (inspect.EndOfBlock, IndentationError):
+            end = block_finder.last + start
+        except Exception:
+            pass
+
+    # the end might still point to a comment or empty line, correct it
+    while end:
+        line = source.lines[end - 1].lstrip()
+        if line.startswith("#") or not line:
+            end -= 1
+        else:
+            break
+    return astnode, start, end
Index: venv/Lib/site-packages/_pytest/_code/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/_code/__init__.py	(date 1543190975748)
+++ venv/Lib/site-packages/_pytest/_code/__init__.py	(date 1543190975748)
@@ -0,0 +1,14 @@
+""" python inspection/code generation API """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+from .code import Code  # noqa
+from .code import ExceptionInfo  # noqa
+from .code import filter_traceback  # noqa
+from .code import Frame  # noqa
+from .code import getrawcode  # noqa
+from .code import Traceback  # noqa
+from .source import compile_ as compile  # noqa
+from .source import getfslineno  # noqa
+from .source import Source  # noqa
Index: venv/Lib/site-packages/_pytest/_code/code.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/_code/code.py	(date 1543190975768)
+++ venv/Lib/site-packages/_pytest/_code/code.py	(date 1543190975768)
@@ -0,0 +1,1052 @@
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import inspect
+import pprint
+import re
+import sys
+import traceback
+from inspect import CO_VARARGS
+from inspect import CO_VARKEYWORDS
+from weakref import ref
+
+import attr
+import pluggy
+import py
+import six
+from six import text_type
+
+import _pytest
+from _pytest.compat import _PY2
+from _pytest.compat import _PY3
+from _pytest.compat import PY35
+from _pytest.compat import safe_str
+
+builtin_repr = repr
+
+if _PY3:
+    from traceback import format_exception_only
+else:
+    from ._py2traceback import format_exception_only
+
+
+class Code(object):
+    """ wrapper around Python code objects """
+
+    def __init__(self, rawcode):
+        if not hasattr(rawcode, "co_filename"):
+            rawcode = getrawcode(rawcode)
+        try:
+            self.filename = rawcode.co_filename
+            self.firstlineno = rawcode.co_firstlineno - 1
+            self.name = rawcode.co_name
+        except AttributeError:
+            raise TypeError("not a code object: %r" % (rawcode,))
+        self.raw = rawcode
+
+    def __eq__(self, other):
+        return self.raw == other.raw
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not self == other
+
+    @property
+    def path(self):
+        """ return a path object pointing to source code (note that it
+        might not point to an actually existing file). """
+        try:
+            p = py.path.local(self.raw.co_filename)
+            # maybe don't try this checking
+            if not p.check():
+                raise OSError("py.path check failed.")
+        except OSError:
+            # XXX maybe try harder like the weird logic
+            # in the standard lib [linecache.updatecache] does?
+            p = self.raw.co_filename
+
+        return p
+
+    @property
+    def fullsource(self):
+        """ return a _pytest._code.Source object for the full source file of the code
+        """
+        from _pytest._code import source
+
+        full, _ = source.findsource(self.raw)
+        return full
+
+    def source(self):
+        """ return a _pytest._code.Source object for the code object's source only
+        """
+        # return source only for that part of code
+        import _pytest._code
+
+        return _pytest._code.Source(self.raw)
+
+    def getargs(self, var=False):
+        """ return a tuple with the argument names for the code object
+
+            if 'var' is set True also return the names of the variable and
+            keyword arguments when present
+        """
+        # handfull shortcut for getting args
+        raw = self.raw
+        argcount = raw.co_argcount
+        if var:
+            argcount += raw.co_flags & CO_VARARGS
+            argcount += raw.co_flags & CO_VARKEYWORDS
+        return raw.co_varnames[:argcount]
+
+
+class Frame(object):
+    """Wrapper around a Python frame holding f_locals and f_globals
+    in which expressions can be evaluated."""
+
+    def __init__(self, frame):
+        self.lineno = frame.f_lineno - 1
+        self.f_globals = frame.f_globals
+        self.f_locals = frame.f_locals
+        self.raw = frame
+        self.code = Code(frame.f_code)
+
+    @property
+    def statement(self):
+        """ statement this frame is at """
+        import _pytest._code
+
+        if self.code.fullsource is None:
+            return _pytest._code.Source("")
+        return self.code.fullsource.getstatement(self.lineno)
+
+    def eval(self, code, **vars):
+        """ evaluate 'code' in the frame
+
+            'vars' are optional additional local variables
+
+            returns the result of the evaluation
+        """
+        f_locals = self.f_locals.copy()
+        f_locals.update(vars)
+        return eval(code, self.f_globals, f_locals)
+
+    def exec_(self, code, **vars):
+        """ exec 'code' in the frame
+
+            'vars' are optiona; additional local variables
+        """
+        f_locals = self.f_locals.copy()
+        f_locals.update(vars)
+        six.exec_(code, self.f_globals, f_locals)
+
+    def repr(self, object):
+        """ return a 'safe' (non-recursive, one-line) string repr for 'object'
+        """
+        return py.io.saferepr(object)
+
+    def is_true(self, object):
+        return object
+
+    def getargs(self, var=False):
+        """ return a list of tuples (name, value) for all arguments
+
+            if 'var' is set True also include the variable and keyword
+            arguments when present
+        """
+        retval = []
+        for arg in self.code.getargs(var):
+            try:
+                retval.append((arg, self.f_locals[arg]))
+            except KeyError:
+                pass  # this can occur when using Psyco
+        return retval
+
+
+class TracebackEntry(object):
+    """ a single entry in a traceback """
+
+    _repr_style = None
+    exprinfo = None
+
+    def __init__(self, rawentry, excinfo=None):
+        self._excinfo = excinfo
+        self._rawentry = rawentry
+        self.lineno = rawentry.tb_lineno - 1
+
+    def set_repr_style(self, mode):
+        assert mode in ("short", "long")
+        self._repr_style = mode
+
+    @property
+    def frame(self):
+        import _pytest._code
+
+        return _pytest._code.Frame(self._rawentry.tb_frame)
+
+    @property
+    def relline(self):
+        return self.lineno - self.frame.code.firstlineno
+
+    def __repr__(self):
+        return "<TracebackEntry %s:%d>" % (self.frame.code.path, self.lineno + 1)
+
+    @property
+    def statement(self):
+        """ _pytest._code.Source object for the current statement """
+        source = self.frame.code.fullsource
+        return source.getstatement(self.lineno)
+
+    @property
+    def path(self):
+        """ path to the source code """
+        return self.frame.code.path
+
+    def getlocals(self):
+        return self.frame.f_locals
+
+    locals = property(getlocals, None, None, "locals of underlaying frame")
+
+    def getfirstlinesource(self):
+        # on Jython this firstlineno can be -1 apparently
+        return max(self.frame.code.firstlineno, 0)
+
+    def getsource(self, astcache=None):
+        """ return failing source code. """
+        # we use the passed in astcache to not reparse asttrees
+        # within exception info printing
+        from _pytest._code.source import getstatementrange_ast
+
+        source = self.frame.code.fullsource
+        if source is None:
+            return None
+        key = astnode = None
+        if astcache is not None:
+            key = self.frame.code.path
+            if key is not None:
+                astnode = astcache.get(key, None)
+        start = self.getfirstlinesource()
+        try:
+            astnode, _, end = getstatementrange_ast(
+                self.lineno, source, astnode=astnode
+            )
+        except SyntaxError:
+            end = self.lineno + 1
+        else:
+            if key is not None:
+                astcache[key] = astnode
+        return source[start:end]
+
+    source = property(getsource)
+
+    def ishidden(self):
+        """ return True if the current frame has a var __tracebackhide__
+            resolving to True
+
+            If __tracebackhide__ is a callable, it gets called with the
+            ExceptionInfo instance and can decide whether to hide the traceback.
+
+            mostly for internal use
+        """
+        try:
+            tbh = self.frame.f_locals["__tracebackhide__"]
+        except KeyError:
+            try:
+                tbh = self.frame.f_globals["__tracebackhide__"]
+            except KeyError:
+                return False
+
+        if callable(tbh):
+            return tbh(None if self._excinfo is None else self._excinfo())
+        else:
+            return tbh
+
+    def __str__(self):
+        try:
+            fn = str(self.path)
+        except py.error.Error:
+            fn = "???"
+        name = self.frame.code.name
+        try:
+            line = str(self.statement).lstrip()
+        except KeyboardInterrupt:
+            raise
+        except:  # noqa
+            line = "???"
+        return "  File %r:%d in %s\n  %s\n" % (fn, self.lineno + 1, name, line)
+
+    def name(self):
+        return self.frame.code.raw.co_name
+
+    name = property(name, None, None, "co_name of underlaying code")
+
+
+class Traceback(list):
+    """ Traceback objects encapsulate and offer higher level
+        access to Traceback entries.
+    """
+
+    Entry = TracebackEntry
+
+    def __init__(self, tb, excinfo=None):
+        """ initialize from given python traceback object and ExceptionInfo """
+        self._excinfo = excinfo
+        if hasattr(tb, "tb_next"):
+
+            def f(cur):
+                while cur is not None:
+                    yield self.Entry(cur, excinfo=excinfo)
+                    cur = cur.tb_next
+
+            list.__init__(self, f(tb))
+        else:
+            list.__init__(self, tb)
+
+    def cut(self, path=None, lineno=None, firstlineno=None, excludepath=None):
+        """ return a Traceback instance wrapping part of this Traceback
+
+            by provding any combination of path, lineno and firstlineno, the
+            first frame to start the to-be-returned traceback is determined
+
+            this allows cutting the first part of a Traceback instance e.g.
+            for formatting reasons (removing some uninteresting bits that deal
+            with handling of the exception/traceback)
+        """
+        for x in self:
+            code = x.frame.code
+            codepath = code.path
+            if (
+                (path is None or codepath == path)
+                and (
+                    excludepath is None
+                    or not hasattr(codepath, "relto")
+                    or not codepath.relto(excludepath)
+                )
+                and (lineno is None or x.lineno == lineno)
+                and (firstlineno is None or x.frame.code.firstlineno == firstlineno)
+            ):
+                return Traceback(x._rawentry, self._excinfo)
+        return self
+
+    def __getitem__(self, key):
+        val = super(Traceback, self).__getitem__(key)
+        if isinstance(key, type(slice(0))):
+            val = self.__class__(val)
+        return val
+
+    def filter(self, fn=lambda x: not x.ishidden()):
+        """ return a Traceback instance with certain items removed
+
+            fn is a function that gets a single argument, a TracebackEntry
+            instance, and should return True when the item should be added
+            to the Traceback, False when not
+
+            by default this removes all the TracebackEntries which are hidden
+            (see ishidden() above)
+        """
+        return Traceback(filter(fn, self), self._excinfo)
+
+    def getcrashentry(self):
+        """ return last non-hidden traceback entry that lead
+        to the exception of a traceback.
+        """
+        for i in range(-1, -len(self) - 1, -1):
+            entry = self[i]
+            if not entry.ishidden():
+                return entry
+        return self[-1]
+
+    def recursionindex(self):
+        """ return the index of the frame/TracebackEntry where recursion
+            originates if appropriate, None if no recursion occurred
+        """
+        cache = {}
+        for i, entry in enumerate(self):
+            # id for the code.raw is needed to work around
+            # the strange metaprogramming in the decorator lib from pypi
+            # which generates code objects that have hash/value equality
+            # XXX needs a test
+            key = entry.frame.code.path, id(entry.frame.code.raw), entry.lineno
+            # print "checking for recursion at", key
+            values = cache.setdefault(key, [])
+            if values:
+                f = entry.frame
+                loc = f.f_locals
+                for otherloc in values:
+                    if f.is_true(
+                        f.eval(
+                            co_equal,
+                            __recursioncache_locals_1=loc,
+                            __recursioncache_locals_2=otherloc,
+                        )
+                    ):
+                        return i
+            values.append(entry.frame.f_locals)
+        return None
+
+
+co_equal = compile(
+    "__recursioncache_locals_1 == __recursioncache_locals_2", "?", "eval"
+)
+
+
+class ExceptionInfo(object):
+    """ wraps sys.exc_info() objects and offers
+        help for navigating the traceback.
+    """
+
+    _striptext = ""
+    _assert_start_repr = (
+        "AssertionError(u'assert " if _PY2 else "AssertionError('assert "
+    )
+
+    def __init__(self, tup=None, exprinfo=None):
+        import _pytest._code
+
+        if tup is None:
+            tup = sys.exc_info()
+            if exprinfo is None and isinstance(tup[1], AssertionError):
+                exprinfo = getattr(tup[1], "msg", None)
+                if exprinfo is None:
+                    exprinfo = py.io.saferepr(tup[1])
+                if exprinfo and exprinfo.startswith(self._assert_start_repr):
+                    self._striptext = "AssertionError: "
+        self._excinfo = tup
+        #: the exception class
+        self.type = tup[0]
+        #: the exception instance
+        self.value = tup[1]
+        #: the exception raw traceback
+        self.tb = tup[2]
+        #: the exception type name
+        self.typename = self.type.__name__
+        #: the exception traceback (_pytest._code.Traceback instance)
+        self.traceback = _pytest._code.Traceback(self.tb, excinfo=ref(self))
+
+    def __repr__(self):
+        return "<ExceptionInfo %s tblen=%d>" % (self.typename, len(self.traceback))
+
+    def exconly(self, tryshort=False):
+        """ return the exception as a string
+
+            when 'tryshort' resolves to True, and the exception is a
+            _pytest._code._AssertionError, only the actual exception part of
+            the exception representation is returned (so 'AssertionError: ' is
+            removed from the beginning)
+        """
+        lines = format_exception_only(self.type, self.value)
+        text = "".join(lines)
+        text = text.rstrip()
+        if tryshort:
+            if text.startswith(self._striptext):
+                text = text[len(self._striptext) :]
+        return text
+
+    def errisinstance(self, exc):
+        """ return True if the exception is an instance of exc """
+        return isinstance(self.value, exc)
+
+    def _getreprcrash(self):
+        exconly = self.exconly(tryshort=True)
+        entry = self.traceback.getcrashentry()
+        path, lineno = entry.frame.code.raw.co_filename, entry.lineno
+        return ReprFileLocation(path, lineno + 1, exconly)
+
+    def getrepr(
+        self,
+        showlocals=False,
+        style="long",
+        abspath=False,
+        tbfilter=True,
+        funcargs=False,
+        truncate_locals=True,
+        chain=True,
+    ):
+        """
+        Return str()able representation of this exception info.
+
+        :param bool showlocals:
+            Show locals per traceback entry.
+            Ignored if ``style=="native"``.
+
+        :param str style: long|short|no|native traceback style
+
+        :param bool abspath:
+            If paths should be changed to absolute or left unchanged.
+
+        :param bool tbfilter:
+            Hide entries that contain a local variable ``__tracebackhide__==True``.
+            Ignored if ``style=="native"``.
+
+        :param bool funcargs:
+            Show fixtures ("funcargs" for legacy purposes) per traceback entry.
+
+        :param bool truncate_locals:
+            With ``showlocals==True``, make sure locals can be safely represented as strings.
+
+        :param bool chain: if chained exceptions in Python 3 should be shown.
+
+        .. versionchanged:: 3.9
+
+            Added the ``chain`` parameter.
+        """
+        if style == "native":
+            return ReprExceptionInfo(
+                ReprTracebackNative(
+                    traceback.format_exception(
+                        self.type, self.value, self.traceback[0]._rawentry
+                    )
+                ),
+                self._getreprcrash(),
+            )
+
+        fmt = FormattedExcinfo(
+            showlocals=showlocals,
+            style=style,
+            abspath=abspath,
+            tbfilter=tbfilter,
+            funcargs=funcargs,
+            truncate_locals=truncate_locals,
+            chain=chain,
+        )
+        return fmt.repr_excinfo(self)
+
+    def __str__(self):
+        entry = self.traceback[-1]
+        loc = ReprFileLocation(entry.path, entry.lineno + 1, self.exconly())
+        return str(loc)
+
+    def __unicode__(self):
+        entry = self.traceback[-1]
+        loc = ReprFileLocation(entry.path, entry.lineno + 1, self.exconly())
+        return text_type(loc)
+
+    def match(self, regexp):
+        """
+        Match the regular expression 'regexp' on the string representation of
+        the exception. If it matches then True is returned (so that it is
+        possible to write 'assert excinfo.match()'). If it doesn't match an
+        AssertionError is raised.
+        """
+        __tracebackhide__ = True
+        if not re.search(regexp, str(self.value)):
+            assert 0, "Pattern '{!s}' not found in '{!s}'".format(regexp, self.value)
+        return True
+
+
+@attr.s
+class FormattedExcinfo(object):
+    """ presenting information about failing Functions and Generators. """
+
+    # for traceback entries
+    flow_marker = ">"
+    fail_marker = "E"
+
+    showlocals = attr.ib(default=False)
+    style = attr.ib(default="long")
+    abspath = attr.ib(default=True)
+    tbfilter = attr.ib(default=True)
+    funcargs = attr.ib(default=False)
+    truncate_locals = attr.ib(default=True)
+    chain = attr.ib(default=True)
+    astcache = attr.ib(default=attr.Factory(dict), init=False, repr=False)
+
+    def _getindent(self, source):
+        # figure out indent for given source
+        try:
+            s = str(source.getstatement(len(source) - 1))
+        except KeyboardInterrupt:
+            raise
+        except:  # noqa
+            try:
+                s = str(source[-1])
+            except KeyboardInterrupt:
+                raise
+            except:  # noqa
+                return 0
+        return 4 + (len(s) - len(s.lstrip()))
+
+    def _getentrysource(self, entry):
+        source = entry.getsource(self.astcache)
+        if source is not None:
+            source = source.deindent()
+        return source
+
+    def _saferepr(self, obj):
+        return py.io.saferepr(obj)
+
+    def repr_args(self, entry):
+        if self.funcargs:
+            args = []
+            for argname, argvalue in entry.frame.getargs(var=True):
+                args.append((argname, self._saferepr(argvalue)))
+            return ReprFuncArgs(args)
+
+    def get_source(self, source, line_index=-1, excinfo=None, short=False):
+        """ return formatted and marked up source lines. """
+        import _pytest._code
+
+        lines = []
+        if source is None or line_index >= len(source.lines):
+            source = _pytest._code.Source("???")
+            line_index = 0
+        if line_index < 0:
+            line_index += len(source)
+        space_prefix = "    "
+        if short:
+            lines.append(space_prefix + source.lines[line_index].strip())
+        else:
+            for line in source.lines[:line_index]:
+                lines.append(space_prefix + line)
+            lines.append(self.flow_marker + "   " + source.lines[line_index])
+            for line in source.lines[line_index + 1 :]:
+                lines.append(space_prefix + line)
+        if excinfo is not None:
+            indent = 4 if short else self._getindent(source)
+            lines.extend(self.get_exconly(excinfo, indent=indent, markall=True))
+        return lines
+
+    def get_exconly(self, excinfo, indent=4, markall=False):
+        lines = []
+        indent = " " * indent
+        # get the real exception information out
+        exlines = excinfo.exconly(tryshort=True).split("\n")
+        failindent = self.fail_marker + indent[1:]
+        for line in exlines:
+            lines.append(failindent + line)
+            if not markall:
+                failindent = indent
+        return lines
+
+    def repr_locals(self, locals):
+        if self.showlocals:
+            lines = []
+            keys = [loc for loc in locals if loc[0] != "@"]
+            keys.sort()
+            for name in keys:
+                value = locals[name]
+                if name == "__builtins__":
+                    lines.append("__builtins__ = <builtins>")
+                else:
+                    # This formatting could all be handled by the
+                    # _repr() function, which is only reprlib.Repr in
+                    # disguise, so is very configurable.
+                    if self.truncate_locals:
+                        str_repr = self._saferepr(value)
+                    else:
+                        str_repr = pprint.pformat(value)
+                    # if len(str_repr) < 70 or not isinstance(value,
+                    #                            (list, tuple, dict)):
+                    lines.append("%-10s = %s" % (name, str_repr))
+                    # else:
+                    #    self._line("%-10s =\\" % (name,))
+                    #    # XXX
+                    #    pprint.pprint(value, stream=self.excinfowriter)
+            return ReprLocals(lines)
+
+    def repr_traceback_entry(self, entry, excinfo=None):
+        import _pytest._code
+
+        source = self._getentrysource(entry)
+        if source is None:
+            source = _pytest._code.Source("???")
+            line_index = 0
+        else:
+            # entry.getfirstlinesource() can be -1, should be 0 on jython
+            line_index = entry.lineno - max(entry.getfirstlinesource(), 0)
+
+        lines = []
+        style = entry._repr_style
+        if style is None:
+            style = self.style
+        if style in ("short", "long"):
+            short = style == "short"
+            reprargs = self.repr_args(entry) if not short else None
+            s = self.get_source(source, line_index, excinfo, short=short)
+            lines.extend(s)
+            if short:
+                message = "in %s" % (entry.name)
+            else:
+                message = excinfo and excinfo.typename or ""
+            path = self._makepath(entry.path)
+            filelocrepr = ReprFileLocation(path, entry.lineno + 1, message)
+            localsrepr = None
+            if not short:
+                localsrepr = self.repr_locals(entry.locals)
+            return ReprEntry(lines, reprargs, localsrepr, filelocrepr, style)
+        if excinfo:
+            lines.extend(self.get_exconly(excinfo, indent=4))
+        return ReprEntry(lines, None, None, None, style)
+
+    def _makepath(self, path):
+        if not self.abspath:
+            try:
+                np = py.path.local().bestrelpath(path)
+            except OSError:
+                return path
+            if len(np) < len(str(path)):
+                path = np
+        return path
+
+    def repr_traceback(self, excinfo):
+        traceback = excinfo.traceback
+        if self.tbfilter:
+            traceback = traceback.filter()
+
+        if is_recursion_error(excinfo):
+            traceback, extraline = self._truncate_recursive_traceback(traceback)
+        else:
+            extraline = None
+
+        last = traceback[-1]
+        entries = []
+        for index, entry in enumerate(traceback):
+            einfo = (last == entry) and excinfo or None
+            reprentry = self.repr_traceback_entry(entry, einfo)
+            entries.append(reprentry)
+        return ReprTraceback(entries, extraline, style=self.style)
+
+    def _truncate_recursive_traceback(self, traceback):
+        """
+        Truncate the given recursive traceback trying to find the starting point
+        of the recursion.
+
+        The detection is done by going through each traceback entry and finding the
+        point in which the locals of the frame are equal to the locals of a previous frame (see ``recursionindex()``.
+
+        Handle the situation where the recursion process might raise an exception (for example
+        comparing numpy arrays using equality raises a TypeError), in which case we do our best to
+        warn the user of the error and show a limited traceback.
+        """
+        try:
+            recursionindex = traceback.recursionindex()
+        except Exception as e:
+            max_frames = 10
+            extraline = (
+                "!!! Recursion error detected, but an error occurred locating the origin of recursion.\n"
+                "  The following exception happened when comparing locals in the stack frame:\n"
+                "    {exc_type}: {exc_msg}\n"
+                "  Displaying first and last {max_frames} stack frames out of {total}."
+            ).format(
+                exc_type=type(e).__name__,
+                exc_msg=safe_str(e),
+                max_frames=max_frames,
+                total=len(traceback),
+            )
+            traceback = traceback[:max_frames] + traceback[-max_frames:]
+        else:
+            if recursionindex is not None:
+                extraline = "!!! Recursion detected (same locals & position)"
+                traceback = traceback[: recursionindex + 1]
+            else:
+                extraline = None
+
+        return traceback, extraline
+
+    def repr_excinfo(self, excinfo):
+        if _PY2:
+            reprtraceback = self.repr_traceback(excinfo)
+            reprcrash = excinfo._getreprcrash()
+
+            return ReprExceptionInfo(reprtraceback, reprcrash)
+        else:
+            repr_chain = []
+            e = excinfo.value
+            descr = None
+            seen = set()
+            while e is not None and id(e) not in seen:
+                seen.add(id(e))
+                if excinfo:
+                    reprtraceback = self.repr_traceback(excinfo)
+                    reprcrash = excinfo._getreprcrash()
+                else:
+                    # fallback to native repr if the exception doesn't have a traceback:
+                    # ExceptionInfo objects require a full traceback to work
+                    reprtraceback = ReprTracebackNative(
+                        traceback.format_exception(type(e), e, None)
+                    )
+                    reprcrash = None
+
+                repr_chain += [(reprtraceback, reprcrash, descr)]
+                if e.__cause__ is not None and self.chain:
+                    e = e.__cause__
+                    excinfo = (
+                        ExceptionInfo((type(e), e, e.__traceback__))
+                        if e.__traceback__
+                        else None
+                    )
+                    descr = "The above exception was the direct cause of the following exception:"
+                elif (
+                    e.__context__ is not None
+                    and not e.__suppress_context__
+                    and self.chain
+                ):
+                    e = e.__context__
+                    excinfo = (
+                        ExceptionInfo((type(e), e, e.__traceback__))
+                        if e.__traceback__
+                        else None
+                    )
+                    descr = "During handling of the above exception, another exception occurred:"
+                else:
+                    e = None
+            repr_chain.reverse()
+            return ExceptionChainRepr(repr_chain)
+
+
+class TerminalRepr(object):
+    def __str__(self):
+        s = self.__unicode__()
+        if _PY2:
+            s = s.encode("utf-8")
+        return s
+
+    def __unicode__(self):
+        # FYI this is called from pytest-xdist's serialization of exception
+        # information.
+        io = py.io.TextIO()
+        tw = py.io.TerminalWriter(file=io)
+        self.toterminal(tw)
+        return io.getvalue().strip()
+
+    def __repr__(self):
+        return "<%s instance at %0x>" % (self.__class__, id(self))
+
+
+class ExceptionRepr(TerminalRepr):
+    def __init__(self):
+        self.sections = []
+
+    def addsection(self, name, content, sep="-"):
+        self.sections.append((name, content, sep))
+
+    def toterminal(self, tw):
+        for name, content, sep in self.sections:
+            tw.sep(sep, name)
+            tw.line(content)
+
+
+class ExceptionChainRepr(ExceptionRepr):
+    def __init__(self, chain):
+        super(ExceptionChainRepr, self).__init__()
+        self.chain = chain
+        # reprcrash and reprtraceback of the outermost (the newest) exception
+        # in the chain
+        self.reprtraceback = chain[-1][0]
+        self.reprcrash = chain[-1][1]
+
+    def toterminal(self, tw):
+        for element in self.chain:
+            element[0].toterminal(tw)
+            if element[2] is not None:
+                tw.line("")
+                tw.line(element[2], yellow=True)
+        super(ExceptionChainRepr, self).toterminal(tw)
+
+
+class ReprExceptionInfo(ExceptionRepr):
+    def __init__(self, reprtraceback, reprcrash):
+        super(ReprExceptionInfo, self).__init__()
+        self.reprtraceback = reprtraceback
+        self.reprcrash = reprcrash
+
+    def toterminal(self, tw):
+        self.reprtraceback.toterminal(tw)
+        super(ReprExceptionInfo, self).toterminal(tw)
+
+
+class ReprTraceback(TerminalRepr):
+    entrysep = "_ "
+
+    def __init__(self, reprentries, extraline, style):
+        self.reprentries = reprentries
+        self.extraline = extraline
+        self.style = style
+
+    def toterminal(self, tw):
+        # the entries might have different styles
+        for i, entry in enumerate(self.reprentries):
+            if entry.style == "long":
+                tw.line("")
+            entry.toterminal(tw)
+            if i < len(self.reprentries) - 1:
+                next_entry = self.reprentries[i + 1]
+                if (
+                    entry.style == "long"
+                    or entry.style == "short"
+                    and next_entry.style == "long"
+                ):
+                    tw.sep(self.entrysep)
+
+        if self.extraline:
+            tw.line(self.extraline)
+
+
+class ReprTracebackNative(ReprTraceback):
+    def __init__(self, tblines):
+        self.style = "native"
+        self.reprentries = [ReprEntryNative(tblines)]
+        self.extraline = None
+
+
+class ReprEntryNative(TerminalRepr):
+    style = "native"
+
+    def __init__(self, tblines):
+        self.lines = tblines
+
+    def toterminal(self, tw):
+        tw.write("".join(self.lines))
+
+
+class ReprEntry(TerminalRepr):
+    localssep = "_ "
+
+    def __init__(self, lines, reprfuncargs, reprlocals, filelocrepr, style):
+        self.lines = lines
+        self.reprfuncargs = reprfuncargs
+        self.reprlocals = reprlocals
+        self.reprfileloc = filelocrepr
+        self.style = style
+
+    def toterminal(self, tw):
+        if self.style == "short":
+            self.reprfileloc.toterminal(tw)
+            for line in self.lines:
+                red = line.startswith("E   ")
+                tw.line(line, bold=True, red=red)
+            # tw.line("")
+            return
+        if self.reprfuncargs:
+            self.reprfuncargs.toterminal(tw)
+        for line in self.lines:
+            red = line.startswith("E   ")
+            tw.line(line, bold=True, red=red)
+        if self.reprlocals:
+            # tw.sep(self.localssep, "Locals")
+            tw.line("")
+            self.reprlocals.toterminal(tw)
+        if self.reprfileloc:
+            if self.lines:
+                tw.line("")
+            self.reprfileloc.toterminal(tw)
+
+    def __str__(self):
+        return "%s\n%s\n%s" % ("\n".join(self.lines), self.reprlocals, self.reprfileloc)
+
+
+class ReprFileLocation(TerminalRepr):
+    def __init__(self, path, lineno, message):
+        self.path = str(path)
+        self.lineno = lineno
+        self.message = message
+
+    def toterminal(self, tw):
+        # filename and lineno output for each entry,
+        # using an output format that most editors unterstand
+        msg = self.message
+        i = msg.find("\n")
+        if i != -1:
+            msg = msg[:i]
+        tw.write(self.path, bold=True, red=True)
+        tw.line(":%s: %s" % (self.lineno, msg))
+
+
+class ReprLocals(TerminalRepr):
+    def __init__(self, lines):
+        self.lines = lines
+
+    def toterminal(self, tw):
+        for line in self.lines:
+            tw.line(line)
+
+
+class ReprFuncArgs(TerminalRepr):
+    def __init__(self, args):
+        self.args = args
+
+    def toterminal(self, tw):
+        if self.args:
+            linesofar = ""
+            for name, value in self.args:
+                ns = "%s = %s" % (safe_str(name), safe_str(value))
+                if len(ns) + len(linesofar) + 2 > tw.fullwidth:
+                    if linesofar:
+                        tw.line(linesofar)
+                    linesofar = ns
+                else:
+                    if linesofar:
+                        linesofar += ", " + ns
+                    else:
+                        linesofar = ns
+            if linesofar:
+                tw.line(linesofar)
+            tw.line("")
+
+
+def getrawcode(obj, trycall=True):
+    """ return code object for given function. """
+    try:
+        return obj.__code__
+    except AttributeError:
+        obj = getattr(obj, "im_func", obj)
+        obj = getattr(obj, "func_code", obj)
+        obj = getattr(obj, "f_code", obj)
+        obj = getattr(obj, "__code__", obj)
+        if trycall and not hasattr(obj, "co_firstlineno"):
+            if hasattr(obj, "__call__") and not inspect.isclass(obj):
+                x = getrawcode(obj.__call__, trycall=False)
+                if hasattr(x, "co_firstlineno"):
+                    return x
+        return obj
+
+
+if PY35:  # RecursionError introduced in 3.5
+
+    def is_recursion_error(excinfo):
+        return excinfo.errisinstance(RecursionError)  # noqa
+
+
+else:
+
+    def is_recursion_error(excinfo):
+        if not excinfo.errisinstance(RuntimeError):
+            return False
+        try:
+            return "maximum recursion depth exceeded" in str(excinfo.value)
+        except UnicodeError:
+            return False
+
+
+# relative paths that we use to filter traceback entries from appearing to the user;
+# see filter_traceback
+# note: if we need to add more paths than what we have now we should probably use a list
+# for better maintenance
+
+_PLUGGY_DIR = py.path.local(pluggy.__file__.rstrip("oc"))
+# pluggy is either a package or a single module depending on the version
+if _PLUGGY_DIR.basename == "__init__.py":
+    _PLUGGY_DIR = _PLUGGY_DIR.dirpath()
+_PYTEST_DIR = py.path.local(_pytest.__file__).dirpath()
+_PY_DIR = py.path.local(py.__file__).dirpath()
+
+
+def filter_traceback(entry):
+    """Return True if a TracebackEntry instance should be removed from tracebacks:
+    * dynamically generated code (no code to show up for it);
+    * internal traceback from pytest or its internal libraries, py and pluggy.
+    """
+    # entry.path might sometimes return a str object when the entry
+    # points to dynamically generated code
+    # see https://bitbucket.org/pytest-dev/py/issues/71
+    raw_filename = entry.frame.code.raw.co_filename
+    is_generated = "<" in raw_filename and ">" in raw_filename
+    if is_generated:
+        return False
+    # entry.path might point to a non-existing file, in which case it will
+    # also return a str object. see #1133
+    p = py.path.local(entry.path)
+    return (
+        not p.relto(_PLUGGY_DIR) and not p.relto(_PYTEST_DIR) and not p.relto(_PY_DIR)
+    )
Index: venv/Lib/site-packages/_pytest/_code/_py2traceback.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/_code/_py2traceback.py	(date 1543190975776)
+++ venv/Lib/site-packages/_pytest/_code/_py2traceback.py	(date 1543190975776)
@@ -0,0 +1,94 @@
+# copied from python-2.7.3's traceback.py
+# CHANGES:
+# - some_str is replaced, trying to create unicode strings
+#
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+from __future__ import unicode_literals
+
+import types
+
+from six import text_type
+
+
+def format_exception_only(etype, value):
+    """Format the exception part of a traceback.
+
+    The arguments are the exception type and value such as given by
+    sys.last_type and sys.last_value. The return value is a list of
+    strings, each ending in a newline.
+
+    Normally, the list contains a single string; however, for
+    SyntaxError exceptions, it contains several lines that (when
+    printed) display detailed information about where the syntax
+    error occurred.
+
+    The message indicating which exception occurred is always the last
+    string in the list.
+
+    """
+
+    # An instance should not have a meaningful value parameter, but
+    # sometimes does, particularly for string exceptions, such as
+    # >>> raise string1, string2  # deprecated
+    #
+    # Clear these out first because issubtype(string1, SyntaxError)
+    # would throw another exception and mask the original problem.
+    if (
+        isinstance(etype, BaseException)
+        or isinstance(etype, types.InstanceType)
+        or etype is None
+        or type(etype) is str
+    ):
+        return [_format_final_exc_line(etype, value)]
+
+    stype = etype.__name__
+
+    if not issubclass(etype, SyntaxError):
+        return [_format_final_exc_line(stype, value)]
+
+    # It was a syntax error; show exactly where the problem was found.
+    lines = []
+    try:
+        msg, (filename, lineno, offset, badline) = value.args
+    except Exception:
+        pass
+    else:
+        filename = filename or "<string>"
+        lines.append('  File "{}", line {}\n'.format(filename, lineno))
+        if badline is not None:
+            if isinstance(badline, bytes):  # python 2 only
+                badline = badline.decode("utf-8", "replace")
+            lines.append("    {}\n".format(badline.strip()))
+            if offset is not None:
+                caretspace = badline.rstrip("\n")[:offset].lstrip()
+                # non-space whitespace (likes tabs) must be kept for alignment
+                caretspace = ((c.isspace() and c or " ") for c in caretspace)
+                # only three spaces to account for offset1 == pos 0
+                lines.append("   {}^\n".format("".join(caretspace)))
+        value = msg
+
+    lines.append(_format_final_exc_line(stype, value))
+    return lines
+
+
+def _format_final_exc_line(etype, value):
+    """Return a list of a single line -- normal case for format_exception_only"""
+    valuestr = _some_str(value)
+    if value is None or not valuestr:
+        line = "{}\n".format(etype)
+    else:
+        line = "{}: {}\n".format(etype, valuestr)
+    return line
+
+
+def _some_str(value):
+    try:
+        return text_type(value)
+    except Exception:
+        try:
+            return bytes(value).decode("UTF-8", "replace")
+        except Exception:
+            pass
+    return "<unprintable {} object>".format(type(value).__name__)
Index: venv/Lib/site-packages/_pytest/mark/structures.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/mark/structures.py	(date 1543190975790)
+++ venv/Lib/site-packages/_pytest/mark/structures.py	(date 1543190975790)
@@ -0,0 +1,471 @@
+import inspect
+import warnings
+from collections import namedtuple
+from functools import reduce
+from operator import attrgetter
+
+import attr
+from six.moves import map
+
+from ..compat import getfslineno
+from ..compat import MappingMixin
+from ..compat import NOTSET
+from ..deprecated import MARK_INFO_ATTRIBUTE
+from ..deprecated import MARK_PARAMETERSET_UNPACKING
+from _pytest.outcomes import fail
+
+
+EMPTY_PARAMETERSET_OPTION = "empty_parameter_set_mark"
+
+
+def alias(name, warning=None):
+    getter = attrgetter(name)
+
+    def warned(self):
+        warnings.warn(warning, stacklevel=2)
+        return getter(self)
+
+    return property(getter if warning is None else warned, doc="alias for " + name)
+
+
+def istestfunc(func):
+    return (
+        hasattr(func, "__call__")
+        and getattr(func, "__name__", "<lambda>") != "<lambda>"
+    )
+
+
+def get_empty_parameterset_mark(config, argnames, func):
+    from ..nodes import Collector
+
+    requested_mark = config.getini(EMPTY_PARAMETERSET_OPTION)
+    if requested_mark in ("", None, "skip"):
+        mark = MARK_GEN.skip
+    elif requested_mark == "xfail":
+        mark = MARK_GEN.xfail(run=False)
+    elif requested_mark == "fail_at_collect":
+        f_name = func.__name__
+        _, lineno = getfslineno(func)
+        raise Collector.CollectError(
+            "Empty parameter set in '%s' at line %d" % (f_name, lineno)
+        )
+    else:
+        raise LookupError(requested_mark)
+    fs, lineno = getfslineno(func)
+    reason = "got empty parameter set %r, function %s at %s:%d" % (
+        argnames,
+        func.__name__,
+        fs,
+        lineno,
+    )
+    return mark(reason=reason)
+
+
+class ParameterSet(namedtuple("ParameterSet", "values, marks, id")):
+    @classmethod
+    def param(cls, *values, **kw):
+        marks = kw.pop("marks", ())
+        if isinstance(marks, MarkDecorator):
+            marks = (marks,)
+        else:
+            assert isinstance(marks, (tuple, list, set))
+
+        def param_extract_id(id=None):
+            return id
+
+        id_ = param_extract_id(**kw)
+        return cls(values, marks, id_)
+
+    @classmethod
+    def extract_from(cls, parameterset, belonging_definition, legacy_force_tuple=False):
+        """
+        :param parameterset:
+            a legacy style parameterset that may or may not be a tuple,
+            and may or may not be wrapped into a mess of mark objects
+
+        :param legacy_force_tuple:
+            enforce tuple wrapping so single argument tuple values
+            don't get decomposed and break tests
+
+        :param belonging_definition: the item that we will be extracting the parameters from.
+        """
+
+        if isinstance(parameterset, cls):
+            return parameterset
+        if not isinstance(parameterset, MarkDecorator) and legacy_force_tuple:
+            return cls.param(parameterset)
+
+        newmarks = []
+        argval = parameterset
+        while isinstance(argval, MarkDecorator):
+            newmarks.append(
+                MarkDecorator(Mark(argval.markname, argval.args[:-1], argval.kwargs))
+            )
+            argval = argval.args[-1]
+        assert not isinstance(argval, ParameterSet)
+        if legacy_force_tuple:
+            argval = (argval,)
+
+        if newmarks and belonging_definition is not None:
+            belonging_definition.warn(MARK_PARAMETERSET_UNPACKING)
+
+        return cls(argval, marks=newmarks, id=None)
+
+    @classmethod
+    def _for_parametrize(cls, argnames, argvalues, func, config, function_definition):
+        if not isinstance(argnames, (tuple, list)):
+            argnames = [x.strip() for x in argnames.split(",") if x.strip()]
+            force_tuple = len(argnames) == 1
+        else:
+            force_tuple = False
+        parameters = [
+            ParameterSet.extract_from(
+                x,
+                legacy_force_tuple=force_tuple,
+                belonging_definition=function_definition,
+            )
+            for x in argvalues
+        ]
+        del argvalues
+
+        if parameters:
+            # check all parameter sets have the correct number of values
+            for param in parameters:
+                if len(param.values) != len(argnames):
+                    raise ValueError(
+                        'In "parametrize" the number of values ({}) must be '
+                        "equal to the number of names ({})".format(
+                            param.values, argnames
+                        )
+                    )
+        else:
+            # empty parameter set (likely computed at runtime): create a single
+            # parameter set with NOSET values, with the "empty parameter set" mark applied to it
+            mark = get_empty_parameterset_mark(config, argnames, func)
+            parameters.append(
+                ParameterSet(values=(NOTSET,) * len(argnames), marks=[mark], id=None)
+            )
+        return argnames, parameters
+
+
+@attr.s(frozen=True)
+class Mark(object):
+    #: name of the mark
+    name = attr.ib(type=str)
+    #: positional arguments of the mark decorator
+    args = attr.ib()  # type: List[object]
+    #: keyword arguments of the mark decorator
+    kwargs = attr.ib()  # type: Dict[str, object]
+
+    def combined_with(self, other):
+        """
+        :param other: the mark to combine with
+        :type other: Mark
+        :rtype: Mark
+
+        combines by appending aargs and merging the mappings
+        """
+        assert self.name == other.name
+        return Mark(
+            self.name, self.args + other.args, dict(self.kwargs, **other.kwargs)
+        )
+
+
+@attr.s
+class MarkDecorator(object):
+    """ A decorator for test functions and test classes.  When applied
+    it will create :class:`MarkInfo` objects which may be
+    :ref:`retrieved by hooks as item keywords <excontrolskip>`.
+    MarkDecorator instances are often created like this::
+
+        mark1 = pytest.mark.NAME              # simple MarkDecorator
+        mark2 = pytest.mark.NAME(name1=value) # parametrized MarkDecorator
+
+    and can then be applied as decorators to test functions::
+
+        @mark2
+        def test_function():
+            pass
+
+    When a MarkDecorator instance is called it does the following:
+      1. If called with a single class as its only positional argument and no
+         additional keyword arguments, it attaches itself to the class so it
+         gets applied automatically to all test cases found in that class.
+      2. If called with a single function as its only positional argument and
+         no additional keyword arguments, it attaches a MarkInfo object to the
+         function, containing all the arguments already stored internally in
+         the MarkDecorator.
+      3. When called in any other case, it performs a 'fake construction' call,
+         i.e. it returns a new MarkDecorator instance with the original
+         MarkDecorator's content updated with the arguments passed to this
+         call.
+
+    Note: The rules above prevent MarkDecorator objects from storing only a
+    single function or class reference as their positional argument with no
+    additional keyword or positional arguments.
+
+    """
+
+    mark = attr.ib(validator=attr.validators.instance_of(Mark))
+
+    name = alias("mark.name")
+    args = alias("mark.args")
+    kwargs = alias("mark.kwargs")
+
+    @property
+    def markname(self):
+        return self.name  # for backward-compat (2.4.1 had this attr)
+
+    def __eq__(self, other):
+        return self.mark == other.mark if isinstance(other, MarkDecorator) else False
+
+    def __repr__(self):
+        return "<MarkDecorator %r>" % (self.mark,)
+
+    def with_args(self, *args, **kwargs):
+        """ return a MarkDecorator with extra arguments added
+
+        unlike call this can be used even if the sole argument is a callable/class
+
+        :return: MarkDecorator
+        """
+
+        mark = Mark(self.name, args, kwargs)
+        return self.__class__(self.mark.combined_with(mark))
+
+    def __call__(self, *args, **kwargs):
+        """ if passed a single callable argument: decorate it with mark info.
+            otherwise add *args/**kwargs in-place to mark information. """
+        if args and not kwargs:
+            func = args[0]
+            is_class = inspect.isclass(func)
+            if len(args) == 1 and (istestfunc(func) or is_class):
+                if is_class:
+                    store_mark(func, self.mark)
+                else:
+                    store_legacy_markinfo(func, self.mark)
+                    store_mark(func, self.mark)
+                return func
+        return self.with_args(*args, **kwargs)
+
+
+def get_unpacked_marks(obj):
+    """
+    obtain the unpacked marks that are stored on an object
+    """
+    mark_list = getattr(obj, "pytestmark", [])
+    if not isinstance(mark_list, list):
+        mark_list = [mark_list]
+    return normalize_mark_list(mark_list)
+
+
+def normalize_mark_list(mark_list):
+    """
+    normalizes marker decorating helpers to mark objects
+
+    :type mark_list: List[Union[Mark, Markdecorator]]
+    :rtype: List[Mark]
+    """
+    return [getattr(mark, "mark", mark) for mark in mark_list]  # unpack MarkDecorator
+
+
+def store_mark(obj, mark):
+    """store a Mark on an object
+    this is used to implement the Mark declarations/decorators correctly
+    """
+    assert isinstance(mark, Mark), mark
+    # always reassign name to avoid updating pytestmark
+    # in a reference that was only borrowed
+    obj.pytestmark = get_unpacked_marks(obj) + [mark]
+
+
+def store_legacy_markinfo(func, mark):
+    """create the legacy MarkInfo objects and put them onto the function
+    """
+    if not isinstance(mark, Mark):
+        raise TypeError("got {mark!r} instead of a Mark".format(mark=mark))
+    holder = getattr(func, mark.name, None)
+    if holder is None:
+        holder = MarkInfo.for_mark(mark)
+        setattr(func, mark.name, holder)
+    elif isinstance(holder, MarkInfo):
+        holder.add_mark(mark)
+
+
+def transfer_markers(funcobj, cls, mod):
+    """
+    this function transfers class level markers and module level markers
+    into function level markinfo objects
+
+    this is the main reason why marks are so broken
+    the resolution will involve phasing out function level MarkInfo objects
+
+    """
+    for obj in (cls, mod):
+        for mark in get_unpacked_marks(obj):
+            if not _marked(funcobj, mark):
+                store_legacy_markinfo(funcobj, mark)
+
+
+def _marked(func, mark):
+    """ Returns True if :func: is already marked with :mark:, False otherwise.
+    This can happen if marker is applied to class and the test file is
+    invoked more than once.
+    """
+    try:
+        func_mark = getattr(func, getattr(mark, "combined", mark).name)
+    except AttributeError:
+        return False
+    return any(mark == info.combined for info in func_mark)
+
+
+@attr.s(repr=False)
+class MarkInfo(object):
+    """ Marking object created by :class:`MarkDecorator` instances. """
+
+    _marks = attr.ib(converter=list)
+
+    @_marks.validator
+    def validate_marks(self, attribute, value):
+        for item in value:
+            if not isinstance(item, Mark):
+                raise ValueError(
+                    "MarkInfo expects Mark instances, got {!r} ({!r})".format(
+                        item, type(item)
+                    )
+                )
+
+    combined = attr.ib(
+        repr=False,
+        default=attr.Factory(
+            lambda self: reduce(Mark.combined_with, self._marks), takes_self=True
+        ),
+    )
+
+    name = alias("combined.name", warning=MARK_INFO_ATTRIBUTE)
+    args = alias("combined.args", warning=MARK_INFO_ATTRIBUTE)
+    kwargs = alias("combined.kwargs", warning=MARK_INFO_ATTRIBUTE)
+
+    @classmethod
+    def for_mark(cls, mark):
+        return cls([mark])
+
+    def __repr__(self):
+        return "<MarkInfo {!r}>".format(self.combined)
+
+    def add_mark(self, mark):
+        """ add a MarkInfo with the given args and kwargs. """
+        self._marks.append(mark)
+        self.combined = self.combined.combined_with(mark)
+
+    def __iter__(self):
+        """ yield MarkInfo objects each relating to a marking-call. """
+        return map(MarkInfo.for_mark, self._marks)
+
+
+class MarkGenerator(object):
+    """ Factory for :class:`MarkDecorator` objects - exposed as
+    a ``pytest.mark`` singleton instance.  Example::
+
+         import pytest
+         @pytest.mark.slowtest
+         def test_function():
+            pass
+
+    will set a 'slowtest' :class:`MarkInfo` object
+    on the ``test_function`` object. """
+
+    _config = None
+
+    def __getattr__(self, name):
+        if name[0] == "_":
+            raise AttributeError("Marker name must NOT start with underscore")
+        if self._config is not None:
+            self._check(name)
+        return MarkDecorator(Mark(name, (), {}))
+
+    def _check(self, name):
+        try:
+            if name in self._markers:
+                return
+        except AttributeError:
+            pass
+        self._markers = values = set()
+        for line in self._config.getini("markers"):
+            marker = line.split(":", 1)[0]
+            marker = marker.rstrip()
+            x = marker.split("(", 1)[0]
+            values.add(x)
+        if name not in self._markers:
+            fail("{!r} not a registered marker".format(name), pytrace=False)
+
+
+MARK_GEN = MarkGenerator()
+
+
+class NodeKeywords(MappingMixin):
+    def __init__(self, node):
+        self.node = node
+        self.parent = node.parent
+        self._markers = {node.name: True}
+
+    def __getitem__(self, key):
+        try:
+            return self._markers[key]
+        except KeyError:
+            if self.parent is None:
+                raise
+            return self.parent.keywords[key]
+
+    def __setitem__(self, key, value):
+        self._markers[key] = value
+
+    def __delitem__(self, key):
+        raise ValueError("cannot delete key in keywords dict")
+
+    def __iter__(self):
+        seen = self._seen()
+        return iter(seen)
+
+    def _seen(self):
+        seen = set(self._markers)
+        if self.parent is not None:
+            seen.update(self.parent.keywords)
+        return seen
+
+    def __len__(self):
+        return len(self._seen())
+
+    def __repr__(self):
+        return "<NodeKeywords for node %s>" % (self.node,)
+
+
+@attr.s(cmp=False, hash=False)
+class NodeMarkers(object):
+    """
+    internal structure for storing marks belonging to a node
+
+    ..warning::
+
+        unstable api
+
+    """
+
+    own_markers = attr.ib(default=attr.Factory(list))
+
+    def update(self, add_markers):
+        """update the own markers
+        """
+        self.own_markers.extend(add_markers)
+
+    def find(self, name):
+        """
+        find markers in own nodes or parent nodes
+        needs a better place
+        """
+        for mark in self.own_markers:
+            if mark.name == name:
+                yield mark
+
+    def __iter__(self):
+        return iter(self.own_markers)
Index: venv/Lib/site-packages/py/_code/_py2traceback.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/_py2traceback.py	(date 1543190975800)
+++ venv/Lib/site-packages/py/_code/_py2traceback.py	(date 1543190975800)
@@ -0,0 +1,79 @@
+# copied from python-2.7.3's traceback.py
+# CHANGES:
+# - some_str is replaced, trying to create unicode strings
+#
+import types
+
+def format_exception_only(etype, value):
+    """Format the exception part of a traceback.
+
+    The arguments are the exception type and value such as given by
+    sys.last_type and sys.last_value. The return value is a list of
+    strings, each ending in a newline.
+
+    Normally, the list contains a single string; however, for
+    SyntaxError exceptions, it contains several lines that (when
+    printed) display detailed information about where the syntax
+    error occurred.
+
+    The message indicating which exception occurred is always the last
+    string in the list.
+
+    """
+
+    # An instance should not have a meaningful value parameter, but
+    # sometimes does, particularly for string exceptions, such as
+    # >>> raise string1, string2  # deprecated
+    #
+    # Clear these out first because issubtype(string1, SyntaxError)
+    # would throw another exception and mask the original problem.
+    if (isinstance(etype, BaseException) or
+        isinstance(etype, types.InstanceType) or
+        etype is None or type(etype) is str):
+        return [_format_final_exc_line(etype, value)]
+
+    stype = etype.__name__
+
+    if not issubclass(etype, SyntaxError):
+        return [_format_final_exc_line(stype, value)]
+
+    # It was a syntax error; show exactly where the problem was found.
+    lines = []
+    try:
+        msg, (filename, lineno, offset, badline) = value.args
+    except Exception:
+        pass
+    else:
+        filename = filename or "<string>"
+        lines.append('  File "%s", line %d\n' % (filename, lineno))
+        if badline is not None:
+            lines.append('    %s\n' % badline.strip())
+            if offset is not None:
+                caretspace = badline.rstrip('\n')[:offset].lstrip()
+                # non-space whitespace (likes tabs) must be kept for alignment
+                caretspace = ((c.isspace() and c or ' ') for c in caretspace)
+                # only three spaces to account for offset1 == pos 0
+                lines.append('   %s^\n' % ''.join(caretspace))
+        value = msg
+
+    lines.append(_format_final_exc_line(stype, value))
+    return lines
+
+def _format_final_exc_line(etype, value):
+    """Return a list of a single line -- normal case for format_exception_only"""
+    valuestr = _some_str(value)
+    if value is None or not valuestr:
+        line = "%s\n" % etype
+    else:
+        line = "%s: %s\n" % (etype, valuestr)
+    return line
+
+def _some_str(value):
+    try:
+        return unicode(value)
+    except Exception:
+        try:
+            return str(value)
+        except Exception:
+            pass
+    return '<unprintable %s object>' % type(value).__name__
Index: venv/Lib/site-packages/_pytest/mark/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/mark/__init__.py	(date 1543190975812)
+++ venv/Lib/site-packages/_pytest/mark/__init__.py	(date 1543190975812)
@@ -0,0 +1,171 @@
+""" generic mechanism for marking and selecting python functions. """
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+from .legacy import matchkeyword
+from .legacy import matchmark
+from .structures import EMPTY_PARAMETERSET_OPTION
+from .structures import get_empty_parameterset_mark
+from .structures import Mark
+from .structures import MARK_GEN
+from .structures import MarkDecorator
+from .structures import MarkGenerator
+from .structures import MarkInfo
+from .structures import ParameterSet
+from .structures import transfer_markers
+from _pytest.config import UsageError
+
+__all__ = [
+    "Mark",
+    "MarkInfo",
+    "MarkDecorator",
+    "MarkGenerator",
+    "transfer_markers",
+    "get_empty_parameterset_mark",
+]
+
+
+def param(*values, **kw):
+    """Specify a parameter in `pytest.mark.parametrize`_ calls or
+    :ref:`parametrized fixtures <fixture-parametrize-marks>`.
+
+    .. code-block:: python
+
+        @pytest.mark.parametrize("test_input,expected", [
+            ("3+5", 8),
+            pytest.param("6*9", 42, marks=pytest.mark.xfail),
+        ])
+        def test_eval(test_input, expected):
+            assert eval(test_input) == expected
+
+    :param values: variable args of the values of the parameter set, in order.
+    :keyword marks: a single mark or a list of marks to be applied to this parameter set.
+    :keyword str id: the id to attribute to this parameter set.
+    """
+    return ParameterSet.param(*values, **kw)
+
+
+def pytest_addoption(parser):
+    group = parser.getgroup("general")
+    group._addoption(
+        "-k",
+        action="store",
+        dest="keyword",
+        default="",
+        metavar="EXPRESSION",
+        help="only run tests which match the given substring expression. "
+        "An expression is a python evaluatable expression "
+        "where all names are substring-matched against test names "
+        "and their parent classes. Example: -k 'test_method or test_"
+        "other' matches all test functions and classes whose name "
+        "contains 'test_method' or 'test_other', while -k 'not test_method' "
+        "matches those that don't contain 'test_method' in their names. "
+        "Additionally keywords are matched to classes and functions "
+        "containing extra names in their 'extra_keyword_matches' set, "
+        "as well as functions which have names assigned directly to them.",
+    )
+
+    group._addoption(
+        "-m",
+        action="store",
+        dest="markexpr",
+        default="",
+        metavar="MARKEXPR",
+        help="only run tests matching given mark expression.  "
+        "example: -m 'mark1 and not mark2'.",
+    )
+
+    group.addoption(
+        "--markers",
+        action="store_true",
+        help="show markers (builtin, plugin and per-project ones).",
+    )
+
+    parser.addini("markers", "markers for test functions", "linelist")
+    parser.addini(EMPTY_PARAMETERSET_OPTION, "default marker for empty parametersets")
+
+
+def pytest_cmdline_main(config):
+    import _pytest.config
+
+    if config.option.markers:
+        config._do_configure()
+        tw = _pytest.config.create_terminal_writer(config)
+        for line in config.getini("markers"):
+            parts = line.split(":", 1)
+            name = parts[0]
+            rest = parts[1] if len(parts) == 2 else ""
+            tw.write("@pytest.mark.%s:" % name, bold=True)
+            tw.line(rest)
+            tw.line()
+        config._ensure_unconfigure()
+        return 0
+
+
+pytest_cmdline_main.tryfirst = True
+
+
+def deselect_by_keyword(items, config):
+    keywordexpr = config.option.keyword.lstrip()
+    if keywordexpr.startswith("-"):
+        keywordexpr = "not " + keywordexpr[1:]
+    selectuntil = False
+    if keywordexpr[-1:] == ":":
+        selectuntil = True
+        keywordexpr = keywordexpr[:-1]
+
+    remaining = []
+    deselected = []
+    for colitem in items:
+        if keywordexpr and not matchkeyword(colitem, keywordexpr):
+            deselected.append(colitem)
+        else:
+            if selectuntil:
+                keywordexpr = None
+            remaining.append(colitem)
+
+    if deselected:
+        config.hook.pytest_deselected(items=deselected)
+        items[:] = remaining
+
+
+def deselect_by_mark(items, config):
+    matchexpr = config.option.markexpr
+    if not matchexpr:
+        return
+
+    remaining = []
+    deselected = []
+    for item in items:
+        if matchmark(item, matchexpr):
+            remaining.append(item)
+        else:
+            deselected.append(item)
+
+    if deselected:
+        config.hook.pytest_deselected(items=deselected)
+        items[:] = remaining
+
+
+def pytest_collection_modifyitems(items, config):
+    deselect_by_keyword(items, config)
+    deselect_by_mark(items, config)
+
+
+def pytest_configure(config):
+    config._old_mark_config = MARK_GEN._config
+    if config.option.strict:
+        MARK_GEN._config = config
+
+    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)
+
+    if empty_parameterset not in ("skip", "xfail", "fail_at_collect", None, ""):
+        raise UsageError(
+            "{!s} must be one of skip, xfail or fail_at_collect"
+            " but it is {!r}".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)
+        )
+
+
+def pytest_unconfigure(config):
+    MARK_GEN._config = getattr(config, "_old_mark_config", None)
Index: venv/Lib/site-packages/py/_code/code.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/code.py	(date 1543190975824)
+++ venv/Lib/site-packages/py/_code/code.py	(date 1543190975824)
@@ -0,0 +1,796 @@
+import py
+import sys
+from inspect import CO_VARARGS, CO_VARKEYWORDS, isclass
+
+builtin_repr = repr
+
+reprlib = py.builtin._tryimport('repr', 'reprlib')
+
+if sys.version_info[0] >= 3:
+    from traceback import format_exception_only
+else:
+    from py._code._py2traceback import format_exception_only
+
+import traceback
+
+
+class Code(object):
+    """ wrapper around Python code objects """
+    def __init__(self, rawcode):
+        if not hasattr(rawcode, "co_filename"):
+            rawcode = py.code.getrawcode(rawcode)
+        try:
+            self.filename = rawcode.co_filename
+            self.firstlineno = rawcode.co_firstlineno - 1
+            self.name = rawcode.co_name
+        except AttributeError:
+            raise TypeError("not a code object: %r" % (rawcode,))
+        self.raw = rawcode
+
+    def __eq__(self, other):
+        return self.raw == other.raw
+
+    def __ne__(self, other):
+        return not self == other
+
+    @property
+    def path(self):
+        """ return a path object pointing to source code (note that it
+        might not point to an actually existing file). """
+        p = py.path.local(self.raw.co_filename)
+        # maybe don't try this checking
+        if not p.check():
+            # XXX maybe try harder like the weird logic
+            # in the standard lib [linecache.updatecache] does?
+            p = self.raw.co_filename
+        return p
+
+    @property
+    def fullsource(self):
+        """ return a py.code.Source object for the full source file of the code
+        """
+        from py._code import source
+        full, _ = source.findsource(self.raw)
+        return full
+
+    def source(self):
+        """ return a py.code.Source object for the code object's source only
+        """
+        # return source only for that part of code
+        return py.code.Source(self.raw)
+
+    def getargs(self, var=False):
+        """ return a tuple with the argument names for the code object
+
+            if 'var' is set True also return the names of the variable and
+            keyword arguments when present
+        """
+        # handfull shortcut for getting args
+        raw = self.raw
+        argcount = raw.co_argcount
+        if var:
+            argcount += raw.co_flags & CO_VARARGS
+            argcount += raw.co_flags & CO_VARKEYWORDS
+        return raw.co_varnames[:argcount]
+
+class Frame(object):
+    """Wrapper around a Python frame holding f_locals and f_globals
+    in which expressions can be evaluated."""
+
+    def __init__(self, frame):
+        self.lineno = frame.f_lineno - 1
+        self.f_globals = frame.f_globals
+        self.f_locals = frame.f_locals
+        self.raw = frame
+        self.code = py.code.Code(frame.f_code)
+
+    @property
+    def statement(self):
+        """ statement this frame is at """
+        if self.code.fullsource is None:
+            return py.code.Source("")
+        return self.code.fullsource.getstatement(self.lineno)
+
+    def eval(self, code, **vars):
+        """ evaluate 'code' in the frame
+
+            'vars' are optional additional local variables
+
+            returns the result of the evaluation
+        """
+        f_locals = self.f_locals.copy()
+        f_locals.update(vars)
+        return eval(code, self.f_globals, f_locals)
+
+    def exec_(self, code, **vars):
+        """ exec 'code' in the frame
+
+            'vars' are optiona; additional local variables
+        """
+        f_locals = self.f_locals.copy()
+        f_locals.update(vars)
+        py.builtin.exec_(code, self.f_globals, f_locals)
+
+    def repr(self, object):
+        """ return a 'safe' (non-recursive, one-line) string repr for 'object'
+        """
+        return py.io.saferepr(object)
+
+    def is_true(self, object):
+        return object
+
+    def getargs(self, var=False):
+        """ return a list of tuples (name, value) for all arguments
+
+            if 'var' is set True also include the variable and keyword
+            arguments when present
+        """
+        retval = []
+        for arg in self.code.getargs(var):
+            try:
+                retval.append((arg, self.f_locals[arg]))
+            except KeyError:
+                pass     # this can occur when using Psyco
+        return retval
+
+
+class TracebackEntry(object):
+    """ a single entry in a traceback """
+
+    _repr_style = None
+    exprinfo = None
+
+    def __init__(self, rawentry):
+        self._rawentry = rawentry
+        self.lineno = rawentry.tb_lineno - 1
+
+    def set_repr_style(self, mode):
+        assert mode in ("short", "long")
+        self._repr_style = mode
+
+    @property
+    def frame(self):
+        return py.code.Frame(self._rawentry.tb_frame)
+
+    @property
+    def relline(self):
+        return self.lineno - self.frame.code.firstlineno
+
+    def __repr__(self):
+        return "<TracebackEntry %s:%d>" % (self.frame.code.path, self.lineno+1)
+
+    @property
+    def statement(self):
+        """ py.code.Source object for the current statement """
+        source = self.frame.code.fullsource
+        return source.getstatement(self.lineno)
+
+    @property
+    def path(self):
+        """ path to the source code """
+        return self.frame.code.path
+
+    def getlocals(self):
+        return self.frame.f_locals
+    locals = property(getlocals, None, None, "locals of underlaying frame")
+
+    def reinterpret(self):
+        """Reinterpret the failing statement and returns a detailed information
+           about what operations are performed."""
+        if self.exprinfo is None:
+            source = str(self.statement).strip()
+            x = py.code._reinterpret(source, self.frame, should_fail=True)
+            if not isinstance(x, str):
+                raise TypeError("interpret returned non-string %r" % (x,))
+            self.exprinfo = x
+        return self.exprinfo
+
+    def getfirstlinesource(self):
+        # on Jython this firstlineno can be -1 apparently
+        return max(self.frame.code.firstlineno, 0)
+
+    def getsource(self, astcache=None):
+        """ return failing source code. """
+        # we use the passed in astcache to not reparse asttrees
+        # within exception info printing
+        from py._code.source import getstatementrange_ast
+        source = self.frame.code.fullsource
+        if source is None:
+            return None
+        key = astnode = None
+        if astcache is not None:
+            key = self.frame.code.path
+            if key is not None:
+                astnode = astcache.get(key, None)
+        start = self.getfirstlinesource()
+        try:
+            astnode, _, end = getstatementrange_ast(self.lineno, source,
+                                                    astnode=astnode)
+        except SyntaxError:
+            end = self.lineno + 1
+        else:
+            if key is not None:
+                astcache[key] = astnode
+        return source[start:end]
+
+    source = property(getsource)
+
+    def ishidden(self):
+        """ return True if the current frame has a var __tracebackhide__
+            resolving to True
+
+            mostly for internal use
+        """
+        try:
+            return self.frame.f_locals['__tracebackhide__']
+        except KeyError:
+            try:
+                return self.frame.f_globals['__tracebackhide__']
+            except KeyError:
+                return False
+
+    def __str__(self):
+        try:
+            fn = str(self.path)
+        except py.error.Error:
+            fn = '???'
+        name = self.frame.code.name
+        try:
+            line = str(self.statement).lstrip()
+        except KeyboardInterrupt:
+            raise
+        except:
+            line = "???"
+        return "  File %r:%d in %s\n  %s\n" % (fn, self.lineno+1, name, line)
+
+    def name(self):
+        return self.frame.code.raw.co_name
+    name = property(name, None, None, "co_name of underlaying code")
+
+
+class Traceback(list):
+    """ Traceback objects encapsulate and offer higher level
+        access to Traceback entries.
+    """
+    Entry = TracebackEntry
+
+    def __init__(self, tb):
+        """ initialize from given python traceback object. """
+        if hasattr(tb, 'tb_next'):
+            def f(cur):
+                while cur is not None:
+                    yield self.Entry(cur)
+                    cur = cur.tb_next
+            list.__init__(self, f(tb))
+        else:
+            list.__init__(self, tb)
+
+    def cut(self, path=None, lineno=None, firstlineno=None, excludepath=None):
+        """ return a Traceback instance wrapping part of this Traceback
+
+            by provding any combination of path, lineno and firstlineno, the
+            first frame to start the to-be-returned traceback is determined
+
+            this allows cutting the first part of a Traceback instance e.g.
+            for formatting reasons (removing some uninteresting bits that deal
+            with handling of the exception/traceback)
+        """
+        for x in self:
+            code = x.frame.code
+            codepath = code.path
+            if ((path is None or codepath == path) and
+                (excludepath is None or not hasattr(codepath, 'relto') or
+                 not codepath.relto(excludepath)) and
+                (lineno is None or x.lineno == lineno) and
+                (firstlineno is None or x.frame.code.firstlineno == firstlineno)):
+                return Traceback(x._rawentry)
+        return self
+
+    def __getitem__(self, key):
+        val = super(Traceback, self).__getitem__(key)
+        if isinstance(key, type(slice(0))):
+            val = self.__class__(val)
+        return val
+
+    def filter(self, fn=lambda x: not x.ishidden()):
+        """ return a Traceback instance with certain items removed
+
+            fn is a function that gets a single argument, a TracebackItem
+            instance, and should return True when the item should be added
+            to the Traceback, False when not
+
+            by default this removes all the TracebackItems which are hidden
+            (see ishidden() above)
+        """
+        return Traceback(filter(fn, self))
+
+    def getcrashentry(self):
+        """ return last non-hidden traceback entry that lead
+        to the exception of a traceback.
+        """
+        for i in range(-1, -len(self)-1, -1):
+            entry = self[i]
+            if not entry.ishidden():
+                return entry
+        return self[-1]
+
+    def recursionindex(self):
+        """ return the index of the frame/TracebackItem where recursion
+            originates if appropriate, None if no recursion occurred
+        """
+        cache = {}
+        for i, entry in enumerate(self):
+            # id for the code.raw is needed to work around
+            # the strange metaprogramming in the decorator lib from pypi
+            # which generates code objects that have hash/value equality
+            #XXX needs a test
+            key = entry.frame.code.path, id(entry.frame.code.raw), entry.lineno
+            #print "checking for recursion at", key
+            l = cache.setdefault(key, [])
+            if l:
+                f = entry.frame
+                loc = f.f_locals
+                for otherloc in l:
+                    if f.is_true(f.eval(co_equal,
+                        __recursioncache_locals_1=loc,
+                        __recursioncache_locals_2=otherloc)):
+                        return i
+            l.append(entry.frame.f_locals)
+        return None
+
+co_equal = compile('__recursioncache_locals_1 == __recursioncache_locals_2',
+                   '?', 'eval')
+
+class ExceptionInfo(object):
+    """ wraps sys.exc_info() objects and offers
+        help for navigating the traceback.
+    """
+    _striptext = ''
+    def __init__(self, tup=None, exprinfo=None):
+        if tup is None:
+            tup = sys.exc_info()
+            if exprinfo is None and isinstance(tup[1], AssertionError):
+                exprinfo = getattr(tup[1], 'msg', None)
+                if exprinfo is None:
+                    exprinfo = str(tup[1])
+                if exprinfo and exprinfo.startswith('assert '):
+                    self._striptext = 'AssertionError: '
+        self._excinfo = tup
+        #: the exception class
+        self.type = tup[0]
+        #: the exception instance
+        self.value = tup[1]
+        #: the exception raw traceback
+        self.tb = tup[2]
+        #: the exception type name
+        self.typename = self.type.__name__
+        #: the exception traceback (py.code.Traceback instance)
+        self.traceback = py.code.Traceback(self.tb)
+
+    def __repr__(self):
+        return "<ExceptionInfo %s tblen=%d>" % (
+            self.typename, len(self.traceback))
+
+    def exconly(self, tryshort=False):
+        """ return the exception as a string
+
+            when 'tryshort' resolves to True, and the exception is a
+            py.code._AssertionError, only the actual exception part of
+            the exception representation is returned (so 'AssertionError: ' is
+            removed from the beginning)
+        """
+        lines = format_exception_only(self.type, self.value)
+        text = ''.join(lines)
+        text = text.rstrip()
+        if tryshort:
+            if text.startswith(self._striptext):
+                text = text[len(self._striptext):]
+        return text
+
+    def errisinstance(self, exc):
+        """ return True if the exception is an instance of exc """
+        return isinstance(self.value, exc)
+
+    def _getreprcrash(self):
+        exconly = self.exconly(tryshort=True)
+        entry = self.traceback.getcrashentry()
+        path, lineno = entry.frame.code.raw.co_filename, entry.lineno
+        return ReprFileLocation(path, lineno+1, exconly)
+
+    def getrepr(self, showlocals=False, style="long",
+                abspath=False, tbfilter=True, funcargs=False):
+        """ return str()able representation of this exception info.
+            showlocals: show locals per traceback entry
+            style: long|short|no|native traceback style
+            tbfilter: hide entries (where __tracebackhide__ is true)
+
+            in case of style==native, tbfilter and showlocals is ignored.
+        """
+        if style == 'native':
+            return ReprExceptionInfo(ReprTracebackNative(
+                traceback.format_exception(
+                    self.type,
+                    self.value,
+                    self.traceback[0]._rawentry,
+                )), self._getreprcrash())
+
+        fmt = FormattedExcinfo(
+            showlocals=showlocals, style=style,
+            abspath=abspath, tbfilter=tbfilter, funcargs=funcargs)
+        return fmt.repr_excinfo(self)
+
+    def __str__(self):
+        entry = self.traceback[-1]
+        loc = ReprFileLocation(entry.path, entry.lineno + 1, self.exconly())
+        return str(loc)
+
+    def __unicode__(self):
+        entry = self.traceback[-1]
+        loc = ReprFileLocation(entry.path, entry.lineno + 1, self.exconly())
+        return loc.__unicode__()
+
+
+class FormattedExcinfo(object):
+    """ presenting information about failing Functions and Generators. """
+    # for traceback entries
+    flow_marker = ">"
+    fail_marker = "E"
+
+    def __init__(self, showlocals=False, style="long",
+                 abspath=True, tbfilter=True, funcargs=False):
+        self.showlocals = showlocals
+        self.style = style
+        self.tbfilter = tbfilter
+        self.funcargs = funcargs
+        self.abspath = abspath
+        self.astcache = {}
+
+    def _getindent(self, source):
+        # figure out indent for given source
+        try:
+            s = str(source.getstatement(len(source)-1))
+        except KeyboardInterrupt:
+            raise
+        except:
+            try:
+                s = str(source[-1])
+            except KeyboardInterrupt:
+                raise
+            except:
+                return 0
+        return 4 + (len(s) - len(s.lstrip()))
+
+    def _getentrysource(self, entry):
+        source = entry.getsource(self.astcache)
+        if source is not None:
+            source = source.deindent()
+        return source
+
+    def _saferepr(self, obj):
+        return py.io.saferepr(obj)
+
+    def repr_args(self, entry):
+        if self.funcargs:
+            args = []
+            for argname, argvalue in entry.frame.getargs(var=True):
+                args.append((argname, self._saferepr(argvalue)))
+            return ReprFuncArgs(args)
+
+    def get_source(self, source, line_index=-1, excinfo=None, short=False):
+        """ return formatted and marked up source lines. """
+        lines = []
+        if source is None or line_index >= len(source.lines):
+            source = py.code.Source("???")
+            line_index = 0
+        if line_index < 0:
+            line_index += len(source)
+        space_prefix = "    "
+        if short:
+            lines.append(space_prefix + source.lines[line_index].strip())
+        else:
+            for line in source.lines[:line_index]:
+                lines.append(space_prefix + line)
+            lines.append(self.flow_marker + "   " + source.lines[line_index])
+            for line in source.lines[line_index+1:]:
+                lines.append(space_prefix + line)
+        if excinfo is not None:
+            indent = 4 if short else self._getindent(source)
+            lines.extend(self.get_exconly(excinfo, indent=indent, markall=True))
+        return lines
+
+    def get_exconly(self, excinfo, indent=4, markall=False):
+        lines = []
+        indent = " " * indent
+        # get the real exception information out
+        exlines = excinfo.exconly(tryshort=True).split('\n')
+        failindent = self.fail_marker + indent[1:]
+        for line in exlines:
+            lines.append(failindent + line)
+            if not markall:
+                failindent = indent
+        return lines
+
+    def repr_locals(self, locals):
+        if self.showlocals:
+            lines = []
+            keys = [loc for loc in locals if loc[0] != "@"]
+            keys.sort()
+            for name in keys:
+                value = locals[name]
+                if name == '__builtins__':
+                    lines.append("__builtins__ = <builtins>")
+                else:
+                    # This formatting could all be handled by the
+                    # _repr() function, which is only reprlib.Repr in
+                    # disguise, so is very configurable.
+                    str_repr = self._saferepr(value)
+                    #if len(str_repr) < 70 or not isinstance(value,
+                    #                            (list, tuple, dict)):
+                    lines.append("%-10s = %s" %(name, str_repr))
+                    #else:
+                    #    self._line("%-10s =\\" % (name,))
+                    #    # XXX
+                    #    pprint.pprint(value, stream=self.excinfowriter)
+            return ReprLocals(lines)
+
+    def repr_traceback_entry(self, entry, excinfo=None):
+        source = self._getentrysource(entry)
+        if source is None:
+            source = py.code.Source("???")
+            line_index = 0
+        else:
+            # entry.getfirstlinesource() can be -1, should be 0 on jython
+            line_index = entry.lineno - max(entry.getfirstlinesource(), 0)
+
+        lines = []
+        style = entry._repr_style
+        if style is None:
+            style = self.style
+        if style in ("short", "long"):
+            short = style == "short"
+            reprargs = self.repr_args(entry) if not short else None
+            s = self.get_source(source, line_index, excinfo, short=short)
+            lines.extend(s)
+            if short:
+                message = "in %s" %(entry.name)
+            else:
+                message = excinfo and excinfo.typename or ""
+            path = self._makepath(entry.path)
+            filelocrepr = ReprFileLocation(path, entry.lineno+1, message)
+            localsrepr = None
+            if not short:
+                localsrepr =  self.repr_locals(entry.locals)
+            return ReprEntry(lines, reprargs, localsrepr, filelocrepr, style)
+        if excinfo:
+            lines.extend(self.get_exconly(excinfo, indent=4))
+        return ReprEntry(lines, None, None, None, style)
+
+    def _makepath(self, path):
+        if not self.abspath:
+            try:
+                np = py.path.local().bestrelpath(path)
+            except OSError:
+                return path
+            if len(np) < len(str(path)):
+                path = np
+        return path
+
+    def repr_traceback(self, excinfo):
+        traceback = excinfo.traceback
+        if self.tbfilter:
+            traceback = traceback.filter()
+        recursionindex = None
+        if excinfo.errisinstance(RuntimeError):
+            if "maximum recursion depth exceeded" in str(excinfo.value):
+                recursionindex = traceback.recursionindex()
+        last = traceback[-1]
+        entries = []
+        extraline = None
+        for index, entry in enumerate(traceback):
+            einfo = (last == entry) and excinfo or None
+            reprentry = self.repr_traceback_entry(entry, einfo)
+            entries.append(reprentry)
+            if index == recursionindex:
+                extraline = "!!! Recursion detected (same locals & position)"
+                break
+        return ReprTraceback(entries, extraline, style=self.style)
+
+    def repr_excinfo(self, excinfo):
+        reprtraceback = self.repr_traceback(excinfo)
+        reprcrash = excinfo._getreprcrash()
+        return ReprExceptionInfo(reprtraceback, reprcrash)
+
+class TerminalRepr:
+    def __str__(self):
+        s = self.__unicode__()
+        if sys.version_info[0] < 3:
+            s = s.encode('utf-8')
+        return s
+
+    def __unicode__(self):
+        # FYI this is called from pytest-xdist's serialization of exception
+        # information.
+        io = py.io.TextIO()
+        tw = py.io.TerminalWriter(file=io)
+        self.toterminal(tw)
+        return io.getvalue().strip()
+
+    def __repr__(self):
+        return "<%s instance at %0x>" %(self.__class__, id(self))
+
+
+class ReprExceptionInfo(TerminalRepr):
+    def __init__(self, reprtraceback, reprcrash):
+        self.reprtraceback = reprtraceback
+        self.reprcrash = reprcrash
+        self.sections = []
+
+    def addsection(self, name, content, sep="-"):
+        self.sections.append((name, content, sep))
+
+    def toterminal(self, tw):
+        self.reprtraceback.toterminal(tw)
+        for name, content, sep in self.sections:
+            tw.sep(sep, name)
+            tw.line(content)
+
+class ReprTraceback(TerminalRepr):
+    entrysep = "_ "
+
+    def __init__(self, reprentries, extraline, style):
+        self.reprentries = reprentries
+        self.extraline = extraline
+        self.style = style
+
+    def toterminal(self, tw):
+        # the entries might have different styles
+        last_style = None
+        for i, entry in enumerate(self.reprentries):
+            if entry.style == "long":
+                tw.line("")
+            entry.toterminal(tw)
+            if i < len(self.reprentries) - 1:
+                next_entry = self.reprentries[i+1]
+                if entry.style == "long" or \
+                   entry.style == "short" and next_entry.style == "long":
+                    tw.sep(self.entrysep)
+
+        if self.extraline:
+            tw.line(self.extraline)
+
+class ReprTracebackNative(ReprTraceback):
+    def __init__(self, tblines):
+        self.style = "native"
+        self.reprentries = [ReprEntryNative(tblines)]
+        self.extraline = None
+
+class ReprEntryNative(TerminalRepr):
+    style = "native"
+
+    def __init__(self, tblines):
+        self.lines = tblines
+
+    def toterminal(self, tw):
+        tw.write("".join(self.lines))
+
+class ReprEntry(TerminalRepr):
+    localssep = "_ "
+
+    def __init__(self, lines, reprfuncargs, reprlocals, filelocrepr, style):
+        self.lines = lines
+        self.reprfuncargs = reprfuncargs
+        self.reprlocals = reprlocals
+        self.reprfileloc = filelocrepr
+        self.style = style
+
+    def toterminal(self, tw):
+        if self.style == "short":
+            self.reprfileloc.toterminal(tw)
+            for line in self.lines:
+                red = line.startswith("E   ")
+                tw.line(line, bold=True, red=red)
+            #tw.line("")
+            return
+        if self.reprfuncargs:
+            self.reprfuncargs.toterminal(tw)
+        for line in self.lines:
+            red = line.startswith("E   ")
+            tw.line(line, bold=True, red=red)
+        if self.reprlocals:
+            #tw.sep(self.localssep, "Locals")
+            tw.line("")
+            self.reprlocals.toterminal(tw)
+        if self.reprfileloc:
+            if self.lines:
+                tw.line("")
+            self.reprfileloc.toterminal(tw)
+
+    def __str__(self):
+        return "%s\n%s\n%s" % ("\n".join(self.lines),
+                               self.reprlocals,
+                               self.reprfileloc)
+
+class ReprFileLocation(TerminalRepr):
+    def __init__(self, path, lineno, message):
+        self.path = str(path)
+        self.lineno = lineno
+        self.message = message
+
+    def toterminal(self, tw):
+        # filename and lineno output for each entry,
+        # using an output format that most editors unterstand
+        msg = self.message
+        i = msg.find("\n")
+        if i != -1:
+            msg = msg[:i]
+        tw.line("%s:%s: %s" %(self.path, self.lineno, msg))
+
+class ReprLocals(TerminalRepr):
+    def __init__(self, lines):
+        self.lines = lines
+
+    def toterminal(self, tw):
+        for line in self.lines:
+            tw.line(line)
+
+class ReprFuncArgs(TerminalRepr):
+    def __init__(self, args):
+        self.args = args
+
+    def toterminal(self, tw):
+        if self.args:
+            linesofar = ""
+            for name, value in self.args:
+                ns = "%s = %s" %(name, value)
+                if len(ns) + len(linesofar) + 2 > tw.fullwidth:
+                    if linesofar:
+                        tw.line(linesofar)
+                    linesofar =  ns
+                else:
+                    if linesofar:
+                        linesofar += ", " + ns
+                    else:
+                        linesofar = ns
+            if linesofar:
+                tw.line(linesofar)
+            tw.line("")
+
+
+
+oldbuiltins = {}
+
+def patch_builtins(assertion=True, compile=True):
+    """ put compile and AssertionError builtins to Python's builtins. """
+    if assertion:
+        from py._code import assertion
+        l = oldbuiltins.setdefault('AssertionError', [])
+        l.append(py.builtin.builtins.AssertionError)
+        py.builtin.builtins.AssertionError = assertion.AssertionError
+    if compile:
+        l = oldbuiltins.setdefault('compile', [])
+        l.append(py.builtin.builtins.compile)
+        py.builtin.builtins.compile = py.code.compile
+
+def unpatch_builtins(assertion=True, compile=True):
+    """ remove compile and AssertionError builtins from Python builtins. """
+    if assertion:
+        py.builtin.builtins.AssertionError = oldbuiltins['AssertionError'].pop()
+    if compile:
+        py.builtin.builtins.compile = oldbuiltins['compile'].pop()
+
+def getrawcode(obj, trycall=True):
+    """ return code object for given function. """
+    try:
+        return obj.__code__
+    except AttributeError:
+        obj = getattr(obj, 'im_func', obj)
+        obj = getattr(obj, 'func_code', obj)
+        obj = getattr(obj, 'f_code', obj)
+        obj = getattr(obj, '__code__', obj)
+        if trycall and not hasattr(obj, 'co_firstlineno'):
+            if hasattr(obj, '__call__') and not isclass(obj):
+                x = getrawcode(obj.__call__, trycall=False)
+                if hasattr(x, 'co_firstlineno'):
+                    return x
+        return obj
+
Index: venv/Lib/site-packages/_pytest/mark/evaluate.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/_pytest/mark/evaluate.py	(date 1543190975832)
+++ venv/Lib/site-packages/_pytest/mark/evaluate.py	(date 1543190975832)
@@ -0,0 +1,125 @@
+import os
+import platform
+import sys
+import traceback
+
+import six
+
+from ..outcomes import fail
+from ..outcomes import TEST_OUTCOME
+
+
+def cached_eval(config, expr, d):
+    if not hasattr(config, "_evalcache"):
+        config._evalcache = {}
+    try:
+        return config._evalcache[expr]
+    except KeyError:
+        import _pytest._code
+
+        exprcode = _pytest._code.compile(expr, mode="eval")
+        config._evalcache[expr] = x = eval(exprcode, d)
+        return x
+
+
+class MarkEvaluator(object):
+    def __init__(self, item, name):
+        self.item = item
+        self._marks = None
+        self._mark = None
+        self._mark_name = name
+
+    def __bool__(self):
+        # dont cache here to prevent staleness
+        return bool(self._get_marks())
+
+    __nonzero__ = __bool__
+
+    def wasvalid(self):
+        return not hasattr(self, "exc")
+
+    def _get_marks(self):
+        return list(self.item.iter_markers(name=self._mark_name))
+
+    def invalidraise(self, exc):
+        raises = self.get("raises")
+        if not raises:
+            return
+        return not isinstance(exc, raises)
+
+    def istrue(self):
+        try:
+            return self._istrue()
+        except TEST_OUTCOME:
+            self.exc = sys.exc_info()
+            if isinstance(self.exc[1], SyntaxError):
+                msg = [" " * (self.exc[1].offset + 4) + "^"]
+                msg.append("SyntaxError: invalid syntax")
+            else:
+                msg = traceback.format_exception_only(*self.exc[:2])
+            fail(
+                "Error evaluating %r expression\n"
+                "    %s\n"
+                "%s" % (self._mark_name, self.expr, "\n".join(msg)),
+                pytrace=False,
+            )
+
+    def _getglobals(self):
+        d = {"os": os, "sys": sys, "platform": platform, "config": self.item.config}
+        if hasattr(self.item, "obj"):
+            d.update(self.item.obj.__globals__)
+        return d
+
+    def _istrue(self):
+        if hasattr(self, "result"):
+            return self.result
+        self._marks = self._get_marks()
+
+        if self._marks:
+            self.result = False
+            for mark in self._marks:
+                self._mark = mark
+                if "condition" in mark.kwargs:
+                    args = (mark.kwargs["condition"],)
+                else:
+                    args = mark.args
+
+                for expr in args:
+                    self.expr = expr
+                    if isinstance(expr, six.string_types):
+                        d = self._getglobals()
+                        result = cached_eval(self.item.config, expr, d)
+                    else:
+                        if "reason" not in mark.kwargs:
+                            # XXX better be checked at collection time
+                            msg = (
+                                "you need to specify reason=STRING "
+                                "when using booleans as conditions."
+                            )
+                            fail(msg)
+                        result = bool(expr)
+                    if result:
+                        self.result = True
+                        self.reason = mark.kwargs.get("reason", None)
+                        self.expr = expr
+                        return self.result
+
+                if not args:
+                    self.result = True
+                    self.reason = mark.kwargs.get("reason", None)
+                    return self.result
+        return False
+
+    def get(self, attr, default=None):
+        if self._mark is None:
+            return default
+        return self._mark.kwargs.get(attr, default)
+
+    def getexplanation(self):
+        expl = getattr(self, "reason", None) or self.get("reason", None)
+        if not expl:
+            if not hasattr(self, "expr"):
+                return ""
+            else:
+                return "condition: " + str(self.expr)
+        return expl
Index: venv/Lib/site-packages/py/_code/_assertionnew.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/_assertionnew.py	(date 1543190975844)
+++ venv/Lib/site-packages/py/_code/_assertionnew.py	(date 1543190975844)
@@ -0,0 +1,322 @@
+"""
+Find intermediate evalutation results in assert statements through builtin AST.
+This should replace _assertionold.py eventually.
+"""
+
+import sys
+import ast
+
+import py
+from py._code.assertion import _format_explanation, BuiltinAssertionError
+
+
+def _is_ast_expr(node):
+    return isinstance(node, ast.expr)
+def _is_ast_stmt(node):
+    return isinstance(node, ast.stmt)
+
+
+class Failure(Exception):
+    """Error found while interpreting AST."""
+
+    def __init__(self, explanation=""):
+        self.cause = sys.exc_info()
+        self.explanation = explanation
+
+
+def interpret(source, frame, should_fail=False):
+    mod = ast.parse(source)
+    visitor = DebugInterpreter(frame)
+    try:
+        visitor.visit(mod)
+    except Failure:
+        failure = sys.exc_info()[1]
+        return getfailure(failure)
+    if should_fail:
+        return ("(assertion failed, but when it was re-run for "
+                "printing intermediate values, it did not fail.  Suggestions: "
+                "compute assert expression before the assert or use --no-assert)")
+
+def run(offending_line, frame=None):
+    if frame is None:
+        frame = py.code.Frame(sys._getframe(1))
+    return interpret(offending_line, frame)
+
+def getfailure(failure):
+    explanation = _format_explanation(failure.explanation)
+    value = failure.cause[1]
+    if str(value):
+        lines = explanation.splitlines()
+        if not lines:
+            lines.append("")
+        lines[0] += " << %s" % (value,)
+        explanation = "\n".join(lines)
+    text = "%s: %s" % (failure.cause[0].__name__, explanation)
+    if text.startswith("AssertionError: assert "):
+        text = text[16:]
+    return text
+
+
+operator_map = {
+    ast.BitOr : "|",
+    ast.BitXor : "^",
+    ast.BitAnd : "&",
+    ast.LShift : "<<",
+    ast.RShift : ">>",
+    ast.Add : "+",
+    ast.Sub : "-",
+    ast.Mult : "*",
+    ast.Div : "/",
+    ast.FloorDiv : "//",
+    ast.Mod : "%",
+    ast.Eq : "==",
+    ast.NotEq : "!=",
+    ast.Lt : "<",
+    ast.LtE : "<=",
+    ast.Gt : ">",
+    ast.GtE : ">=",
+    ast.Pow : "**",
+    ast.Is : "is",
+    ast.IsNot : "is not",
+    ast.In : "in",
+    ast.NotIn : "not in"
+}
+
+unary_map = {
+    ast.Not : "not %s",
+    ast.Invert : "~%s",
+    ast.USub : "-%s",
+    ast.UAdd : "+%s"
+}
+
+
+class DebugInterpreter(ast.NodeVisitor):
+    """Interpret AST nodes to gleam useful debugging information. """
+
+    def __init__(self, frame):
+        self.frame = frame
+
+    def generic_visit(self, node):
+        # Fallback when we don't have a special implementation.
+        if _is_ast_expr(node):
+            mod = ast.Expression(node)
+            co = self._compile(mod)
+            try:
+                result = self.frame.eval(co)
+            except Exception:
+                raise Failure()
+            explanation = self.frame.repr(result)
+            return explanation, result
+        elif _is_ast_stmt(node):
+            mod = ast.Module([node])
+            co = self._compile(mod, "exec")
+            try:
+                self.frame.exec_(co)
+            except Exception:
+                raise Failure()
+            return None, None
+        else:
+            raise AssertionError("can't handle %s" %(node,))
+
+    def _compile(self, source, mode="eval"):
+        return compile(source, "<assertion interpretation>", mode)
+
+    def visit_Expr(self, expr):
+        return self.visit(expr.value)
+
+    def visit_Module(self, mod):
+        for stmt in mod.body:
+            self.visit(stmt)
+
+    def visit_Name(self, name):
+        explanation, result = self.generic_visit(name)
+        # See if the name is local.
+        source = "%r in locals() is not globals()" % (name.id,)
+        co = self._compile(source)
+        try:
+            local = self.frame.eval(co)
+        except Exception:
+            # have to assume it isn't
+            local = False
+        if not local:
+            return name.id, result
+        return explanation, result
+
+    def visit_Compare(self, comp):
+        left = comp.left
+        left_explanation, left_result = self.visit(left)
+        for op, next_op in zip(comp.ops, comp.comparators):
+            next_explanation, next_result = self.visit(next_op)
+            op_symbol = operator_map[op.__class__]
+            explanation = "%s %s %s" % (left_explanation, op_symbol,
+                                        next_explanation)
+            source = "__exprinfo_left %s __exprinfo_right" % (op_symbol,)
+            co = self._compile(source)
+            try:
+                result = self.frame.eval(co, __exprinfo_left=left_result,
+                                         __exprinfo_right=next_result)
+            except Exception:
+                raise Failure(explanation)
+            try:
+                if not result:
+                    break
+            except KeyboardInterrupt:
+                raise
+            except:
+                break
+            left_explanation, left_result = next_explanation, next_result
+
+        rcomp = py.code._reprcompare
+        if rcomp:
+            res = rcomp(op_symbol, left_result, next_result)
+            if res:
+                explanation = res
+        return explanation, result
+
+    def visit_BoolOp(self, boolop):
+        is_or = isinstance(boolop.op, ast.Or)
+        explanations = []
+        for operand in boolop.values:
+            explanation, result = self.visit(operand)
+            explanations.append(explanation)
+            if result == is_or:
+                break
+        name = is_or and " or " or " and "
+        explanation = "(" + name.join(explanations) + ")"
+        return explanation, result
+
+    def visit_UnaryOp(self, unary):
+        pattern = unary_map[unary.op.__class__]
+        operand_explanation, operand_result = self.visit(unary.operand)
+        explanation = pattern % (operand_explanation,)
+        co = self._compile(pattern % ("__exprinfo_expr",))
+        try:
+            result = self.frame.eval(co, __exprinfo_expr=operand_result)
+        except Exception:
+            raise Failure(explanation)
+        return explanation, result
+
+    def visit_BinOp(self, binop):
+        left_explanation, left_result = self.visit(binop.left)
+        right_explanation, right_result = self.visit(binop.right)
+        symbol = operator_map[binop.op.__class__]
+        explanation = "(%s %s %s)" % (left_explanation, symbol,
+                                      right_explanation)
+        source = "__exprinfo_left %s __exprinfo_right" % (symbol,)
+        co = self._compile(source)
+        try:
+            result = self.frame.eval(co, __exprinfo_left=left_result,
+                                     __exprinfo_right=right_result)
+        except Exception:
+            raise Failure(explanation)
+        return explanation, result
+
+    def visit_Call(self, call):
+        func_explanation, func = self.visit(call.func)
+        arg_explanations = []
+        ns = {"__exprinfo_func" : func}
+        arguments = []
+        for arg in call.args:
+            arg_explanation, arg_result = self.visit(arg)
+            arg_name = "__exprinfo_%s" % (len(ns),)
+            ns[arg_name] = arg_result
+            arguments.append(arg_name)
+            arg_explanations.append(arg_explanation)
+        for keyword in call.keywords:
+            arg_explanation, arg_result = self.visit(keyword.value)
+            arg_name = "__exprinfo_%s" % (len(ns),)
+            ns[arg_name] = arg_result
+            keyword_source = "%s=%%s" % (keyword.arg)
+            arguments.append(keyword_source % (arg_name,))
+            arg_explanations.append(keyword_source % (arg_explanation,))
+        if call.starargs:
+            arg_explanation, arg_result = self.visit(call.starargs)
+            arg_name = "__exprinfo_star"
+            ns[arg_name] = arg_result
+            arguments.append("*%s" % (arg_name,))
+            arg_explanations.append("*%s" % (arg_explanation,))
+        if call.kwargs:
+            arg_explanation, arg_result = self.visit(call.kwargs)
+            arg_name = "__exprinfo_kwds"
+            ns[arg_name] = arg_result
+            arguments.append("**%s" % (arg_name,))
+            arg_explanations.append("**%s" % (arg_explanation,))
+        args_explained = ", ".join(arg_explanations)
+        explanation = "%s(%s)" % (func_explanation, args_explained)
+        args = ", ".join(arguments)
+        source = "__exprinfo_func(%s)" % (args,)
+        co = self._compile(source)
+        try:
+            result = self.frame.eval(co, **ns)
+        except Exception:
+            raise Failure(explanation)
+        pattern = "%s\n{%s = %s\n}"
+        rep = self.frame.repr(result)
+        explanation = pattern % (rep, rep, explanation)
+        return explanation, result
+
+    def _is_builtin_name(self, name):
+        pattern = "%r not in globals() and %r not in locals()"
+        source = pattern % (name.id, name.id)
+        co = self._compile(source)
+        try:
+            return self.frame.eval(co)
+        except Exception:
+            return False
+
+    def visit_Attribute(self, attr):
+        if not isinstance(attr.ctx, ast.Load):
+            return self.generic_visit(attr)
+        source_explanation, source_result = self.visit(attr.value)
+        explanation = "%s.%s" % (source_explanation, attr.attr)
+        source = "__exprinfo_expr.%s" % (attr.attr,)
+        co = self._compile(source)
+        try:
+            result = self.frame.eval(co, __exprinfo_expr=source_result)
+        except Exception:
+            raise Failure(explanation)
+        explanation = "%s\n{%s = %s.%s\n}" % (self.frame.repr(result),
+                                              self.frame.repr(result),
+                                              source_explanation, attr.attr)
+        # Check if the attr is from an instance.
+        source = "%r in getattr(__exprinfo_expr, '__dict__', {})"
+        source = source % (attr.attr,)
+        co = self._compile(source)
+        try:
+            from_instance = self.frame.eval(co, __exprinfo_expr=source_result)
+        except Exception:
+            from_instance = True
+        if from_instance:
+            rep = self.frame.repr(result)
+            pattern = "%s\n{%s = %s\n}"
+            explanation = pattern % (rep, rep, explanation)
+        return explanation, result
+
+    def visit_Assert(self, assrt):
+        test_explanation, test_result = self.visit(assrt.test)
+        if test_explanation.startswith("False\n{False =") and \
+                test_explanation.endswith("\n"):
+            test_explanation = test_explanation[15:-2]
+        explanation = "assert %s" % (test_explanation,)
+        if not test_result:
+            try:
+                raise BuiltinAssertionError
+            except Exception:
+                raise Failure(explanation)
+        return explanation, test_result
+
+    def visit_Assign(self, assign):
+        value_explanation, value_result = self.visit(assign.value)
+        explanation = "... = %s" % (value_explanation,)
+        name = ast.Name("__exprinfo_expr", ast.Load(),
+                        lineno=assign.value.lineno,
+                        col_offset=assign.value.col_offset)
+        new_assign = ast.Assign(assign.targets, name, lineno=assign.lineno,
+                                col_offset=assign.col_offset)
+        mod = ast.Module([new_assign])
+        co = self._compile(mod, "exec")
+        try:
+            self.frame.exec_(co, __exprinfo_expr=value_result)
+        except Exception:
+            raise Failure(explanation)
+        return explanation, value_result
Index: venv/Lib/site-packages/py/_code/assertion.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- venv/Lib/site-packages/py/_code/assertion.py	(date 1543190975860)
+++ venv/Lib/site-packages/py/_code/assertion.py	(date 1543190975860)
@@ -0,0 +1,90 @@
+import sys
+import py
+
+BuiltinAssertionError = py.builtin.builtins.AssertionError
+
+_reprcompare = None # if set, will be called by assert reinterp for comparison ops
+
+def _format_explanation(explanation):
+    """This formats an explanation
+
+    Normally all embedded newlines are escaped, however there are
+    three exceptions: \n{, \n} and \n~.  The first two are intended
+    cover nested explanations, see function and attribute explanations
+    for examples (.visit_Call(), visit_Attribute()).  The last one is
+    for when one explanation needs to span multiple lines, e.g. when
+    displaying diffs.
+    """
+    raw_lines = (explanation or '').split('\n')
+    # escape newlines not followed by {, } and ~
+    lines = [raw_lines[0]]
+    for l in raw_lines[1:]:
+        if l.startswith('{') or l.startswith('}') or l.startswith('~'):
+            lines.append(l)
+        else:
+            lines[-1] += '\\n' + l
+
+    result = lines[:1]
+    stack = [0]
+    stackcnt = [0]
+    for line in lines[1:]:
+        if line.startswith('{'):
+            if stackcnt[-1]:
+                s = 'and   '
+            else:
+                s = 'where '
+            stack.append(len(result))
+            stackcnt[-1] += 1
+            stackcnt.append(0)
+            result.append(' +' + '  '*(len(stack)-1) + s + line[1:])
+        elif line.startswith('}'):
+            assert line.startswith('}')
+            stack.pop()
+            stackcnt.pop()
+            result[stack[-1]] += line[1:]
+        else:
+            assert line.startswith('~')
+            result.append('  '*len(stack) + line[1:])
+    assert len(stack) == 1
+    return '\n'.join(result)
+
+
+class AssertionError(BuiltinAssertionError):
+    def __init__(self, *args):
+        BuiltinAssertionError.__init__(self, *args)
+        if args:
+            try:
+                self.msg = str(args[0])
+            except py.builtin._sysex:
+                raise
+            except:
+                self.msg = "<[broken __repr__] %s at %0xd>" %(
+                    args[0].__class__, id(args[0]))
+        else:
+            f = py.code.Frame(sys._getframe(1))
+            try:
+                source = f.code.fullsource
+                if source is not None:
+                    try:
+                        source = source.getstatement(f.lineno, assertion=True)
+                    except IndexError:
+                        source = None
+                    else:
+                        source = str(source.deindent()).strip()
+            except py.error.ENOENT:
+                source = None
+                # this can also occur during reinterpretation, when the
+                # co_filename is set to "<run>".
+            if source:
+                self.msg = reinterpret(source, f, should_fail=True)
+            else:
+                self.msg = "<could not determine information>"
+            if not self.args:
+                self.args = (self.msg,)
+
+if sys.version_info > (3, 0):
+    AssertionError.__module__ = "builtins"
+    reinterpret_old = "old reinterpretation not available for py3"
+else:
+    from py._code._assertionold import interpret as reinterpret_old
+from py._code._assertionnew import interpret as reinterpret
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/workspace.xml	(date 1542774566000)
+++ .idea/workspace.xml	(date 1543190977344)
@@ -1,9 +1,205 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="ChangeListManager">
-    <list default="true" id="f5cc79e0-3245-4ecd-a8cd-15253f496041" name="Default Changelist" comment="">
-      <change afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/requirements.txt" afterDir="false" />
+    <list default="true" id="f5cc79e0-3245-4ecd-a8cd-15253f496041" name="Default Changelist" comment="Adding answers for ctci chapter 1&#10;&#10;also adding venv">
+      <change afterPath="$PROJECT_DIR$/.idea/shelf/Adding_answers_for_ctci_chapter_1__also_adding_venv.xml" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/OneCharacterDifference.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/Palindrome.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/Permutation.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/RotateMatrix.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/SetToZero.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/StringCompression.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/StringRotation.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/Urlify.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_is_perm.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_one_character_difference.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_palindrome.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_set_to_zero.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_string_compression.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_string_rotation.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/Chapter1/tests/test_urlify.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/_argcomplete.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/_code/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/_code/_py2traceback.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/_code/code.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/_code/source.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/_version.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/assertion/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/assertion/rewrite.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/assertion/truncate.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/assertion/util.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/cacheprovider.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/capture.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/compat.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/config/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/config/argparsing.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/config/exceptions.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/config/findpaths.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/debugging.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/deprecated.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/doctest.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/fixtures.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/freeze_support.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/helpconfig.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/hookspec.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/junitxml.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/logging.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/main.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/mark/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/mark/evaluate.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/mark/legacy.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/mark/structures.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/monkeypatch.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/nodes.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/nose.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/outcomes.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/pastebin.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/pathlib.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/pytester.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/python.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/python_api.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/recwarn.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/reports.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/resultlog.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/runner.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/setuponly.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/setupplan.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/skipping.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/stepwise.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/terminal.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/tmpdir.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/unittest.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/warning_types.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/_pytest/warnings.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/atomicwrites/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/__init__.pyi" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/_compat.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/_config.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/_funcs.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/_make.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/converters.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/converters.pyi" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/exceptions.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/exceptions.pyi" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/filters.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/filters.pyi" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/py.typed" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/validators.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attr/validators.pyi" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attrs-18.2.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attrs-18.2.0.dist-info/LICENSE.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attrs-18.2.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attrs-18.2.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attrs-18.2.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/attrs-18.2.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/DESCRIPTION.rst" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/LICENSE.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/metadata.json" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama-0.4.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama/ansi.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama/ansitowin32.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama/initialise.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama/win32.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/colorama/winterm.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools-4.3.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools-4.3.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools-4.3.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools-4.3.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools-4.3.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools/more.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools/recipes.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools/tests/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools/tests/test_more.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/more_itertools/tests/test_recipes.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy-0.8.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy-0.8.0.dist-info/LICENSE" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy-0.8.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy-0.8.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy-0.8.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy-0.8.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy/_tracing.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy/_version.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy/callers.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy/hooks.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pluggy/manager.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py-1.7.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py-1.7.0.dist-info/LICENSE" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py-1.7.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py-1.7.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py-1.7.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py-1.7.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/__metainfo.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_builtin.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/_assertionnew.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/_assertionold.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/_py2traceback.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/assertion.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/code.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_code/source.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_error.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_io/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_io/capture.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_io/saferepr.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_io/terminalwriter.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_log/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_log/log.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_log/warning.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_path/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_path/cacheutil.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_path/common.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_path/local.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_path/svnurl.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_path/svnwc.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_process/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_process/cmdexec.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_process/forkedfunc.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_process/killproc.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_std.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_vendored_packages/__init__.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_vendored_packages/apipkg.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_vendored_packages/iniconfig.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_version.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/_xmlgen.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/py/test.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/LICENSE" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/entry_points.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest-4.0.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/pytest.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/DESCRIPTION.rst" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/INSTALLER" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/METADATA" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/RECORD" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/WHEEL" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/metadata.json" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six-1.11.0.dist-info/top_level.txt" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Lib/site-packages/six.py" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Scripts/py.test.exe" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/venv/Scripts/pytest.exe" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+    </list>
+    <list id="96a0739b-9b6a-4479-9d8b-a1690b0e7a75" name="Adding answers for ctci chapter 1  also adding venv" comment="">
+      <change beforePath="$PROJECT_DIR$/requirements.txt" beforeDir="false" afterPath="$PROJECT_DIR$/requirements.txt" afterDir="false" />
     </list>
     <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
     <option name="SHOW_DIALOG" value="false" />
@@ -15,55 +211,54 @@
     <session id="-2008137370">
       <usages-collector id="statistics.lifecycle.project">
         <counts>
-          <entry key="project.closed" value="5" />
-          <entry key="project.open.time.0" value="2" />
+          <entry key="project.closed" value="6" />
+          <entry key="project.open.time.0" value="3" />
+          <entry key="project.open.time.1" value="1" />
           <entry key="project.open.time.13" value="1" />
           <entry key="project.open.time.3" value="1" />
           <entry key="project.open.time.9" value="1" />
-          <entry key="project.opened" value="5" />
+          <entry key="project.opened" value="7" />
         </counts>
       </usages-collector>
       <usages-collector id="statistics.file.extensions.open">
         <counts>
           <entry key="bat" value="1" />
           <entry key="pth" value="2" />
-          <entry key="py" value="2" />
+          <entry key="py" value="21" />
           <entry key="txt" value="1" />
         </counts>
       </usages-collector>
       <usages-collector id="statistics.file.types.open">
         <counts>
           <entry key="PLAIN_TEXT" value="4" />
-          <entry key="Python" value="2" />
+          <entry key="Python" value="21" />
         </counts>
       </usages-collector>
       <usages-collector id="statistics.file.extensions.edit">
         <counts>
-          <entry key="Python Console" value="36" />
-          <entry key="py" value="8" />
-          <entry key="txt" value="16" />
+          <entry key="Python Console" value="264" />
+          <entry key="dummy" value="12" />
+          <entry key="py" value="2172" />
+          <entry key="txt" value="32" />
         </counts>
       </usages-collector>
       <usages-collector id="statistics.file.types.edit">
         <counts>
-          <entry key="PLAIN_TEXT" value="16" />
-          <entry key="Python" value="44" />
+          <entry key="PLAIN_TEXT" value="44" />
+          <entry key="Python" value="2436" />
         </counts>
       </usages-collector>
     </session>
   </component>
   <component name="FileEditorManager">
-    <leaf SIDE_TABS_SIZE_LIMIT_KEY="300">
-      <file pinned="false" current-in-tab="true">
-        <entry file="file://$PROJECT_DIR$/requirements.txt">
-          <provider selected="true" editor-type-id="text-editor">
-            <state>
-              <caret column="32" selection-start-column="32" selection-end-column="32" />
-            </state>
-          </provider>
-        </entry>
-      </file>
-    </leaf>
+    <leaf SIDE_TABS_SIZE_LIMIT_KEY="300" />
+  </component>
+  <component name="FileTemplateManagerImpl">
+    <option name="RECENT_TEMPLATES">
+      <list>
+        <option value="Python Script" />
+      </list>
+    </option>
   </component>
   <component name="Git.Settings">
     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
@@ -73,6 +268,23 @@
       <list>
         <option value="$PROJECT_DIR$/venv/Scripts/pip-script.py" />
         <option value="$PROJECT_DIR$/requirements.txt" />
+        <option value="$PROJECT_DIR$/Chapter1/__init__.py" />
+        <option value="$PROJECT_DIR$/Chapter1/OneCharacterDifference.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_one_character_difference.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_is_perm.py" />
+        <option value="$PROJECT_DIR$/Chapter1/Permutation.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_urlify.py" />
+        <option value="$PROJECT_DIR$/Chapter1/Urlify.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_palidrome.py" />
+        <option value="$PROJECT_DIR$/Chapter1/Palindrome.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_palindrome.py" />
+        <option value="$PROJECT_DIR$/Chapter1/StringCompression.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_string_compression.py" />
+        <option value="$PROJECT_DIR$/Chapter1/RotateMatrix.py" />
+        <option value="$PROJECT_DIR$/Chapter1/SetToZero.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_set_to_zero.py" />
+        <option value="$PROJECT_DIR$/Chapter1/.pytest_cache/StringRotation.py" />
+        <option value="$PROJECT_DIR$/Chapter1/tests/test_string_rotation.py" />
       </list>
     </option>
   </component>
@@ -93,6 +305,11 @@
               <item name="ctci" type="b2602c69:ProjectViewProjectNode" />
               <item name="ctci" type="462c0819:PsiDirectoryNode" />
             </path>
+            <path>
+              <item name="ctci" type="b2602c69:ProjectViewProjectNode" />
+              <item name="ctci" type="462c0819:PsiDirectoryNode" />
+              <item name="Chapter1" type="462c0819:PsiDirectoryNode" />
+            </path>
           </expand>
           <select />
         </subPane>
@@ -101,8 +318,13 @@
     </panes>
   </component>
   <component name="PropertiesComponent">
-    <property name="last_opened_file_path" value="$PROJECT_DIR$" />
+    <property name="last_opened_file_path" value="$PROJECT_DIR$/../test_python" />
     <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable" />
+  </component>
+  <component name="RecentsManager">
+    <key name="MoveFile.RECENT_KEYS">
+      <recent name="C:\Users\plim\Documents\personal_repo\ctci\Chapter1" />
+    </key>
   </component>
   <component name="RunDashboard">
     <option name="ruleStates">
@@ -127,6 +349,14 @@
       <option name="presentableId" value="Default" />
       <updated>1542770272043</updated>
     </task>
+    <task id="LOCAL-00001" summary="Adding answers for ctci chapter 1&#10;&#10;also adding venv">
+      <created>1543190255592</created>
+      <option name="number" value="00001" />
+      <option name="presentableId" value="LOCAL-00001" />
+      <option name="project" value="LOCAL" />
+      <updated>1543190255596</updated>
+    </task>
+    <option name="localTasksCounter" value="2" />
     <servers />
   </component>
   <component name="ToolWindowManager">
@@ -136,23 +366,69 @@
       <window_info id="Structure" order="1" side_tool="true" weight="0.25" />
       <window_info id="Favorites" order="2" side_tool="true" />
       <window_info anchor="bottom" id="Message" order="0" />
-      <window_info anchor="bottom" id="Find" order="1" />
+      <window_info anchor="bottom" id="Find" order="1" weight="0.32991204" />
       <window_info anchor="bottom" id="Run" order="2" />
       <window_info anchor="bottom" id="Debug" order="3" weight="0.4" />
       <window_info anchor="bottom" id="Cvs" order="4" weight="0.25" />
       <window_info anchor="bottom" id="Inspection" order="5" weight="0.4" />
       <window_info anchor="bottom" id="TODO" order="6" />
-      <window_info anchor="bottom" id="Version Control" order="7" show_stripe_button="false" />
-      <window_info active="true" anchor="bottom" id="Terminal" order="8" visible="true" weight="0.32991204" />
+      <window_info active="true" anchor="bottom" id="Version Control" order="7" show_stripe_button="false" visible="true" weight="0.32991204" />
+      <window_info anchor="bottom" id="Terminal" order="8" weight="0.32991204" />
       <window_info anchor="bottom" id="Event Log" order="9" side_tool="true" />
       <window_info anchor="bottom" id="Python Console" order="10" weight="0.32991204" />
       <window_info anchor="right" id="Commander" internal_type="SLIDING" order="0" type="SLIDING" weight="0.4" />
       <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />
       <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />
     </layout>
+  </component>
+  <component name="Vcs.Log.Tabs.Properties">
+    <option name="TAB_STATES">
+      <map>
+        <entry key="MAIN">
+          <value>
+            <State>
+              <option name="RECENTLY_FILTERED_USER_GROUPS">
+                <collection />
+              </option>
+              <option name="RECENTLY_FILTERED_BRANCH_GROUPS">
+                <collection />
+              </option>
+              <option name="COLUMN_ORDER">
+                <list>
+                  <option value="0" />
+                  <option value="1" />
+                  <option value="2" />
+                  <option value="3" />
+                </list>
+              </option>
+            </State>
+          </value>
+        </entry>
+      </map>
+    </option>
   </component>
   <component name="VcsContentAnnotationSettings">
     <option name="myLimit" value="2678400000" />
+  </component>
+  <component name="VcsManagerConfiguration">
+    <option name="CHECK_CODE_SMELLS_BEFORE_PROJECT_COMMIT" value="true" />
+    <option name="CHECK_CODE_CLEANUP_BEFORE_PROJECT_COMMIT" value="true" />
+    <MESSAGE value="Adding answers for ctci chapter 1&#10;&#10;also adding venv" />
+    <option name="LAST_COMMIT_MESSAGE" value="Adding answers for ctci chapter 1&#10;&#10;also adding venv" />
+    <option name="OPTIMIZE_IMPORTS_BEFORE_PROJECT_COMMIT" value="true" />
+    <option name="REFORMAT_BEFORE_PROJECT_COMMIT" value="true" />
+    <option name="REARRANGE_BEFORE_PROJECT_COMMIT" value="true" />
+  </component>
+  <component name="XDebuggerManager">
+    <breakpoint-manager>
+      <breakpoints>
+        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
+          <url>file://$PROJECT_DIR$/Chapter1/tests/test_urlify.py</url>
+          <line>4</line>
+          <option name="timeStamp" value="1" />
+        </line-breakpoint>
+      </breakpoints>
+    </breakpoint-manager>
   </component>
   <component name="editorHistoryManager">
     <entry file="file://$PROJECT_DIR$/venv/Lib/site-packages/virtualenv.py" />
@@ -164,8 +440,116 @@
     </entry>
     <entry file="file://$PROJECT_DIR$/requirements.txt">
       <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="34">
+          <caret line="2" column="15" selection-start-line="2" selection-start-column="15" selection-end-line="2" selection-end-column="15" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/__init__.py">
+      <provider selected="true" editor-type-id="text-editor" />
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_is_perm.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="102">
+          <caret line="6" column="15" selection-start-line="6" selection-start-column="15" selection-end-line="6" selection-end-column="15" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_urlify.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="68">
+          <caret line="4" column="63" lean-forward="true" selection-start-line="4" selection-start-column="63" selection-end-line="4" selection-end-column="63" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_palindrome.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="85">
+          <caret line="5" column="39" selection-start-line="5" selection-start-column="39" selection-end-line="5" selection-end-column="39" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_one_character_difference.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="272">
+          <caret line="16" column="15" selection-start-line="16" selection-start-column="15" selection-end-line="16" selection-end-column="15" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/OneCharacterDifference.py">
+      <provider selected="true" editor-type-id="text-editor">
         <state>
-          <caret column="32" selection-start-column="32" selection-end-column="32" />
+          <caret column="54" selection-start-column="54" selection-end-column="54" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/StringCompression.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="204">
+          <caret line="12" column="44" selection-start-line="12" selection-start-column="44" selection-end-line="12" selection-end-column="44" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_string_compression.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="68">
+          <caret line="4" column="36" selection-start-line="4" selection-start-column="36" selection-end-line="4" selection-end-column="36" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/RotateMatrix.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state>
+          <caret selection-end-column="23" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/SetToZero.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="204">
+          <caret line="16" column="36" selection-start-line="16" selection-start-column="36" selection-end-line="16" selection-end-column="36" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_set_to_zero.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="136">
+          <caret line="8" lean-forward="true" selection-start-line="8" selection-end-line="8" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/StringRotation.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="85">
+          <caret line="5" column="22" lean-forward="true" selection-start-line="5" selection-start-column="22" selection-end-line="5" selection-end-column="22" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/tests/test_string_rotation.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="68">
+          <caret line="4" column="38" selection-start-line="4" selection-start-column="38" selection-end-line="4" selection-end-column="38" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/Permutation.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="255">
+          <caret line="15" lean-forward="true" selection-start-line="15" selection-end-line="15" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/Urlify.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state>
+          <caret column="30" lean-forward="true" selection-start-column="30" selection-end-column="30" />
+        </state>
+      </provider>
+    </entry>
+    <entry file="file://$PROJECT_DIR$/Chapter1/Palindrome.py">
+      <provider selected="true" editor-type-id="text-editor">
+        <state relative-caret-position="136">
+          <caret line="8" column="25" selection-start-line="8" selection-start-column="25" selection-end-line="8" selection-end-column="25" />
         </state>
       </provider>
     </entry>
diff --git venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/RECORD venv/Lib/site-packages/atomicwrites-1.2.1.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/attr/py.typed venv/Lib/site-packages/attr/py.typed
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/attrs-18.2.0.dist-info/RECORD venv/Lib/site-packages/attrs-18.2.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/colorama-0.4.0.dist-info/RECORD venv/Lib/site-packages/colorama-0.4.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/more_itertools-4.3.0.dist-info/RECORD venv/Lib/site-packages/more_itertools-4.3.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/pluggy-0.8.0.dist-info/LICENSE venv/Lib/site-packages/pluggy-0.8.0.dist-info/LICENSE
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/pluggy-0.8.0.dist-info/RECORD venv/Lib/site-packages/pluggy-0.8.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/py-1.7.0.dist-info/LICENSE venv/Lib/site-packages/py-1.7.0.dist-info/LICENSE
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/py-1.7.0.dist-info/RECORD venv/Lib/site-packages/py-1.7.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/pytest-4.0.0.dist-info/LICENSE venv/Lib/site-packages/pytest-4.0.0.dist-info/LICENSE
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/pytest-4.0.0.dist-info/RECORD venv/Lib/site-packages/pytest-4.0.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Lib/site-packages/six-1.11.0.dist-info/RECORD venv/Lib/site-packages/six-1.11.0.dist-info/RECORD
new file mode 100644
index 0000000000000000000000000000000000000000..e69de29bb2d1d6434b8b29ae775ad8c2e48c5391
GIT binary patch
literal 0
Hc$@<O00001

diff --git venv/Scripts/py.test.exe venv/Scripts/py.test.exe
new file mode 100644
index 0000000000000000000000000000000000000000..c058a1c7d545ac646b3dc69ea5d149ef33d77782
GIT binary patch
literal 93052
zc%1CLe|!|xxi~!gE14vl%mN7n2oNDC8r0|#Bwd0FWJ6Sf3k$nMNWcnl-BQIc16T<p
zoh)WDY_+Z4tNm)PTxzdg?Jc*JUn;oEYBnfVK*cCjqfPOwlWHt6ED$o^=Q%UG325)_
z`^Wov|9R2OoH^$?zn=4)=RD7Io^!VPuE!V?!!Ty}Q&oo9&uIUg%>Vu`0e?A@Uddrz
z&Uojl{f33_T(#7H--g2V4G-MgaQBZ3@45T_`yb#7f4H`=LAby0zWWO+?(`J?_<=QR
zZ^+KhEYiz(^8B4QoPP4E#^m3fCl56K8Qw8VTjM4Ae!cNM`j#7Cg!czse`x%O!WK3@
zLgOFR;a}C?uhI9C`|j~$dH<;GZWqHWG+3Bde)Rrb$+#}YXvi{TGE4`2{923q)%EbO
z(L@a^7&bDDg)z|d<eLc_C=yG*F#tZD%@hz}Q}5J^{#$P{Ftcex49sub-_yX|2F97e
zFpqu4Fa`g^80;UsVywEbU;h~X27c{k9^OA_*BgX=HD3->$S|vKXjpSMe>cNq7VCYV
z4u3~4hl6^ZH)vqY8#A#ygH~qZJ8<C}8a6cC17X@%=rgkf-mKxf<u$Bb_W%I?XO4yg
zTHamXft&Y_d-(tV`+xFpncUOdV+I1)*)no2V}Da}4Ty~_Be+5?n_CsEq2RzpRrRaD
zBm77wZt?-l9Py1@Ey3-de!<C*2eTnA>~xdqxtM4T7}Pwb%gM;q1NL_a19W^O3N^{q
ztk157DhJ%$Axn7TT*keaC^<AoFwBoXfKhUWgB6T&B2;CNU2JhAR8caZyer36)nW-^
z&vc)EAygT14cJxx>S8EEY8;Rnd&#{}i~Wcr#yuYKF9nFjq)=7WfYGN41H_vT><!+l
z#xTrNl8aad231vjqexoTBe@ceSffd5OnAHin?SH@H1Jo=KzJVLjKGr8Q5eO_y~M6!
z)<Q>&pCI=JEH$CV_s>2jH?qYslPmF*+zVyKVg56RfOySb63Jp1$<-%Ar3}-1v1X{g
zWNin=(AvCMQ6D)v62JPOqPL)pa<4t?ILAE^_OFLNNkWgC+=kJvo?=&DzydYa0Ps^<
z8?b8f4$Cmm8u5+k#X@(n&{cf)A)~!Nz<9B$MOszRCm*>7Dx$@=j}M>g^gj;eyGhR_
zikDEu9JOwRl2b3+4(x`6ddCPpy~+{W@ReecT)kLS-B`%(>aAIIL>m~ZH*f<W$lfmr
z333%QqNWB0b%NLLzkaSpJJ15wtLCvl7?8qODi8YnFVnH?bHjMLNo<VPb&8dF9HleI
zpm1Brm2kiQ20-FiDuu&}bPq35$VEV(m!yxPH05X)-d9Za{z@!vZ#uMSmE2xOo9mT(
z)x2EDC0@-0i~$3n2a9s6c@;>uy}^FLs^-l`fJB;LsDykP{o&jgxzk@d7rT%VfCl6h
z0F*uK)Y7{X%{`}?<aByNYANbu5Kk-+mtFPwq>7>fHE#x1(iy5Kvbh86;kDTv$ndCn
z(>2Uk#Vtj)^@0ToRgCtq|0o@qB?GG3yrZZUXKe{$m*(WPoL0!`@1bzl0bHP>&I^e%
zd~R}T5k;fK7fq8(X8~BCUp?uD#5JT32q|VRvR=e&XJIx&ncr%Oe)6G~IE^Nr)Dru&
z#C7BqEwO?o9?%jE{^_HfOst}4B`%3-o)hW<;C#$6-R<-FfaZKE4~<guY>)=QT>olX
z!X_v|1}GRah|S-H=!H%dYEXc$Dr~o^h4Zy?fjiO9BJ6o9EvAGv1fp#k_c;m!vKa6#
zmsfn|WL|v<fIKkB>W4VK{G3oF3*3&|$J7JPCy9y4{I~$?CW1{PUBL>#0~)aK9%RUt
zYgw_Kl`qEM!6B_>16KcjER#6Xk@W<_z<NCX&Wp%<ese)pLl5V3`_jcX^09(ZSoT=G
zY(6=*9)H0AHeI-Y)6Oc!jF1Dta}fMXPH)N=_2R9Je2yQ>?MuUi<H-bQkg>ijP544j
z*smw>tUX*Wr9rBX)B!<wV1h4&n#QXEW_j}$IDderxXGpSSg);KbW9emhAiTo$sX?U
zu)meI>QhM7%7Lb}8^x#*8kmFvmUN6l9RMh(9$>KHS7S47N;V^(W>;u$3X+joP!?pU
z$BxM^t5gEqy>11am(4vzrr~Q5vgAB7jAgwzYcg*R6e^a$WHD^6S?neUP04|Z1-qb+
z9YFp{QE0tU8G+UPF6VoyllCB_#@7$w>fsFlsZOI6l;ihgo|X0xfKjqzL45xZB1K}9
zpTH0Mk$TBGFBI&Bu)AGb!pK_aznrj#gDT(zW<}v8#LBJ&5M$^OtjXSABfslNY{+XH
z(R3l3w>DkK<kROmIvT!KjPf^-u^*8+i)LGg*=jtYVBaOIB8@3N=k*0xfBX{8sS?VZ
z>|y&U$63s?hUS@-(1xi+z)UqYp*{GnFM9@GDVljEJ4qUpW+n<>(2<<te+&wNF?W;R
zb95pbS83z5E}0?IbPn<7hzf*exym0-W;sZ+Xz;VY2R;<+K~#CAXYfsa1P>|LjhGCV
zJ%ew59~OnA*l<pZML>VypdPytVr7~G=25812n&)aR_}OE=r4{OPsqJ8t>8NeQt<Qu
zW+dO2D0j$|U_x$4$cKdBDM&bcJYniEg)pBl#NWhv$w3&q)WG^z4kE6P_QUE=iAben
zqVDOTPuiEq0L1I{kzcdOb4z^WOCXJ-@gf)oM>f*5U_2X*Uk@@8u#WXA2u|hWfjm^H
zvD+R7hT`}XDssexT=L;KhKVtwfzObiK+qmm9tH@(N<{&XJU)SeD4U~&Pmo`YK@o$6
zoY~|VniJ#~MmYkKQGJ<1C?u_^;sS#qSFhWTjUl@W=rXD7gr(2s^^jjt;mszwx??Vs
zk5rOD*RF1I3i3x$3OWI6ZcS8H=@Kfiz!^u8Vn_^(u9Hg0yC@R0D@Fb$1{ZQ0$d6<s
zm6ohh8W4sV`jJj9A`}DbDJ=$;#(H^~RblHLZ}B6=FicgpK6pgvtuM3jz-)9dTzL8G
zp$RZwOY<ksg~_l~TlDk2<OM9TS6i>$qz1lfq_kuOi^a7Aj2Gn#Xb$$_+6f4aGH1V#
zU*;O%M-e|{LBb`gu%zk%iKT)<vVmUtoAyd8R(22h!L@+vN>;8~C*{aherb_e&T(Y>
z$IoT>k#ct7SP%@V)(hz*el@_Q$(3e@Wm-NYj+P-)DxD=&ldv2!#P&Pa8--l4YP}IE
zF({cb3ne?vm<UqGVKbv4pvMNwg|EzI<64et>kp9aIP$yv6s5Q!xF68HE&d_`G+Kiy
z|0xJvxuNP_Qlg^N*eh<%WrVrKpK|-m4lyyeAzMt`wTTtOh1|Yg;6}Z;U_o>iMyJu}
zFz|e}+QwJZ!y0&Ny`z_pDzlJ?xP2x!`T9DBfvnnhIxHF2Q5w>g3djce`Ap1d!JHl3
zKKQ@AIMUQOz|`^Sa&<zyd;O(VD|B3o<yA1Wj8}LFI05z)<!Fu0#*pZkR8Q;2=si{L
zk*lr2BmC#Z-$0LYuISM*=+QB5pW!<_iqIZGyG~%cj`302uEWI<WmG^XT%;6{DhakE
zC3#Q)xY)Jn0k2OiM;c^=e6r|9p#F*E$?HKuQn78%Uq{*CDc&qcLHY!(XozH&BmYhW
zRpIJ@wXV$a(lj89Y!6uiW#B^g0?dv-LkD3houn^Z7?oTPxd{Qt;n9cyD}(%CMQwCH
zW1GuFcZMr*70a!I{OSAAG@+z9+8fj5_Fb3~FuTcfH(`r*{bnW#t-{2B*(;S|8rgAK
zf+a9+d0o_g;sBPbSaxExWHpMBLh-P<`Fs<wj4fXV2I~OA1`s~^a3o=o&A}#+*5nJ~
z7n34iq{(I=AC+ev?YtR^G)gx?_Ib_c*F%Oae_CY^*G0*+84S}@&LjSK3+aP4sHIpJ
z83jCa7;~ZhbM!V$ZXR3>b#EFc|Eahma^50FY>P>KDZ?}`vNFJFYLrZ|y%4m3m4Mx0
zY(-4uHjWm<Ha96NMK)$_uF~KE#AO9aaBEqHa?qYTA`O$uX@&XCtF7ubRV|J{M`=N0
zX3*?f-qpkMR<l^-`P{})dLG(HV*f69MUmA5tY(S4w1~BzYFk-kJ$D!laQx`DO!2Vc
z=C}C<kr?=!wOHXxk(e7s`s9m|zp$oH@nti8s*GO+G7z7W%;AI_!rxa!5%#Zgrv2^L
z)xp87rt{)As{LIYyw4bep_%WJZyx~YDK{(p*ht(4K`R7}O2?|uJat7hG;eSfJ}=Sd
z06dd;f%c9R3EMpD&wqv{!7RTI#MPQ4e_cFWTmyOLl+SS%mayF1<g&0I)Uo(<1J$3s
zWWh`%I){sGNY{kJ4*+#CBRg|JV7OLp2hoHd4~u|!9w+U2oV1a`dI@GUNG<uoU+v-e
z=YScHC!l&?M^yuqoHuZQJ3vB^suPa4fmi(ND4Z(S;e6aN3YVMse?hpcn%yvhR!TNP
zY+!P{7MO_R?XB|zUG@{p&wV2%j19MhDl*t|R4zA-A_uYHHylyEAjTX8wyTT)F$vWS
zh{}jDhz~K$0vnS%fg5L&Nu!ceRM}3uwHTY}Q`hH`!cydn`GCt29*T&UX3*tV?p3Vh
z3(&;_*VVwf^NoiDf$h}D?V+_jAQo#T6qK`)JhBJalMPvVEef91Eb?AlY43+@$X9D>
zQjAs4f;^2fv{$voSRc8ND<652kUPZjJh#wB)~2e0@`3GHL5XU#0dl3<0a#SViH*4o
zp9`z>7;^o{6jwer0yz^E<z*osc)nHaQ0*tqohx(YZoEposPa}%0Cb}&r)Ki$=OaS^
zoAz+OZ_GVcX|=+TN{zkpr#vfH=1Z<VB|YZqLpvbIVJ#m+MLG~)0jn#Zvz%-FJ1!F!
z9i0tEIpJs=;2wDuB7EvhRN#aJ`Qfb$bM02MVUD3OQT!=z^lKXj<i_535TG2jeGMzc
z#y*ChbO2Wr`w7QK8#Cm{IiXLEDCu$(1JUBcN)}yk9G#nta@64(*t7zWp74^cIY7>C
z@|W_Y8S7zWfNKn{L~-Y}t^uXUOTI#i$Jiwz3=cmU21j)zS`E;>J5&%hTz$b)T<~hT
zK<CC^!$qeN6k!|_93Ga8xs?`9A~wYJWN3B#QG{A#EtF%$z_QN?ws?ycV^exSxO@zS
z%Pt%09+J>qCfN8J%Y<D1x-ubOxSp2ILFs6aA+OBQ3SVPO4P-iI43odwsMMFQO?L@#
znSU9zd`OK&xx)lTizYBCG~06*Qv5uX4YYX3co(I^+}bEKbvHJ(6l**s)uJ5S$T}{f
zWE+Jd-sMt_YCwBXhZ=vAu772<Rtm$PmKs?fiJiw5)(-S9usVeYeB}0W9p&T2#30CC
z$08Rjz#u-G6!|R8WPJjcEX8tQGe~XybBneK*COax1kIJ{64Ny)(v@a1hcv+b6wq1J
z#OIRop%!(a>9V?8EvxMoruc|bj&dd1O<{gpedLolD3y2nyyV9e#RXSN)j>{|s<)g^
zA!_k{+=ZzxbFl(Q%ST|5H)x+5K$LQU1lcnIRQG-6xyl3-X#<9ki*=*9b&Vzso328W
z2L4rBr$qGmzgTwJ&^$((a#D?-l7nbG5`~r4N{t)UEX?N#GD~N*ZwT;0HUh?f#-N}#
z!iO@`4cxvtkgXnA!AKeOs>8!|>|W3i8Hk8L#0Y>EKByPV7^!-IpA8(5+cyiOeaxB1
z?Yjvxw*%~9fHmrwf4~Ts88Zp*E7Xo*fN$sma7WibapYX*`0y0hz^b|wL$rE;J;7?~
zxCkWkbatxgw`OZ3vleg&YFViR2M7o`QMSt5Xp&Z$0|t+m{P8wA0bu!ZM7bRoad3RF
zDC6dYz!ons$ETtmm@ePR%ALg@Nwt0bhfUCzlSopzl$69XlOku*`YUcWHvz33cO2Vb
zlY5(fkSQ4E&vTq?_!jcu%ooPX(Kwm|TTX2Ln)F$d?TkMH51?EF*YYy0-3(Y`uUgg@
ze~t?J30X)KM@)w!7cEdzsNfl_6ZAdVL~AX9S|17+kyRwfnJUfn=^79U<pr=Zv8E0s
zqiI&AU{YPI6NH<y=N4FTi$`%{4$2?@yGmzX4_N?R$}B2I0?lo*$#+`&BP`FJi{OID
zo8$%gv|_B)%wv%t9srw@U416kKphJ5Fr|;-l>VWW&Qli)^AtulkC;*&Ccn+11EWks
z>dyj|x(1ar{J0L+zVFdMYpnWQara*)B+8Z6=S9IrOVkR-a_<$pz7`v82C332<ao&k
zz^4o#pRKhqHC{4t8WdS+t!W8A#EM-50Hch4-oTH1p5=31z-|iZvC4czfyT1DWMCHM
z@ofvx%!jtHgvvb;3C&gOC<p7s?rzAsqPw}N7Lk3KTC;AI1slw@OmWb_Tf{-5@G<TG
zw|f7*I$NEjtIXfUf+tJI!tLLtuppK<%|x9^E?om6HF6DQlMfW88_G&oLIi&=8N8ig
zc9Dr7VdvkDdhSCRr1dro2zO|ipiOhBg6+Vv7eiW&oKU8@NhJmyv5n*8w0d#&=5k?#
z53S^cPZA8ziS1??bbH|huKXZ3q=hOr8<jpli;aOAS3=hV>0}>h%{90d4QLF05Se#7
zaHOv?l2YO?AOvfb!b`URp8&RClu7`hf{lXmAHZOcEEOfAPRA$w2OjbQG$OR#5HNbl
zs9p_Y>2}o-1NQY~Mp6tTp$ruN0GG;mkJn9ZDc0skOt=bbiD4~LV+zrubVPp%xuQP&
zN1kVC4+^GTX8G`m@2Y_0TylNJko*IXSuv%eztSr5v%F-_R2-HBnRy4i$-bGmdscrt
z)sN{^dskIP%9RCZqI8qdUqct_3t-i%w=$^rQPL_w9Oh?e>kL|eSZXY!1olTZRkN4X
z2rL__cJkS@2<Sx-_QFg4^Y2LlBeT`Zrx&i*%KI{kqv!rUjHG&iT8yBbtuLffJ2@~h
zsoowLkK#KtF4ynI#y!lUkWp6pED)iP<@E*(poy)6#b|%^UAS^taKDzf;K<J0IUB;w
z`!NRh--Ry^WYN{FH6LPx)8c*}-Z>lJvmYtjO&GKQMx^R)a#t25RyI&TP+qSgYQ7#}
zBMWK7y>}w*43L`&DSfkn@gzC{+NtLGp(VSXM(y&YMKBAxaTa`0twXWo8H6IM@6aPM
z$PSDM7|1=?O&~i^b{@j0oj8|vt%iqNEnSMre5o6rWKxelSG&rDZXwN03;<20!9%%0
zcJ;`toFP@8b}uG>z^MfIT}x!wX#f`+yBUQ4q5uUhfY*mac6E_;=`e2O6KHV!3Eb>c
zsbzc`D1^HblYsSS_u(_I7oQV)@L5XmS>6rL`W<<;LVRVL>1#q4jkKJmuc@8%b^ZJB
zdiqfd3m~$K*)=c;-{xHme1k->%Zl;TNE)+LL7D;n+lh(01^|OGOD{Y#%uG0D>6<v0
zx<F7RPzrWJmYuCMh?Z0}Zwn596N&(&{>LIjE~Dmc#!Z`-K665l$33=k1c22RU_^xR
zW7*mU9ca$$;WecE?949)ZS#Z&1s7PerDc86vV^p(S23YoTbxtKqxD%#+|8GWi3Wa(
znApURA=@pf$#SiQ3N&{EgMZZkI90Okr^M<3gOc%Th5={VfKiiX>__JMK)B&rPC|6(
zp>40A=RxoY*HU0WStu+fJlvzdMBROxND8@@eq4P>7Qdv5pD&Vp{(6yQ@>hXU&INZG
za6wIQK{VaPTnWUO__i$`g?HAc@z+oQh&s98?`XV}8t`JSUIdFjMH7u&@G;7q2E@M%
z!m=g4ZOn>6|Kn(D6&n+bz^BSBRPGnaQvNQH<nXR4zymZYPb6tva4Z0vi!xzAwkzvn
zWdSNaf}?rufciQNwW|;FD>u>DsTs=#k};F?JR_RlMhl9<?Wg)!CvUbNQH)ugDd~?3
zo~G(cFT=Gwi{|FSRob|e&EXRPlh^+;3_1xf)t3)0h})TBd)g2Xj9|GSq_SB2uR#tk
z`Ljaj8O(YRH8Y_Zuuv;=1FXM;CLbD}Y{O(Dqf8E@`%ly4e@i8g7u$0%*}x2=7rTm;
zjU;!QQbb}#!YJ@JQLBY5<igEBSoqF(=x(ZR%Ps_cO|^8P*8-?<RaUv$Ds47Pv!u<e
zw7Ed4vQb?)VDqm>PPy2GIu5n=1D!uN8LiZ{1Gp%5IjB933%!LC32k8^^X{^Ieg&FE
zP`;^p0nskZ4OLze6ShqwLzOl+*?ASU8gea<Cv&MYc6-UC9^8_l-?DjkzZ2FXtJ_PK
z{tcrmm7mKAXn=B0U>2!D#wKS|JD>T#L6=(Of0omWf~=a^s)_0qG)@==6_6hjC`dC7
z7VK8WrvTBEre&SI8)}eNSsfSo(arZ#n;Xd5(kfP(B&{kC@3g7O<tGa%I!3m@RE)|L
zEqe-6%PdHiyK;fY>c$9-0S>b@$+fTwUsU;Y4_S0Os(a5NzhVLlLv+6=0ITgMH^RiF
zY)s=!p<u}+jbBslBn7+RQwp8N=M$ayeCB<8?m33fgGX^2ZO0P{`U>^X*E1dT6?}uf
zo(t30?_Pt~(~kywFCharhpNp|2shtiv_52>QjlQUZ39xM8v{ToA#9giZG#xvmYx*9
z3@~y+W0E1-Y`4ZHfqZR2kP-Dx*HAgFdSI3PofYKiziI{|Sbq<V0p{rq7|EN|d<|Ou
za7J3EE99lQ)FR!gxg3~k)vhbG``<%zj@rX+{6}J%#-17(`w@rvoyTA-_)&Ak^Vc_g
z6RP@~cz(pDoIv(+7%=lYkB`KWvs9oDPEL)Z19Y~C7-nmuWE)3U@3j4iQFECn#6`)v
zWYmBbWz_{O^0`V)T#F@^{FKUmz2r4`OC=y49mRkC!cr%*MlD6J2)UxjCao*7h2XEa
z%j5M?V!6pRV1LssttFu80Qb~MPjV$fuHH4fFke)z?p-5gW3Xlwn%w?cyI3pz=uv&u
z$)`pzc>`-N#WH<zTDwbSboLl}*oLNqY<ZE{^se1Hi*Vi0>P1$$lGVP|zaUw#{Z4be
z#)4tgL(7Qd8IV`N8b+k*9`WKJzbbSaO#Bt{!tJ@CitRSZ)r*2_B6x()l|Lj{6;x^n
zhBrI6Es$Laxf5y?{?yc{GJKJoc6k$a{6%Ymmp0)CWD9LVpVqr58r0|xA>g*T?4Auj
z?h>vQ%b!F&f-m&ro1DE9IUU;9IC&W?%uCcfj2GVkoze<1<Z%Nvs+TRd@+18kQr?q0
z$iHaOa&-b3;uWpx|NQb+o%x(@O376$bnrUJiH;>|na9et+zA1_*tf}CNQ#d|dPH}Q
zrA0Ov>RfqYQU0<e?!}A!&RbG6ko3E$C}P)0Q+28+k(aXoJ>5Q5UT+l#2YCmSF+;pC
z$eSI1-*`i4#>UXfKicFhXtDUPnGufq4cLqMEII6Em;*S*`0+k`D7)7@ib6A5NdcKr
zDAs&#t~m{2_9Gl`hx%CPkiCPj(7R=_KVMyMRoC0l20TZ%zfu_JhGg82R{rQRD2A1<
zRUa%+AIw)DoJR6=z{6%{nb+r$zr;O%`w4r$T~&{-po-R)@;7n>IOZfbiZhUU1kzRY
z3~p3;eF0{P|I97uiL&U|3<E7i_oQ`2?2^UkcSH6J>gBV*Z2Y*GqgeJBdNQFO%M+1Z
zxM3wnQrjCqgyVH1xx;1Mz>!jv4fV~a+9>z?YM371fJS7fw1>sPu1%x70e1Md7fkP)
z#d6&7V)z0tS(U48d7Yr9DLyS(l#&f|11d|4888Amdi`$zMf_wCqxdl*$>yz9yvZJp
z?nkG^=>C!PX=d>`0>i)peR3}yKy)=M@VQCnwOBH@uS1SVTg}o|R@!Qfd}hmvgtppV
zeDTEtOfJ&36@ZKX^g3p2%QdvxoOcT6Lfa=8(2<YEu@JXNIJc@UxgHf*E?bX$p&+?{
z%zC3)&3hcWOm`=6fgYe;Yi*%khfYVVp|36Y6@az}F`}>~%$J0o`5Gd)y&c?MlcQtP
z=;Dae9eO+)(*uP|NZz$nVrrXj5TnMHuy7KFYa=>mLMEus4Rs@^8$H>`{KY6}cpx5P
zVX^V0l6{cLL;C5|uFwGnh6DJi*#m)&Q=lTm+YT32(;qSLIZX@GCfM3`Sg=@SM1RD{
z=V4SKMnOTXJJJwgN_y+lG=P15U0I@`F&6BGV*X7<H=1i{SbhSZp_Uv>HXRGyRVZE@
zyD772Va^0wXmO#EEnXPA$%>zap~YRTHpSG=FmoO6Hnb;~z2`o`We*MBC}Dkl9%PEA
zP~lJPq&w{k*7Fm@ZR;3*jJ(MY#K{H<$$z37lH5+xq3UQLn-rkC0BXko0$Qr0ly2A0
z4EFQmVC8&TBVDd}5UGSu_mUrfit-NvNelckg@$YZ`Xqo}rdR(=7P_H=&&Q-h8c<(6
zFfzD#^DGo2O(=l*0Srl)7_(pyIf$C~8z^X2?Evr6cX5>2;@~A=<ZzH@0Yo_^4h{$-
zk$*bPLy5{8m^U332yylLOLBW^Z@s7RGU3Te%@|~jO1+o*CA7*2IdYV|Lfv!XsIoxE
z?BTNgCD2E%<>y$lt6L10l=nig;frRKTmnU?g$KxHHBQ5Rsv5;W*m#~|j%)Fv^5h~w
zdvsD@)GZK2XJ}}Cf!9rDT@CblVjhZR51XY8*0N=U+m3Ulsqrf)@;zK)g|FLkT0r$e
zw{>oBCCro~@fVoOiuq<LF09>9%#V(gfKVO!Z>KgkN^x7I0VdhC+}=6d-mn5F>uPJ7
z4vB1qV*-?BSl~!({1TmJ+l@_g7~vQUoC+#>J1aJJnW2P+xEzDF#pY9wb#mWDn3ZYL
zd~0aFEhNo=g6^u9Z>pC{#E4N08*dlBk<XG30Vw`5?#V4QO)xthk&XRW{8p9Wg6ND9
znm_TtAa;^vowo_+<@shZ0<u7<l804H637}F&(c`c!^o<X|0pZPapr<ck%4!pI1lQm
z{CA2@gk1k_oCs(7A+@?oB|Fk^GDwZ53CfZ3DnE=lc@TwL7wedB=30C>6ooM9$qz>0
zyyy&`;#w*p@&IaPFeT)RXP*<NP{&E~GIcMLTwSQS4N%vN)9OZlYL<+UEB)o#JaH4(
zX*4y}`8{$u&J6X#{>t^B#D0m|tOaMMfeZc_Rm5!aR9<ol&NuIxjtkFxc2@~~TX)TX
zw>>NY;Uz4Mwt9Ktd|SO_brnLiQz0~^9EqSYyKP~9L2GN_XiSJ}2{<Dffnnt%hiPq{
zHU`tqsC3q*nmvln=2XLXoWh1rz&MZkVRA+racY%7V@Ki26;-B+2~{X;zNqE$5HIE;
zlfK1O5j9A~EUxWh(3<mWh>MElJ5ah3Mg}esFWR_c7K|{^l|gqe@yex$DcsBOsVC(}
zb~Dr~$>he5{lh<A9{v#?`UtIZ$6PE5Bh3#diU7xahHTQ)#D@nMJ`*sU{EphxYF2;(
z-UoOK774LbQlQPjX5fyih@0)uG(^__XUzh!6;A*p@g%VFcC?wGuR)Z5pqvF2ocGJy
zv1t%dSC%i_C2!xaeT{*yQEsy5BN)cLn2XFq8&i$E{pHI59v=eOUyT6jUM!Dn8H#`K
zBb)&8_OO<*0x~+~?Qg)>^*EK?#0>!Qb~N(5j&_;in46T-sAKxqjkGY#Pl`UG-bM0u
z>}dHkM9cWHC$UY~nnR%7se3VrT<oM?om*2#+@>LMgq#kI$bv=y)t*G4vQ-28NO^&I
zDEf7b7Go5rF)!JTpO=j>I*B<nACDPcxx{gfpXQThkpND0SOdp<$ycZ{&tYnC5qxZ%
zwg_&ZE()<a^kH5_E!D@6@7(`)m?`;2+-B1j;L7zNxow37xPTZidi^?m6)s}6Rk-=@
zxC&dzzl_jXfLe;abYlBDFR4*AcGG>?96SWjkD?znFzF~ttt~*9Q8n)+cu{9LuUfi(
zJWlW3Nmu^yYU%8hwk!9h0A9w=_PXfKby#IW<wv{K(ux$MdQ8m56m{o%Jv|53wf$(Y
z%%%mzcY`buVEw(=_l9pkVVV6`v}wME<qB-9a^<rL0Ip|26kQ-~&6T#UZ{LmwuI9II
zzXPWJ{8*(Q`3G>7f3YR|kNkAFC@}|lq*ZfEml_AqVY+f1TEBN9q9CkpTt{9-pOj>d
zJS3WF(3~h#3+;g7>rm)HJTK!kVFdlE(Opt4#U9ED@&;x-M$xs%p9`1<)nZ*1-7rNu
z_<>i0R7;)1@Pi)S0me%bgVggr?+wJwBC{%`DH&ce|0KlP`=O>V#N*iute9*=iKCa&
zfsGWTQ97uL0vhuTfX3opNTu5xEqIJft}KE|fROt?K#HrJu6+^hYlimqvGz4v`#P$9
zIkm4t+E<14wOjkD(!Ty(`&wC!!-Nq(#|S_d%Ow}2t$y@(@eLCMRgL3=<n+NXocpv<
zdKaC}A&#nyTh~F}DL(Q$^n-AeQy<aXW|ht%t9UCTKq1!+AGnDOZWLLuT;l&)Rgs+O
z@cmmh9W@AB$uG6A>KjgM=u?<MW?VwaZB-Pwbq8A5H~*EgZ2vlZ@0x`JchbL_e$3WB
zmeUV9q$kC4gka=SoEE!q8t|jV^4Zi+FIy~k(g1q(745{CMT^*pvms`|j2-iwj6|tp
zmo|lPLhjOM4%ZSv>5)!DVCN_VQr`L;+E+_4yIhL%SUsu1=#AB=O>e9=HTA~QI>;Hi
zGsNE`mm@v;r3$BBn);!7Y*%ttS0w5AX*NaAC709lhm@AbBP~xKxRRFftVTMO=j`FS
zRT}4{ZW>}wF1luLEsxMO5|7JO_mKAYkb-;UMY;A<j<<z8V6LI6*XzaeV>g-WH3wAX
z4(ittFi_8qi6~nQ{uvo=7@a(7`04V`j#5F_Y)}eA%LbMN454N068B>AagOdqhJd^o
zT|H*iCeY!l4^@S_q_pqPKa(U5=vbbgJwq*k9on}AkHH+PP5S1rqyt$kMrsFV0xYpu
zDaT;Rlq{WNkVjEv>-Cby@hlfv{-p|WAK!`LH|g`0YJBdhrY)=++A9UEo<rNEoCAuz
zQ9UlUn;n9+p(p99DV9G*El*?p_$CjPQ_}#SN!x=_HRLrnh^gy7gE3x;8wfk;$^d09
z_4@q2EfCWJ0Q(n0+95YQYUG5YeFG<_Lor5R<1w>iu;ClA{Bf*jRUJRxk0HY8HCY1;
z^`FSYSTtt@3jI!GM!!}-&}Yf{Or0G7C6rmVpa9;2ejK|tL$J+d`*(C^6&tM}mp@C%
zycNyhrIbgWlsl!`W5H9rUoCAx8~sU?$KRJ~PfLxR;@4&fJ1#cdL2d@!wJe?g8+^=B
zZ^3M25=2Sq>U&yw7?mudtoF2EDRXu5Iap5ZG0D|QOO<PnDKExc-Rl7d&5hk#;I(0d
z?CO>o9TBc>vvMZp>T03@T`f95*APG#1<?3WA>CTCF~YSm+H2%$fQ}IvxU~vYa}Xs1
zNat}Y^&+n5QL-DzBI$Lgd9VF`aJbVU#M1MWPbFi~WD#J9q<!Nj+Aw~if6_c8t~rmA
zo6$t8?L$-RG)=XK<!aVpeRKC$z{E41Vq$c|SM=O~`OTNVat>`DAXC1~RTb1<FFBy;
zzo%-XgJ!7Hagl3Thf~u;#xABlWCpG!U5j8BYc?xjhUg3p316W!Hi()K*D@0|sh+Qa
zL~~6j{sF#xq$4x6(}mKgACCha`U50+J@va@DVnPvK6>?{ks81!`Co$qJYMoxG9PbE
zTHp%_&bODZVHhX0YWBwKyyQRNBV=|Vdz3qh{}eDCKkt7T3Ml@_<0hdy^{p!5p#LR^
zJcP~i`UrEUUbOI>x(B-qaXpKYaX<Il3Jr{ZHDvIS`>M4AB6S}87k>zC`F(2MEGk7g
z&hnMwpvup+huf?RT6b93K|FL+uz+Ws<!G#KAf8YVD{zN`nC5P+y-2oHp(~9Z;Z^gF
zYNv!XCHBLkREaf_U*D;rp3j4ipWmsWeUgrLVYDAHPNojx!DI}Lr{c%ZuF><;QoBZK
zDSo8(IXKGrk|*$LqeJIQdKP*^u9tyDcH#z%Gf-IPCF_i+2H1}{A_9wkWE^~l9%F#e
zcTpFtQXZa;!y9IbVT)LGQLT?TRVGuaGC^PxliBXP3O?+uRX56|)J-hx47o2hw_^d0
zlMU~9eD!73XSkLeYBDE|2-jl5V7?eO1BIHRhY%9a3xBf3D1TBm0jq2L(d#Yn!WNRF
z2K~g<V$p(Wg`rlOBi#|%aFgC9akYtQT0N;rTy1Bx_QA6-6B>6TBXiIs)1RPGj^hm{
zfJ<ssZ25O3O{O8c8a%bN0rwi{Lb?*I`92t~whXieR`*9(Aq!CUzJ}a#`J8xWk{pX9
zERi#5rWxAF0L(0<$*zGmrnS;ccNjyJ*3`}-*MgdrTFHv8gn5DL8gN|P@-zD>`79Pe
z(T1A{DxZaQr!_4yHz^OcSDKrHrvyu&f4Pzwny;cqpcwwvt&?U#R8@W+$X;`NskYgt
zBBe-k#Dr16Qk+VLm@o-u2(sU46F(i=qhumjEDbr~eDR`*+u?_hO2=HyJ4O%vu3Axd
zB#MqV{n}#Zv-cyL`qMkeQ))mayQa*t8|ZK2Bp~%J+|S!iU=}*GND~@xdeM&Xmgex2
zDkSBw-AJ$`oSOf1S<x%X(o1Svh?bxlY}E8JmzDn~ON)G`wB+{S8Csy$G$_&b&z5*l
zcW$!zSK|`v=mxP0J%2$y`?*Qm6AzeHNsV2Oa@-VeTq>WV+sb7HyLne~N1Jn#Pd-M?
z7AV7nMoBey%e2cku1_cTqjA%E|B+#v)(e!KS31^R_zS9`1~Su_vekNY_d>a&=`)l4
zRMUB*;Cun?e|(u-$@=6u#UONVo$hmc$!Qz)54_cr^ey8cUrYEQPVBmb?uF^-sV%;(
zu7ZqWy&0xMog7W-;QBc_(3fxnt46ueOSY&~7UZcn=A?6#R&+e!b3yI4p^@Q5sHf&!
zXU+I9s^4|g7pn<z`Ss_3OY|?08c#!K<{34W@iG?!akz`YEWS==C_=r^jp$KiqxKW?
zq-6t1T*_6}{)oumShkE6M!3oCs*d!DfOKVSStBdt;w}J;$BlZDV9IcTY%@TB6ET%a
ziyegFt|9k?qqLG}asWnB5rZ|rAn+#Hb(*aITpNj(7%G1ns5hjhvD*7z-w(7T&i?kb
z@wg652${d#k2>%yI)l{`F_xd2!d6(EinhE5Tz*wuR4k%^xWDv`ta{`LNF3fn7zYCh
zoMM!?)okFied>EYvLgnf$JMa@w6o2Fodv)TPgBTM=;z31Af#Y&tM3h^pQ#%<E2GYM
zb3ZjMXy<(bR{!%jG)q6jp;>?@Jx`TQz-=)hpNs?nFEEjwan%;Gb$!&nB(R|ww83Q)
zd9xf-ejLar{|6OC5Nj_A968W6wD+dC1DRwwqfMN$i9#{Og)fN*VT_Nw+KvikODYpg
zHYH1%qk#JPZ2K_vGdUUl)`dfmNv>5>9)WlWGNkoPoI~wXQ#2X{m2?F0p--+l^YRl|
zVo#yRXFnB4w})#&K$5jxXJ0I<&4q4X_%vxGCC_|H&De43+SF)6pDxEmeyroHkVoDd
z0^6v8DL<lTFeF#EBeBT@xKxFLkP96bVy>QfxQqz7l0e)*?&>m@9%ao1F{RWI-7;CN
z?%tdZl5T6hG6M3rJtUj1?nulQ*_Eqsc&MPeb>$qDdnPOrW8KiH#Kv3(+B1KsJ!d|l
z?Wv7=<XRgQBw;zS!7R3w307gGJskf}w0`!3UWNuX!A8<jnW?uo>4y@a^_tIx<Ko8a
z<XQ7QUjMIu3%blfD*NW+?*0Pu4pud5vQR^!5RzsoZaLql13s<+wpYwi8H64S!ni7o
zAy4Ufrjkc7PrgzR3_mo!J&gj{$WK1Ow%{=mGC}LekVOz0bj6XN^I9dtxRr0HV|nCy
zC_!`JJq{YI+)h^udfdQ*hr2$NPZl4;BfWT%Fl?*`4bXI_@D(1a7T(8$Sbu|Dfywmb
zlk%EQYaq04&B8;;WE?{cu@q76RGZYi?xC}H=yYw}I1+RKJTky%IK_z3;j%V-Lp?+m
zhZYvG#U0{joGCK?NLHjK{^bgWNyVloW8a5Z?W_dSpqFIOTU)H?C;t3T0i~6HMx5ac
zp}ZVO_C{C=o_F%ur1;NCbSi)G*iSug;73b!=I3piSwLRIid}<J4y*%E82Y7m7$FQ0
zFkfH5b4<c?auZBLShXCzyp>F)VW*>4$i`D$6Kgf;H{DC#T8VtW(u#|ak85e7<}p^D
z6RI*uIr5_X;>2yzBD3S-)(Jj(Anf-GlLs4=YO$jbYQ;J9kX&sQ&*RCM^LR2QB6dxZ
zk4G+8=z*6fE<5mIF646qMvrGPSqtcyau^Tx!gQGmwYF8Wt*kN{Seg${pkQ^*RCQ&I
z1HdOWJSliWfC^t!So&XB!>6ZGbL^+5G}iFiWvrn9SVKP9KLoZy2SX<~oeKa901nWM
z(%P*XGe8}tCxz2O=39Ytq*w+JxqCR5@B){Zhg>3)atYPdm1Gp%blVGi{ykhImP({t
z#74PDy;QMv@E@>|fsa#d|F@6-H#YKLSFn-SQ<>v3)q+3%UN-Wh1Hc`AKEy_DBildL
zSVAq?@-by2ODP+nfc`<;lE-^Wq=j1thcgnlp6eP?`7vcA6M>OTz*{hKG*)us$0=5F
z;-f2Ai7wdWk<6hU{|<oS7bxLcpBK57uNj;~T<{Bg8$rmYWJ(Xoh#h!*Lz^KW9KBP6
z!jT0?PfAla=Bpc7FIkgL<*s|vG{VEvfLsgWg<2eciaU*!)}IQCz2pb!`gyPtFS$Vr
z5AsEz{$B+jps#pCv#GX1M!+}Bh#H&?={2kLsnF&$7yWehPla?ma$E>H|5kcFM99N#
zTz+f>Bs4ikU1a9=8s<tlN-ot+x@=<DmI3n*gg?O1&=Of7FQWq=7+fy7dZcCDFzv^a
zo=!kzAw!OLrkD;;c%y}3Jb3fR7S=(vkcLU*a3>B6c|HY5?&#F!!y*gb#Q<IN;h7<=
zcXB!?Rc#AP%%Hsqxg@A%{!uEk;%`QOl5Lw7Nws~B_qdicC<MeiE_ez0S5|A~OWP_+
zij3i7iB{JjcPLyHFxT*7tArf+@VR5i_{7f#rDZm`)+*KZDnHR;g|TG3R+FJKMF_w7
zP*s(g^5Nq|s<t^I4JOHj$6CqDe}_e+6J(iQm<kigyB{Wn7V;qtvN|&EH>3G9X=0k|
zh0bzPMb0#w&P#Kq%be*?{d3J#a+Lo`+ijMn^O<}DwN$NBt8Gn<gG_6d%!TF~bPvAv
ziX2NO@0Pi?g*j6Z*hPVFZDnQ7spUXWqXs%PQ<zFYuSU>u6f`#p3ScG;?CQ(_6RIYQ
zp<8Y_U7eAp<`G@x-E2Zv1rj{Mwf-1&q-q=Y$Qq1GH&pk9D$>mTOcU4AZ9o@@K_l0K
z_G?%<Gn*Wlf~AQyE2gHxi*ju*9=nQ4wZOsp9G#qaoT09TZHC$7xR&3;$Lwt0+G?6V
z7jPW^IhF4EsvI2~@<VeCcq9zZ*+EjfDN_*u|H_Y5mn}e@HSk=adU>mbOl`*qLVz6t
z*pbuwp{Z4TZd0S0$scGpWy|Sp)oSa)G>bCTQQHfOHYPj^<D_cmKA)nF-!>X;2Kf2V
zAiU?{r<Fi<N}imq_1%e`G%A)h12kTa7Q1?J0HBjx@ED`HRN*e#9c@`HM>eO;k8h`v
zu#?++MB&7QdD|$cydmcfZf};e=|EQj+LlS%C~ogt+#v}+gGYpH!heADgh#}cpUic1
z2xe2K;*`1mikqNIQ|GrXy~!dbj9W6=M#)_3(wwRD(O!`Jx_W+br!w+f=Tia061+H!
zyiRpL8;H-vwY|p)E{Gmg=nXK#ZtlT@zF}cT@}82hxX&Y2_n-$P2rRh&G~!hh@?AZ^
zow%S(%|d-~QG3f{>_;3??um#g3<XIGN0%t=KoeQ@;{Qw()Rhr%j3?@WEIz^sbUvFO
zQ7>iTEgfMajC_0#rJO!7GU$kGn20y#h-H~VHZ?@q0-5ymClXN$=62bPI+Yml!nJ=y
zB`YYEEK5?!w0f~Ik;(rdkiEQKG9jfTkWw&k9s*P4^!AFht234BkaE&B;2<TPK}2xf
z5{h6gK0_-6+Mgt#aY#U8VNUZo=KeG!pd6!;Q7<zZ7z_%qwD>Pj&!O!LSn3?@u)^K{
zUW#*Wd=DLq;{jYY6F=sHcVS>{4-;QGNVnBcd<oe69jML)agPUY0~rK%UH+cNt|z}Y
zoL%olN<Foibx=!M!#FZp2fKJ8RpqZCsGN|az^0Qd`mA=CR8Hp(Rg{>;E(71L9Xxm0
z#)qA-n!bBNE9T`BDOZzy9`f#*<c?)Jp3OAyx&-ebzc`;fO{k0^+lK0XL@NgmmL(NH
ztF8d{oIo3XE$bm;)(&^ar^n7_r|Ko29@pg;*=ZYE^mAd+$I}sa)64Qkk*pI*4dM64
zQA1FwD90QPGETz?FKs4E`fkun&9T&>cN8k{tR=#}3a}e;NaXmCuJDJz=;gSME-kX6
z4{q=Tf1f?vR#C*ZgoV+~7f?8E$PvremC|cQ;yLvoGt1}23+9HK&V3|)X5y{I$6M3I
zm_dvignqdr(#4u0__D$4E%9?xByQx>&b|l*XKHX?A{<n(3NP_656L)Qf@fabgkP*%
zW4DmIU(w}xiU^J@ekCc>uLeG)9U0MYF%TAcd@%Oxb)Z?_%Djs5gHY%pFDdARl#bp>
zp-K?KC6s%XOO^Q`<tW+mt?0!%N2<#QJpyDBqjvLxbA@gY8oDy+8kC#Sf@H%DHjsDz
zrmD^LR`n}9ZJ3YOAEJ9g4dm&cYjyHz;zN+BNWIOxIZGbVYE%vAFlU9OezBXJ{<|*f
z3Z{&-sG64CSZOj|aW2EE?fUuTMx??}=r_a8RG=^|1z)DmUi$2yPePwZ>GL)E#1j_e
zp}p`p@-BWq4&Ojp#pIQDQxsSW!KQ<|AqAa?f-m8Q)avz@aQ@wrMa4g-Q0FBM6w+VW
ztnUZwcLLyb0CI0+&_eG7*h4iRqx=@V5a9m|zYqX#12}IPb|HXKK8&{kaKQ(uGppkx
zuH{|`wT;q`l7#3{lF)v5wm$JSJX=n1EkDa-nECd8=@~pSQnm*Hxg8HdWN2R3?B$y{
z?$BZGP*Z-d6XZ`0$B{eK5}5^`f%HhiTq6Z{;5A|q?vX;sqZS3Ht_R2vq787{N-<3F
zwuj<#55?pjis3zo$#@)QJ=7tRLjHD<nE06@Vfm?5Rd_PY#0B5NL#82wXXA%bVRQTs
zsjwmbTL?GPFix-dzowFmaT&r*7p@bgi!rk{$nv%U=^(bnG02714V8F~o}h`}g>JfZ
z?0*!_<PN<Rs$h?4v=F})PXh13p2cVA#a?}Ru|zL6j}}XD5YM0mk}C?NrF_L=DYx;<
znlAYHilz(e`23~|o4DXfHrXGPE8{T)bF33a&(|Yi&S=9Ge~C@D-xhy16)ucF4&gS_
z?3u#EriTqPgnU?P^t?@}yz2pGww*%UtU)}75O_<F4zUO!)^IJA_`Z*8nS<{KxR#mt
z7Pyuh@V%L9xf<Wgxt58z$+HLP;VL?|p&-sMH@EjNh!AdSFK7!Q-PQ1u<q*!h5T!Sg
zKLAu}ny*#cf=(Fd6*?TEAH7x&rE8>;Si?QK7ae+AmK#y2@^Fv70t3%46v<rP2BcF2
ze{5A17km*Eg{H%Wv0y7b@5C?~-N(I<?;M@yCD3Lrh_`AF!}z1j@MIx#C`qQHDxOyb
z3%!;F#$N-pVc&-+0S|C-ErVvf9Y)C7**yVIo?@g-pE1fs=rPKpW;~q<*qaQ3Hne+N
zafEBZ-eLO{NR(-*-%}A^!tGlyp!vq@7c+)}IK|!M<lXvlZhlgXvMuU?J*sWNKx<Gt
z0M@BTY8kb*#kXK}=_#6q><+og4AR^Tt!~5s_c|km5Sq_@3NI%d)|FczyEgLi>3DT>
zSE|=;GQJqbKc0u3O|0i0EjQxuO{K%PmfK;X@%M5++efwJ`}i$l;(q=HG4TNC;DDEY
zT78p-3a#;|aq;W)k%4lQ)nX7+%`$z->j#K$p(d375RVDa5(;^1y&Ob}LL(rn1*Nnh
z9L48YQW&R2JGI&}Q3Rn8=OQ?VxRx&M_6?s|jInX6@rqm_ddVfdutIu<p5_ZaOZh93
zPop(P82~y>Dgj|c(}jD5d$cGzPQEf4-kPTIiDt@I@JQI!a+wy;++K@UhmeWgFmEVD
z10UY6jhIb8J-7$!lRK46tzgU!&85yC&|)drgvkpAq+rX?OjRkvhAF1fYBVZ<*k>sS
z=J2@H($<O8?dh0&5W6bAQPBJa@?Cy{NE^xsxq5LPwe)cvwx*`(Ahz>fAwQ@N2Y74<
zz;V4WLLX0bLe%i)iAU&=6Me{~5U$b6bt2iowcHPE0;WmJaukViwRqK#9ETWP%dcTl
zw4;rqjrv5~4Df9fz`VFUh({|+T7w_ZT(~}=J{`{)q+@ME_K-VBCt!c1kk8kU(jNh#
zgnNC#fMUi;_>?jVaEXzor(lgdF$6R&cw*b=E#_c&gY8`BsFUYD9_pb!ryheQUywTm
zqx}l<ptLYfq+I!&cK69;bRkExVnW(gbV&^fXSGE}r3@+<-j;^R{Pi;J_ESsTJ`ec<
zFL{WRNY7}bAzu*Bmu*cmQH-|cEK&}JTxW~hEA@6E>C(*79y;BBh|Y=fpPI@_c%Mo+
zfJ~q5h7zZ8>uvQApAKppD6waYDG44=DAOqS>$-ybDe1R0%>wDy39#R4uv$&xL7azx
za6Gf7O*h10DU1VdaAs&@b-gkUxB2z2V#SI(eIvB5LTv=8pCethi)q2dx&-$uEzv4W
zl@rQ@;S0>}!aK<?zQq>cm&%)i>b6f+idy*~N_g@!6qr^5Y?dxczq}<$U2IJae}fh@
zL*WOp9%ZanwEXt&k~>N16@~vrJcx{v(Z+`tg5j+X%6l|aJb8)UT&#vL;0~nGi^zkI
z;fL66B<EM?%w3pSMq~LK)IE<~*;1N^HnV3Yz#qi2Ko1apt4tB8IH)S)v<xu8yJ+7i
z^dWi=p4L=m%guVH_-pk}eFtkR`>w#6cn~=e!;ez;V1T^;p8)V2jjNIA3g2dGrD8x!
zm>(sFcF>mNd}%utZ}|3m1!s*>ryO!BUqFYP$6mkJ$sAhiWWIvGh4oJ6N%-3Ze{uL5
z>vuB4RH09nX@*w8Mn=6cOdVFLeGo_e8r*7LPtr{T_i|7jM|l@FZQaE523kcR!+2`F
z)bE$nl;RNHbyRpM<v>7C6~7Q2ri%X|swv0+8Xc~RKYpbuF6&_HQ($CN^q*11J*0lw
zKT@>&2Zt%zqlZeK82yKewirz++W)oevO{8Wtu1&;NVkXMX$HDM&Isek;lnAtXDtM^
zt6tAAc*zXj;RO)S4nfRMLEs$|zSpS@;nR(IWXllDBnVO&Our-6`hs>G*NHTLyS$7o
zKFRGf-+aZbsvV&JbkHj{uDDgT-FOGysd@zORPEs3<n|ro_C<;hE4O&Ocznojpxz7N
z<+=x}P(XSk+LeV`dxj3J#T1(u9>kQPJ7Vjuyd;(j{+vnS=C_eluWpMZd)`8=T6jO~
zr-v}2Ot5XtB@YjQPK;24#3~@&|5q-MoqqWRvh=QFR@(*zhU{XGC#q7nXyO?gykrKQ
zVFu(hJlNuv%h7I#S6#Y29`!?X1&i`?14cJFeo8wVF#r)Is*rF8RCOl8z%05h1X{S8
zJg{7|M{LfccQiSo!e0G$M(VLtRy)A=<1ZsT{aYwXQDhYwfVV{X?5Jjs!-?|@AgNwV
zl=FrKUQ&iT{vp0HdC}V$Pr$suM;4r-7W*1$0=-J=lt8^!)@o%brCwrye0ZxzO=z=$
zpBymyNUqj+JOVV=>vNNT|15bu$8BQN9GbBeuaFboRA~`p;5kU0ia|!4!o)01sdG~`
zD^}G-ReFULIZ2@~NZCzy(rq$+i28|o)x19Hwg~F_H)xfqi`JLr@HTp@C@UoNcdw_o
zJ+#~iYk2X;Ngu9k$lHr~W2;uwMLk~VvVL*)nV~IlFX?vcTTJeqlw%DVgpB?sBte6a
zg_nI5^gAmI{OEv@9B||2g`6O}-SjTh7@mm6U&g6%Yrl0cWJiVd6XX>yVchz5&Sea-
zrX5%iXg<8vN8UQ5Gfty+6BqDD)(D9C_|P!^_=`gt<J)v-IDc%pl0W`P2Xm*u$k~Jc
z9Dl5IU%?-NGk&07>ZWjH@L;Oq@8O3V4kh{Fuickjw?(%L`H9c7{5W+ZOX9nz73&;z
z$*+;p&^lIW9yZNnrg;{<*5EpEv&|$F$<EyJLd!45@_FS~;VY+nGQQHw8Rt_5!9w;-
zr03WVn;HMR8=d+MMahGCn$r><SpkU_1*SzSfj7z#Uzv^17Q@!i0d!w+#2UVCj?hqK
zgIT-0oJw+THh6-v@^7)%7c7ERT+QNsMZB9v7&K>cU{oHtZnd;%HK>B(d6o;J1vyYu
zBX3<Pt|?<dqO>-j$MU!QO=je+Ys!DdFkvAhR=Ea!x|FTuk0rmG@%#SrpC`X@e3iQL
zUnalt-cw~!c_{gfJEh8;@<)^3xSyijQ2vYLcN>0BEZ<|)zeD()Q~ol3r^7ey4yYT~
z1X%S%jkI-*l8zl*j30HYSI|A-+SCC^3;Cv9MOM?DVm0|lgUHKgYm8<&OfO(GX@<76
zmay<8<uae0q|>oRDn}j(6#uqXf=97?$u*Fn2^q|CWH1H~`Qu5-V9@>lRxhx^r^h7y
zn-_q3VLFS4d^=QH0C{F7GLCM_Uat8*_JS3XO%!V7ci2nYD@ix>#d5XHV-I_!bouY{
zGHVR?UGNe`J_Bc;i#1E5fL%AunJl1>fNS87lex#kmFS!?TTO>`gl$V}HO`ZkS=%OZ
zd!z13^3!G7>4Z^gI-V^6F|FF#mZrL_t%gdd0IF*_#otUXmVBY<Vj*v7x|kvS8<b>j
zpQkc71)-Z<OB|ZfmNvVPH_y%x(khj+i<H06gk$>Z2@P~<4Ya8S`>FYOrBmhHra3G5
z^Vr&}akF?5y}8yJsx&msnk<;*UL_mvoPcgXC!i0<<FLq%yp2|FTsaRqbVT?D`vN1#
zFQaW_p$T`)&fpgWPx0m4p|Bf(r;ulsYMsn(OM~udom10?da7iTpXeYaNPwhe*2=gS
zm<D7|Z#OcCG0b3#=g`~J*t!)63*1XJ47(uIe#+}Bn}8$;6!-whn3^lT?K*VDZ=H}^
zj4pc#bQ#6V;-u1bFw(HJrbFLm<qIZB7?76@;BJ@46Kd=une;c9(EGI<y-YUTj+<xa
z)eZCHMC1!&$jmt+4Kv;33~m$k);P|BSg&O_4f?!Tz>!PI0;+c5MRF3oRL&k&OqvhH
zu%;)Mu1<Tu;}h+E$NDn6zI2u7OIL}|>yyg|(5=zyEslDRC!B7N*DJaDG_j$bpXDaL
z_b4A8fUoPkUX&VCp%0)?YCwTyfIRkV?WSLkzT^RQX6WJM&CaTK|7sQV0etwr_nZyA
zA;Y`hk5K;q8A`v>4L1+OwFyeJ9^dPW&NyFv6@QNqR>tgLl+QSKY!}`sr>ylN4%IyC
zXL!JJz%C@zJQl+CUhTXVzRmQTUW%Q^Ae^hu?&`JoI?f5{hwg-u6<hGEV3pgmM=W5N
zNS7_ESE85toI5F%VlC8TN1VDIcaD-xoB;&X@3J*{<zA`wbZhOPRGWyoj%wbN$M_7X
z_WgF3YEv>}uJ@_=vlbM?({8drqg^ieNgDpPViT;hE}Jm&oXf^I(-}O&bDB3dRjW<1
z%O-Z2ilYZ0a~O@RP5k^Sep(e@NIuz%&J$veN+NrcJ85h8qTm|;gl^0BDdVASz-X{o
z28!*`?)PyjCTUrp?8*(;YKkNLE%0|8{7ryAn@F6(b7jl===AMTCdOPn=(eEbL4Y2!
zwL*XzModyItf;nEpkQXo;RERD;-fd4I3nBZ{4|&(MKDZb%F&L&FD=JklN7FxxwON&
zOCf;2E~wlA0b0Sla>fFHGs+pj2xL9XUrPq|BzySjo@5WjJ(@Qmj77|)-KUWb0cvn?
z*<!9<G=&9Y{Af9QA<Ud}$EQ^1w;b7=uHTyXyptc<T#ffsn47En@V+;(y2tzi-3Bvd
zH1<AU$Y*HjtdjM-jZfD;Y-Ax`ZThw<p}c$*`QaWa2uTx(YYz%8_`53P2iP<wzFOlq
za=Gm@C-p<=jcK=Y2qfe>3R9~GW)~^~Faf)uwDrIv@DNaVN{6FED25?3@Kc-D_Mv7%
zvqLV(``wJU$TR<uE<BiYCOG;s`uINkGPVrnd%WI^4e3gre-JAE*D~;A-}aa3F~BZe
z3hftuN2*`Oe&gj>%Cp+xiE1@<c%oWm5qc)+s(@ihlaJw6S?XG3bfT(h1L8hnXkBPD
ze<vN1LlwrNroyJy>Pt;)FIBZxtHQSaNE6rcJWvlH$jGk`7(Gz_ufEpLK{zf7W69A!
zg7`NJr5@f5i5mfhah2}YcQWX?(uuLZ`Z%dnjH?$LJI4v5<k(Y7FlDZG+6gH4Fm)iB
zNgQ8OScuu(?^2=uX;A;`I7JVj>wU1%CUCOr^pu!j$*8s|rVN)2h;T~G5#cM!k+}G4
zL6U^m<Z`@ukbW7pFEc}>Ofw@)Y<CSBlzdpK_T#malnOE-&ZwB-$>@`pYk7%YT?FlL
zN{!uI@EOhhgEEFGk#d~Z+Tq!9$|W9jM7ZEX`U#>KxBY&!7bJ`uL6tRcEEW?MF1P}>
za1OZ!?P?X*G7)z?xZnc3kjK@n4uXhjjE}?vZbqLEP|;sPjb2%Y`J+A>@z)aF_0tjM
zT7HK25t%}+Zp7oPk94eYEgPxRgpm&bU2sA4-EVH}{`%F|8DTm0I<EZ)9&O+|bmzgy
zZNCrixJsD0M|>*%okpx|bFy}>1&<nNEx1REoN^dy3ZkqTPp8Xo_f$NDTRsR6VI08W
z?E^LB>HpSQh$JN9tDs}$*hyi$FJJ_i#eYk+`7qj45&d&$Ew^YX%C7(|*z$mBg&Zx8
zxkDA@w6}L(rTHVEYvCi1)s%32y6w-vDuAx>&Uo2MH;1*W<3kmOqBi#C>cOVZww18|
z2m*bzY>~Jv{8@U_=i4&hYHGa1w6elgl$(#oT-w&No>9wXZej~B<0M-tC)u2uwn<(R
zFd-`e(wT}JhW`3d9<nOnC@CMLCw8mqKdc8h!%XtXT-;CEiNDY{Q~uMiUQiAqnR7sj
zi7&gLs`QK?`N{7=9uDOCr=jY(YPWtK1#d3S*MGZ87)8$iKFQ^u`8_qj)Bx`Xp}3LN
zf8DCAv4DpOmpgSEZVq&g4?Fp{q{e~ae(6Yqaywa>(0_uUYxwO4GVsk92!XJo6z-<?
zAVB?PjotjTvc@hAv#DGD_5KX?c*?w#>Pe5P4!;+XT%`{8hNp*P&GZl<3gj#rh4Q$4
z2K*ts?0Sb$VDUzv!$#!{L~{EwizBtkiv@?@F9<pH+ma2uR@&UzrbzQFdP(xv_7nOw
z$yNE><A>$Lmlcsxc&lccI=Fpvb3I;e--BuP6TVOdi@(7!UT(C?RaVFOh75T*Yx>A>
zu_1Gw7@p=h*+8gBcX^AnZV&paVEnYZ6?XzY8MoNO4qd32u)pa}-JU3|C4hPi`SD_B
zavjAGUgxqD+I2m>>{&~3(-gdE<Oi~|C_*NkgZ03Wy!Uw69gNx~h4lJl`-x_}LOM))
zj<+Z4;CSfw$_&_k?e@E6$k+X3yOVknExeOqYLkUtd0*en^eVxs0ec5o{tJ3vpG|g8
zTOzxQmXKWPg2aC3x<0&wu%gJe%ngX@-G1fWgZP7&W(_w0H4X0`#9Ied{s-cgqUkE1
z=HQE_Z@fM<W20>SqqMNdiq{Tq`6H|lW3+n*EB?rm+Za8t3Rm8J*lfMG`o)9x@EVzZ
zH$P;?HV8I(u~lATEnCbA7TUF_XYs4O6F_Rt(gQNqbq6cWH%mXVE?ewgUQ=7M;;@-f
zk6kW_Q#T%YSw2;o9Pe$N1T#^7>$X|>JnMA4E%b{=RQYgmq{?x)(cqL^`5+6I)fNd^
z)b4`6T;?j0OG~KAP*yw5<ADhT^BQf;<~Olnz>12rWAMGOoTFuA2}CD<gy)?8BRsdJ
zeuQV%pMX5B_z|8TJ$~hn@Zc}SfUMeAR@=wF<f9T4&Rd+qMcR!MU5L}tZfa5004Ogx
zNzJO-4HZ<p4Z<wGR(2I)<V%cpar2|Qw1yW9&q&=O<;H~L;?{Y?8b1>o?}%&~O}64e
z&;iFq-XBZHmWwe~8RsVd^~>-4f)F+H0pP8ml|dD~!)k%~GTGxPt1T4F9*>fy3We0;
zKjHIW&+-PSXKBJm7X1qq-uj5^U#M<b6I$Dy`T?OWk6!)*LM+<*3x1BL2d0Ja2Yri@
z<qk1BH~A~wcP_fj5TE=_k>Nl4goHw=pkO!^6bw;8AyPpur2^X!6%-&9012Q@yKU?2
zX0;cc&u0uD``JgoJN6I!;ydW;44&d&37Kzo2N(|_AJUZ^@q;}<3Mimx9D%2ZJai#k
zqhZZM@}Ec|Yv|XO?)=&JAnWT#5m`kPSy!M*p=SPq??aPUzsu$x6Pn1(<VGxIBTKHK
zZ!4KZ-!?LazH<pj-}xjR-!lnAKMP6XXZS86z4See5c-}@y6C%vbkg?>a*VzUNC$n-
zB4PTTP4@o`Tj*3bI?3;7R0VmCzN^SH^u3TgLEml?qVJ_7NZ-pzBYm$V0)4M0Kc??B
zWG#LBNiBV^Bg^P}J*lQ|p1A0HGbyL<Eu>U$!d_I|$Tb+d7Y&o7fCllpIWmF<cVIA$
z2GQI}E`~6On|P#`2A{;>Uup1Z41P?5&tmXh8vG3g-=M+gF?b-9y29(fLa7V5cF`c-
z-bJ3IL3Ao7AsWQ%SIAF8dXv#qMtGWlau>Oe22rRbbu@@S`Aj@Ch+KwL(IDD)NjVJ?
z4BkwGJ+%KcNU!%Qput|+e;Vwg{ineM?f(u8(mM}&X%N*+@>d!}D;D{f2Ju)Jd3T52
zWb`d15t?Ab;9eTc#o&uHn2*6{X%O$TCr{8|AqLxMun2?OXmA<^c^bsuaU=K9U<n56
zXmADwJv2BAgH<#*8-wLE=)~a7G+2SbYiO_vg9XVZFT}4Ln&8Hui3XQqFd<`bIR^hm
zgDWxkISsDH;D<7m%jzyWd&JksX$}j$94_5WUY6-?PiBY3s>l4h7Q;F$Ha+GsEvCd_
znWe{Ur7;_4I7(+v)b2i8hcTB|#I@kHhH|CVVae6=Rca;K9F}}NW`-7%>#!8)F_X2J
ze21k_kFjYn1rAG*9y8cRV+tLXX?jeL7E|P~OxI&R)?#KkEKWV9LyMX1uvF+Vd$ky+
z!&0Tk{6>qZa99@VF~87asvH)#9@9i)HZF9OF4cQ~f1B2OU0y^K=(ce92U2k8Hm1#(
ziRYvb8@LzEManmTA&?mUFMD4C5LNa4e}@@hRCF-4)HFxMrEtMeQ&AZNR8SN}L31IL
zK|nT#8JAK)2g-58^xLMTrKx3QeXU$tTtLjFEHzuqtkkrIsKhkIMDPE6?t5=|AfWZ_
z``iBC2WQ@UcRlCcbMHO(-22WYcYBd$v6t}Lr!lP4`DOp=EVA!4x(`|%tB;L?R#*Di
zt%>W?b;>kh<~lJ=2$Vi7)h+TUJ>&e%zihF7k&l-tPkd5(k)kx-=fPa7)>Up2-zP1F
zspZ=-emWRimXBBL@AT-Wv2`P)I`&J@*gDidYi(WR^6eMmVQWE-jr%2NZNBy*oqdn4
z{#o0nPLex|m)%`>^pw3&Q+#EQkRY2cCJ|pl$^1wJQlyht_CWV#U7zHH>`xw_kn29A
z{{f}Hlcofviw;$mUmTY2X)5TPr*{@Pk81Y?-I%ElDmN@#L&-0=itf_VO4-TYBrewe
zqrv`zA?U{Bc$;TQ6BA=s_6u5?7L|C|&uHye^_F`tZs2}TmHh*YmhZvSUZS)3*iUJ-
z2e@Cpj@-Fl0eiy4meD<rUY9kc9}__$LHnbNy%u>d9;{h3M6-CX2PL~`h=+Zj*1lgP
ze#o6T)u}tI2&KU(;rl%h>LqumWl|WbbRf821K&mJG=8MpX9R}`_7dzM*g~+0U_EFE
zTYA<J_V`)4yXfws`_FX$neJtDFQfY<x?iGuIo-?YUP1SY0v#5rn6^w?u9OA`(RzZW
z1f8FNc33|-{$TMkV5okUsFz*9)9MnT;!wgCSbJ0y%<Wqt*MVPU9W=ataYF^=yW~ma
zd*v%C>Hbd&dX+l4D%FWU>SWmyqD~Na*&2G@OYk$n;=$VXM;8sz+J6<LcV3j<TdJgi
zn;fRHu70JEq81jZLM~H<qd=8)_N&%@9w-|YVqK+b+9tXUC5R>%NAM6qGC>xB{Yg<b
zt*ES9(Y-m{o7251-J8<gm+roF_o2HF-Su?W(_Ke*UDdjg%4ik+t|!<+aNtQ*-3-<e
z)~dP??^WwT?N+7ks!q2LiTPiVIB?Z(v4$FKUZHh_<X}5547(Ss_fy@Rn)k$6sz>Z)
zJa7;71h0srR9()H3W|Au-dU^PD<s)b!-O?rZuKbrxFCch7yqK-f{+{Tr|a&g3i;_z
z^q)>HI!+&@<GfHXm`gopsy;axs+LR7bMAWn4eBOMvq{puQ<#!GQc9C6lWNxN`msNa
zl?`9uyg0e=DU)nGbDf`m2&=T7)S2Gab-_;netP<csE){WHtc`Z#A5qK>#PRnh3S`l
zwA8y7`ULH>{5<`jk2Xp_IjAVx6W-$NZr&@vUopP~t7?mY>(J-jW=f8Woe2$chFP0A
zi&H(YOwo=&Pe9MMP}k_!q4=eM*v*P{Vu%B~fZ|&Gl#b=ICOVHv=Ry@^>78DsqnyQd
zm%)0!-Q{I%JJfoI%emUU-=`ZrmcF|SIIYD`>7Bbk=vw@g*53tE*Wzb?_*rR+A`o|k
zp9(Cr&pV|t<b5HggQslXsajXpw>j?{eip;z@g1;qiG@)6HNCYyQDpVBU(?y{c8+|=
z5%rm4$V23A8|WOF=!iP9e@G%ET)1>`HVmNRbVQwWHtb0cTJhR9>g2o@&Zv`Apw767
zj<Cjh9)7a)8<*iVv4>iv=Rz87_^iYjKK9i3(iT*h&UwdivXoVyN>UoWCM*_yRncnf
z3|DaSa)uvq3`q<ubX{4c7;Xa-^siFu>r9oeVxtm@B~GzRCt0O~ox2K}(3J&UG%Ump
z1m_L^YXw7e_Hv!Y7UNpek6ez^`}m;a*+btEHn5IodpL`=#X-duLo`+&hi;e6`rTO&
z>PxNzh3oyYtF?O(_lPd&`HsxBB6DgR1BBtoFCAX?eY#lw<vM{(xL(=^Bdu7b>Qara
z=eG&tDrK>%_#$xrWt(Se^Kp}l?Hw652Ek?v_;k&4RLmFNz`BBTIAKLChZF9gfW@vO
zZzu(bu!OYGTwXaoUhMITjSJ*_dlq(Ki|ieb;n}`lXXl+QKU6M;`l(bf;rbZjJ!iNN
z&8{gM!z<DUiS_|uR2{^YF5A51^;gl1n_{6;*zSg~?;Ie^f36@eu_MfoCqB6s7B-{#
z7s-p@u?~swFY#^_??c`1<HY-L<$c{4e;g2Q^-VTODZ(upZ3REhD3`<!K}FUfeH$XI
zH8>hvfk$UK>=x#8YZscKcNW{zS`<W`9F^)rbLvs4nrMCu$3I*SFW1=WEr{}E%*aXu
z*8-QIaF_MoXi5LUk2u1AM%=Z-Wgmm&qsM9)Jb5oc58Qmky!<Q_;_w6`xOcQ#=ewu&
zH<>b-vQm*Zy;izSncy@En|xCBH_k6`KB?7<#JZ8TOGMR={zswib?EBj$Wm-PP>h@G
zfpHVxm6fvStBQ~t<DAqqR<iW)sm-_VSYhcwC}P#Z@8>HNWag|8!tXcIhR`I3N9hq2
zRvx9FIrrGFaa(heh%ZRUG?J0&M97r3b6)WO&9L3aOFlyzhii<qYKPfMu~!ea9AM@<
ze~wV9A|YRAluv4Ok|Qkg#<&t34?vl?2Cr~aQj*H$GwH;+AhYkWU-g*pW524kHC>By
z11A-Wo1>xh;%czM-T%JvjPk*#@`0kQ0krC?bH#b$@;=svXg^-_MVDF{6;~P{jupXS
z#i>j=Ql$B5+3M}&zMeQ##A=FlHP|ef&1!AGacbsAv94?X#Cp(@XDW>)p+;SgJcCUc
z$_j}8GicLZrDt4ItGG9j+@1SNKa^?3CX%3!W>y}9;+t)7byKBY8e;foly7XD^FrTA
zdTRqv@oFz&R9_sltmo1eCSseWLEmQk`d^GqW!mpzTzx(e`YLQ|R%~aybG9WFS8y}+
zhn46Dz_K)S=Jz~@uSWWa-vIjUJI_}rQs3~xMl@R+*DFuM%7^Rmr`=_L|I?CT2&b2_
zlki4NK`Ut|pVt0ko1!1R77y>^=W+1JRmW;SN^?;`F#YCU^{{&8Ue(w-5z}2cip@Z+
zUBjN1_6G)3CV%WH&P!TT+Ly!n=!{ka464GM?n_O@;$5t3?49y)Wh?OwkM?qyw=UO^
zx5NYHlr}(aNeevKcWBdsd?V#*c(N$kspUProfmjBBX)Eggn7h=D0I*Tt4|++njtUR
z1K-xS0xzr<MIs{8K%CzNg%a*-c(lDIKCdvH!-pt{lvilTpGJM;;s(yGej;%0)%w^4
zk>BbZ*21*=?X&wZYqQ1CJr|9=v?%I#`$K&gK6JknT{_ILt0>y_V{>UgQa@(_^7Q{m
z8|6!4R?q>%qZ`CJYC(S3Iefw6n%=x}$?zXK#zMJ3r1b7oO^g&M+BHNK21YF)45oS(
zL|vlJv7i89Mn&_jAWM!dX?&&Khy!2+gB1vBqho=iGap1b85NymToWZ;AD^3v$j$<A
zi?+y-58mm!6%h?fE^G1O0_bOkJgm>U)5L0eWup7SFEy-^@S7qcLTU_4HbcdkkMy}n
zy#x#N{WVrye-B$*!}h?ygZ3L#(nYX3AdvBJYz2Le0^}?Q9L<HB>-GDokduN$AsO-`
zkdH{zL&np3Z)(GF(GKD7%B>Q(mB6EqzysJg!+raT{0s}PUMIBlFtpKVaT6)bqA`Y^
z&PI+fL!XlK9ys3@tl0;wxt3mYcY<e_qd-a;%0!9N`bH6NT?Z$B6nNQRFhW88Q2Gsu
z^3CqJxJhV;V>K!*_mBG2#R)w2v4*C>i+oLk7u?`YXiopRvrLNOUxxDTEY+cKsks_M
zk(~&q5vT|4Gb{;$Td}|B5Q1O`A&tl`>EK4)!;t@RRiuaFTfhw{55ir-94w1$Cj<FV
z!}ccHZ?&ID_}dBpmYS`=Kege6Bu8_naMteAY()~%Z<51TyKlixJl+6h@BCTHQZzSH
zmY}Id*$_}ROoWu$dKZNxoA`<euQFjOvaZTx1v#G*%)b2&jo^CiCm^knL{zQhY@`m&
zQW$tSHa2-|Lz)y8l$BD0EGR&-{zc-u%xGs(bgXRUL$u7}LEjqko{?LTpq<Fr7hRCo
z3z2Io0IQF7D*^_6oAXhrk2C^FtW7Qxoq|w*ndm-Bao{ZE(qO^`F=1qeZ$${+vyVI3
zW>T5jH-rf$7ICYlZx>?-v!&U0iZIr$sh*SjiY91l>Ke7oz5RRqG8o4w4VIhdq-FSK
zpoc;WI&%|E2nCM0eOihY9Y0rN5x*7Uw^$~91ap88a0*2HMWdJ?o#Zsx^|e*l{`E~h
z0MWa{GS#N_ZyuLMn>~-$`BBd{IoNaVV6K6W-`=M6<!x*Gs3)Ub^-)hqWy%qc*ZNV<
z8;>iS*uQEkY*_jxyFk;Z$K5nFaa~@jre$qaTJCUt>GpO#Opm1}YNf$T(C|r&>tmye
z1}~zaM~o}lD1B4lcUo)$YamxW5u>x4&oVJnY#~;7oKa^Tde=is>)M_F`BH^2*4Dj6
zV$|hOA5*Ne%!#eC)`s>+NT%~9QAOibI?&!pSVf;7Kr@-ej7Rx6KXN^_ladVA+Xr%6
zBYW_DHiPq{&B3mmov<YC!*V{yxd@)l@Ct{wq8Gjm0~4FBS2r-R@p@ebCWJu>$-qQ&
z;yYJz0p3?#mkmseFK~-B6-)4)+&jv5a$Bxf8kk5>8JIZn-oMen#AS3SvVjTlIiO>!
z^tq^H?*X3+R+^c3tG@W8S8Zg%QPs%Aw%j#W-9{#y1xRFiVLijPJbfX#r|OGby2+9a
z4(f*U&SS@y_jr}ziMQUunyzAcLYSpcO7wuLjLY0*T=HY3>4~8*J<-#DpD-QJRD4T(
zkbLV2OBH{!;R%}7IR3QZ3Ht`|ZFNat?UpByZc~-z34QIBCw{5L^2Fy=El=#L-SWh1
zD$5fus4P!BaT}H=GH+>lB1*PA5iVPv7$94o=p|d8=qg*D=pb93XblWDh>wTu8^m|D
z1>)OL$@auk4ePKyvFhDwwkMvdZhPWk3Q_XD%J#%|VS8fiEo@J0RBTTyxn9NgM9hDU
z?TKr*VSD1BVtb;M%J#(Dvh4}iU$i~(U>lX~iS^fS*Y?Dmn`}??muye;x-HuiJwb|8
z^(CFF8=rU{XG51XR*X;d7RD#qDaI$bRyIEIHj|7`%!cua`-Jg{@2eZ1kove=7@qjH
zo@96;^45kYlmfba!xP_7aP1A}kaA~SMM=Hth9_hj3^mxFzz5)eo8^i1YgLvf)?BY@
zc>+1zzU2wgPPs4}bF<}%71#f)<q45oU6v=50JpY0u~$$d@F~E+EnA(i%2p>PC{`zS
zsjN;QTrE~7dI_r&2vED#iN-3c6L<Y}s}pzUf0}cbusYHB%5nRrtZuUta_Rj^yA%1h
zZFd6wy|6nWF^1dj1d8I;b|<D*+MO78lidkZM3TJ^Qw&f1_SX$hpdJ1j4Nt7NUWeg{
z7H`*Lcmk4NO@=30{;u>Z)eTP|pQ?r@cD!}_h9_V|LKvP9wk8zA6R-&*3{T{?P#K<p
zD-2I8s*Y);;fZWv8UktEY<ObT_3DNv!iACfnhZ|}qHZd+@87)1@B}&{VR!-$t_jJQ
zV+yyM4Nn-P1{-*J@sX0m-`%E1Xr>?@ybbvUmueKTtC^yBKMC{0f(X{{RTFz)qlu*u
zd_d6n6%%VsFqPmb@~gVu3rpWR{{wdyUOCeKfOBsLRz_m&0ZV;n(fB8w%%Sru?ut$z
zpOu!#+Ztsxt0TPJ8SWbwOA`)Py(Uy2hxz!R{kF!g{tJ{jl5@ZF%hE_;JE3Bf_?k`_
zw!n7M{kA5G9ZYMzXjiudm@Xf#-J%6$HkJq#C%EdhG+Fec82Ahc$2*<E_nGB4Y^_|!
za-}KmJGpKgik-)#>0=>HA3f!%@N06oW$tjUKzb}aD)zk>^cS-XXPG>Wq*=l69y<GJ
znhHm|9=)U5RJc_YYw%x677ZNXCmmx?m9}totIVOdl&OSr)w$zI=h#!Or^&w<Y3#Yf
zJ$sZ)A&LXYUGF}Ny+%=bM+mlvH?&9i==X;RgUY3i=|xu%(v-Z&2_3jIL~l>fF^8sd
zkrG8@aIMZ!5W@Pis#NZ9Ep&UiI?!Y3w>N+HKoe>WO{h(iYS<Bt13`Q+;fpim_ZEZm
z*-eD;`^v1ZTdeEYCUFMF4Qsnt*M53dTbABV@0FINX^L08*yQJz)8E68hs}YpuBSK2
zXKPSGi&Y8Dua;0oEeUB1c`t~BqErcms1oW`EujuKC3M-O%e77tUsqg8^~4_kXxGK2
zikRsw4!tX#6v+F|E1Ms{N9bnX;q+QOe88nedS@fq;B_M^!U30Jqg`*TQ4FIW7!owE
zZ0?aHEXo?~gLOA%H*_|FEewao?&VS15J%Zjgo;+;R92<Ie>epVUivijfF|%@U(a#=
zA<Xb(k#Z_M?4+PdU=rKftnVaWt8brsa2~cksMsnkYy}o#0a&(f(k)R~H|aaBsqG#q
zke6XwBMPNHFB@n5eFVA<+q|M(*c&RAp69_V%A!qT*N$d>hrUt1bB%$Y_MN0RJhf*u
zmDi}))OtKiC)xSUFQm{|M)M64Q7pzjlQq`6ow<0S%nW%+;)4gVPq^eku`gq;VvJag
z473bEVqH$;R0vDMlys`5YHo)7e(3Dqlh0SHY^<M4jdhZ0D>If|U4Bz>)O@(!8CB+V
zVAHE%yDp>yq~4mgFiYlGF%ud;zWV1Yhhp*hM1w+GXXkJ~UwZZl{PfBN5<SBF^mH$C
z7GFsu_XEy-xNDD=4x#6X<N~v;6y|8j(XWsGbo6+GgSJaoE;`F7R8tBO=I49m2klWy
zqaX@5OK&j*QP`RFM);G*-DCWk27XOXdV2D?a)RWp6U_Oc^O*B1<TH7XuVjztvPsx8
zovmlqmcm5yed1upcfrF+K}9xCdm}!nn0rmSr5-C((PQ-@wlQpnA}iWi?0OoXvxMtC
z>;w6Dn*q8k-_&4opO2Cf%B&+bDYItlswuOY%E~OPyw39}DA<Biz_)&e-_>XFo4-l?
zmW$ux;`fsHJt=-Si{B&k>l&6oKhHfZlv&qgW!931-O8-)4`ZY)ye5ydJFZnKvworZ
zPvGUC8`i^y?RSwZE^zo+{O%RM8}a+pDf&$c`ofU6zCKpE#%r%ScCNW5?Co8Hs%f^Q
zYD%(~L)o;wy0S^6B`KQ%)XF9}L)kPEMOyA{c&wqMYHIL-q-p}W5bjj;9#@q>xw`~P
zPC?bQy_%}YzerX!Z4;^{1TWbx6gYU)mAvMD)|9*;R84pms-|U#Azn-J>%kb#ANSe(
zomzXbPN^IqLT%8IRGHwF)o?5sBlJSYuSt5L?Xq4-c=Z*UCXmHSx+>{*sFLm_Io(Dg
zT~Puh9wNm{)l$TJ$&Y%8@bU=jD0_Lb)nqSEvo^Pv&obm6(kmnh#m7!P@(WJ0HP&90
zooS3Mc}cI}?_2V$``K8sR3z+eFYj$@kz~*D=xMuyCQEWeDx;Eg1TGJheD9ZhH^3Kq
zrjn7uS2k`+lYU9ZggJj+Pw`+g<oSz-*@nD!;$fU2uZ7Svfh~w$G=<Rxg2VQUT88lN
zx(m&@q|93;JJIlX520?@t*DEztKFI-)J4Pq4@%q04Ed*N{%?o6XoZ}T#MMqw#1he_
zf}IuDlv(}GGEp693;72Pj-}+bUlcj!_9fp6B@-e^N~VLXvgCF$wV%yfc6aU+IdN|D
z+%42g#k$KPlu@dB=Y$H!YGi82y9(XX*X{`x9PJx^7NxQkFZtZCw6Q1bdqAP)?THmC
zbRULou-EMMhrDr0Gk7o;1oYjB-?>LhPAUqi?+AY=qn-lZE^kBLr5jk;GUUIfL&1U}
z11}F&@Y{Ms)hn&PhGX^?<sZ0)sRgo)c8c4+{DVM|Z{8$yPw=Oi3Q9EEHAt+dkTfyJ
z;Mj_mT<V?V5Pnh!iAbsIDd`PWRb`tHYwki-6(|*}TUCWP);m`E@2TXEk_*r_Z8##D
z7)+b0$}rmXJ8bWl9MQ^(s&hio__0P-RP9m}RX<`bQl4VXfTGGzD5_o*iYn1R(7YM>
zPLbOJR8+BUWT_Ti!B<2R&YLaNQ=$lkdJ3GJ<j_JrB|2K|e$lB3w6EwC1~To>NBZ^M
zTqLQbRzfZHtuwUT8B<a6Ilb8Kpx$GeEl%P}p;Q<abYQ+->KL2{7F-pIr3VV$lvGM$
z9ZK;0ct`%mYl=##vfOFvTwh8|sFbv_N~xGqTn6vZ3P=8vm6gu7q9qBH(j_;0kn7JP
z2x7#kRZ6Qt3RFtpD=H<?4MJlil8aNTl#=W_fhcrJU#ml?bV|WOrzFaU$QvTH*SL}v
zH$cuM(Pv=%^hUY(3BA%I6@ta{Rw;U=Pw+9k2qkHhMD0qYFKLwKVi6=@9C7L)6o3e7
zFC0bhpMc^53_~SxP$}gr{iz`z@0D%a+DdvbN#z6eQm9Zbg;uOAy-W6^qE%E(B9!c0
zqnb&fSkAJFnn{!>)J$%UXlWN+vZ7{!JJd{qLu54*h$z^4O(=21a8n=+L6w>&6o{m0
z^1Mv6LDRJ4S`|$b3P#d2<s%`XY*HGB)Q37m$7P)?lui3``vh2HxM;sl!GTggwT}gq
z_7@%BS$CtA{3{!HX}ys`CFP|p%I7eJ3h$%kQZDwLXi!uM8^wMBps>+o^?yZZnRKaL
zOB-#}(A~e(Yomv?X{vF2lB3{|NdBapymKc8YJbsT`tKBShG4~wJ~qG7d!#`r)hLZh
zBVCJyW&_WByik&S%eNwqb0_35=jzWyTR0^3gb3z(?02Plp<3!LJ?d;7og$agmZ<?!
z+RoyUt}fM6KV#o1IyT#M=V~!9eLX+HDHy*>N38U~>qQ$J=KA0_Y4V=GL{#j2KfZOn
zC|QA?$j()GiF55v1Q?(Hb<XC}ZuSC^acKvsMN1TMQHu&)BH}h#t%MggH&7<XdY??t
zO+^-Wsd|ywccM2EdL=x#w6PfOgxh$h5Hp>kRgg3ic-fIJ$)fv+jgFMe_#HAR<OL{}
zaQ8OkYksd$+?6_A_dIjT7+JCO;tmsg@jVm!jG+7bCiV!yV+0=)?A;+-ImJPUaruR_
z$4gp;>`{_shca=<lB8BK6#d|3@85{qddUYCW5L>XkKM(rzF4xdHHk^RRH~0j{k>Eh
zlX{sq>x}(t-i}sYfrS%F?{s~g;Z{?8pP}rUa38|zjM7WrWq&kxLQq42LyWTsdZi21
z4tkQ*H@)rs1GqInIXk(v|3_Be2&+D#7A)*OUNqe-ZRQ$ViN&N0VV*~QwwJ7KY3>S<
zFm!dyQ0-@^qIYTOYAuKHs7!K0I<ds(H(SNH9Hu9nKX&T$;^@rIP=&RiX!te?=L(Ax
zhAR&jmiOrge%*Jn-qtI%zH4LwMzu*5cyDpjxxO~7W71hZSg$Cj0<fEZ(phV3k+!r4
zQdZ9ug!MtZiNXlhS=WhlSdsXe(4b5jFHxV1S)=g`#FY;KZJs<7RK!pU*i?ZJA5Nw=
zaDDHT&(9QF39xUlfonMucFe25$?)7{C<sF5)pIA3#cn^CfN|JPId#ItQ*5CxGuWTT
zm^E0Zu}!egr%7uc!VsTdjt~4gluAOl-F<UWcseGXEY;%NWpf2{bw<U_JIQQ!6-@St
zk?2O6*1KaQLhSoYrFQ4M<4)TtO5XtFi$#PV_E9jJO8ZNA7Txfo!aU`vEpyn;+HpeX
zoFOG$sIbL>)ptK8SuH(9y?;W1kBH&W$cI-u8!y-+Xxfu~*FKYu+4X#%$+JFe3EB%y
z6sh!^q8~jS^Ug|~aM*sjP0?wkzV?A};#^n|K&k4~`&X20`pwdCu4x0;D15?LoMbp(
zI4TC`9~vk^j&qOwOiq!@+xmd~<xi3!M?(<eiytF?0`OzPPc(iW!cSI#17gfj+mZZF
ztq(Z&(0tZvDAiJTg7^gyzC&%7?Pm<uR?a<vUl;x4VbwcY6h!DEZRPe;TC3Nh79m4z
ze@qxx>^y$uYkRS;|FOWr(avM`Gw{=dMB4r+Dn%ShNjJ<^{$R;i6lHzhtP8c)b@(Ju
zF;ZEn4U2Qm^9{OaYaDcKW<yEO<>6>fZTb=EMN8!>&PL3c*~FEZs_Zgvk}7tY$8uY9
zsE9P96lIwqA0J^SIm4U2i&Gqvf{JGL4!USHQ1T7pVq#qnuMj(=Tz;vF3d_|3X~~)_
zmGxeV)iLPWETijc3O17q`!Do_aQU*vOPn#k$V*nwN%pja#;iY=?ByX$0A!OWpHVS!
zv8kGZsHUT09Fu&6J`DTsC}PvTlY9*MVw-xDKIkLsPKT!ST}dBrFMrsO4?`qD7Y%vY
zxL-3oI-Twy<)6<8Qc5N$8{DfMh5Cfhr!}o|)Y1HgIKs#^!zq1S;tX#kA70wrHA%ST
zU$(Zy7g=zMRUKg(Ks8u;r}Gp412)f8k8!090t;z=xw5bzjA<&rE*8dZOa0=62J8Au
zib*S9r<Y;7ZZ=Hw-h-X~Erf|*^7z8J&)*Yqipo8%97j5p@1<purYp`_9$4r+oX@Sp
z`+8gJ*^6{0dtYX|5^GA;MZ0F%h0Q`(0nEQ_)2G&R&Bj)IVZE=J|BYzZ0c=jd$2Lyg
z188f%*gL{dAU?KJI1!^HPMy9Kw2#W6esbmckJF@0=x8%B&gOB{K?QwlHKz`Uas3)4
zZI2JSVI3Rvopn@TVN%~&9>P9d`C3pA<e7|Plk2;BQ}wJ9F8ge=*TN=eUz?9LkVJv*
zt~)l8pD-KT<z>h?bK-=3W5RueYvD8n4~%6v&a1DjoEkrD+3mC4ovL&7UPzR#n<$dD
zo^S;86~%9BLSA<ZFDX~+ZbyJqm^&uq-}Z-LqKc!`ua~(7-w;Fu-7qY<j=?3+kO!-;
z1wG&Ay<LG(!dxxPi3k%}B!V~^VZlQaco`JTO7)l!gD;*AZ=k%i#nG<P1@1C=kUZe`
zw(J+@N?RmzgCYN%=;6u&4;JW#Bsuid=(NRGzPkJ1m80zsjEdvUdP@8M4ECr?-1SJ3
z(oo}EYlc&5R0`HcNc$hdg+;sZL|yo$k`th1gl>qV5uxAL%XU#ZQPp4{fj&qVCmUWq
zy+A=Dua{CWCI0k8$=V3>c^+53D;VMtwBN8KpHdtkrSUM1%u3bCX{?sgfC?}HxsI(U
z@Oj74*fB$g;^`r!`4#!Z;&L@JQzC@#nPCdPfrTahH{?cJX|kjLaG~e+aYkKQJho}x
z7)@&u!*HJ19aS{n?ZbU#`}5ksLQ{<@aGg+sr!v>GysApQc}y%$vem%8iQXYjnRC7U
zJ;_VqE@3pyG4^LHfsDs7x@f}Be2*!4`wwxH?p1CL!KdHzeErMr{==|nAK{aur;h1S
zSgH_5fyJa!PZ2FX+iEsWtSwgHOmElrMEALvo3O0GL<gG;4FPg#rop-eHJp4tw|<T;
z=%PjEEH3qM?u!;&L}+|03LL2QUWwdid*vLX=6=`-(=+7=a+FC&FIN!h3JPOj&gE-y
z-lA&=<!kTbX=~uRFHtcOX#a#$qc7bVbS-DbT*@|kdQ4^Sx#|q(${E6jyf82mxxP+9
zI<~0xAr_Usmm9j$5nk4Qk7Mj5oFj0r>!Ybk@~&f3D?ib3coDAcZI|pfC^gvLj}e9w
zT}ZS?m8`xJ=l2Qz5w)glAQj881x+Q1xxOq|ezG{k&!aHTux*acu&Yqo_j0s+!8O<c
zv_{jN9IS)r4y%71ara=>dvMn=+ko5%U9Pi!!SEh_iyP;jS&;joW>MqPPE}nO=6>i=
z>dH;f<&-w8^vP|Tn-2lo<}J*GPAW!WbYO*y1U(Z|eTyj$;oCmN-K9P_1w;5a3ea$(
zKZ#R%tb4{e_X)YikPoXy&ZG9zIYmEtTg|0j1<y&sO{N#Y2oi2GV@bHloDAW{n_wj5
zojAxl@#K`5MDk8%2FW{_GfCdboS#J=(;x$7LI#=z87L>KK-hFC*p1&v+q(RN)(Gd(
zqMvXm-(Bkba=Z&>`WEE)M%vEXPaCX$G;b;Kur_qw>A0(4rmi4I7h$`IU9(ziJ$!FJ
zcu0ip%DBn#lZxMi8pi*K|A(WTdz1ioF1kwuC~{RvVyNxn_!8`mcjXp~eqWz@r)wcS
zj=$`=hQ<XCYvWW+ax=zEsan^%c+m{#>7iMQ9cS@X8qI$a+$CK8ko?tJl`qhSOX9tU
zYy2$tbYPTyz-G$hhRxHJh&{`A0TW9rrw5C1AZ!Ib?1|EkBA)Lrx@GGbtc)sVm89dx
z7cWH@q8vZo!nOY)_3`5(wUPlE`2g})A95c+etM(EdKXR^#_{9$!oJ$^<2Zj9Hg;1z
z?5EC8Xi)4vVY!Rz^$6}hgM6)ccAr81>?ujA_KtN8#$)9f<oLu#K7-stK7-u<BgY7u
z&MSwI-*-gbKwnWhLO$JjfDp|7#3AI(V(=~5DA#x2RyJ#ESL8cMpX6v>+8W<yRUkX(
zHQ_X=!u8f+C10FI-oRaKrQXhBVK=h!IC7d#_no8{-z<d0#-aZh@jOYGS(;RjSl2t@
zZp)+AHslu@=en4yh+#VC{!$;w@Zo~V;*ikl_Vk2(j~Hi^Z-ax@DD*k=e71+Y{opnu
zzVq)`|LkIKYp42!*7o*&8vA}tzaK4L{l1^&;qgPi{q$5!Py70vvNgaNl}7^)_B&;*
zhjmzP@woDpvuFZDF7dsXmj08eDon|({=nzJF!Q($%vY?ipw$PP0KDb%1u9V#rtOCN
z`8GHJ>u|PuINI{c={>$I=E`Y#88^|dsaASAtvxn@ym*Htl*WIq{|i^SPQ$!BHLN*7
zM*<VUXo4hyxdbZ+wh(+saEhRU;0`YeOVFEOFu`PkEP`L_YuHJG_4K@%U<bix1V0np
zAn^63cm(|jVhOASiwHIo6cQXEI7#pm!DWI*)X8)t2q5TBFoNJgf@Ff31i1uH609e9
zkKho&ae|)+$_eV%)39~~_Yw3X7)&sZz(TNu;6;LW2tFk^Lr_j|2jOod2p||pFoNJA
z0xLlt!5V_M2o4eaQC}m<aEX`ZrgAN6ZDPs6CieXb6Wemo#2U{sx&2OkZeo^uOgF_*
zuJ@*Y_8{)q=M;qp%)3h&E2E}7v`q+`N`KkpG?tBFgIQPBNA=u;^=89axJYL#8^I!2
zC>zPbgv(I+>&MdRuOG$F7GV<Qzb?#3c}agpx62&)j|ung!o9of!dSF~9Sf1~Va!aJ
znJN7#^lK4rBUmPzS<P)Eg|d>n;u1smEOJqYqFEQ4MvzVJxFYE}P0kn385B;+JBz}n
zkRNbNpy#QuLrP^~rnD>+5^hSo1d3PbBH^pxsNkjGqu`+At>i1^Gsm5`lCP4dk`K~J
zp!96ymng?T7+_oZK8CPGh-{Tx9Ho;eD6DiHL!s2~QG|1bDo%{RP5quAXp!<$@=?-O
z(o@n=;^Tvae(CA`vITP_($&QnMVAo|bLe7GQQZ?0yU!7sL{qhg5QLehn$xG4Mdgmj
zoaufZIn|np#~5>#RdEclO|xZNAtt7YG$L&oq9Q}GEGeQ66D(6j{h6m&YzY=AOhSfu
zq<oM*(nXp`3+W&YiZ=&oAU@(E4vR^!+AN6)B8|b86!A1B*=EU>-QvuN8D{xqj7@rq
z%FGZBF*f<0U`1TSLwJNk82Gbc)T%}k_k>f63uO1RZp2Z;=}+XBmOa>FHsc;+w#Fu;
z*~Ie@)pJN%TIN)x&1*cgI!`ZeeZBe(d>S?~_%^<yNz-O`-qpNC%ez~(zNd|`ZM*h<
z9XfXEeD8h!UAlJb9?;|dz@EK&KhURdzo7mD1_ql#28D)&4<0f!B68U9s1YNhM~#jd
zGd4DE-1rA4Oq?`1{-J~^QxnZe(~?tCr>CW7WM<8<WLs@BXU(4T@FR2Q&Cg+>nU?U`
zDb{F9=2SCkKb?4OD)EMexWr79B~lAO{a6H_Sc#|7$=xVgt3`w}3OX9H`Z8Y+r}h*>
zf9f!jZw&QHBiN7{e9$IG5>JMR5H<Oarv5E}N;^=vbfqvMgpJg9pbs&Mp2aA74zuXf
zklS#20yT-kElH%AF2W`gCE4_pAbLcp2SPuCKF}uGP6qV>M*2+<RL>MCRHg<06ycLV
z@lx2sayYcA`l8iI>8FU+nL;rW1h!J1M#{}5(uY6#+f0!w{IcjT%^gEZu^ahB2r8vi
z)5$ekyd&gvN>{=ibOAey$O*j{!ekQVMv-2c2rp5VAaYj9sjHw3Wr;o&eT9*Arapfv
zy;<13qV&K4Q{6bJ%QK<IlFAS`f^(#P-y(3aREZfTa6(U-BIvAM-}k%gJA-0a1#e`C
z(wauJ8Yzb?iaS-VUn%u8x=Yk5H6{6^t4g$bK0R*1S2x$USykSll+GBrUMy}Osf05{
zsi7_XJNTkH9RY4S6r7ZDtBHcdYVq$UnL>$g6E!+TF2%Y^0c8OEl(f|8J@6OnZ<e62
z?sisFe!c%fe&Eu?znEVycYax-rjYJT3U3h-0Me+b<tS~jGDRi5o__)Vc#*1^%@&w<
zmpMv$L(M6*cr*SzSl>G9JCkxV%NR@TIaBsWFE~?hW6kMS<s)E|C8RE^+_xw^Q&V5B
zPUnGJq?0c9aw($4SwyOd?ml4pEz|!i{8BZiL{Z)ea_UODmF*B^nko39v*<^Y#h7Ch
z60f-mH{9GF161{M`}iS*#Dl1_bn$Mjf?t5Der`WqNV|~Dl@zmY;@<#Of1M=iKx#eG
zh?7O{DI%s(j80j?#UkDnETlMzRmuVv=0wrIny^mH%6~BlmDn1(Bg8nmLs7`+-Wcvb
zo7f$2r+X8)(;Wx+EGsp!77XVjnOIA@ANk3|?xy=gbceADU%KA|_YxCpLw7yhA>FKT
znPB*UZT`VT{731~9kQd9?hhj$y2DCyG~F>}3!r<HXd4zWPGkH9ZLy;7S9*m|=1+e{
zD!HnX)o^;k45o7aQeQ5IZsL!z{$l=-No9&q>GIes#YS4wMQP5W-+^-7RLvpW-6GnG
zw4<w})=$vfS<INgmG_D?I%n9@(&*6({~9VQruAZ89=^Kp@NiFDy#jDlB?UD0i5};z
zXAcAf#6^2EW;CM8nEs*Uhv;H#cGhgV^b~@5GrgW}diwL$v;SPUj5qytcK_Y%ck|y+
zs+qd}@@n|28e)O!Pjj1p>i7#)e;&8_r^Ge>cNhQvfa~TuP5!Uu08QoJ?Os(lKvVhW
zahrdY9PqFH-HLwvHKjlGo7(TTNtWrZ`hL6gR?=PFMVueXau+PL=jA{8*doVb=aPb@
zk1t#Pk0+jd>gi`ztbF#lRjZ$WVa?hX*R9|1(#soPdG)nTufOrn&2PT-_Li;Nw!ic4
zd++bqxodY}(VpVHAMD$I;NXWJ9s2l_!$*#OdhD~$zxeX_S0}zc`OUZAojQHy`?KeM
z_|aAJQ|ZsY{Cd9Z!fzKZ{eJmM`PDzJRb0Qp|7FEQ?TUxnQcV1J)BoR{|G!-^RJ;HG
zi1NqTPYvWAu{AyG<mabV&p5|eksFq(o*!2|FH=1)S3Unj_56hD8D|?S&s$Z`Fce--
zN>6OR7-Cj*W^pMQiJ7xvtO?eX%nZ1X%{E&`PDwRSwMJwlWm?jON1POActW-{WU4h~
zra3w@%a$eFq<1M97DXv0OfwJ4oE^u;vKXOhtgd6k<&~TJXzqes62!ER=03VGx2dNm
zNn-i=`BZQL0lCq+i%6>K+^J7=TrSC3B#cEz<D?a1=iEiP6pN8KmYkfd*L%;-%9@px
zRYeZN%E1T%tSw+m<lqErLYmQRv1D3|DH+DJ1Y5?`WV5B8u|u{HOf5qDjc_Sx=0u}4
z)0mlM&M=y1o2S~W2~*Ob=pCDZ2lyosp~i#^V?q`MN~G}6{89mQQ-!gZ6B3O{mdtbt
zEuypbZL#hULKqFDG8spA#)9Osh|HWqc)5$(IKyVP%t^_ZW=s+Y-Q=Hbwpvx*EZdq$
zWF^|N(o&{MArv3smua)s>`8u9C^h?4(lV8Zv6_up61Ny_*~q$6hqUZYRm*Ie*-Ay0
zVl__9Of(xalav^c`!Vm8);+ol4X1_fQ^Z`VyFA-duJGAe#CTGQQb|*K>FEjdM5T?a
ziPTQrsBSvpDLdIbC4n5%QZmd`pJ~}OrZFoy#cIyZN|<UkCL~$S7GtOGwrorHDJdD<
z%^5R0DG{sHab^7@CkmKi$;?PMXIR}CRmsb2Nl(d05EVm3PO-Yquw_!gQN2}5swSkz
zsG>{pW~Eq@QFYnY1dGb~_L5W8i=aggQ$yJ(cuQ?VomQ2wiDpr)YJZs(#*P`>wa?Az
zc52_rm>^>hZm5!S4R~~F+lgpPOUs-k_^bU*)muZH+RLE^KC(=+q4Khgoy{|;b*Cg5
z&FNXzIrr9`&lF-AnJE&m?t!MDFr+AibaQ&9We#h{I?!A*o9;&W$ykFM)-wP4g^#bJ
zxk>cpqhrEiJlbcqIaPc*{M8Oy8m#cTuofS7hW49?{yTeOELG~9iPXoVBhQ|gosyoF
zW{y|-zKMw`+182H!27#pC5q0^*o!gK1B{hDT65mmkdFIj@?ClNZ)vL2f1F?4{tG(P
z?f-h`y8Yk2w{HKA{&o9%cB$%rNaa7VtBGZGt?GZITKvWL*PZ^PpxV>Ny?gL2=o?hk
z|9Cb3Z$nM)=U-IM)x)g`uk_obdM>OME+n#UdVNOKP0!P#C4XE~Mw@D-tHqeQ^JzJy
zZh!lXy8WM+SvQ_P<keoT&pm2lZ#-JN|EZ@;?Ceuj{i~Pb$In#tuTFpD%DV9%x1nzT
z9xv5RU)Gko^Y601s{es%{ud5N{<yl*^Cqpv{XQT2Mov**p{sOTL2hBES&i3!_Uin7
zdv#i9)XUwEX-NJKm4>6?G#bUR*18xo1k&gPYjPZ$L2qg)o+L?0vS%AvsF3TFNdR%M
zNXuri&>*R#e^nQkkYXL2X^EjhIn6A`okk%u%od6rnwgQEnPv{PTGGO4P_;64Ckx5W
zPMMY=r!Xe7GE4Ryasc|FBucnf?3;R!YgA^UEzLZbWR?*L=|l$GpdAG%xJKNkX`^gu
z)|5eWtmZM9aVd%B(BuRQdrGFr9WI2iM5G;KO&m()13BEoL!QHgV=_RTjq*_uA%(Lr
z7YmbxVzV4|Gz(43%vRopg^wN)KAc9+#I!V$7c?<e3;jnB-Z4Xm$Av^k2#>=aL(K_U
zVmk%<NIXkhCw^t&86<XvT2ic(MOqBuim4ats~v7mm}$PrJw>9zLUk}^P8Le%(Q5S`
z!j6gbtJXHAnu=UmS>DHVV>6Nk8HwSur<$`6k_z66Z7v&79<_UGBeKKHQ*6_wnJv*4
zb2cjcdyj|=LN_5T<>Bgxhh!wiWTj+;X4)v+Ped~$$mq-z(9S-@t{ByObKPib+Sm*d
z{u0^8f)=SZX?7-PjRsxpJmp5AsSu}|6C*NcYLYIvu2k(#2`lc&h#L|b&DaAd!;#@p
zc&<-$#1h7df)8o7%0AGIaqnx{k7xIOmjifn?}XWhH&LO@E4fzU396NBl%9&aK2Wu&
zG0B({M$ptM+(Vvwha@IiM2&RtjH8kh+|M$RhLoaIaO@&dfgkFgO_g|oglbzBiX@I5
zrIJiDTW?~Uw{$USW^)$nsvRC0MXVwC2kl%tnlKTWu_WY%N2MBAf(GP;S59`Mc+^3h
z5UsZc57y-77EEogv8U2B$7H(OD|=aL*U@H+VAG7L5}B0s6G&xD%GBvH-9<O|M^t=s
z1pRZet>*MGDU?sPC>eTUkIU^J4sk44J3KRi+Qt-1f@Kcj_^IHj(PpWVpOxB=)b5ER
zHmTl;5Gt8C&EPa!b}|whWJ^jSiJGy;P+F?qL`QriW0q+dY{srFv(hdS88y$W1dG{S
z?s15%D!<qSOA4kIaV$piNgSCZ)k>sCrFI5b)95X=ZfawU`AOU&V;fiVko$lBD(oHN
zzH2lp58s=^V(nFPvvU=HkG~PO|6Kp~FYwcdA58DR*<yE?@{W&g6kgKGcj$Vtc8?<(
z@hKSQ=+MK$tPAw8dih>YzSo!i8mRp4l;h%Vkkj>*-LPNa4jJIyR(9_tzlX^0q4ImQ
z9A~ub9wXo5<n+hOd8f(l>5Pe0P3$Yi9s`SvtCt);SH^jPd|xR0+hzYeIi2MMSc!jL
zeqSr&vtG{cW!ZhZjNd1+|Ch3Vb8o3ElrsDGUcR+nlE1Om>)(#rf5}z*;+EuJ`{K)g
zFW!IW_5V8$$k+dNR%lA{frn1No;u`*7S37NR(5{rJL$f5gLGf;!YOQlVy5}I;=Yl>
z7p*(7&R9#b3vNhvlYHNLo8d#``!))H_{Fm?wq)mCbiFvC_Vnkk6;GpR02y^+@(Cl0
zKaqOk{+q)eJO1sdtBm!SFU5o&2Yr5@b0*f4Ab_9?L1zL#0wY0l0$&0>LB&}UD<g0b
zoFq6-@EO4of<puc2=)>b66_#&hhPiAW`a!w>j_p6EF)MXhtDOLO^`*9NHCEgnjnn8
zM9`lgfS?tDFF`$BrJSaxcScbDJ>f;*A~;2GoZtY#I|LgEo+QX6$Re0XFos|_K^Q@Q
zf}R9j2>b|I5i}+6A<z+2oH4PV362vSA}Bl~h2KK=jRY$Q@(8R14-pI}2qWlE(3yZC
z{%MoIw=VheU%C8Rg#4}V8g?_T`g<zFthhkDaoNPyTp=1M?y{C4jLX-mize}$Tc7<)
zm!{hN&$`#<|7XM3=Kr7TU%zg(@5rOtrIjxwen1)VAp!XDS>ijR=Myc|>35TX5%0G0
zzcu8@myW_4{c8ub1&y4xnlDVpOt%HfRee6G=+)iVFi)?)qn!VLzofl1S~1`1Ow*A@
zOw3hsG3Qz&O;1$eyhWX^A$QczJ9J09BXozqi|&}GQJ`E@PIJ0rE*7Avo{mQBW*Az7
zJJNrs26tSuRSczeUsQ|xidx(^*5dw7E$#<uaX(&*yQ>CwjLqfbt{<&oE-JjU@+PLT
zF&frcQ~BOJR>L;xE8hzzYgn>p<$LEu^6yaje#AlVzLoE@pQZ4+%J);xYs7c4%KOk4
zH0(iDelP%MBrpjqm7P^JU){QOV?%}vVR3PBEF~p{*=#ncqH=TTKbNgov4Xw)^2_Yq
zci&}&g@x?PFTZ3rZrosU)6Eru>7@*BKJ4*BxjxLWf7YzS;`J~;Uy<umF>BV`xd?Ec
zAF4Ra4_zVe{q(M<m-7^t-e=9iyX)|wLx;pWhE#?_me2EwB;h}6ZkhgPip=-P@3Ri;
z%Mm{*sX}_sLHI+5ladbam)|QSe;lJ)fp<#3g8Xq&m>em6={@a=2!H6%;eC?B6_NgT
z$X|M={5f|X#-bwJfM3PotKZSvW%vvH7gj7jRB`As(!l$T(Gw#mKt&p*Pw$>P4mQ1a
z)uF>gLK4bHfBf|YP0mYlL^<BC=ilFW_@ToTVhM^%U-8PbJ^Dxi#C!S2hu62;bV!5+
zko(Ue{dqY>7dimK|C4oN4wY9N&Mg$-4|9Hf?C$ak;f?TAz9p;5x$qX{k0e}@H^K`$
z62~QPk-or9@@D!)@+En*iZ+Egr?k1j!~$(ppe4}cGO44f1vGLvb-dtOAcuhGG7W*2
zz?;B8(1wH0ePv$16`%L)*^@;@MX{Ke820eP4_D#wWy_YaS6_XVZP~I#@c0*Be8JA0
zJLl%}ET~&HQy;o{yEkg$k*r7fwxr!GXZQKtNz*e~4pmXoZq9Rdm&Ow(OwalC_xNq}
zkn{Yx37lU`ns@Nr*s)`GCk^lU8r|ckN6r|@`PO(o-_dFJgt74~hp*ecbu7|*cPY}(
z;ry2?S2i=j#g8yHzfBwN>)nPktqiOVP{Mf2V35iQWn>cNRJW$6Lx&E`-`}4F1O%`F
z0|u~=kPsFT5h2QM)TmJ`Ha3=xA3vT=nly>cPaMpqO`FD2Q&U-bdOEXMETaFIH*X$W
zYYS$tJv@NDJwJ%qr-id6(?i*lnIY^si;2CzpdWiZH-bI8U<%v5B8%;Nd>A{jZaV9{
zi?c3!IP0;Gv*5j)_4<&r{-1C*@ng<HKjUoJ3C>1+$5}SP*fX3>_>r@zr#PGPGiM7H
zEMN|YgDqdaoIUf*Gi>F`m2B0jRcy_gHEhF%4WfQGZ{EzdZrv*SvK>2iuw%uW*}@B)
zZ7t*MgAYDn2M-=(AAkHYJ9_je`|PvN*ohM-*f-yN!_J>O&W`=Y+3C}#1z(hul(0+Z
ze`4QX<*cl%j9s~MMeqtPkM1-+L^I|^Oru}MSbgG~2GrOaQ3E#eJJ<l;gH7P0*c?8C
zt>DYqR{kdYj2~6{Q`VH?x1;z06n_B4A5QVdQ~YTZe>QK-7E}CH6#os1Ur6ykrTAx6
z@jFs{6UBd!;#(>HQi}fy#ot5mk5c^O6#rX_|2@Soq4?)1{$*AC?j0G6rm0UBO~02}
z8QZ*+=H#!?m{v@U@YBYOAMe5VH=`IoJA?6`mNQ=VCgYb?@tacob`(E=;t!<wQ52uj
zDodgGb142|iocrT|C8buQT$IS{y9~A5<a4-DQA(ef%6(R)4b|1^*?1K#Bk#sj1Q#v
z6Dj_~6#p5Dzm4L5ri#xRv1oP|wb{088S|%R+nXIG&M#vTj5mIe@g7->k9w5x8LJpy
z{ubkJ9$@_FcdGbCir<^!52yH3DE@4Uzm(#yr}%GE{9P1(KgFj!m!G8g=O})eJAM~R
zVHl;5LMc2(DQut=_EHL`DTT7eoc-2=vrD5myF7!lE6X{%`X*=Bj&gVWyD5HGiXTkz
zM^pT%6n`egUqta&Qv8=F{uYYAhvFZm_$MiTsVcr+E`eqg|89!kmg0A$_+2ReK#D((
z;?JP?ODO(J6n{6xKcR|W^@^7+wNq&5ppZc!Lch<3-`BZ=U%Pf4hq!%121Q0hgoQ<h
z1_y_P#dq!8sZ$5PAw$|LDTGCkH~mM@Ls(e6|Gfw>WQbArkBkZpj|`^d!$U)Y2Zh9U
zL4Xb&+O?JaBce<pks+aBp%fo@b?f5qKQO)$$;hZk<r;i<^Sk1^b(2!?YuDD;ehA`I
z`jL?l!IAN;o3v<7{uH3I9H3)7#Saca<j~0YyPGs=A^8g&{n{A`$q0A)@y(hxX)<hp
z2;eUQv^64rXc&A$;NP@K>tQl#!|y{56hA&VBx*!tWO!tJOC->u`CWJ2>Eq+mYB+L$
zf0Vc={gzb%#G@GC9~vGN5g8d39@VBw0P^p2pGbdDR9IwqR9MvDds;S=1Hk{@&RvHy
zDg989g;Hwq{SiPeKaqZqpeQQhsPM=rL4?RbDSyI0KCFicC`3{kEe8*7(xeFmaQnyi
z_KG)k52p-9kpDe{2MZKhx&1>8o`yb+0>UH1qNtPyw-H3N9xSs*aKDg{`?UtofZ+J3
z_^60*8OtbzyCOn+4hrqA)6^d!d!Vc$!rYpgi1@zUed~E?G>wN6hCneYGME^t(m&*Z
zUIBsiwE8<D$TM^h@p8|ep`n%j@$rK~Mg}$V_UuiMq47vPBCIn1_)r8H8Pw3j+XVm6
zU}D!uR_TxOAqF!wXxwOId}vf~5b+vg>hz^+sBh!GQ6W^05h`z_A11uX{ei&Hpops8
z68}*8VZ?|L;l27*^H!x#MH3OyubMZDta?RN^X9xTr`(Vme2N5#!oNqJ%c%isl;v_+
za5Z_ZZaGDf=SGhnE##5;<{@s`<K@`{*`kziw!#w1wk!;1o1dM}9ymZU1@&`7zvL|T
zj3hJ6ru)-RKh2(d?m4!4^=h_u?OL{e{dyrQy#4muLLPkYz4wHy@Ok0O>^YJ*Hj}Kd
zckf>I$tRx(+2HJ%@7S3$XV}@ZXIW`!Df{{7pV@C0&I{S#_uqeK*RNk^%dc?uCcPiM
zrs`+A<Ku@1XrQBZxoj#8baQB+dz=Qkmsn%Ih4tXO*eHI0&EUt_a(<G%$<NXFU8agp
z17bAI=(A|BUDk!-_onzJiXTbwCs6zu6#p@bznbE|Mez?({K|3eKXS@{<dpxda!O0N
z4`|u4rC7RZA+(?^n|J8my*o@Hw=}kF*}P@j``Y+6YIG0rS&Md^J9OyOp?hOr!@UjZ
zy=B|>ojOt2#=dR3`*-(et=iq!xqIvS-5XPYMhzR@)2eNU&fOc-?|hH!U^I5Vue)CF
z)0yJjdq<;&Et}tUU-t%jef@f#o<8>)3@vqDE$?gHKwlpY-F@3M^VWE`>yE2+Jx`>6
zXLFAx^wyw#{d)EMseQHWaJRM<`BIeD^iKKvw`$s{y?^)a{`i21^1sjD-_PH_t-qkJ
z6<t_EZQE8_smn1i)*nhZtqip(>ouw{2#<{tZ6y5=j!Sq*1Togx&)&wRZ0Yb)fv247
zf5r7zmMVZRwoo){)20my6@bs;I@YUKk9rnifR##0n3ABLLTtlOO8oD-v~s#Ww;3Mg
zis2FLZ+zi}7vgB#dH?+R^FRFh>#sl3*mLHWUw%19_wO!Ux^$lArDso`Jo)DS{rjC7
zjmE!!|Nh-&nwrb$U`q<h;m?#G>KX&{9UVJ%Y)^NTRioRC+kC==3BkSTqUXE6{PN4k
zX&%jY@7~RS{P9Ol<0=2*i!Y#{;@^Gu9jEy>hd<H4X`KDW<#Lq}t*1Zz^wZ~yii&au
z4H^{4q<X>@oV%E`MFzN_UhB(%XJtzew%)Wx*!1-D!1D6)KNz~f+sD5JmG@z4gFTVP
z0}njV5%>{a0{;&`{E)x<?z^1u<L|ulj==lexpVx7AAaCRjvV1fj~*4_5Qk(0xSyps
zFTDBYoAb7B-#(8-ws5=MJ~AsSD{Se~rO_l;12=3B^1th@y8;~!$AkCZe?Q8ud01Fj
zXQcaQ@xOTSA}3j9dHeS5dr=uK{pqKlcwu3oyPOXnKFq)R>MMaK)sMg(&!<kE;$MIL
zwRi_j3Xser?!<GKE?l@!PJDNb(scdt#~=K+-+sIJ`RAX%`~COde@A&;ML44K32JY>
z2#2MJ`)Bbdc?x;C0r)Eb8WcdCC;<EwI+SMxs?(wX;p_&gb2q5n0e=Pm;^N{ZRFCb5
zC-OkUo;`a6{@{-jCr*euIDPuGcn6MX6V!&q{n)W%0?;;4AGo95&~^~#qmMok_@fS~
z{d3gAjT<+(`l9!1<X!=PYQy*c8T>C_zRYPD68zt%PoIw9V*v2~_~VcH`|rQcsm?jc
z%%TmW{81kV4;~Z%+z%W$All0D<HyA_Xh0tTenUG!9Ras(zjAIq!Fli}ocBD)dG`-+
z&Ku|53OOJBA?L52<NWu_myc0fY4vCD-?eMkaz8)6UL?aWrT!B2A!q=;D07r6=s{fo
zcRZu+zy0=G0eD84qr8DH_yDv3Z<Igk_{E<&5Bq|1)2EyV9p?OjL!1X5AR6{^ejm}$
zaVO{P-s61fNzN-ODpvg&{Hd>Z1MpWssS5@EN;^S20Kde2%lVMwoQHl+<qsOD4tjsY
z`Tayg#+RI5uHZcBDCYsY+)ER;h5wZ+SHR0l0s{lv5ijI{2C9dfXaO$ZBj8vQ9VmB{
zIqC>}1O7+9OLI1X&`836*w+#bgFfSYAmQ4NXy`?JlXYCeKjj$bemkT#al81_n8B6)
zAN)__5eHPS6NS%FuBZ#}6?j9T18p392EIqTQ0{0KxMEIoK7we7B>o@#r9{JkBb@jB
zSfU|-+CrB-oOj;+=kce$czK5o9ePncEJZs*-%=AD;Pu-03*`@gj0=c|enx%8o~1Sl
z8ouE?f@laQ8aDsJZ|Ax|@N8}PU%h&j(>PNFK!XAb9W~WSO>|tlc8wo>cQxNIH<CX)
zBbYy(X%a|0_ygx-zvq0^DbAxn!&h>9CZ6f9wC96Tdq$tsahKGdyY7(MH1)WLYQvxE
zc}dTnJ=;-#o(KHFC)Mcy--EBK)1lA;UI!n2cW4WLc~*bE&NhHQpFL2}fNN3-=i_A>
zqQB#OIN>z(D^+_24RU+#hCYe<)DF}qwIv$byd(9kbS<a}|90)#x%r>Qc#QKm)d$)y
z#sj4;&>rxv&;b0Y-{XbPB=Xnh^ye?l8o*y98dehxxDu%UoJcf`BRs~Ok!VobGiXrS
zGy0?+`>EWEIlmV)Q286*rS^Y7B=bp4_)~u`_@CO^QpiJSa|#^_EuaD8L2bMR{LxQt
zT@b?GcqE9wN;GUB8rE7R{Ikz<{!l5=;Nm>)oYbDtCq;f;*`7gz(w;$s(w@;Lb$(wY
zbEP`|XlEE-NX~KtXi%U!9W}KPg%(`fbNceP=Jw-nJRHPdnN2jz9Ke4s`-y+~heSg>
z(J<jhqCwT3BjxrSa!l%z`g|;n&q|-viD+p5evSQ-z@Oy%CB1s}YDY3k9`HxMh&y-&
zG(hH2Xn`BXT175{AI4kA47lFQ?aQ~#@5|pL8eS(FHWCdxR%Y@`=Syy@vne4u)2UAS
zDD7F6F*@z48GrN_3jg=(*RLb$LIJc_;0@e>yFv^4e)RX4*P!3TScS0-*RF+q_`5{I
z*7^PT=D9(96VXt;JwHW#((?2WzGV6!z9=P>+oy%{oWwBhv^~hb{ql&QK`mo+lVyzB
z@TdM>@IT?R6nFzK+<_DDMtcC>N}ZsOSIfs3e?cSozj)C=zLRKphiKR`k7%H_fc6X;
zUX*EADbuhFG^7sVk0lcgNnw0`Vz{6I7y6`rDjB2K2Q~9Q`V5R=kRt#aH*Vywz4jW1
zT%>@yPU>nW*RNmaN1jjMMfL~yjs-*mwS~8dhJVWK8GX`P+d#hBGLWyx3g%B{nE2yq
zA>2tcJW4byBpT)s4Y;by7?Y3H-2VW7;swF~#MgPC<<UnU<(oEb67<{-9SSXo>pJ>2
z-;?(MFC-e?CmKY1CK}KuDeZX;^+~HN!Tgyl6MuqeSV}Z3CK~dIj~1B4!A+u13Q@@z
zZ<p5G{{w%8|AT^pIsymaw`kEKHx1S4sEd~C*DLtxqG$OBOG5c>dmsM3+@9Z3wdeIR
z4bRCm{Db&t>GTlpNRep3C1ea5pNA8y{!xs-AF-RS7N~O?f0vIMH7YVABjZEhiuQ;$
zFn|7hL4%sVZdE6^qfJ$xW7Twhx%UmXjDhxCAh+jgSDo??@JHPb9Xb^Cz+ZXg6(M^;
zmT@>7eCEuVZW`*Mqpmu^g+6J^{M%^HL_-bzOl?;Sl+&_h%ZjM)<efTo;_>nEe8Ywf
z9OH6!b~d+Kt$fLnC8Aw_^UXJ+-+?St6D`0SV*~ms$U=}uF(1H%_I&sy8?X3-<{Rr~
zy4$lNW2}_h^D=4+x59tNjvWS)b;c<8ckSA>cT!SPMq*-ODfOeG9$tL$MLu%mNFEat
z!wU)u_|s26&7XYoNr4aM_rMo4U@X8mq0oUj3}`@q3O>YGh&=W>!}zB!1OLnX!}T*O
zWsI4UjDhxyKIz%nQ9%Ee^RNE>`#Ykdq85OEh}W0Xyua7hty?!y8|LK4XV0F^sZDUa
z4;wa2$Os>N@PXh5;0|0-M+#pl^#S_8dzj}yu0vg*J)ljC_DuDlZqKh&YtM(azW_P#
zx!Yl$zJ2>XxpL)7p$9?Ua$DxPxw$w<khgE&p5J@#y_{rgfeY|J+fV~&P@p<30PvKO
zHu~0&S5M(P@=Y{8OELz==hx<i^6gJd<6nQYjbHx#_hVGwx2=Czv0??!%gejCeED*|
zaN)w=AAImZo|cv-%AMwwf|o!8+6CwYZlI$&Ezm(=90uQGj7D35J_7SdxIsoj-GP=G
zE+YTxw<x1OtN%e{YP)N)va-H=<dH{i0MEF%I00zW3Jv$&cORcMYnG@7j2Vh<N1+4w
z0)Iv4i@5>rXb)&3Xb;ufJH~AF+ynDx_9yjkXj|Za;-$3<7A*J-?KCnnlFywxSJVS&
z0RDpp4dUa*jT7#u1JIxVXi(<8n2SNa2Hyiu+`&VjP0d@7sSuv}l7IO5`SsqiWy|B3
zL;Mx|!J7c^67<b*176TM+iW(`enUe;xyfYW-MV!X^#FgwsZK{tyrr}a<qkeVe*nHh
ze~h|Q^c#c|mfLQ3{X*bRbT8@MyLUS(!#uR-ojZ358c;sa8&dlaG$bS>@ZrOU3*K74
ze!ajSWsNe&Gw?<`K>q`G$fn>Q$l7QJXai^yNEdxD;eLbC$!p%cxryri#l3s?x|p=)
z<9)mMBVV=rqm(NE^F`o8b<0V%z^-D^9;m)K@tfcQj8Q0KC61y`L_dl$MgRZSTW|3<
z-grZdf&cvHKSey0HI<W#`nE|lM$RSN_mJCTOj`H2-SrzGzd`;%|4;34Dc;fEa0f1^
zZ?swBQz1*Fr>Bd)mD;)(-_X~9zZE`2J3zZcoq$hJ2k4X4@(`YpF6s#Nf$^N^#TSO?
zH$86?cQ^iOURCq3nzw-)=mHO+Ej;$vW1RXdF;1&5;HCiLpr1isgbVzGIS~N3gRU1|
zcmX=bH69)we-?K){)+rh<(&r_lzy=$I#Ax|gJ|p)^91k|#@ZTm`T~E{jUq!}T?c#*
zUP76p4Xwat{y$&tRq$8yKl+I3V{CO=aEFe4;>3yknP;96{H-o`1rQFr1YXBG#sJ{1
ztdEdfyZT?iUEr^t|I*mA6nu#>2y`g=e)J#c>o6Xv=|I_T+qR8A`|PuVpOrQY0Nsji
z9&!`j!86MG0ri<LYqi>c1$Q_8>Tyvm!>DDOy6Ob5X3ZKAA9Nu+Xam0BE%cqBMZulq
z)0h4tzu$yEaG~}k_@Bn_JZ1h>7cGj;Q(3=5-M|g?psdNE&d?WOEdgs#par;79)G2u
zsS|&-{zsWh)m0~u?;-!-9qV!c@D}d-_U#k>F3JGy75onT(GG|o*Z+;U3;fmkPwFS!
z`XA7Mu@mwO`akdi#v_cKC}YeyQTC_@MZb%Bz&rYU^tI^6Xig#4HHhZF8+U;}c(*P-
zuZ`c;eG&W>y#>k{G=kTOk8Y5R;G(+1xZ3h>#vK>Tk=*%j2IPT#4}Xj49-d2s%kEjT
zDwsFF5j<<wDaL}!q&q$R&3CPQ*T{GFH{CVW(pTl1E8h$M4*YZEJD2Vn`L31k-tyfb
z-`mLdVELXS-??<x;9m8+9V7b-7xwpf%iziCkQJftBREKKx!QaY?^sc(t`Ds3LSD^D
z_6?vhKhkVAk0N<LjQV_R!^XBV$lT4CicgXDH|3nqJj40WFQhd#=z_7PaDOr96F=en
zi{At;b>RS7TX}kVK0tH38PulB(Vvmb`8)NuCDbqdO#RXclFwfx**2AAV0^>SgP<MB
z8|SB;mDb6i3&lELkgUu7>>}rfFK`~bSLFX|9r?GWK71YJS*~7BSN57H`g2+4zd>-3
z`rKpGZ@!0wv1W?(MyzvTeFZvk=wd&=#QBlmZfmW#4f^SY3l}Cl`Q($azyY!o<_{Pj
z(XV4HLSGG87IF&w@QiDMt8%>%Ydl!*giaglJJ88vjqO(XV-7%b&<vU{q$=}!%yW@1
z<Y<(MGUtKZq`t6T_TZ1wdLP!xwv^SRx~OuUuf`7|fA!vn>U$ngCK$hdId_7;Y>yRs
z%%!ppaLO;7$Nwa)o5q}x)_s-z18RQ6`ViI``_ujNsyx{SV+ze*6G+aDRqw+<{X+%@
zE*O8_Uzsj+V9*CcC$HoWnEaEp?uqp_!H>tKwKlBrfFH3&g|$ws6OR8#L_MJ7k8zyl
z`x*1*%}Z6UcPsKN?vSnDm>(*1iO}alkEqTcYp+;8j;qFxCV7npYkgQ_0zdlil==rH
zf5<=TwbJVA@4yAuW_f*L-AqXzd+Gd7e8GjPIDj8xtMOy7yk;6G^JBGjI*~uklM+_0
zTp6pz19^kbamR)AHt1Bbz5t!@wr8?#xn}s&ADmkVmjOqmwKlW~taqyOhg>md&YX;#
zoSank+ADB?-UMZV3;K1eHN7sc_hFq0`cUvA)|jxiVVBpJ=1!I1>4hl*2f>d=D%ZZN
z=U;s-xcV9}>c8l*V6onXwIb*=p&M8D5qfc~uV8ILtZ~Wt&r2LE@*1Mz#{q|`)<0x2
zhr^MuYSpS(v_;JKA)kY8;DR#1{nK?RV%-qyRnV)xChN9ekk=Q`Ca^w&wZdF;n7a&c
zsrzWG-KzN?ZR_EOAI_luKUG;Dz`Ou+JCq6f9+br;*H`?*C!)nV0rb<GW&QekRhz&%
zlT%(N%aL)wCHRr@ok(!<O4atS%+JscA@i%(S=4KHD5qPk86Dg6PqD^=wYogQVZOZ9
zsJd?I|B%1a=}dV3`R8M?HUxPbcqsE~W#1t1Kv|$af*&rd-@fs1Wt*spA62|oWB(5s
zd+yx18IL{oSUSq#@y8z*{T}*VjD6_;!3!u4@FMb7uQ~mC<}?1wnJ=hKRO83A5cgVH
zUHM~7ft~|8U6e8ASJW2Wy7cO6VM^VgE<RWu&CAYy#?OEMMI}F4EBW!c`Qwp&jpIM1
z@1f)$8ykB%I5=47U9mQul9Iv~FJ3I>cfd*M3zWVR^@Fmx=sLkaSv#G-YY!270Th0G
zan4}=)>B!$^z2E_Ymt8j4jdS0GMVOpj`{QFXHJ<iWq&|G0G~d6y3hkJUAk20E|j?s
z${cr;zp}Rx<xzc1#)UK~+^57_b;^HTyLKH*?Ox0SG1g;U25U<sXYmOWCJ4G~(=}JG
z8)Y0<_Eu8z*!Nub2mVz4$eZMkpRkq)y>UcDgwVeNhZ!?wh;m1NpsbN7JfP^16@H*`
zq9QFVZ5r`%Hpxi%up4v!Tg|E3psc9umnA1B@534obo67#j^(Hetgq3y>|QTGxhs6A
z>=9A!G*<mV<@pGu^#aY$e__%m8@IaJC^~+m0oe}a4P7pH5V~}%YoL9o*AY+$=ob(V
zxS%Z1Z==ryp1XJNew^Lj8ii>8OO`B2Si5#@tTN|DJp+en)24BMe}6t=#0Y_#qW4qQ
zhY${Yqx2Wpm-yCOZ^0yHv)jm9<c~bj|Jd#JRHO%;JjQ(VIaphmG-;ApV@A6`SX?Lr
zMaK(y8EYz#+lhu%e<E*p{?&C@YMlheBa6i%`UdP(RrHFeFO)UtMxT7_*s+)XWZoiw
z<U@Up=>KcNLy>{seDh7ddi83dD@NZ4os+Vr_!sjQ`6C}?`~@$8UPT5++f&vhfdhC9
zYaGx&ZQs6K*(dl{^LEpJJ33JGGwAzJ&zm=I2LJs+W#M3w{^YM-_}0YtF9O=vt@^iG
zuZlLg!KXA;zP$z9>YH8lx4Z6mOoHn6SN_CzyT)4ar17v#ZGOa$p)b7f!j>0beDN~%
zQNM23u;Cvsz4TI*erMCBP3I|%%vWE1Rk%|a-MV$_BG#-~v+MQOUl;YMjA5u}YSUk+
z<6}LosHg~f)@zi;DdN9NXor{^gJ0jEIY`Xc(mtqQlCPgTBa+&##79{0G-NnMo>AHq
z`m*>EY0d=s^ivXRdhV|xA2W=>$O~;vnG>mH!GvF=Iq>%1ZW@MvC)kF*3GE2DD&Kb;
z*|DB4&y-}tsq)+j^GD2IF;~D`C4lBiD+w>GwPH>V+`<3I_m%k(LdLmBbFk+wNoim%
zj=2}+ewg=R-r0xdoseN5Qvq-ETevWXfxP(kQ!_*w>Z|mcq|<>O0dqE#AL<EXkg^B$
z{YS%vyajm=vL0kj$hw$sY+B_IX<*JVl<+|PjUPW=taGCeLphw<yOwXu9U$hDkli7-
zW8Q$d(>(JKkw?sToNuIZdG5LAggl5nB3M^LU4mb#%i>3hHVe6b-c+~D4Pv*V{AgSd
z{T9~buzx@qOL4t9e<1(q)G<+>m_y~Ki2N@p^$*@dUk^S-U5*|-T9hgJY1HMndtT&k
zEgT~Df3BWAjDPsv%ZR^KiN9;tE+MNa`*F~3L*_z#pg&dPf@h57YW_!frT&#YNk|Lh
zB=X02gn0teM!!sBe~vmn`f1>ebWj#pD*{azv!PEyT+FjEcJJN0w@O@G^Sw8P_!2O!
z46F`N!g$MIfV+lyGo#U0SbKuSH4Q8hi#OO?^I)(u49fwqwx(sUN{lzyTGO$B0I7F^
zr8Q4Eq*2&e^O8dvg_SjL);}RT+nhcnZH{qvdRj*IfOa-ZM!)Q-$>#Kg?5^o4Q!Sa<
znMu~JQ!~^1C1j^}o7tnCF+Cw8CCQv^jWt`cQ!+CKwCm9=pxwZR^^L~<R*NlLoIrA$
zsRc^$C}y^Ks?CyOog=@Ki^V*{M!A?1qb(^jQ_{@S%-L>FwRgBU1db3HZk}mQGp6Bp
zK)ZzOh>V$;)6JH4Mq5hAR2-!+pj}czTDG~}!2bWQy(<r{qDbQpxl#cnLUt2S%ZEgg
zup#N`Yr1=Sx)X_928b@W0iOE;IY@*Ym5YE;6Ge?KLWHR3Mu=_}kp%?AfC?@`)QB94
z3tmCv0Y*7>IkFtf_B_RPx61$apRLMQH8s=o-hBP_*T3)g^}K%7o%9P2|GV;}U#?vy
z{fDhG>8D1UvP`<{PnDjMo|2k6cEae4j2|z$%Ky8vmxS9*oP~oFFcr)LkARKfHE;l|
zvclm|m<3B=HCzRo;hXRRyb4{5C>n{TpbGQ|YC><JUFbOKj{VrhX?QBG!1v(Ca06a}
zH{jRtoA^U~7$3o!+)8T55psq^QI|eWo9H|A0_|z{wTIZQ{agECd#(MN-JMZZ!=7Nn
z`FMT@pU2Pgm&B`Lw;1hAbh4cyr%rM=&n<NCa<{nK-8T1#+v)aDk?LwSTv0Vr%~W&M
zgQ`KTP`lJ6b)}Bdj=n?tLIaF?bGiw9fbPX-@I`zb8AjHVw@Hfql0BKF@)o{}ALQTg
zZep5P?nIdv(6RD1IYSo8GWmd9D4&$=@{l|s<K0A;xQ@HdZ4TMc>h5v(8%w@)zjePe
z)?9LXtNtoV4OI!sQnpG_<J4p|UFE6@b*HK^);+D7)Qid&n$g(i^VX4g7Q7DH!AL9D
zs<oC_Z(AQ(-C-mg0^=Zq<KRTN9Il6tqCcXQ=rB5l&LN-i^b}l$7a9M4iXrJsBWVI1
zO_$L(=zFxy?#BkPAj@GztOrlw8N5||BnCQuXSl<h6z68=9_L}F-dW>pa&|h$og3s-
zSs)L}b8@7+!F|sirEXO@YK~g0o>I@Mm(@OXT%A=HRWIE~57sHhpLgm-`V;L<E{!qV
zIUJOLH^D>JCMyY!g;U`YxC8El2VfiQfXCrkcoFtO15h;bqhSalhHgR=(PR`vHRy4)
z1zkW_-~<dY!xL~WUVwX%c!J0*QcAXv?c_spkQ_3o`JQx=OQa|5XIeUl4xz&-r4CJ|
zqv$xAPAAi8G?Nz5`{^I(61tQ&(m&HRbOU{vw$k17ecEP_c7;9I{>c8!?yyhTSFs1!
zLiP+>&DOIWY&YA-j<Zg7B_G5QS9}z|jR$xEU%}V$0|pak`9FEQct?CHP72%LaEepr
zR5|xLbxw=(o^#k>1<Pu=R_>Qy$PPKcWv((9UE^+a-*zL^V0Dwa-Sqr&wO4(v`fI3}
zo}p*yIeM+$q<82G+S^2;%;2CWxC%@FzXMsI3Oo%~fZgC@@EJG;TCF428EX*CgD;o}
z+y?i-Z$e)6qga%TCZVY)%S7T+=wp;<e7J~gCYxvki(&`(CEmxm-r4MY;}p6vDp7r*
zzEgR++>3`ypO2Z-I4}vE0?^8~7Fg}D0@b3i_$Ur1fYg!Y<Q1})y}_qA4Nj}kvD@{9
z7K8OB=x+e=U<9xL0UWr7Gb+G+;7?#HI02%pm*7Iwi255Yn1+|(=kbfU1@AQs5KAVL
z#iW63G=18i+H`;&ZO>x!*ao(RU1VW=03XT|`EhYc^mh6=1Dt4QzQO4VXOA;j4wFO*
zIZbAoSbSbK%k6Tf+$TSkz1{xqV7Eo3>KF8O{ki_T*S2b3XpPfeAR1(VN-!Q3naJ6T
zPN09F2uyGW?n$EQwKR#2r_<?7gN_t?y!}Q98xd>@`<`v*QUpb(_)?u#z4ajd8-0t;
zGJbndKdJwsx9Yt=)Kus5g?01#Ey{RfmDOgQvd){x4TF7Q1mrLX?}GDTEnEQWU_D$4
z8(<^+7M_HsV5ecx8K}T`dl9NfOHl*bioQmJ41>ntI1>%P3^N&)_yH3Sb+{fc#XHD3
z;-fw3K<Zh3J%u65i)b@_m7b>OXg9l;-OnCi`|TRTq;+;Qi)A)bY!qu|ud){QK0CwC
zGarxQMZBEf$(QhE{yKk)f56-LF@Bn#=RHLq@hfq)xIrWeE|eH8ZV>_TgjjEoKhZE@
zKyHwmWs5v72fEL?-3*7dsEzud=kG?J&zlgXpvk%$PC)md$It<E8Z9>ceiY{#B&{Qd
z$w{(`j<;vokJ_gVKOuIrbEACU{k6JLWqDk<&KKIvdKB1TF#ZaB4Q@BNW+&VOC!zo<
zM@vlqokcbH5Dp{PlaVBctR-j3GjuggH(6s2pCRUnW#T#ah^K2?Xsu%3Fpv)(1Dil2
z>_hsKfh3AtO|BzDNi1>51QI0k$zRDn@+}Fcw;SeIMqi;{(@6U|gN12!w%uem+uz$!
zEQY1AyA5Bou+4lc-y@ESdCoJ=e&>+$oLnPcHb~qrBVE6nWOBk`*EQT(W3o?^!HKsJ
zvNvfR3lhOYpc(YAc3a0FMgrY}evj@#UXFa193Y>N&kes(>Lp-rKido|U}c(!%(Kd@
zN^7;X&f2K97;o=Ve^YJhD|J+zQWsPY-B(BIYjliG&{#{Is?+o&9q{_&<PQsvoKl^t
zR<G2px<h+oRL{R*AP$TH*&q+pf|Z~Zbbv4`(gK#WGE7}dttM-m)o%HqA11>9%!E}Y
z?>8FGX@@?;-^nNw%|^b6ZoWwG-vGd9V{trz1CBZ4k|*<2K8C09bUw*sodD0|**uTW
z=Eb~>SMn-e&FAx4zJS;9dcKr5@J8OmSMt?{XE*ZAd<)-ZvT&=(!|(ET{uS@wNBK#9
zig)r0+$Va7Fws{;h)5AFt`U9_BjQAY00Ijpq(~O2VvI-=>0*+|Fu2VW*&<KO7R91W
zREjE5E#`|_(P3gb%<xK_ljdYN0VmUpDe?@Px4U1t9qv&#O!ZX}W;7A4u2Fs!qvA{s
zXG*GMm8!<5G?lI<sSH)D%2cJQQq^j{s#ObAovK&={l3yAUD738(j{H;{~$w$WQjm|
zXs7$)+4%*5?4qo4Z&yuIH1~=Mr_T<S<P;YLvdXgZ0~I-i6@k*MlKf)t^SNbtMTLnu
zl{w-4!qac=-Xk)k@SXBG<L@uO_TW}??H%3>M=)40J-;v*Oe~%|)IVbQ2!B>lc7EYZ
z;V&=C9l^Xi;rRu{MI~kalAOy|rE^Qe!*ffD3jC&`oYFG?kM})I;o<qY{$Q|hdO=Pw
z=yzRz?ByC_Md-IB^Kjzyl9?6L!0mq5C`~LapAlCQ8#m$y;{(Q!Il3y~86U4>ViWwa
z=J?q|@jq$Fsmw2n^K{3>$D3AmyCTx}%k8`@)uF#k{;bvMKkicE?Q6l!`EclK{{kb9
BEIa@J

diff --git venv/Scripts/pytest.exe venv/Scripts/pytest.exe
new file mode 100644
index 0000000000000000000000000000000000000000..c058a1c7d545ac646b3dc69ea5d149ef33d77782
GIT binary patch
literal 93052
zc%1CLe|!|xxi~!gE14vl%mN7n2oNDC8r0|#Bwd0FWJ6Sf3k$nMNWcnl-BQIc16T<p
zoh)WDY_+Z4tNm)PTxzdg?Jc*JUn;oEYBnfVK*cCjqfPOwlWHt6ED$o^=Q%UG325)_
z`^Wov|9R2OoH^$?zn=4)=RD7Io^!VPuE!V?!!Ty}Q&oo9&uIUg%>Vu`0e?A@Uddrz
z&Uojl{f33_T(#7H--g2V4G-MgaQBZ3@45T_`yb#7f4H`=LAby0zWWO+?(`J?_<=QR
zZ^+KhEYiz(^8B4QoPP4E#^m3fCl56K8Qw8VTjM4Ae!cNM`j#7Cg!czse`x%O!WK3@
zLgOFR;a}C?uhI9C`|j~$dH<;GZWqHWG+3Bde)Rrb$+#}YXvi{TGE4`2{923q)%EbO
z(L@a^7&bDDg)z|d<eLc_C=yG*F#tZD%@hz}Q}5J^{#$P{Ftcex49sub-_yX|2F97e
zFpqu4Fa`g^80;UsVywEbU;h~X27c{k9^OA_*BgX=HD3->$S|vKXjpSMe>cNq7VCYV
z4u3~4hl6^ZH)vqY8#A#ygH~qZJ8<C}8a6cC17X@%=rgkf-mKxf<u$Bb_W%I?XO4yg
zTHamXft&Y_d-(tV`+xFpncUOdV+I1)*)no2V}Da}4Ty~_Be+5?n_CsEq2RzpRrRaD
zBm77wZt?-l9Py1@Ey3-de!<C*2eTnA>~xdqxtM4T7}Pwb%gM;q1NL_a19W^O3N^{q
ztk157DhJ%$Axn7TT*keaC^<AoFwBoXfKhUWgB6T&B2;CNU2JhAR8caZyer36)nW-^
z&vc)EAygT14cJxx>S8EEY8;Rnd&#{}i~Wcr#yuYKF9nFjq)=7WfYGN41H_vT><!+l
z#xTrNl8aad231vjqexoTBe@ceSffd5OnAHin?SH@H1Jo=KzJVLjKGr8Q5eO_y~M6!
z)<Q>&pCI=JEH$CV_s>2jH?qYslPmF*+zVyKVg56RfOySb63Jp1$<-%Ar3}-1v1X{g
zWNin=(AvCMQ6D)v62JPOqPL)pa<4t?ILAE^_OFLNNkWgC+=kJvo?=&DzydYa0Ps^<
z8?b8f4$Cmm8u5+k#X@(n&{cf)A)~!Nz<9B$MOszRCm*>7Dx$@=j}M>g^gj;eyGhR_
zikDEu9JOwRl2b3+4(x`6ddCPpy~+{W@ReecT)kLS-B`%(>aAIIL>m~ZH*f<W$lfmr
z333%QqNWB0b%NLLzkaSpJJ15wtLCvl7?8qODi8YnFVnH?bHjMLNo<VPb&8dF9HleI
zpm1Brm2kiQ20-FiDuu&}bPq35$VEV(m!yxPH05X)-d9Za{z@!vZ#uMSmE2xOo9mT(
z)x2EDC0@-0i~$3n2a9s6c@;>uy}^FLs^-l`fJB;LsDykP{o&jgxzk@d7rT%VfCl6h
z0F*uK)Y7{X%{`}?<aByNYANbu5Kk-+mtFPwq>7>fHE#x1(iy5Kvbh86;kDTv$ndCn
z(>2Uk#Vtj)^@0ToRgCtq|0o@qB?GG3yrZZUXKe{$m*(WPoL0!`@1bzl0bHP>&I^e%
zd~R}T5k;fK7fq8(X8~BCUp?uD#5JT32q|VRvR=e&XJIx&ncr%Oe)6G~IE^Nr)Dru&
z#C7BqEwO?o9?%jE{^_HfOst}4B`%3-o)hW<;C#$6-R<-FfaZKE4~<guY>)=QT>olX
z!X_v|1}GRah|S-H=!H%dYEXc$Dr~o^h4Zy?fjiO9BJ6o9EvAGv1fp#k_c;m!vKa6#
zmsfn|WL|v<fIKkB>W4VK{G3oF3*3&|$J7JPCy9y4{I~$?CW1{PUBL>#0~)aK9%RUt
zYgw_Kl`qEM!6B_>16KcjER#6Xk@W<_z<NCX&Wp%<ese)pLl5V3`_jcX^09(ZSoT=G
zY(6=*9)H0AHeI-Y)6Oc!jF1Dta}fMXPH)N=_2R9Je2yQ>?MuUi<H-bQkg>ijP544j
z*smw>tUX*Wr9rBX)B!<wV1h4&n#QXEW_j}$IDderxXGpSSg);KbW9emhAiTo$sX?U
zu)meI>QhM7%7Lb}8^x#*8kmFvmUN6l9RMh(9$>KHS7S47N;V^(W>;u$3X+joP!?pU
z$BxM^t5gEqy>11am(4vzrr~Q5vgAB7jAgwzYcg*R6e^a$WHD^6S?neUP04|Z1-qb+
z9YFp{QE0tU8G+UPF6VoyllCB_#@7$w>fsFlsZOI6l;ihgo|X0xfKjqzL45xZB1K}9
zpTH0Mk$TBGFBI&Bu)AGb!pK_aznrj#gDT(zW<}v8#LBJ&5M$^OtjXSABfslNY{+XH
z(R3l3w>DkK<kROmIvT!KjPf^-u^*8+i)LGg*=jtYVBaOIB8@3N=k*0xfBX{8sS?VZ
z>|y&U$63s?hUS@-(1xi+z)UqYp*{GnFM9@GDVljEJ4qUpW+n<>(2<<te+&wNF?W;R
zb95pbS83z5E}0?IbPn<7hzf*exym0-W;sZ+Xz;VY2R;<+K~#CAXYfsa1P>|LjhGCV
zJ%ew59~OnA*l<pZML>VypdPytVr7~G=25812n&)aR_}OE=r4{OPsqJ8t>8NeQt<Qu
zW+dO2D0j$|U_x$4$cKdBDM&bcJYniEg)pBl#NWhv$w3&q)WG^z4kE6P_QUE=iAben
zqVDOTPuiEq0L1I{kzcdOb4z^WOCXJ-@gf)oM>f*5U_2X*Uk@@8u#WXA2u|hWfjm^H
zvD+R7hT`}XDssexT=L;KhKVtwfzObiK+qmm9tH@(N<{&XJU)SeD4U~&Pmo`YK@o$6
zoY~|VniJ#~MmYkKQGJ<1C?u_^;sS#qSFhWTjUl@W=rXD7gr(2s^^jjt;mszwx??Vs
zk5rOD*RF1I3i3x$3OWI6ZcS8H=@Kfiz!^u8Vn_^(u9Hg0yC@R0D@Fb$1{ZQ0$d6<s
zm6ohh8W4sV`jJj9A`}DbDJ=$;#(H^~RblHLZ}B6=FicgpK6pgvtuM3jz-)9dTzL8G
zp$RZwOY<ksg~_l~TlDk2<OM9TS6i>$qz1lfq_kuOi^a7Aj2Gn#Xb$$_+6f4aGH1V#
zU*;O%M-e|{LBb`gu%zk%iKT)<vVmUtoAyd8R(22h!L@+vN>;8~C*{aherb_e&T(Y>
z$IoT>k#ct7SP%@V)(hz*el@_Q$(3e@Wm-NYj+P-)DxD=&ldv2!#P&Pa8--l4YP}IE
zF({cb3ne?vm<UqGVKbv4pvMNwg|EzI<64et>kp9aIP$yv6s5Q!xF68HE&d_`G+Kiy
z|0xJvxuNP_Qlg^N*eh<%WrVrKpK|-m4lyyeAzMt`wTTtOh1|Yg;6}Z;U_o>iMyJu}
zFz|e}+QwJZ!y0&Ny`z_pDzlJ?xP2x!`T9DBfvnnhIxHF2Q5w>g3djce`Ap1d!JHl3
zKKQ@AIMUQOz|`^Sa&<zyd;O(VD|B3o<yA1Wj8}LFI05z)<!Fu0#*pZkR8Q;2=si{L
zk*lr2BmC#Z-$0LYuISM*=+QB5pW!<_iqIZGyG~%cj`302uEWI<WmG^XT%;6{DhakE
zC3#Q)xY)Jn0k2OiM;c^=e6r|9p#F*E$?HKuQn78%Uq{*CDc&qcLHY!(XozH&BmYhW
zRpIJ@wXV$a(lj89Y!6uiW#B^g0?dv-LkD3houn^Z7?oTPxd{Qt;n9cyD}(%CMQwCH
zW1GuFcZMr*70a!I{OSAAG@+z9+8fj5_Fb3~FuTcfH(`r*{bnW#t-{2B*(;S|8rgAK
zf+a9+d0o_g;sBPbSaxExWHpMBLh-P<`Fs<wj4fXV2I~OA1`s~^a3o=o&A}#+*5nJ~
z7n34iq{(I=AC+ev?YtR^G)gx?_Ib_c*F%Oae_CY^*G0*+84S}@&LjSK3+aP4sHIpJ
z83jCa7;~ZhbM!V$ZXR3>b#EFc|Eahma^50FY>P>KDZ?}`vNFJFYLrZ|y%4m3m4Mx0
zY(-4uHjWm<Ha96NMK)$_uF~KE#AO9aaBEqHa?qYTA`O$uX@&XCtF7ubRV|J{M`=N0
zX3*?f-qpkMR<l^-`P{})dLG(HV*f69MUmA5tY(S4w1~BzYFk-kJ$D!laQx`DO!2Vc
z=C}C<kr?=!wOHXxk(e7s`s9m|zp$oH@nti8s*GO+G7z7W%;AI_!rxa!5%#Zgrv2^L
z)xp87rt{)As{LIYyw4bep_%WJZyx~YDK{(p*ht(4K`R7}O2?|uJat7hG;eSfJ}=Sd
z06dd;f%c9R3EMpD&wqv{!7RTI#MPQ4e_cFWTmyOLl+SS%mayF1<g&0I)Uo(<1J$3s
zWWh`%I){sGNY{kJ4*+#CBRg|JV7OLp2hoHd4~u|!9w+U2oV1a`dI@GUNG<uoU+v-e
z=YScHC!l&?M^yuqoHuZQJ3vB^suPa4fmi(ND4Z(S;e6aN3YVMse?hpcn%yvhR!TNP
zY+!P{7MO_R?XB|zUG@{p&wV2%j19MhDl*t|R4zA-A_uYHHylyEAjTX8wyTT)F$vWS
zh{}jDhz~K$0vnS%fg5L&Nu!ceRM}3uwHTY}Q`hH`!cydn`GCt29*T&UX3*tV?p3Vh
z3(&;_*VVwf^NoiDf$h}D?V+_jAQo#T6qK`)JhBJalMPvVEef91Eb?AlY43+@$X9D>
zQjAs4f;^2fv{$voSRc8ND<652kUPZjJh#wB)~2e0@`3GHL5XU#0dl3<0a#SViH*4o
zp9`z>7;^o{6jwer0yz^E<z*osc)nHaQ0*tqohx(YZoEposPa}%0Cb}&r)Ki$=OaS^
zoAz+OZ_GVcX|=+TN{zkpr#vfH=1Z<VB|YZqLpvbIVJ#m+MLG~)0jn#Zvz%-FJ1!F!
z9i0tEIpJs=;2wDuB7EvhRN#aJ`Qfb$bM02MVUD3OQT!=z^lKXj<i_535TG2jeGMzc
z#y*ChbO2Wr`w7QK8#Cm{IiXLEDCu$(1JUBcN)}yk9G#nta@64(*t7zWp74^cIY7>C
z@|W_Y8S7zWfNKn{L~-Y}t^uXUOTI#i$Jiwz3=cmU21j)zS`E;>J5&%hTz$b)T<~hT
zK<CC^!$qeN6k!|_93Ga8xs?`9A~wYJWN3B#QG{A#EtF%$z_QN?ws?ycV^exSxO@zS
z%Pt%09+J>qCfN8J%Y<D1x-ubOxSp2ILFs6aA+OBQ3SVPO4P-iI43odwsMMFQO?L@#
znSU9zd`OK&xx)lTizYBCG~06*Qv5uX4YYX3co(I^+}bEKbvHJ(6l**s)uJ5S$T}{f
zWE+Jd-sMt_YCwBXhZ=vAu772<Rtm$PmKs?fiJiw5)(-S9usVeYeB}0W9p&T2#30CC
z$08Rjz#u-G6!|R8WPJjcEX8tQGe~XybBneK*COax1kIJ{64Ny)(v@a1hcv+b6wq1J
z#OIRop%!(a>9V?8EvxMoruc|bj&dd1O<{gpedLolD3y2nyyV9e#RXSN)j>{|s<)g^
zA!_k{+=ZzxbFl(Q%ST|5H)x+5K$LQU1lcnIRQG-6xyl3-X#<9ki*=*9b&Vzso328W
z2L4rBr$qGmzgTwJ&^$((a#D?-l7nbG5`~r4N{t)UEX?N#GD~N*ZwT;0HUh?f#-N}#
z!iO@`4cxvtkgXnA!AKeOs>8!|>|W3i8Hk8L#0Y>EKByPV7^!-IpA8(5+cyiOeaxB1
z?Yjvxw*%~9fHmrwf4~Ts88Zp*E7Xo*fN$sma7WibapYX*`0y0hz^b|wL$rE;J;7?~
zxCkWkbatxgw`OZ3vleg&YFViR2M7o`QMSt5Xp&Z$0|t+m{P8wA0bu!ZM7bRoad3RF
zDC6dYz!ons$ETtmm@ePR%ALg@Nwt0bhfUCzlSopzl$69XlOku*`YUcWHvz33cO2Vb
zlY5(fkSQ4E&vTq?_!jcu%ooPX(Kwm|TTX2Ln)F$d?TkMH51?EF*YYy0-3(Y`uUgg@
ze~t?J30X)KM@)w!7cEdzsNfl_6ZAdVL~AX9S|17+kyRwfnJUfn=^79U<pr=Zv8E0s
zqiI&AU{YPI6NH<y=N4FTi$`%{4$2?@yGmzX4_N?R$}B2I0?lo*$#+`&BP`FJi{OID
zo8$%gv|_B)%wv%t9srw@U416kKphJ5Fr|;-l>VWW&Qli)^AtulkC;*&Ccn+11EWks
z>dyj|x(1ar{J0L+zVFdMYpnWQara*)B+8Z6=S9IrOVkR-a_<$pz7`v82C332<ao&k
zz^4o#pRKhqHC{4t8WdS+t!W8A#EM-50Hch4-oTH1p5=31z-|iZvC4czfyT1DWMCHM
z@ofvx%!jtHgvvb;3C&gOC<p7s?rzAsqPw}N7Lk3KTC;AI1slw@OmWb_Tf{-5@G<TG
zw|f7*I$NEjtIXfUf+tJI!tLLtuppK<%|x9^E?om6HF6DQlMfW88_G&oLIi&=8N8ig
zc9Dr7VdvkDdhSCRr1dro2zO|ipiOhBg6+Vv7eiW&oKU8@NhJmyv5n*8w0d#&=5k?#
z53S^cPZA8ziS1??bbH|huKXZ3q=hOr8<jpli;aOAS3=hV>0}>h%{90d4QLF05Se#7
zaHOv?l2YO?AOvfb!b`URp8&RClu7`hf{lXmAHZOcEEOfAPRA$w2OjbQG$OR#5HNbl
zs9p_Y>2}o-1NQY~Mp6tTp$ruN0GG;mkJn9ZDc0skOt=bbiD4~LV+zrubVPp%xuQP&
zN1kVC4+^GTX8G`m@2Y_0TylNJko*IXSuv%eztSr5v%F-_R2-HBnRy4i$-bGmdscrt
z)sN{^dskIP%9RCZqI8qdUqct_3t-i%w=$^rQPL_w9Oh?e>kL|eSZXY!1olTZRkN4X
z2rL__cJkS@2<Sx-_QFg4^Y2LlBeT`Zrx&i*%KI{kqv!rUjHG&iT8yBbtuLffJ2@~h
zsoowLkK#KtF4ynI#y!lUkWp6pED)iP<@E*(poy)6#b|%^UAS^taKDzf;K<J0IUB;w
z`!NRh--Ry^WYN{FH6LPx)8c*}-Z>lJvmYtjO&GKQMx^R)a#t25RyI&TP+qSgYQ7#}
zBMWK7y>}w*43L`&DSfkn@gzC{+NtLGp(VSXM(y&YMKBAxaTa`0twXWo8H6IM@6aPM
z$PSDM7|1=?O&~i^b{@j0oj8|vt%iqNEnSMre5o6rWKxelSG&rDZXwN03;<20!9%%0
zcJ;`toFP@8b}uG>z^MfIT}x!wX#f`+yBUQ4q5uUhfY*mac6E_;=`e2O6KHV!3Eb>c
zsbzc`D1^HblYsSS_u(_I7oQV)@L5XmS>6rL`W<<;LVRVL>1#q4jkKJmuc@8%b^ZJB
zdiqfd3m~$K*)=c;-{xHme1k->%Zl;TNE)+LL7D;n+lh(01^|OGOD{Y#%uG0D>6<v0
zx<F7RPzrWJmYuCMh?Z0}Zwn596N&(&{>LIjE~Dmc#!Z`-K665l$33=k1c22RU_^xR
zW7*mU9ca$$;WecE?949)ZS#Z&1s7PerDc86vV^p(S23YoTbxtKqxD%#+|8GWi3Wa(
znApURA=@pf$#SiQ3N&{EgMZZkI90Okr^M<3gOc%Th5={VfKiiX>__JMK)B&rPC|6(
zp>40A=RxoY*HU0WStu+fJlvzdMBROxND8@@eq4P>7Qdv5pD&Vp{(6yQ@>hXU&INZG
za6wIQK{VaPTnWUO__i$`g?HAc@z+oQh&s98?`XV}8t`JSUIdFjMH7u&@G;7q2E@M%
z!m=g4ZOn>6|Kn(D6&n+bz^BSBRPGnaQvNQH<nXR4zymZYPb6tva4Z0vi!xzAwkzvn
zWdSNaf}?rufciQNwW|;FD>u>DsTs=#k};F?JR_RlMhl9<?Wg)!CvUbNQH)ugDd~?3
zo~G(cFT=Gwi{|FSRob|e&EXRPlh^+;3_1xf)t3)0h})TBd)g2Xj9|GSq_SB2uR#tk
z`Ljaj8O(YRH8Y_Zuuv;=1FXM;CLbD}Y{O(Dqf8E@`%ly4e@i8g7u$0%*}x2=7rTm;
zjU;!QQbb}#!YJ@JQLBY5<igEBSoqF(=x(ZR%Ps_cO|^8P*8-?<RaUv$Ds47Pv!u<e
zw7Ed4vQb?)VDqm>PPy2GIu5n=1D!uN8LiZ{1Gp%5IjB933%!LC32k8^^X{^Ieg&FE
zP`;^p0nskZ4OLze6ShqwLzOl+*?ASU8gea<Cv&MYc6-UC9^8_l-?DjkzZ2FXtJ_PK
z{tcrmm7mKAXn=B0U>2!D#wKS|JD>T#L6=(Of0omWf~=a^s)_0qG)@==6_6hjC`dC7
z7VK8WrvTBEre&SI8)}eNSsfSo(arZ#n;Xd5(kfP(B&{kC@3g7O<tGa%I!3m@RE)|L
zEqe-6%PdHiyK;fY>c$9-0S>b@$+fTwUsU;Y4_S0Os(a5NzhVLlLv+6=0ITgMH^RiF
zY)s=!p<u}+jbBslBn7+RQwp8N=M$ayeCB<8?m33fgGX^2ZO0P{`U>^X*E1dT6?}uf
zo(t30?_Pt~(~kywFCharhpNp|2shtiv_52>QjlQUZ39xM8v{ToA#9giZG#xvmYx*9
z3@~y+W0E1-Y`4ZHfqZR2kP-Dx*HAgFdSI3PofYKiziI{|Sbq<V0p{rq7|EN|d<|Ou
za7J3EE99lQ)FR!gxg3~k)vhbG``<%zj@rX+{6}J%#-17(`w@rvoyTA-_)&Ak^Vc_g
z6RP@~cz(pDoIv(+7%=lYkB`KWvs9oDPEL)Z19Y~C7-nmuWE)3U@3j4iQFECn#6`)v
zWYmBbWz_{O^0`V)T#F@^{FKUmz2r4`OC=y49mRkC!cr%*MlD6J2)UxjCao*7h2XEa
z%j5M?V!6pRV1LssttFu80Qb~MPjV$fuHH4fFke)z?p-5gW3Xlwn%w?cyI3pz=uv&u
z$)`pzc>`-N#WH<zTDwbSboLl}*oLNqY<ZE{^se1Hi*Vi0>P1$$lGVP|zaUw#{Z4be
z#)4tgL(7Qd8IV`N8b+k*9`WKJzbbSaO#Bt{!tJ@CitRSZ)r*2_B6x()l|Lj{6;x^n
zhBrI6Es$Laxf5y?{?yc{GJKJoc6k$a{6%Ymmp0)CWD9LVpVqr58r0|xA>g*T?4Auj
z?h>vQ%b!F&f-m&ro1DE9IUU;9IC&W?%uCcfj2GVkoze<1<Z%Nvs+TRd@+18kQr?q0
z$iHaOa&-b3;uWpx|NQb+o%x(@O376$bnrUJiH;>|na9et+zA1_*tf}CNQ#d|dPH}Q
zrA0Ov>RfqYQU0<e?!}A!&RbG6ko3E$C}P)0Q+28+k(aXoJ>5Q5UT+l#2YCmSF+;pC
z$eSI1-*`i4#>UXfKicFhXtDUPnGufq4cLqMEII6Em;*S*`0+k`D7)7@ib6A5NdcKr
zDAs&#t~m{2_9Gl`hx%CPkiCPj(7R=_KVMyMRoC0l20TZ%zfu_JhGg82R{rQRD2A1<
zRUa%+AIw)DoJR6=z{6%{nb+r$zr;O%`w4r$T~&{-po-R)@;7n>IOZfbiZhUU1kzRY
z3~p3;eF0{P|I97uiL&U|3<E7i_oQ`2?2^UkcSH6J>gBV*Z2Y*GqgeJBdNQFO%M+1Z
zxM3wnQrjCqgyVH1xx;1Mz>!jv4fV~a+9>z?YM371fJS7fw1>sPu1%x70e1Md7fkP)
z#d6&7V)z0tS(U48d7Yr9DLyS(l#&f|11d|4888Amdi`$zMf_wCqxdl*$>yz9yvZJp
z?nkG^=>C!PX=d>`0>i)peR3}yKy)=M@VQCnwOBH@uS1SVTg}o|R@!Qfd}hmvgtppV
zeDTEtOfJ&36@ZKX^g3p2%QdvxoOcT6Lfa=8(2<YEu@JXNIJc@UxgHf*E?bX$p&+?{
z%zC3)&3hcWOm`=6fgYe;Yi*%khfYVVp|36Y6@az}F`}>~%$J0o`5Gd)y&c?MlcQtP
z=;Dae9eO+)(*uP|NZz$nVrrXj5TnMHuy7KFYa=>mLMEus4Rs@^8$H>`{KY6}cpx5P
zVX^V0l6{cLL;C5|uFwGnh6DJi*#m)&Q=lTm+YT32(;qSLIZX@GCfM3`Sg=@SM1RD{
z=V4SKMnOTXJJJwgN_y+lG=P15U0I@`F&6BGV*X7<H=1i{SbhSZp_Uv>HXRGyRVZE@
zyD772Va^0wXmO#EEnXPA$%>zap~YRTHpSG=FmoO6Hnb;~z2`o`We*MBC}Dkl9%PEA
zP~lJPq&w{k*7Fm@ZR;3*jJ(MY#K{H<$$z37lH5+xq3UQLn-rkC0BXko0$Qr0ly2A0
z4EFQmVC8&TBVDd}5UGSu_mUrfit-NvNelckg@$YZ`Xqo}rdR(=7P_H=&&Q-h8c<(6
zFfzD#^DGo2O(=l*0Srl)7_(pyIf$C~8z^X2?Evr6cX5>2;@~A=<ZzH@0Yo_^4h{$-
zk$*bPLy5{8m^U332yylLOLBW^Z@s7RGU3Te%@|~jO1+o*CA7*2IdYV|Lfv!XsIoxE
z?BTNgCD2E%<>y$lt6L10l=nig;frRKTmnU?g$KxHHBQ5Rsv5;W*m#~|j%)Fv^5h~w
zdvsD@)GZK2XJ}}Cf!9rDT@CblVjhZR51XY8*0N=U+m3Ulsqrf)@;zK)g|FLkT0r$e
zw{>oBCCro~@fVoOiuq<LF09>9%#V(gfKVO!Z>KgkN^x7I0VdhC+}=6d-mn5F>uPJ7
z4vB1qV*-?BSl~!({1TmJ+l@_g7~vQUoC+#>J1aJJnW2P+xEzDF#pY9wb#mWDn3ZYL
zd~0aFEhNo=g6^u9Z>pC{#E4N08*dlBk<XG30Vw`5?#V4QO)xthk&XRW{8p9Wg6ND9
znm_TtAa;^vowo_+<@shZ0<u7<l804H637}F&(c`c!^o<X|0pZPapr<ck%4!pI1lQm
z{CA2@gk1k_oCs(7A+@?oB|Fk^GDwZ53CfZ3DnE=lc@TwL7wedB=30C>6ooM9$qz>0
zyyy&`;#w*p@&IaPFeT)RXP*<NP{&E~GIcMLTwSQS4N%vN)9OZlYL<+UEB)o#JaH4(
zX*4y}`8{$u&J6X#{>t^B#D0m|tOaMMfeZc_Rm5!aR9<ol&NuIxjtkFxc2@~~TX)TX
zw>>NY;Uz4Mwt9Ktd|SO_brnLiQz0~^9EqSYyKP~9L2GN_XiSJ}2{<Dffnnt%hiPq{
zHU`tqsC3q*nmvln=2XLXoWh1rz&MZkVRA+racY%7V@Ki26;-B+2~{X;zNqE$5HIE;
zlfK1O5j9A~EUxWh(3<mWh>MElJ5ah3Mg}esFWR_c7K|{^l|gqe@yex$DcsBOsVC(}
zb~Dr~$>he5{lh<A9{v#?`UtIZ$6PE5Bh3#diU7xahHTQ)#D@nMJ`*sU{EphxYF2;(
z-UoOK774LbQlQPjX5fyih@0)uG(^__XUzh!6;A*p@g%VFcC?wGuR)Z5pqvF2ocGJy
zv1t%dSC%i_C2!xaeT{*yQEsy5BN)cLn2XFq8&i$E{pHI59v=eOUyT6jUM!Dn8H#`K
zBb)&8_OO<*0x~+~?Qg)>^*EK?#0>!Qb~N(5j&_;in46T-sAKxqjkGY#Pl`UG-bM0u
z>}dHkM9cWHC$UY~nnR%7se3VrT<oM?om*2#+@>LMgq#kI$bv=y)t*G4vQ-28NO^&I
zDEf7b7Go5rF)!JTpO=j>I*B<nACDPcxx{gfpXQThkpND0SOdp<$ycZ{&tYnC5qxZ%
zwg_&ZE()<a^kH5_E!D@6@7(`)m?`;2+-B1j;L7zNxow37xPTZidi^?m6)s}6Rk-=@
zxC&dzzl_jXfLe;abYlBDFR4*AcGG>?96SWjkD?znFzF~ttt~*9Q8n)+cu{9LuUfi(
zJWlW3Nmu^yYU%8hwk!9h0A9w=_PXfKby#IW<wv{K(ux$MdQ8m56m{o%Jv|53wf$(Y
z%%%mzcY`buVEw(=_l9pkVVV6`v}wME<qB-9a^<rL0Ip|26kQ-~&6T#UZ{LmwuI9II
zzXPWJ{8*(Q`3G>7f3YR|kNkAFC@}|lq*ZfEml_AqVY+f1TEBN9q9CkpTt{9-pOj>d
zJS3WF(3~h#3+;g7>rm)HJTK!kVFdlE(Opt4#U9ED@&;x-M$xs%p9`1<)nZ*1-7rNu
z_<>i0R7;)1@Pi)S0me%bgVggr?+wJwBC{%`DH&ce|0KlP`=O>V#N*iute9*=iKCa&
zfsGWTQ97uL0vhuTfX3opNTu5xEqIJft}KE|fROt?K#HrJu6+^hYlimqvGz4v`#P$9
zIkm4t+E<14wOjkD(!Ty(`&wC!!-Nq(#|S_d%Ow}2t$y@(@eLCMRgL3=<n+NXocpv<
zdKaC}A&#nyTh~F}DL(Q$^n-AeQy<aXW|ht%t9UCTKq1!+AGnDOZWLLuT;l&)Rgs+O
z@cmmh9W@AB$uG6A>KjgM=u?<MW?VwaZB-Pwbq8A5H~*EgZ2vlZ@0x`JchbL_e$3WB
zmeUV9q$kC4gka=SoEE!q8t|jV^4Zi+FIy~k(g1q(745{CMT^*pvms`|j2-iwj6|tp
zmo|lPLhjOM4%ZSv>5)!DVCN_VQr`L;+E+_4yIhL%SUsu1=#AB=O>e9=HTA~QI>;Hi
zGsNE`mm@v;r3$BBn);!7Y*%ttS0w5AX*NaAC709lhm@AbBP~xKxRRFftVTMO=j`FS
zRT}4{ZW>}wF1luLEsxMO5|7JO_mKAYkb-;UMY;A<j<<z8V6LI6*XzaeV>g-WH3wAX
z4(ittFi_8qi6~nQ{uvo=7@a(7`04V`j#5F_Y)}eA%LbMN454N068B>AagOdqhJd^o
zT|H*iCeY!l4^@S_q_pqPKa(U5=vbbgJwq*k9on}AkHH+PP5S1rqyt$kMrsFV0xYpu
zDaT;Rlq{WNkVjEv>-Cby@hlfv{-p|WAK!`LH|g`0YJBdhrY)=++A9UEo<rNEoCAuz
zQ9UlUn;n9+p(p99DV9G*El*?p_$CjPQ_}#SN!x=_HRLrnh^gy7gE3x;8wfk;$^d09
z_4@q2EfCWJ0Q(n0+95YQYUG5YeFG<_Lor5R<1w>iu;ClA{Bf*jRUJRxk0HY8HCY1;
z^`FSYSTtt@3jI!GM!!}-&}Yf{Or0G7C6rmVpa9;2ejK|tL$J+d`*(C^6&tM}mp@C%
zycNyhrIbgWlsl!`W5H9rUoCAx8~sU?$KRJ~PfLxR;@4&fJ1#cdL2d@!wJe?g8+^=B
zZ^3M25=2Sq>U&yw7?mudtoF2EDRXu5Iap5ZG0D|QOO<PnDKExc-Rl7d&5hk#;I(0d
z?CO>o9TBc>vvMZp>T03@T`f95*APG#1<?3WA>CTCF~YSm+H2%$fQ}IvxU~vYa}Xs1
zNat}Y^&+n5QL-DzBI$Lgd9VF`aJbVU#M1MWPbFi~WD#J9q<!Nj+Aw~if6_c8t~rmA
zo6$t8?L$-RG)=XK<!aVpeRKC$z{E41Vq$c|SM=O~`OTNVat>`DAXC1~RTb1<FFBy;
zzo%-XgJ!7Hagl3Thf~u;#xABlWCpG!U5j8BYc?xjhUg3p316W!Hi()K*D@0|sh+Qa
zL~~6j{sF#xq$4x6(}mKgACCha`U50+J@va@DVnPvK6>?{ks81!`Co$qJYMoxG9PbE
zTHp%_&bODZVHhX0YWBwKyyQRNBV=|Vdz3qh{}eDCKkt7T3Ml@_<0hdy^{p!5p#LR^
zJcP~i`UrEUUbOI>x(B-qaXpKYaX<Il3Jr{ZHDvIS`>M4AB6S}87k>zC`F(2MEGk7g
z&hnMwpvup+huf?RT6b93K|FL+uz+Ws<!G#KAf8YVD{zN`nC5P+y-2oHp(~9Z;Z^gF
zYNv!XCHBLkREaf_U*D;rp3j4ipWmsWeUgrLVYDAHPNojx!DI}Lr{c%ZuF><;QoBZK
zDSo8(IXKGrk|*$LqeJIQdKP*^u9tyDcH#z%Gf-IPCF_i+2H1}{A_9wkWE^~l9%F#e
zcTpFtQXZa;!y9IbVT)LGQLT?TRVGuaGC^PxliBXP3O?+uRX56|)J-hx47o2hw_^d0
zlMU~9eD!73XSkLeYBDE|2-jl5V7?eO1BIHRhY%9a3xBf3D1TBm0jq2L(d#Yn!WNRF
z2K~g<V$p(Wg`rlOBi#|%aFgC9akYtQT0N;rTy1Bx_QA6-6B>6TBXiIs)1RPGj^hm{
zfJ<ssZ25O3O{O8c8a%bN0rwi{Lb?*I`92t~whXieR`*9(Aq!CUzJ}a#`J8xWk{pX9
zERi#5rWxAF0L(0<$*zGmrnS;ccNjyJ*3`}-*MgdrTFHv8gn5DL8gN|P@-zD>`79Pe
z(T1A{DxZaQr!_4yHz^OcSDKrHrvyu&f4Pzwny;cqpcwwvt&?U#R8@W+$X;`NskYgt
zBBe-k#Dr16Qk+VLm@o-u2(sU46F(i=qhumjEDbr~eDR`*+u?_hO2=HyJ4O%vu3Axd
zB#MqV{n}#Zv-cyL`qMkeQ))mayQa*t8|ZK2Bp~%J+|S!iU=}*GND~@xdeM&Xmgex2
zDkSBw-AJ$`oSOf1S<x%X(o1Svh?bxlY}E8JmzDn~ON)G`wB+{S8Csy$G$_&b&z5*l
zcW$!zSK|`v=mxP0J%2$y`?*Qm6AzeHNsV2Oa@-VeTq>WV+sb7HyLne~N1Jn#Pd-M?
z7AV7nMoBey%e2cku1_cTqjA%E|B+#v)(e!KS31^R_zS9`1~Su_vekNY_d>a&=`)l4
zRMUB*;Cun?e|(u-$@=6u#UONVo$hmc$!Qz)54_cr^ey8cUrYEQPVBmb?uF^-sV%;(
zu7ZqWy&0xMog7W-;QBc_(3fxnt46ueOSY&~7UZcn=A?6#R&+e!b3yI4p^@Q5sHf&!
zXU+I9s^4|g7pn<z`Ss_3OY|?08c#!K<{34W@iG?!akz`YEWS==C_=r^jp$KiqxKW?
zq-6t1T*_6}{)oumShkE6M!3oCs*d!DfOKVSStBdt;w}J;$BlZDV9IcTY%@TB6ET%a
ziyegFt|9k?qqLG}asWnB5rZ|rAn+#Hb(*aITpNj(7%G1ns5hjhvD*7z-w(7T&i?kb
z@wg652${d#k2>%yI)l{`F_xd2!d6(EinhE5Tz*wuR4k%^xWDv`ta{`LNF3fn7zYCh
zoMM!?)okFied>EYvLgnf$JMa@w6o2Fodv)TPgBTM=;z31Af#Y&tM3h^pQ#%<E2GYM
zb3ZjMXy<(bR{!%jG)q6jp;>?@Jx`TQz-=)hpNs?nFEEjwan%;Gb$!&nB(R|ww83Q)
zd9xf-ejLar{|6OC5Nj_A968W6wD+dC1DRwwqfMN$i9#{Og)fN*VT_Nw+KvikODYpg
zHYH1%qk#JPZ2K_vGdUUl)`dfmNv>5>9)WlWGNkoPoI~wXQ#2X{m2?F0p--+l^YRl|
zVo#yRXFnB4w})#&K$5jxXJ0I<&4q4X_%vxGCC_|H&De43+SF)6pDxEmeyroHkVoDd
z0^6v8DL<lTFeF#EBeBT@xKxFLkP96bVy>QfxQqz7l0e)*?&>m@9%ao1F{RWI-7;CN
z?%tdZl5T6hG6M3rJtUj1?nulQ*_Eqsc&MPeb>$qDdnPOrW8KiH#Kv3(+B1KsJ!d|l
z?Wv7=<XRgQBw;zS!7R3w307gGJskf}w0`!3UWNuX!A8<jnW?uo>4y@a^_tIx<Ko8a
z<XQ7QUjMIu3%blfD*NW+?*0Pu4pud5vQR^!5RzsoZaLql13s<+wpYwi8H64S!ni7o
zAy4Ufrjkc7PrgzR3_mo!J&gj{$WK1Ow%{=mGC}LekVOz0bj6XN^I9dtxRr0HV|nCy
zC_!`JJq{YI+)h^udfdQ*hr2$NPZl4;BfWT%Fl?*`4bXI_@D(1a7T(8$Sbu|Dfywmb
zlk%EQYaq04&B8;;WE?{cu@q76RGZYi?xC}H=yYw}I1+RKJTky%IK_z3;j%V-Lp?+m
zhZYvG#U0{joGCK?NLHjK{^bgWNyVloW8a5Z?W_dSpqFIOTU)H?C;t3T0i~6HMx5ac
zp}ZVO_C{C=o_F%ur1;NCbSi)G*iSug;73b!=I3piSwLRIid}<J4y*%E82Y7m7$FQ0
zFkfH5b4<c?auZBLShXCzyp>F)VW*>4$i`D$6Kgf;H{DC#T8VtW(u#|ak85e7<}p^D
z6RI*uIr5_X;>2yzBD3S-)(Jj(Anf-GlLs4=YO$jbYQ;J9kX&sQ&*RCM^LR2QB6dxZ
zk4G+8=z*6fE<5mIF646qMvrGPSqtcyau^Tx!gQGmwYF8Wt*kN{Seg${pkQ^*RCQ&I
z1HdOWJSliWfC^t!So&XB!>6ZGbL^+5G}iFiWvrn9SVKP9KLoZy2SX<~oeKa901nWM
z(%P*XGe8}tCxz2O=39Ytq*w+JxqCR5@B){Zhg>3)atYPdm1Gp%blVGi{ykhImP({t
z#74PDy;QMv@E@>|fsa#d|F@6-H#YKLSFn-SQ<>v3)q+3%UN-Wh1Hc`AKEy_DBildL
zSVAq?@-by2ODP+nfc`<;lE-^Wq=j1thcgnlp6eP?`7vcA6M>OTz*{hKG*)us$0=5F
z;-f2Ai7wdWk<6hU{|<oS7bxLcpBK57uNj;~T<{Bg8$rmYWJ(Xoh#h!*Lz^KW9KBP6
z!jT0?PfAla=Bpc7FIkgL<*s|vG{VEvfLsgWg<2eciaU*!)}IQCz2pb!`gyPtFS$Vr
z5AsEz{$B+jps#pCv#GX1M!+}Bh#H&?={2kLsnF&$7yWehPla?ma$E>H|5kcFM99N#
zTz+f>Bs4ikU1a9=8s<tlN-ot+x@=<DmI3n*gg?O1&=Of7FQWq=7+fy7dZcCDFzv^a
zo=!kzAw!OLrkD;;c%y}3Jb3fR7S=(vkcLU*a3>B6c|HY5?&#F!!y*gb#Q<IN;h7<=
zcXB!?Rc#AP%%Hsqxg@A%{!uEk;%`QOl5Lw7Nws~B_qdicC<MeiE_ez0S5|A~OWP_+
zij3i7iB{JjcPLyHFxT*7tArf+@VR5i_{7f#rDZm`)+*KZDnHR;g|TG3R+FJKMF_w7
zP*s(g^5Nq|s<t^I4JOHj$6CqDe}_e+6J(iQm<kigyB{Wn7V;qtvN|&EH>3G9X=0k|
zh0bzPMb0#w&P#Kq%be*?{d3J#a+Lo`+ijMn^O<}DwN$NBt8Gn<gG_6d%!TF~bPvAv
ziX2NO@0Pi?g*j6Z*hPVFZDnQ7spUXWqXs%PQ<zFYuSU>u6f`#p3ScG;?CQ(_6RIYQ
zp<8Y_U7eAp<`G@x-E2Zv1rj{Mwf-1&q-q=Y$Qq1GH&pk9D$>mTOcU4AZ9o@@K_l0K
z_G?%<Gn*Wlf~AQyE2gHxi*ju*9=nQ4wZOsp9G#qaoT09TZHC$7xR&3;$Lwt0+G?6V
z7jPW^IhF4EsvI2~@<VeCcq9zZ*+EjfDN_*u|H_Y5mn}e@HSk=adU>mbOl`*qLVz6t
z*pbuwp{Z4TZd0S0$scGpWy|Sp)oSa)G>bCTQQHfOHYPj^<D_cmKA)nF-!>X;2Kf2V
zAiU?{r<Fi<N}imq_1%e`G%A)h12kTa7Q1?J0HBjx@ED`HRN*e#9c@`HM>eO;k8h`v
zu#?++MB&7QdD|$cydmcfZf};e=|EQj+LlS%C~ogt+#v}+gGYpH!heADgh#}cpUic1
z2xe2K;*`1mikqNIQ|GrXy~!dbj9W6=M#)_3(wwRD(O!`Jx_W+br!w+f=Tia061+H!
zyiRpL8;H-vwY|p)E{Gmg=nXK#ZtlT@zF}cT@}82hxX&Y2_n-$P2rRh&G~!hh@?AZ^
zow%S(%|d-~QG3f{>_;3??um#g3<XIGN0%t=KoeQ@;{Qw()Rhr%j3?@WEIz^sbUvFO
zQ7>iTEgfMajC_0#rJO!7GU$kGn20y#h-H~VHZ?@q0-5ymClXN$=62bPI+Yml!nJ=y
zB`YYEEK5?!w0f~Ik;(rdkiEQKG9jfTkWw&k9s*P4^!AFht234BkaE&B;2<TPK}2xf
z5{h6gK0_-6+Mgt#aY#U8VNUZo=KeG!pd6!;Q7<zZ7z_%qwD>Pj&!O!LSn3?@u)^K{
zUW#*Wd=DLq;{jYY6F=sHcVS>{4-;QGNVnBcd<oe69jML)agPUY0~rK%UH+cNt|z}Y
zoL%olN<Foibx=!M!#FZp2fKJ8RpqZCsGN|az^0Qd`mA=CR8Hp(Rg{>;E(71L9Xxm0
z#)qA-n!bBNE9T`BDOZzy9`f#*<c?)Jp3OAyx&-ebzc`;fO{k0^+lK0XL@NgmmL(NH
ztF8d{oIo3XE$bm;)(&^ar^n7_r|Ko29@pg;*=ZYE^mAd+$I}sa)64Qkk*pI*4dM64
zQA1FwD90QPGETz?FKs4E`fkun&9T&>cN8k{tR=#}3a}e;NaXmCuJDJz=;gSME-kX6
z4{q=Tf1f?vR#C*ZgoV+~7f?8E$PvremC|cQ;yLvoGt1}23+9HK&V3|)X5y{I$6M3I
zm_dvignqdr(#4u0__D$4E%9?xByQx>&b|l*XKHX?A{<n(3NP_656L)Qf@fabgkP*%
zW4DmIU(w}xiU^J@ekCc>uLeG)9U0MYF%TAcd@%Oxb)Z?_%Djs5gHY%pFDdARl#bp>
zp-K?KC6s%XOO^Q`<tW+mt?0!%N2<#QJpyDBqjvLxbA@gY8oDy+8kC#Sf@H%DHjsDz
zrmD^LR`n}9ZJ3YOAEJ9g4dm&cYjyHz;zN+BNWIOxIZGbVYE%vAFlU9OezBXJ{<|*f
z3Z{&-sG64CSZOj|aW2EE?fUuTMx??}=r_a8RG=^|1z)DmUi$2yPePwZ>GL)E#1j_e
zp}p`p@-BWq4&Ojp#pIQDQxsSW!KQ<|AqAa?f-m8Q)avz@aQ@wrMa4g-Q0FBM6w+VW
ztnUZwcLLyb0CI0+&_eG7*h4iRqx=@V5a9m|zYqX#12}IPb|HXKK8&{kaKQ(uGppkx
zuH{|`wT;q`l7#3{lF)v5wm$JSJX=n1EkDa-nECd8=@~pSQnm*Hxg8HdWN2R3?B$y{
z?$BZGP*Z-d6XZ`0$B{eK5}5^`f%HhiTq6Z{;5A|q?vX;sqZS3Ht_R2vq787{N-<3F
zwuj<#55?pjis3zo$#@)QJ=7tRLjHD<nE06@Vfm?5Rd_PY#0B5NL#82wXXA%bVRQTs
zsjwmbTL?GPFix-dzowFmaT&r*7p@bgi!rk{$nv%U=^(bnG02714V8F~o}h`}g>JfZ
z?0*!_<PN<Rs$h?4v=F})PXh13p2cVA#a?}Ru|zL6j}}XD5YM0mk}C?NrF_L=DYx;<
znlAYHilz(e`23~|o4DXfHrXGPE8{T)bF33a&(|Yi&S=9Ge~C@D-xhy16)ucF4&gS_
z?3u#EriTqPgnU?P^t?@}yz2pGww*%UtU)}75O_<F4zUO!)^IJA_`Z*8nS<{KxR#mt
z7Pyuh@V%L9xf<Wgxt58z$+HLP;VL?|p&-sMH@EjNh!AdSFK7!Q-PQ1u<q*!h5T!Sg
zKLAu}ny*#cf=(Fd6*?TEAH7x&rE8>;Si?QK7ae+AmK#y2@^Fv70t3%46v<rP2BcF2
ze{5A17km*Eg{H%Wv0y7b@5C?~-N(I<?;M@yCD3Lrh_`AF!}z1j@MIx#C`qQHDxOyb
z3%!;F#$N-pVc&-+0S|C-ErVvf9Y)C7**yVIo?@g-pE1fs=rPKpW;~q<*qaQ3Hne+N
zafEBZ-eLO{NR(-*-%}A^!tGlyp!vq@7c+)}IK|!M<lXvlZhlgXvMuU?J*sWNKx<Gt
z0M@BTY8kb*#kXK}=_#6q><+og4AR^Tt!~5s_c|km5Sq_@3NI%d)|FczyEgLi>3DT>
zSE|=;GQJqbKc0u3O|0i0EjQxuO{K%PmfK;X@%M5++efwJ`}i$l;(q=HG4TNC;DDEY
zT78p-3a#;|aq;W)k%4lQ)nX7+%`$z->j#K$p(d375RVDa5(;^1y&Ob}LL(rn1*Nnh
z9L48YQW&R2JGI&}Q3Rn8=OQ?VxRx&M_6?s|jInX6@rqm_ddVfdutIu<p5_ZaOZh93
zPop(P82~y>Dgj|c(}jD5d$cGzPQEf4-kPTIiDt@I@JQI!a+wy;++K@UhmeWgFmEVD
z10UY6jhIb8J-7$!lRK46tzgU!&85yC&|)drgvkpAq+rX?OjRkvhAF1fYBVZ<*k>sS
z=J2@H($<O8?dh0&5W6bAQPBJa@?Cy{NE^xsxq5LPwe)cvwx*`(Ahz>fAwQ@N2Y74<
zz;V4WLLX0bLe%i)iAU&=6Me{~5U$b6bt2iowcHPE0;WmJaukViwRqK#9ETWP%dcTl
zw4;rqjrv5~4Df9fz`VFUh({|+T7w_ZT(~}=J{`{)q+@ME_K-VBCt!c1kk8kU(jNh#
zgnNC#fMUi;_>?jVaEXzor(lgdF$6R&cw*b=E#_c&gY8`BsFUYD9_pb!ryheQUywTm
zqx}l<ptLYfq+I!&cK69;bRkExVnW(gbV&^fXSGE}r3@+<-j;^R{Pi;J_ESsTJ`ec<
zFL{WRNY7}bAzu*Bmu*cmQH-|cEK&}JTxW~hEA@6E>C(*79y;BBh|Y=fpPI@_c%Mo+
zfJ~q5h7zZ8>uvQApAKppD6waYDG44=DAOqS>$-ybDe1R0%>wDy39#R4uv$&xL7azx
za6Gf7O*h10DU1VdaAs&@b-gkUxB2z2V#SI(eIvB5LTv=8pCethi)q2dx&-$uEzv4W
zl@rQ@;S0>}!aK<?zQq>cm&%)i>b6f+idy*~N_g@!6qr^5Y?dxczq}<$U2IJae}fh@
zL*WOp9%ZanwEXt&k~>N16@~vrJcx{v(Z+`tg5j+X%6l|aJb8)UT&#vL;0~nGi^zkI
z;fL66B<EM?%w3pSMq~LK)IE<~*;1N^HnV3Yz#qi2Ko1apt4tB8IH)S)v<xu8yJ+7i
z^dWi=p4L=m%guVH_-pk}eFtkR`>w#6cn~=e!;ez;V1T^;p8)V2jjNIA3g2dGrD8x!
zm>(sFcF>mNd}%utZ}|3m1!s*>ryO!BUqFYP$6mkJ$sAhiWWIvGh4oJ6N%-3Ze{uL5
z>vuB4RH09nX@*w8Mn=6cOdVFLeGo_e8r*7LPtr{T_i|7jM|l@FZQaE523kcR!+2`F
z)bE$nl;RNHbyRpM<v>7C6~7Q2ri%X|swv0+8Xc~RKYpbuF6&_HQ($CN^q*11J*0lw
zKT@>&2Zt%zqlZeK82yKewirz++W)oevO{8Wtu1&;NVkXMX$HDM&Isek;lnAtXDtM^
zt6tAAc*zXj;RO)S4nfRMLEs$|zSpS@;nR(IWXllDBnVO&Our-6`hs>G*NHTLyS$7o
zKFRGf-+aZbsvV&JbkHj{uDDgT-FOGysd@zORPEs3<n|ro_C<;hE4O&Ocznojpxz7N
z<+=x}P(XSk+LeV`dxj3J#T1(u9>kQPJ7Vjuyd;(j{+vnS=C_eluWpMZd)`8=T6jO~
zr-v}2Ot5XtB@YjQPK;24#3~@&|5q-MoqqWRvh=QFR@(*zhU{XGC#q7nXyO?gykrKQ
zVFu(hJlNuv%h7I#S6#Y29`!?X1&i`?14cJFeo8wVF#r)Is*rF8RCOl8z%05h1X{S8
zJg{7|M{LfccQiSo!e0G$M(VLtRy)A=<1ZsT{aYwXQDhYwfVV{X?5Jjs!-?|@AgNwV
zl=FrKUQ&iT{vp0HdC}V$Pr$suM;4r-7W*1$0=-J=lt8^!)@o%brCwrye0ZxzO=z=$
zpBymyNUqj+JOVV=>vNNT|15bu$8BQN9GbBeuaFboRA~`p;5kU0ia|!4!o)01sdG~`
zD^}G-ReFULIZ2@~NZCzy(rq$+i28|o)x19Hwg~F_H)xfqi`JLr@HTp@C@UoNcdw_o
zJ+#~iYk2X;Ngu9k$lHr~W2;uwMLk~VvVL*)nV~IlFX?vcTTJeqlw%DVgpB?sBte6a
zg_nI5^gAmI{OEv@9B||2g`6O}-SjTh7@mm6U&g6%Yrl0cWJiVd6XX>yVchz5&Sea-
zrX5%iXg<8vN8UQ5Gfty+6BqDD)(D9C_|P!^_=`gt<J)v-IDc%pl0W`P2Xm*u$k~Jc
z9Dl5IU%?-NGk&07>ZWjH@L;Oq@8O3V4kh{Fuickjw?(%L`H9c7{5W+ZOX9nz73&;z
z$*+;p&^lIW9yZNnrg;{<*5EpEv&|$F$<EyJLd!45@_FS~;VY+nGQQHw8Rt_5!9w;-
zr03WVn;HMR8=d+MMahGCn$r><SpkU_1*SzSfj7z#Uzv^17Q@!i0d!w+#2UVCj?hqK
zgIT-0oJw+THh6-v@^7)%7c7ERT+QNsMZB9v7&K>cU{oHtZnd;%HK>B(d6o;J1vyYu
zBX3<Pt|?<dqO>-j$MU!QO=je+Ys!DdFkvAhR=Ea!x|FTuk0rmG@%#SrpC`X@e3iQL
zUnalt-cw~!c_{gfJEh8;@<)^3xSyijQ2vYLcN>0BEZ<|)zeD()Q~ol3r^7ey4yYT~
z1X%S%jkI-*l8zl*j30HYSI|A-+SCC^3;Cv9MOM?DVm0|lgUHKgYm8<&OfO(GX@<76
zmay<8<uae0q|>oRDn}j(6#uqXf=97?$u*Fn2^q|CWH1H~`Qu5-V9@>lRxhx^r^h7y
zn-_q3VLFS4d^=QH0C{F7GLCM_Uat8*_JS3XO%!V7ci2nYD@ix>#d5XHV-I_!bouY{
zGHVR?UGNe`J_Bc;i#1E5fL%AunJl1>fNS87lex#kmFS!?TTO>`gl$V}HO`ZkS=%OZ
zd!z13^3!G7>4Z^gI-V^6F|FF#mZrL_t%gdd0IF*_#otUXmVBY<Vj*v7x|kvS8<b>j
zpQkc71)-Z<OB|ZfmNvVPH_y%x(khj+i<H06gk$>Z2@P~<4Ya8S`>FYOrBmhHra3G5
z^Vr&}akF?5y}8yJsx&msnk<;*UL_mvoPcgXC!i0<<FLq%yp2|FTsaRqbVT?D`vN1#
zFQaW_p$T`)&fpgWPx0m4p|Bf(r;ulsYMsn(OM~udom10?da7iTpXeYaNPwhe*2=gS
zm<D7|Z#OcCG0b3#=g`~J*t!)63*1XJ47(uIe#+}Bn}8$;6!-whn3^lT?K*VDZ=H}^
zj4pc#bQ#6V;-u1bFw(HJrbFLm<qIZB7?76@;BJ@46Kd=une;c9(EGI<y-YUTj+<xa
z)eZCHMC1!&$jmt+4Kv;33~m$k);P|BSg&O_4f?!Tz>!PI0;+c5MRF3oRL&k&OqvhH
zu%;)Mu1<Tu;}h+E$NDn6zI2u7OIL}|>yyg|(5=zyEslDRC!B7N*DJaDG_j$bpXDaL
z_b4A8fUoPkUX&VCp%0)?YCwTyfIRkV?WSLkzT^RQX6WJM&CaTK|7sQV0etwr_nZyA
zA;Y`hk5K;q8A`v>4L1+OwFyeJ9^dPW&NyFv6@QNqR>tgLl+QSKY!}`sr>ylN4%IyC
zXL!JJz%C@zJQl+CUhTXVzRmQTUW%Q^Ae^hu?&`JoI?f5{hwg-u6<hGEV3pgmM=W5N
zNS7_ESE85toI5F%VlC8TN1VDIcaD-xoB;&X@3J*{<zA`wbZhOPRGWyoj%wbN$M_7X
z_WgF3YEv>}uJ@_=vlbM?({8drqg^ieNgDpPViT;hE}Jm&oXf^I(-}O&bDB3dRjW<1
z%O-Z2ilYZ0a~O@RP5k^Sep(e@NIuz%&J$veN+NrcJ85h8qTm|;gl^0BDdVASz-X{o
z28!*`?)PyjCTUrp?8*(;YKkNLE%0|8{7ryAn@F6(b7jl===AMTCdOPn=(eEbL4Y2!
zwL*XzModyItf;nEpkQXo;RERD;-fd4I3nBZ{4|&(MKDZb%F&L&FD=JklN7FxxwON&
zOCf;2E~wlA0b0Sla>fFHGs+pj2xL9XUrPq|BzySjo@5WjJ(@Qmj77|)-KUWb0cvn?
z*<!9<G=&9Y{Af9QA<Ud}$EQ^1w;b7=uHTyXyptc<T#ffsn47En@V+;(y2tzi-3Bvd
zH1<AU$Y*HjtdjM-jZfD;Y-Ax`ZThw<p}c$*`QaWa2uTx(YYz%8_`53P2iP<wzFOlq
za=Gm@C-p<=jcK=Y2qfe>3R9~GW)~^~Faf)uwDrIv@DNaVN{6FED25?3@Kc-D_Mv7%
zvqLV(``wJU$TR<uE<BiYCOG;s`uINkGPVrnd%WI^4e3gre-JAE*D~;A-}aa3F~BZe
z3hftuN2*`Oe&gj>%Cp+xiE1@<c%oWm5qc)+s(@ihlaJw6S?XG3bfT(h1L8hnXkBPD
ze<vN1LlwrNroyJy>Pt;)FIBZxtHQSaNE6rcJWvlH$jGk`7(Gz_ufEpLK{zf7W69A!
zg7`NJr5@f5i5mfhah2}YcQWX?(uuLZ`Z%dnjH?$LJI4v5<k(Y7FlDZG+6gH4Fm)iB
zNgQ8OScuu(?^2=uX;A;`I7JVj>wU1%CUCOr^pu!j$*8s|rVN)2h;T~G5#cM!k+}G4
zL6U^m<Z`@ukbW7pFEc}>Ofw@)Y<CSBlzdpK_T#malnOE-&ZwB-$>@`pYk7%YT?FlL
zN{!uI@EOhhgEEFGk#d~Z+Tq!9$|W9jM7ZEX`U#>KxBY&!7bJ`uL6tRcEEW?MF1P}>
za1OZ!?P?X*G7)z?xZnc3kjK@n4uXhjjE}?vZbqLEP|;sPjb2%Y`J+A>@z)aF_0tjM
zT7HK25t%}+Zp7oPk94eYEgPxRgpm&bU2sA4-EVH}{`%F|8DTm0I<EZ)9&O+|bmzgy
zZNCrixJsD0M|>*%okpx|bFy}>1&<nNEx1REoN^dy3ZkqTPp8Xo_f$NDTRsR6VI08W
z?E^LB>HpSQh$JN9tDs}$*hyi$FJJ_i#eYk+`7qj45&d&$Ew^YX%C7(|*z$mBg&Zx8
zxkDA@w6}L(rTHVEYvCi1)s%32y6w-vDuAx>&Uo2MH;1*W<3kmOqBi#C>cOVZww18|
z2m*bzY>~Jv{8@U_=i4&hYHGa1w6elgl$(#oT-w&No>9wXZej~B<0M-tC)u2uwn<(R
zFd-`e(wT}JhW`3d9<nOnC@CMLCw8mqKdc8h!%XtXT-;CEiNDY{Q~uMiUQiAqnR7sj
zi7&gLs`QK?`N{7=9uDOCr=jY(YPWtK1#d3S*MGZ87)8$iKFQ^u`8_qj)Bx`Xp}3LN
zf8DCAv4DpOmpgSEZVq&g4?Fp{q{e~ae(6Yqaywa>(0_uUYxwO4GVsk92!XJo6z-<?
zAVB?PjotjTvc@hAv#DGD_5KX?c*?w#>Pe5P4!;+XT%`{8hNp*P&GZl<3gj#rh4Q$4
z2K*ts?0Sb$VDUzv!$#!{L~{EwizBtkiv@?@F9<pH+ma2uR@&UzrbzQFdP(xv_7nOw
z$yNE><A>$Lmlcsxc&lccI=Fpvb3I;e--BuP6TVOdi@(7!UT(C?RaVFOh75T*Yx>A>
zu_1Gw7@p=h*+8gBcX^AnZV&paVEnYZ6?XzY8MoNO4qd32u)pa}-JU3|C4hPi`SD_B
zavjAGUgxqD+I2m>>{&~3(-gdE<Oi~|C_*NkgZ03Wy!Uw69gNx~h4lJl`-x_}LOM))
zj<+Z4;CSfw$_&_k?e@E6$k+X3yOVknExeOqYLkUtd0*en^eVxs0ec5o{tJ3vpG|g8
zTOzxQmXKWPg2aC3x<0&wu%gJe%ngX@-G1fWgZP7&W(_w0H4X0`#9Ied{s-cgqUkE1
z=HQE_Z@fM<W20>SqqMNdiq{Tq`6H|lW3+n*EB?rm+Za8t3Rm8J*lfMG`o)9x@EVzZ
zH$P;?HV8I(u~lATEnCbA7TUF_XYs4O6F_Rt(gQNqbq6cWH%mXVE?ewgUQ=7M;;@-f
zk6kW_Q#T%YSw2;o9Pe$N1T#^7>$X|>JnMA4E%b{=RQYgmq{?x)(cqL^`5+6I)fNd^
z)b4`6T;?j0OG~KAP*yw5<ADhT^BQf;<~Olnz>12rWAMGOoTFuA2}CD<gy)?8BRsdJ
zeuQV%pMX5B_z|8TJ$~hn@Zc}SfUMeAR@=wF<f9T4&Rd+qMcR!MU5L}tZfa5004Ogx
zNzJO-4HZ<p4Z<wGR(2I)<V%cpar2|Qw1yW9&q&=O<;H~L;?{Y?8b1>o?}%&~O}64e
z&;iFq-XBZHmWwe~8RsVd^~>-4f)F+H0pP8ml|dD~!)k%~GTGxPt1T4F9*>fy3We0;
zKjHIW&+-PSXKBJm7X1qq-uj5^U#M<b6I$Dy`T?OWk6!)*LM+<*3x1BL2d0Ja2Yri@
z<qk1BH~A~wcP_fj5TE=_k>Nl4goHw=pkO!^6bw;8AyPpur2^X!6%-&9012Q@yKU?2
zX0;cc&u0uD``JgoJN6I!;ydW;44&d&37Kzo2N(|_AJUZ^@q;}<3Mimx9D%2ZJai#k
zqhZZM@}Ec|Yv|XO?)=&JAnWT#5m`kPSy!M*p=SPq??aPUzsu$x6Pn1(<VGxIBTKHK
zZ!4KZ-!?LazH<pj-}xjR-!lnAKMP6XXZS86z4See5c-}@y6C%vbkg?>a*VzUNC$n-
zB4PTTP4@o`Tj*3bI?3;7R0VmCzN^SH^u3TgLEml?qVJ_7NZ-pzBYm$V0)4M0Kc??B
zWG#LBNiBV^Bg^P}J*lQ|p1A0HGbyL<Eu>U$!d_I|$Tb+d7Y&o7fCllpIWmF<cVIA$
z2GQI}E`~6On|P#`2A{;>Uup1Z41P?5&tmXh8vG3g-=M+gF?b-9y29(fLa7V5cF`c-
z-bJ3IL3Ao7AsWQ%SIAF8dXv#qMtGWlau>Oe22rRbbu@@S`Aj@Ch+KwL(IDD)NjVJ?
z4BkwGJ+%KcNU!%Qput|+e;Vwg{ineM?f(u8(mM}&X%N*+@>d!}D;D{f2Ju)Jd3T52
zWb`d15t?Ab;9eTc#o&uHn2*6{X%O$TCr{8|AqLxMun2?OXmA<^c^bsuaU=K9U<n56
zXmADwJv2BAgH<#*8-wLE=)~a7G+2SbYiO_vg9XVZFT}4Ln&8Hui3XQqFd<`bIR^hm
zgDWxkISsDH;D<7m%jzyWd&JksX$}j$94_5WUY6-?PiBY3s>l4h7Q;F$Ha+GsEvCd_
znWe{Ur7;_4I7(+v)b2i8hcTB|#I@kHhH|CVVae6=Rca;K9F}}NW`-7%>#!8)F_X2J
ze21k_kFjYn1rAG*9y8cRV+tLXX?jeL7E|P~OxI&R)?#KkEKWV9LyMX1uvF+Vd$ky+
z!&0Tk{6>qZa99@VF~87asvH)#9@9i)HZF9OF4cQ~f1B2OU0y^K=(ce92U2k8Hm1#(
ziRYvb8@LzEManmTA&?mUFMD4C5LNa4e}@@hRCF-4)HFxMrEtMeQ&AZNR8SN}L31IL
zK|nT#8JAK)2g-58^xLMTrKx3QeXU$tTtLjFEHzuqtkkrIsKhkIMDPE6?t5=|AfWZ_
z``iBC2WQ@UcRlCcbMHO(-22WYcYBd$v6t}Lr!lP4`DOp=EVA!4x(`|%tB;L?R#*Di
zt%>W?b;>kh<~lJ=2$Vi7)h+TUJ>&e%zihF7k&l-tPkd5(k)kx-=fPa7)>Up2-zP1F
zspZ=-emWRimXBBL@AT-Wv2`P)I`&J@*gDidYi(WR^6eMmVQWE-jr%2NZNBy*oqdn4
z{#o0nPLex|m)%`>^pw3&Q+#EQkRY2cCJ|pl$^1wJQlyht_CWV#U7zHH>`xw_kn29A
z{{f}Hlcofviw;$mUmTY2X)5TPr*{@Pk81Y?-I%ElDmN@#L&-0=itf_VO4-TYBrewe
zqrv`zA?U{Bc$;TQ6BA=s_6u5?7L|C|&uHye^_F`tZs2}TmHh*YmhZvSUZS)3*iUJ-
z2e@Cpj@-Fl0eiy4meD<rUY9kc9}__$LHnbNy%u>d9;{h3M6-CX2PL~`h=+Zj*1lgP
ze#o6T)u}tI2&KU(;rl%h>LqumWl|WbbRf821K&mJG=8MpX9R}`_7dzM*g~+0U_EFE
zTYA<J_V`)4yXfws`_FX$neJtDFQfY<x?iGuIo-?YUP1SY0v#5rn6^w?u9OA`(RzZW
z1f8FNc33|-{$TMkV5okUsFz*9)9MnT;!wgCSbJ0y%<Wqt*MVPU9W=ataYF^=yW~ma
zd*v%C>Hbd&dX+l4D%FWU>SWmyqD~Na*&2G@OYk$n;=$VXM;8sz+J6<LcV3j<TdJgi
zn;fRHu70JEq81jZLM~H<qd=8)_N&%@9w-|YVqK+b+9tXUC5R>%NAM6qGC>xB{Yg<b
zt*ES9(Y-m{o7251-J8<gm+roF_o2HF-Su?W(_Ke*UDdjg%4ik+t|!<+aNtQ*-3-<e
z)~dP??^WwT?N+7ks!q2LiTPiVIB?Z(v4$FKUZHh_<X}5547(Ss_fy@Rn)k$6sz>Z)
zJa7;71h0srR9()H3W|Au-dU^PD<s)b!-O?rZuKbrxFCch7yqK-f{+{Tr|a&g3i;_z
z^q)>HI!+&@<GfHXm`gopsy;axs+LR7bMAWn4eBOMvq{puQ<#!GQc9C6lWNxN`msNa
zl?`9uyg0e=DU)nGbDf`m2&=T7)S2Gab-_;netP<csE){WHtc`Z#A5qK>#PRnh3S`l
zwA8y7`ULH>{5<`jk2Xp_IjAVx6W-$NZr&@vUopP~t7?mY>(J-jW=f8Woe2$chFP0A
zi&H(YOwo=&Pe9MMP}k_!q4=eM*v*P{Vu%B~fZ|&Gl#b=ICOVHv=Ry@^>78DsqnyQd
zm%)0!-Q{I%JJfoI%emUU-=`ZrmcF|SIIYD`>7Bbk=vw@g*53tE*Wzb?_*rR+A`o|k
zp9(Cr&pV|t<b5HggQslXsajXpw>j?{eip;z@g1;qiG@)6HNCYyQDpVBU(?y{c8+|=
z5%rm4$V23A8|WOF=!iP9e@G%ET)1>`HVmNRbVQwWHtb0cTJhR9>g2o@&Zv`Apw767
zj<Cjh9)7a)8<*iVv4>iv=Rz87_^iYjKK9i3(iT*h&UwdivXoVyN>UoWCM*_yRncnf
z3|DaSa)uvq3`q<ubX{4c7;Xa-^siFu>r9oeVxtm@B~GzRCt0O~ox2K}(3J&UG%Ump
z1m_L^YXw7e_Hv!Y7UNpek6ez^`}m;a*+btEHn5IodpL`=#X-duLo`+&hi;e6`rTO&
z>PxNzh3oyYtF?O(_lPd&`HsxBB6DgR1BBtoFCAX?eY#lw<vM{(xL(=^Bdu7b>Qara
z=eG&tDrK>%_#$xrWt(Se^Kp}l?Hw652Ek?v_;k&4RLmFNz`BBTIAKLChZF9gfW@vO
zZzu(bu!OYGTwXaoUhMITjSJ*_dlq(Ki|ieb;n}`lXXl+QKU6M;`l(bf;rbZjJ!iNN
z&8{gM!z<DUiS_|uR2{^YF5A51^;gl1n_{6;*zSg~?;Ie^f36@eu_MfoCqB6s7B-{#
z7s-p@u?~swFY#^_??c`1<HY-L<$c{4e;g2Q^-VTODZ(upZ3REhD3`<!K}FUfeH$XI
zH8>hvfk$UK>=x#8YZscKcNW{zS`<W`9F^)rbLvs4nrMCu$3I*SFW1=WEr{}E%*aXu
z*8-QIaF_MoXi5LUk2u1AM%=Z-Wgmm&qsM9)Jb5oc58Qmky!<Q_;_w6`xOcQ#=ewu&
zH<>b-vQm*Zy;izSncy@En|xCBH_k6`KB?7<#JZ8TOGMR={zswib?EBj$Wm-PP>h@G
zfpHVxm6fvStBQ~t<DAqqR<iW)sm-_VSYhcwC}P#Z@8>HNWag|8!tXcIhR`I3N9hq2
zRvx9FIrrGFaa(heh%ZRUG?J0&M97r3b6)WO&9L3aOFlyzhii<qYKPfMu~!ea9AM@<
ze~wV9A|YRAluv4Ok|Qkg#<&t34?vl?2Cr~aQj*H$GwH;+AhYkWU-g*pW524kHC>By
z11A-Wo1>xh;%czM-T%JvjPk*#@`0kQ0krC?bH#b$@;=svXg^-_MVDF{6;~P{jupXS
z#i>j=Ql$B5+3M}&zMeQ##A=FlHP|ef&1!AGacbsAv94?X#Cp(@XDW>)p+;SgJcCUc
z$_j}8GicLZrDt4ItGG9j+@1SNKa^?3CX%3!W>y}9;+t)7byKBY8e;foly7XD^FrTA
zdTRqv@oFz&R9_sltmo1eCSseWLEmQk`d^GqW!mpzTzx(e`YLQ|R%~aybG9WFS8y}+
zhn46Dz_K)S=Jz~@uSWWa-vIjUJI_}rQs3~xMl@R+*DFuM%7^Rmr`=_L|I?CT2&b2_
zlki4NK`Ut|pVt0ko1!1R77y>^=W+1JRmW;SN^?;`F#YCU^{{&8Ue(w-5z}2cip@Z+
zUBjN1_6G)3CV%WH&P!TT+Ly!n=!{ka464GM?n_O@;$5t3?49y)Wh?OwkM?qyw=UO^
zx5NYHlr}(aNeevKcWBdsd?V#*c(N$kspUProfmjBBX)Eggn7h=D0I*Tt4|++njtUR
z1K-xS0xzr<MIs{8K%CzNg%a*-c(lDIKCdvH!-pt{lvilTpGJM;;s(yGej;%0)%w^4
zk>BbZ*21*=?X&wZYqQ1CJr|9=v?%I#`$K&gK6JknT{_ILt0>y_V{>UgQa@(_^7Q{m
z8|6!4R?q>%qZ`CJYC(S3Iefw6n%=x}$?zXK#zMJ3r1b7oO^g&M+BHNK21YF)45oS(
zL|vlJv7i89Mn&_jAWM!dX?&&Khy!2+gB1vBqho=iGap1b85NymToWZ;AD^3v$j$<A
zi?+y-58mm!6%h?fE^G1O0_bOkJgm>U)5L0eWup7SFEy-^@S7qcLTU_4HbcdkkMy}n
zy#x#N{WVrye-B$*!}h?ygZ3L#(nYX3AdvBJYz2Le0^}?Q9L<HB>-GDokduN$AsO-`
zkdH{zL&np3Z)(GF(GKD7%B>Q(mB6EqzysJg!+raT{0s}PUMIBlFtpKVaT6)bqA`Y^
z&PI+fL!XlK9ys3@tl0;wxt3mYcY<e_qd-a;%0!9N`bH6NT?Z$B6nNQRFhW88Q2Gsu
z^3CqJxJhV;V>K!*_mBG2#R)w2v4*C>i+oLk7u?`YXiopRvrLNOUxxDTEY+cKsks_M
zk(~&q5vT|4Gb{;$Td}|B5Q1O`A&tl`>EK4)!;t@RRiuaFTfhw{55ir-94w1$Cj<FV
z!}ccHZ?&ID_}dBpmYS`=Kege6Bu8_naMteAY()~%Z<51TyKlixJl+6h@BCTHQZzSH
zmY}Id*$_}ROoWu$dKZNxoA`<euQFjOvaZTx1v#G*%)b2&jo^CiCm^knL{zQhY@`m&
zQW$tSHa2-|Lz)y8l$BD0EGR&-{zc-u%xGs(bgXRUL$u7}LEjqko{?LTpq<Fr7hRCo
z3z2Io0IQF7D*^_6oAXhrk2C^FtW7Qxoq|w*ndm-Bao{ZE(qO^`F=1qeZ$${+vyVI3
zW>T5jH-rf$7ICYlZx>?-v!&U0iZIr$sh*SjiY91l>Ke7oz5RRqG8o4w4VIhdq-FSK
zpoc;WI&%|E2nCM0eOihY9Y0rN5x*7Uw^$~91ap88a0*2HMWdJ?o#Zsx^|e*l{`E~h
z0MWa{GS#N_ZyuLMn>~-$`BBd{IoNaVV6K6W-`=M6<!x*Gs3)Ub^-)hqWy%qc*ZNV<
z8;>iS*uQEkY*_jxyFk;Z$K5nFaa~@jre$qaTJCUt>GpO#Opm1}YNf$T(C|r&>tmye
z1}~zaM~o}lD1B4lcUo)$YamxW5u>x4&oVJnY#~;7oKa^Tde=is>)M_F`BH^2*4Dj6
zV$|hOA5*Ne%!#eC)`s>+NT%~9QAOibI?&!pSVf;7Kr@-ej7Rx6KXN^_ladVA+Xr%6
zBYW_DHiPq{&B3mmov<YC!*V{yxd@)l@Ct{wq8Gjm0~4FBS2r-R@p@ebCWJu>$-qQ&
z;yYJz0p3?#mkmseFK~-B6-)4)+&jv5a$Bxf8kk5>8JIZn-oMen#AS3SvVjTlIiO>!
z^tq^H?*X3+R+^c3tG@W8S8Zg%QPs%Aw%j#W-9{#y1xRFiVLijPJbfX#r|OGby2+9a
z4(f*U&SS@y_jr}ziMQUunyzAcLYSpcO7wuLjLY0*T=HY3>4~8*J<-#DpD-QJRD4T(
zkbLV2OBH{!;R%}7IR3QZ3Ht`|ZFNat?UpByZc~-z34QIBCw{5L^2Fy=El=#L-SWh1
zD$5fus4P!BaT}H=GH+>lB1*PA5iVPv7$94o=p|d8=qg*D=pb93XblWDh>wTu8^m|D
z1>)OL$@auk4ePKyvFhDwwkMvdZhPWk3Q_XD%J#%|VS8fiEo@J0RBTTyxn9NgM9hDU
z?TKr*VSD1BVtb;M%J#(Dvh4}iU$i~(U>lX~iS^fS*Y?Dmn`}??muye;x-HuiJwb|8
z^(CFF8=rU{XG51XR*X;d7RD#qDaI$bRyIEIHj|7`%!cua`-Jg{@2eZ1kove=7@qjH
zo@96;^45kYlmfba!xP_7aP1A}kaA~SMM=Hth9_hj3^mxFzz5)eo8^i1YgLvf)?BY@
zc>+1zzU2wgPPs4}bF<}%71#f)<q45oU6v=50JpY0u~$$d@F~E+EnA(i%2p>PC{`zS
zsjN;QTrE~7dI_r&2vED#iN-3c6L<Y}s}pzUf0}cbusYHB%5nRrtZuUta_Rj^yA%1h
zZFd6wy|6nWF^1dj1d8I;b|<D*+MO78lidkZM3TJ^Qw&f1_SX$hpdJ1j4Nt7NUWeg{
z7H`*Lcmk4NO@=30{;u>Z)eTP|pQ?r@cD!}_h9_V|LKvP9wk8zA6R-&*3{T{?P#K<p
zD-2I8s*Y);;fZWv8UktEY<ObT_3DNv!iACfnhZ|}qHZd+@87)1@B}&{VR!-$t_jJQ
zV+yyM4Nn-P1{-*J@sX0m-`%E1Xr>?@ybbvUmueKTtC^yBKMC{0f(X{{RTFz)qlu*u
zd_d6n6%%VsFqPmb@~gVu3rpWR{{wdyUOCeKfOBsLRz_m&0ZV;n(fB8w%%Sru?ut$z
zpOu!#+Ztsxt0TPJ8SWbwOA`)Py(Uy2hxz!R{kF!g{tJ{jl5@ZF%hE_;JE3Bf_?k`_
zw!n7M{kA5G9ZYMzXjiudm@Xf#-J%6$HkJq#C%EdhG+Fec82Ahc$2*<E_nGB4Y^_|!
za-}KmJGpKgik-)#>0=>HA3f!%@N06oW$tjUKzb}aD)zk>^cS-XXPG>Wq*=l69y<GJ
znhHm|9=)U5RJc_YYw%x677ZNXCmmx?m9}totIVOdl&OSr)w$zI=h#!Or^&w<Y3#Yf
zJ$sZ)A&LXYUGF}Ny+%=bM+mlvH?&9i==X;RgUY3i=|xu%(v-Z&2_3jIL~l>fF^8sd
zkrG8@aIMZ!5W@Pis#NZ9Ep&UiI?!Y3w>N+HKoe>WO{h(iYS<Bt13`Q+;fpim_ZEZm
z*-eD;`^v1ZTdeEYCUFMF4Qsnt*M53dTbABV@0FINX^L08*yQJz)8E68hs}YpuBSK2
zXKPSGi&Y8Dua;0oEeUB1c`t~BqErcms1oW`EujuKC3M-O%e77tUsqg8^~4_kXxGK2
zikRsw4!tX#6v+F|E1Ms{N9bnX;q+QOe88nedS@fq;B_M^!U30Jqg`*TQ4FIW7!owE
zZ0?aHEXo?~gLOA%H*_|FEewao?&VS15J%Zjgo;+;R92<Ie>epVUivijfF|%@U(a#=
zA<Xb(k#Z_M?4+PdU=rKftnVaWt8brsa2~cksMsnkYy}o#0a&(f(k)R~H|aaBsqG#q
zke6XwBMPNHFB@n5eFVA<+q|M(*c&RAp69_V%A!qT*N$d>hrUt1bB%$Y_MN0RJhf*u
zmDi}))OtKiC)xSUFQm{|M)M64Q7pzjlQq`6ow<0S%nW%+;)4gVPq^eku`gq;VvJag
z473bEVqH$;R0vDMlys`5YHo)7e(3Dqlh0SHY^<M4jdhZ0D>If|U4Bz>)O@(!8CB+V
zVAHE%yDp>yq~4mgFiYlGF%ud;zWV1Yhhp*hM1w+GXXkJ~UwZZl{PfBN5<SBF^mH$C
z7GFsu_XEy-xNDD=4x#6X<N~v;6y|8j(XWsGbo6+GgSJaoE;`F7R8tBO=I49m2klWy
zqaX@5OK&j*QP`RFM);G*-DCWk27XOXdV2D?a)RWp6U_Oc^O*B1<TH7XuVjztvPsx8
zovmlqmcm5yed1upcfrF+K}9xCdm}!nn0rmSr5-C((PQ-@wlQpnA}iWi?0OoXvxMtC
z>;w6Dn*q8k-_&4opO2Cf%B&+bDYItlswuOY%E~OPyw39}DA<Biz_)&e-_>XFo4-l?
zmW$ux;`fsHJt=-Si{B&k>l&6oKhHfZlv&qgW!931-O8-)4`ZY)ye5ydJFZnKvworZ
zPvGUC8`i^y?RSwZE^zo+{O%RM8}a+pDf&$c`ofU6zCKpE#%r%ScCNW5?Co8Hs%f^Q
zYD%(~L)o;wy0S^6B`KQ%)XF9}L)kPEMOyA{c&wqMYHIL-q-p}W5bjj;9#@q>xw`~P
zPC?bQy_%}YzerX!Z4;^{1TWbx6gYU)mAvMD)|9*;R84pms-|U#Azn-J>%kb#ANSe(
zomzXbPN^IqLT%8IRGHwF)o?5sBlJSYuSt5L?Xq4-c=Z*UCXmHSx+>{*sFLm_Io(Dg
zT~Puh9wNm{)l$TJ$&Y%8@bU=jD0_Lb)nqSEvo^Pv&obm6(kmnh#m7!P@(WJ0HP&90
zooS3Mc}cI}?_2V$``K8sR3z+eFYj$@kz~*D=xMuyCQEWeDx;Eg1TGJheD9ZhH^3Kq
zrjn7uS2k`+lYU9ZggJj+Pw`+g<oSz-*@nD!;$fU2uZ7Svfh~w$G=<Rxg2VQUT88lN
zx(m&@q|93;JJIlX520?@t*DEztKFI-)J4Pq4@%q04Ed*N{%?o6XoZ}T#MMqw#1he_
zf}IuDlv(}GGEp693;72Pj-}+bUlcj!_9fp6B@-e^N~VLXvgCF$wV%yfc6aU+IdN|D
z+%42g#k$KPlu@dB=Y$H!YGi82y9(XX*X{`x9PJx^7NxQkFZtZCw6Q1bdqAP)?THmC
zbRULou-EMMhrDr0Gk7o;1oYjB-?>LhPAUqi?+AY=qn-lZE^kBLr5jk;GUUIfL&1U}
z11}F&@Y{Ms)hn&PhGX^?<sZ0)sRgo)c8c4+{DVM|Z{8$yPw=Oi3Q9EEHAt+dkTfyJ
z;Mj_mT<V?V5Pnh!iAbsIDd`PWRb`tHYwki-6(|*}TUCWP);m`E@2TXEk_*r_Z8##D
z7)+b0$}rmXJ8bWl9MQ^(s&hio__0P-RP9m}RX<`bQl4VXfTGGzD5_o*iYn1R(7YM>
zPLbOJR8+BUWT_Ti!B<2R&YLaNQ=$lkdJ3GJ<j_JrB|2K|e$lB3w6EwC1~To>NBZ^M
zTqLQbRzfZHtuwUT8B<a6Ilb8Kpx$GeEl%P}p;Q<abYQ+->KL2{7F-pIr3VV$lvGM$
z9ZK;0ct`%mYl=##vfOFvTwh8|sFbv_N~xGqTn6vZ3P=8vm6gu7q9qBH(j_;0kn7JP
z2x7#kRZ6Qt3RFtpD=H<?4MJlil8aNTl#=W_fhcrJU#ml?bV|WOrzFaU$QvTH*SL}v
zH$cuM(Pv=%^hUY(3BA%I6@ta{Rw;U=Pw+9k2qkHhMD0qYFKLwKVi6=@9C7L)6o3e7
zFC0bhpMc^53_~SxP$}gr{iz`z@0D%a+DdvbN#z6eQm9Zbg;uOAy-W6^qE%E(B9!c0
zqnb&fSkAJFnn{!>)J$%UXlWN+vZ7{!JJd{qLu54*h$z^4O(=21a8n=+L6w>&6o{m0
z^1Mv6LDRJ4S`|$b3P#d2<s%`XY*HGB)Q37m$7P)?lui3``vh2HxM;sl!GTggwT}gq
z_7@%BS$CtA{3{!HX}ys`CFP|p%I7eJ3h$%kQZDwLXi!uM8^wMBps>+o^?yZZnRKaL
zOB-#}(A~e(Yomv?X{vF2lB3{|NdBapymKc8YJbsT`tKBShG4~wJ~qG7d!#`r)hLZh
zBVCJyW&_WByik&S%eNwqb0_35=jzWyTR0^3gb3z(?02Plp<3!LJ?d;7og$agmZ<?!
z+RoyUt}fM6KV#o1IyT#M=V~!9eLX+HDHy*>N38U~>qQ$J=KA0_Y4V=GL{#j2KfZOn
zC|QA?$j()GiF55v1Q?(Hb<XC}ZuSC^acKvsMN1TMQHu&)BH}h#t%MggH&7<XdY??t
zO+^-Wsd|ywccM2EdL=x#w6PfOgxh$h5Hp>kRgg3ic-fIJ$)fv+jgFMe_#HAR<OL{}
zaQ8OkYksd$+?6_A_dIjT7+JCO;tmsg@jVm!jG+7bCiV!yV+0=)?A;+-ImJPUaruR_
z$4gp;>`{_shca=<lB8BK6#d|3@85{qddUYCW5L>XkKM(rzF4xdHHk^RRH~0j{k>Eh
zlX{sq>x}(t-i}sYfrS%F?{s~g;Z{?8pP}rUa38|zjM7WrWq&kxLQq42LyWTsdZi21
z4tkQ*H@)rs1GqInIXk(v|3_Be2&+D#7A)*OUNqe-ZRQ$ViN&N0VV*~QwwJ7KY3>S<
zFm!dyQ0-@^qIYTOYAuKHs7!K0I<ds(H(SNH9Hu9nKX&T$;^@rIP=&RiX!te?=L(Ax
zhAR&jmiOrge%*Jn-qtI%zH4LwMzu*5cyDpjxxO~7W71hZSg$Cj0<fEZ(phV3k+!r4
zQdZ9ug!MtZiNXlhS=WhlSdsXe(4b5jFHxV1S)=g`#FY;KZJs<7RK!pU*i?ZJA5Nw=
zaDDHT&(9QF39xUlfonMucFe25$?)7{C<sF5)pIA3#cn^CfN|JPId#ItQ*5CxGuWTT
zm^E0Zu}!egr%7uc!VsTdjt~4gluAOl-F<UWcseGXEY;%NWpf2{bw<U_JIQQ!6-@St
zk?2O6*1KaQLhSoYrFQ4M<4)TtO5XtFi$#PV_E9jJO8ZNA7Txfo!aU`vEpyn;+HpeX
zoFOG$sIbL>)ptK8SuH(9y?;W1kBH&W$cI-u8!y-+Xxfu~*FKYu+4X#%$+JFe3EB%y
z6sh!^q8~jS^Ug|~aM*sjP0?wkzV?A};#^n|K&k4~`&X20`pwdCu4x0;D15?LoMbp(
zI4TC`9~vk^j&qOwOiq!@+xmd~<xi3!M?(<eiytF?0`OzPPc(iW!cSI#17gfj+mZZF
ztq(Z&(0tZvDAiJTg7^gyzC&%7?Pm<uR?a<vUl;x4VbwcY6h!DEZRPe;TC3Nh79m4z
ze@qxx>^y$uYkRS;|FOWr(avM`Gw{=dMB4r+Dn%ShNjJ<^{$R;i6lHzhtP8c)b@(Ju
zF;ZEn4U2Qm^9{OaYaDcKW<yEO<>6>fZTb=EMN8!>&PL3c*~FEZs_Zgvk}7tY$8uY9
zsE9P96lIwqA0J^SIm4U2i&Gqvf{JGL4!USHQ1T7pVq#qnuMj(=Tz;vF3d_|3X~~)_
zmGxeV)iLPWETijc3O17q`!Do_aQU*vOPn#k$V*nwN%pja#;iY=?ByX$0A!OWpHVS!
zv8kGZsHUT09Fu&6J`DTsC}PvTlY9*MVw-xDKIkLsPKT!ST}dBrFMrsO4?`qD7Y%vY
zxL-3oI-Twy<)6<8Qc5N$8{DfMh5Cfhr!}o|)Y1HgIKs#^!zq1S;tX#kA70wrHA%ST
zU$(Zy7g=zMRUKg(Ks8u;r}Gp412)f8k8!090t;z=xw5bzjA<&rE*8dZOa0=62J8Au
zib*S9r<Y;7ZZ=Hw-h-X~Erf|*^7z8J&)*Yqipo8%97j5p@1<purYp`_9$4r+oX@Sp
z`+8gJ*^6{0dtYX|5^GA;MZ0F%h0Q`(0nEQ_)2G&R&Bj)IVZE=J|BYzZ0c=jd$2Lyg
z188f%*gL{dAU?KJI1!^HPMy9Kw2#W6esbmckJF@0=x8%B&gOB{K?QwlHKz`Uas3)4
zZI2JSVI3Rvopn@TVN%~&9>P9d`C3pA<e7|Plk2;BQ}wJ9F8ge=*TN=eUz?9LkVJv*
zt~)l8pD-KT<z>h?bK-=3W5RueYvD8n4~%6v&a1DjoEkrD+3mC4ovL&7UPzR#n<$dD
zo^S;86~%9BLSA<ZFDX~+ZbyJqm^&uq-}Z-LqKc!`ua~(7-w;Fu-7qY<j=?3+kO!-;
z1wG&Ay<LG(!dxxPi3k%}B!V~^VZlQaco`JTO7)l!gD;*AZ=k%i#nG<P1@1C=kUZe`
zw(J+@N?RmzgCYN%=;6u&4;JW#Bsuid=(NRGzPkJ1m80zsjEdvUdP@8M4ECr?-1SJ3
z(oo}EYlc&5R0`HcNc$hdg+;sZL|yo$k`th1gl>qV5uxAL%XU#ZQPp4{fj&qVCmUWq
zy+A=Dua{CWCI0k8$=V3>c^+53D;VMtwBN8KpHdtkrSUM1%u3bCX{?sgfC?}HxsI(U
z@Oj74*fB$g;^`r!`4#!Z;&L@JQzC@#nPCdPfrTahH{?cJX|kjLaG~e+aYkKQJho}x
z7)@&u!*HJ19aS{n?ZbU#`}5ksLQ{<@aGg+sr!v>GysApQc}y%$vem%8iQXYjnRC7U
zJ;_VqE@3pyG4^LHfsDs7x@f}Be2*!4`wwxH?p1CL!KdHzeErMr{==|nAK{aur;h1S
zSgH_5fyJa!PZ2FX+iEsWtSwgHOmElrMEALvo3O0GL<gG;4FPg#rop-eHJp4tw|<T;
z=%PjEEH3qM?u!;&L}+|03LL2QUWwdid*vLX=6=`-(=+7=a+FC&FIN!h3JPOj&gE-y
z-lA&=<!kTbX=~uRFHtcOX#a#$qc7bVbS-DbT*@|kdQ4^Sx#|q(${E6jyf82mxxP+9
zI<~0xAr_Usmm9j$5nk4Qk7Mj5oFj0r>!Ybk@~&f3D?ib3coDAcZI|pfC^gvLj}e9w
zT}ZS?m8`xJ=l2Qz5w)glAQj881x+Q1xxOq|ezG{k&!aHTux*acu&Yqo_j0s+!8O<c
zv_{jN9IS)r4y%71ara=>dvMn=+ko5%U9Pi!!SEh_iyP;jS&;joW>MqPPE}nO=6>i=
z>dH;f<&-w8^vP|Tn-2lo<}J*GPAW!WbYO*y1U(Z|eTyj$;oCmN-K9P_1w;5a3ea$(
zKZ#R%tb4{e_X)YikPoXy&ZG9zIYmEtTg|0j1<y&sO{N#Y2oi2GV@bHloDAW{n_wj5
zojAxl@#K`5MDk8%2FW{_GfCdboS#J=(;x$7LI#=z87L>KK-hFC*p1&v+q(RN)(Gd(
zqMvXm-(Bkba=Z&>`WEE)M%vEXPaCX$G;b;Kur_qw>A0(4rmi4I7h$`IU9(ziJ$!FJ
zcu0ip%DBn#lZxMi8pi*K|A(WTdz1ioF1kwuC~{RvVyNxn_!8`mcjXp~eqWz@r)wcS
zj=$`=hQ<XCYvWW+ax=zEsan^%c+m{#>7iMQ9cS@X8qI$a+$CK8ko?tJl`qhSOX9tU
zYy2$tbYPTyz-G$hhRxHJh&{`A0TW9rrw5C1AZ!Ib?1|EkBA)Lrx@GGbtc)sVm89dx
z7cWH@q8vZo!nOY)_3`5(wUPlE`2g})A95c+etM(EdKXR^#_{9$!oJ$^<2Zj9Hg;1z
z?5EC8Xi)4vVY!Rz^$6}hgM6)ccAr81>?ujA_KtN8#$)9f<oLu#K7-stK7-u<BgY7u
z&MSwI-*-gbKwnWhLO$JjfDp|7#3AI(V(=~5DA#x2RyJ#ESL8cMpX6v>+8W<yRUkX(
zHQ_X=!u8f+C10FI-oRaKrQXhBVK=h!IC7d#_no8{-z<d0#-aZh@jOYGS(;RjSl2t@
zZp)+AHslu@=en4yh+#VC{!$;w@Zo~V;*ikl_Vk2(j~Hi^Z-ax@DD*k=e71+Y{opnu
zzVq)`|LkIKYp42!*7o*&8vA}tzaK4L{l1^&;qgPi{q$5!Py70vvNgaNl}7^)_B&;*
zhjmzP@woDpvuFZDF7dsXmj08eDon|({=nzJF!Q($%vY?ipw$PP0KDb%1u9V#rtOCN
z`8GHJ>u|PuINI{c={>$I=E`Y#88^|dsaASAtvxn@ym*Htl*WIq{|i^SPQ$!BHLN*7
zM*<VUXo4hyxdbZ+wh(+saEhRU;0`YeOVFEOFu`PkEP`L_YuHJG_4K@%U<bix1V0np
zAn^63cm(|jVhOASiwHIo6cQXEI7#pm!DWI*)X8)t2q5TBFoNJgf@Ff31i1uH609e9
zkKho&ae|)+$_eV%)39~~_Yw3X7)&sZz(TNu;6;LW2tFk^Lr_j|2jOod2p||pFoNJA
z0xLlt!5V_M2o4eaQC}m<aEX`ZrgAN6ZDPs6CieXb6Wemo#2U{sx&2OkZeo^uOgF_*
zuJ@*Y_8{)q=M;qp%)3h&E2E}7v`q+`N`KkpG?tBFgIQPBNA=u;^=89axJYL#8^I!2
zC>zPbgv(I+>&MdRuOG$F7GV<Qzb?#3c}agpx62&)j|ung!o9of!dSF~9Sf1~Va!aJ
znJN7#^lK4rBUmPzS<P)Eg|d>n;u1smEOJqYqFEQ4MvzVJxFYE}P0kn385B;+JBz}n
zkRNbNpy#QuLrP^~rnD>+5^hSo1d3PbBH^pxsNkjGqu`+At>i1^Gsm5`lCP4dk`K~J
zp!96ymng?T7+_oZK8CPGh-{Tx9Ho;eD6DiHL!s2~QG|1bDo%{RP5quAXp!<$@=?-O
z(o@n=;^Tvae(CA`vITP_($&QnMVAo|bLe7GQQZ?0yU!7sL{qhg5QLehn$xG4Mdgmj
zoaufZIn|np#~5>#RdEclO|xZNAtt7YG$L&oq9Q}GEGeQ66D(6j{h6m&YzY=AOhSfu
zq<oM*(nXp`3+W&YiZ=&oAU@(E4vR^!+AN6)B8|b86!A1B*=EU>-QvuN8D{xqj7@rq
z%FGZBF*f<0U`1TSLwJNk82Gbc)T%}k_k>f63uO1RZp2Z;=}+XBmOa>FHsc;+w#Fu;
z*~Ie@)pJN%TIN)x&1*cgI!`ZeeZBe(d>S?~_%^<yNz-O`-qpNC%ez~(zNd|`ZM*h<
z9XfXEeD8h!UAlJb9?;|dz@EK&KhURdzo7mD1_ql#28D)&4<0f!B68U9s1YNhM~#jd
zGd4DE-1rA4Oq?`1{-J~^QxnZe(~?tCr>CW7WM<8<WLs@BXU(4T@FR2Q&Cg+>nU?U`
zDb{F9=2SCkKb?4OD)EMexWr79B~lAO{a6H_Sc#|7$=xVgt3`w}3OX9H`Z8Y+r}h*>
zf9f!jZw&QHBiN7{e9$IG5>JMR5H<Oarv5E}N;^=vbfqvMgpJg9pbs&Mp2aA74zuXf
zklS#20yT-kElH%AF2W`gCE4_pAbLcp2SPuCKF}uGP6qV>M*2+<RL>MCRHg<06ycLV
z@lx2sayYcA`l8iI>8FU+nL;rW1h!J1M#{}5(uY6#+f0!w{IcjT%^gEZu^ahB2r8vi
z)5$ekyd&gvN>{=ibOAey$O*j{!ekQVMv-2c2rp5VAaYj9sjHw3Wr;o&eT9*Arapfv
zy;<13qV&K4Q{6bJ%QK<IlFAS`f^(#P-y(3aREZfTa6(U-BIvAM-}k%gJA-0a1#e`C
z(wauJ8Yzb?iaS-VUn%u8x=Yk5H6{6^t4g$bK0R*1S2x$USykSll+GBrUMy}Osf05{
zsi7_XJNTkH9RY4S6r7ZDtBHcdYVq$UnL>$g6E!+TF2%Y^0c8OEl(f|8J@6OnZ<e62
z?sisFe!c%fe&Eu?znEVycYax-rjYJT3U3h-0Me+b<tS~jGDRi5o__)Vc#*1^%@&w<
zmpMv$L(M6*cr*SzSl>G9JCkxV%NR@TIaBsWFE~?hW6kMS<s)E|C8RE^+_xw^Q&V5B
zPUnGJq?0c9aw($4SwyOd?ml4pEz|!i{8BZiL{Z)ea_UODmF*B^nko39v*<^Y#h7Ch
z60f-mH{9GF161{M`}iS*#Dl1_bn$Mjf?t5Der`WqNV|~Dl@zmY;@<#Of1M=iKx#eG
zh?7O{DI%s(j80j?#UkDnETlMzRmuVv=0wrIny^mH%6~BlmDn1(Bg8nmLs7`+-Wcvb
zo7f$2r+X8)(;Wx+EGsp!77XVjnOIA@ANk3|?xy=gbceADU%KA|_YxCpLw7yhA>FKT
znPB*UZT`VT{731~9kQd9?hhj$y2DCyG~F>}3!r<HXd4zWPGkH9ZLy;7S9*m|=1+e{
zD!HnX)o^;k45o7aQeQ5IZsL!z{$l=-No9&q>GIes#YS4wMQP5W-+^-7RLvpW-6GnG
zw4<w})=$vfS<INgmG_D?I%n9@(&*6({~9VQruAZ89=^Kp@NiFDy#jDlB?UD0i5};z
zXAcAf#6^2EW;CM8nEs*Uhv;H#cGhgV^b~@5GrgW}diwL$v;SPUj5qytcK_Y%ck|y+
zs+qd}@@n|28e)O!Pjj1p>i7#)e;&8_r^Ge>cNhQvfa~TuP5!Uu08QoJ?Os(lKvVhW
zahrdY9PqFH-HLwvHKjlGo7(TTNtWrZ`hL6gR?=PFMVueXau+PL=jA{8*doVb=aPb@
zk1t#Pk0+jd>gi`ztbF#lRjZ$WVa?hX*R9|1(#soPdG)nTufOrn&2PT-_Li;Nw!ic4
zd++bqxodY}(VpVHAMD$I;NXWJ9s2l_!$*#OdhD~$zxeX_S0}zc`OUZAojQHy`?KeM
z_|aAJQ|ZsY{Cd9Z!fzKZ{eJmM`PDzJRb0Qp|7FEQ?TUxnQcV1J)BoR{|G!-^RJ;HG
zi1NqTPYvWAu{AyG<mabV&p5|eksFq(o*!2|FH=1)S3Unj_56hD8D|?S&s$Z`Fce--
zN>6OR7-Cj*W^pMQiJ7xvtO?eX%nZ1X%{E&`PDwRSwMJwlWm?jON1POActW-{WU4h~
zra3w@%a$eFq<1M97DXv0OfwJ4oE^u;vKXOhtgd6k<&~TJXzqes62!ER=03VGx2dNm
zNn-i=`BZQL0lCq+i%6>K+^J7=TrSC3B#cEz<D?a1=iEiP6pN8KmYkfd*L%;-%9@px
zRYeZN%E1T%tSw+m<lqErLYmQRv1D3|DH+DJ1Y5?`WV5B8u|u{HOf5qDjc_Sx=0u}4
z)0mlM&M=y1o2S~W2~*Ob=pCDZ2lyosp~i#^V?q`MN~G}6{89mQQ-!gZ6B3O{mdtbt
zEuypbZL#hULKqFDG8spA#)9Osh|HWqc)5$(IKyVP%t^_ZW=s+Y-Q=Hbwpvx*EZdq$
zWF^|N(o&{MArv3smua)s>`8u9C^h?4(lV8Zv6_up61Ny_*~q$6hqUZYRm*Ie*-Ay0
zVl__9Of(xalav^c`!Vm8);+ol4X1_fQ^Z`VyFA-duJGAe#CTGQQb|*K>FEjdM5T?a
ziPTQrsBSvpDLdIbC4n5%QZmd`pJ~}OrZFoy#cIyZN|<UkCL~$S7GtOGwrorHDJdD<
z%^5R0DG{sHab^7@CkmKi$;?PMXIR}CRmsb2Nl(d05EVm3PO-Yquw_!gQN2}5swSkz
zsG>{pW~Eq@QFYnY1dGb~_L5W8i=aggQ$yJ(cuQ?VomQ2wiDpr)YJZs(#*P`>wa?Az
zc52_rm>^>hZm5!S4R~~F+lgpPOUs-k_^bU*)muZH+RLE^KC(=+q4Khgoy{|;b*Cg5
z&FNXzIrr9`&lF-AnJE&m?t!MDFr+AibaQ&9We#h{I?!A*o9;&W$ykFM)-wP4g^#bJ
zxk>cpqhrEiJlbcqIaPc*{M8Oy8m#cTuofS7hW49?{yTeOELG~9iPXoVBhQ|gosyoF
zW{y|-zKMw`+182H!27#pC5q0^*o!gK1B{hDT65mmkdFIj@?ClNZ)vL2f1F?4{tG(P
z?f-h`y8Yk2w{HKA{&o9%cB$%rNaa7VtBGZGt?GZITKvWL*PZ^PpxV>Ny?gL2=o?hk
z|9Cb3Z$nM)=U-IM)x)g`uk_obdM>OME+n#UdVNOKP0!P#C4XE~Mw@D-tHqeQ^JzJy
zZh!lXy8WM+SvQ_P<keoT&pm2lZ#-JN|EZ@;?Ceuj{i~Pb$In#tuTFpD%DV9%x1nzT
z9xv5RU)Gko^Y601s{es%{ud5N{<yl*^Cqpv{XQT2Mov**p{sOTL2hBES&i3!_Uin7
zdv#i9)XUwEX-NJKm4>6?G#bUR*18xo1k&gPYjPZ$L2qg)o+L?0vS%AvsF3TFNdR%M
zNXuri&>*R#e^nQkkYXL2X^EjhIn6A`okk%u%od6rnwgQEnPv{PTGGO4P_;64Ckx5W
zPMMY=r!Xe7GE4Ryasc|FBucnf?3;R!YgA^UEzLZbWR?*L=|l$GpdAG%xJKNkX`^gu
z)|5eWtmZM9aVd%B(BuRQdrGFr9WI2iM5G;KO&m()13BEoL!QHgV=_RTjq*_uA%(Lr
z7YmbxVzV4|Gz(43%vRopg^wN)KAc9+#I!V$7c?<e3;jnB-Z4Xm$Av^k2#>=aL(K_U
zVmk%<NIXkhCw^t&86<XvT2ic(MOqBuim4ats~v7mm}$PrJw>9zLUk}^P8Le%(Q5S`
z!j6gbtJXHAnu=UmS>DHVV>6Nk8HwSur<$`6k_z66Z7v&79<_UGBeKKHQ*6_wnJv*4
zb2cjcdyj|=LN_5T<>Bgxhh!wiWTj+;X4)v+Ped~$$mq-z(9S-@t{ByObKPib+Sm*d
z{u0^8f)=SZX?7-PjRsxpJmp5AsSu}|6C*NcYLYIvu2k(#2`lc&h#L|b&DaAd!;#@p
zc&<-$#1h7df)8o7%0AGIaqnx{k7xIOmjifn?}XWhH&LO@E4fzU396NBl%9&aK2Wu&
zG0B({M$ptM+(Vvwha@IiM2&RtjH8kh+|M$RhLoaIaO@&dfgkFgO_g|oglbzBiX@I5
zrIJiDTW?~Uw{$USW^)$nsvRC0MXVwC2kl%tnlKTWu_WY%N2MBAf(GP;S59`Mc+^3h
z5UsZc57y-77EEogv8U2B$7H(OD|=aL*U@H+VAG7L5}B0s6G&xD%GBvH-9<O|M^t=s
z1pRZet>*MGDU?sPC>eTUkIU^J4sk44J3KRi+Qt-1f@Kcj_^IHj(PpWVpOxB=)b5ER
zHmTl;5Gt8C&EPa!b}|whWJ^jSiJGy;P+F?qL`QriW0q+dY{srFv(hdS88y$W1dG{S
z?s15%D!<qSOA4kIaV$piNgSCZ)k>sCrFI5b)95X=ZfawU`AOU&V;fiVko$lBD(oHN
zzH2lp58s=^V(nFPvvU=HkG~PO|6Kp~FYwcdA58DR*<yE?@{W&g6kgKGcj$Vtc8?<(
z@hKSQ=+MK$tPAw8dih>YzSo!i8mRp4l;h%Vkkj>*-LPNa4jJIyR(9_tzlX^0q4ImQ
z9A~ub9wXo5<n+hOd8f(l>5Pe0P3$Yi9s`SvtCt);SH^jPd|xR0+hzYeIi2MMSc!jL
zeqSr&vtG{cW!ZhZjNd1+|Ch3Vb8o3ElrsDGUcR+nlE1Om>)(#rf5}z*;+EuJ`{K)g
zFW!IW_5V8$$k+dNR%lA{frn1No;u`*7S37NR(5{rJL$f5gLGf;!YOQlVy5}I;=Yl>
z7p*(7&R9#b3vNhvlYHNLo8d#``!))H_{Fm?wq)mCbiFvC_Vnkk6;GpR02y^+@(Cl0
zKaqOk{+q)eJO1sdtBm!SFU5o&2Yr5@b0*f4Ab_9?L1zL#0wY0l0$&0>LB&}UD<g0b
zoFq6-@EO4of<puc2=)>b66_#&hhPiAW`a!w>j_p6EF)MXhtDOLO^`*9NHCEgnjnn8
zM9`lgfS?tDFF`$BrJSaxcScbDJ>f;*A~;2GoZtY#I|LgEo+QX6$Re0XFos|_K^Q@Q
zf}R9j2>b|I5i}+6A<z+2oH4PV362vSA}Bl~h2KK=jRY$Q@(8R14-pI}2qWlE(3yZC
z{%MoIw=VheU%C8Rg#4}V8g?_T`g<zFthhkDaoNPyTp=1M?y{C4jLX-mize}$Tc7<)
zm!{hN&$`#<|7XM3=Kr7TU%zg(@5rOtrIjxwen1)VAp!XDS>ijR=Myc|>35TX5%0G0
zzcu8@myW_4{c8ub1&y4xnlDVpOt%HfRee6G=+)iVFi)?)qn!VLzofl1S~1`1Ow*A@
zOw3hsG3Qz&O;1$eyhWX^A$QczJ9J09BXozqi|&}GQJ`E@PIJ0rE*7Avo{mQBW*Az7
zJJNrs26tSuRSczeUsQ|xidx(^*5dw7E$#<uaX(&*yQ>CwjLqfbt{<&oE-JjU@+PLT
zF&frcQ~BOJR>L;xE8hzzYgn>p<$LEu^6yaje#AlVzLoE@pQZ4+%J);xYs7c4%KOk4
zH0(iDelP%MBrpjqm7P^JU){QOV?%}vVR3PBEF~p{*=#ncqH=TTKbNgov4Xw)^2_Yq
zci&}&g@x?PFTZ3rZrosU)6Eru>7@*BKJ4*BxjxLWf7YzS;`J~;Uy<umF>BV`xd?Ec
zAF4Ra4_zVe{q(M<m-7^t-e=9iyX)|wLx;pWhE#?_me2EwB;h}6ZkhgPip=-P@3Ri;
z%Mm{*sX}_sLHI+5ladbam)|QSe;lJ)fp<#3g8Xq&m>em6={@a=2!H6%;eC?B6_NgT
z$X|M={5f|X#-bwJfM3PotKZSvW%vvH7gj7jRB`As(!l$T(Gw#mKt&p*Pw$>P4mQ1a
z)uF>gLK4bHfBf|YP0mYlL^<BC=ilFW_@ToTVhM^%U-8PbJ^Dxi#C!S2hu62;bV!5+
zko(Ue{dqY>7dimK|C4oN4wY9N&Mg$-4|9Hf?C$ak;f?TAz9p;5x$qX{k0e}@H^K`$
z62~QPk-or9@@D!)@+En*iZ+Egr?k1j!~$(ppe4}cGO44f1vGLvb-dtOAcuhGG7W*2
zz?;B8(1wH0ePv$16`%L)*^@;@MX{Ke820eP4_D#wWy_YaS6_XVZP~I#@c0*Be8JA0
zJLl%}ET~&HQy;o{yEkg$k*r7fwxr!GXZQKtNz*e~4pmXoZq9Rdm&Ow(OwalC_xNq}
zkn{Yx37lU`ns@Nr*s)`GCk^lU8r|ckN6r|@`PO(o-_dFJgt74~hp*ecbu7|*cPY}(
z;ry2?S2i=j#g8yHzfBwN>)nPktqiOVP{Mf2V35iQWn>cNRJW$6Lx&E`-`}4F1O%`F
z0|u~=kPsFT5h2QM)TmJ`Ha3=xA3vT=nly>cPaMpqO`FD2Q&U-bdOEXMETaFIH*X$W
zYYS$tJv@NDJwJ%qr-id6(?i*lnIY^si;2CzpdWiZH-bI8U<%v5B8%;Nd>A{jZaV9{
zi?c3!IP0;Gv*5j)_4<&r{-1C*@ng<HKjUoJ3C>1+$5}SP*fX3>_>r@zr#PGPGiM7H
zEMN|YgDqdaoIUf*Gi>F`m2B0jRcy_gHEhF%4WfQGZ{EzdZrv*SvK>2iuw%uW*}@B)
zZ7t*MgAYDn2M-=(AAkHYJ9_je`|PvN*ohM-*f-yN!_J>O&W`=Y+3C}#1z(hul(0+Z
ze`4QX<*cl%j9s~MMeqtPkM1-+L^I|^Oru}MSbgG~2GrOaQ3E#eJJ<l;gH7P0*c?8C
zt>DYqR{kdYj2~6{Q`VH?x1;z06n_B4A5QVdQ~YTZe>QK-7E}CH6#os1Ur6ykrTAx6
z@jFs{6UBd!;#(>HQi}fy#ot5mk5c^O6#rX_|2@Soq4?)1{$*AC?j0G6rm0UBO~02}
z8QZ*+=H#!?m{v@U@YBYOAMe5VH=`IoJA?6`mNQ=VCgYb?@tacob`(E=;t!<wQ52uj
zDodgGb142|iocrT|C8buQT$IS{y9~A5<a4-DQA(ef%6(R)4b|1^*?1K#Bk#sj1Q#v
z6Dj_~6#p5Dzm4L5ri#xRv1oP|wb{088S|%R+nXIG&M#vTj5mIe@g7->k9w5x8LJpy
z{ubkJ9$@_FcdGbCir<^!52yH3DE@4Uzm(#yr}%GE{9P1(KgFj!m!G8g=O})eJAM~R
zVHl;5LMc2(DQut=_EHL`DTT7eoc-2=vrD5myF7!lE6X{%`X*=Bj&gVWyD5HGiXTkz
zM^pT%6n`egUqta&Qv8=F{uYYAhvFZm_$MiTsVcr+E`eqg|89!kmg0A$_+2ReK#D((
z;?JP?ODO(J6n{6xKcR|W^@^7+wNq&5ppZc!Lch<3-`BZ=U%Pf4hq!%121Q0hgoQ<h
z1_y_P#dq!8sZ$5PAw$|LDTGCkH~mM@Ls(e6|Gfw>WQbArkBkZpj|`^d!$U)Y2Zh9U
zL4Xb&+O?JaBce<pks+aBp%fo@b?f5qKQO)$$;hZk<r;i<^Sk1^b(2!?YuDD;ehA`I
z`jL?l!IAN;o3v<7{uH3I9H3)7#Saca<j~0YyPGs=A^8g&{n{A`$q0A)@y(hxX)<hp
z2;eUQv^64rXc&A$;NP@K>tQl#!|y{56hA&VBx*!tWO!tJOC->u`CWJ2>Eq+mYB+L$
zf0Vc={gzb%#G@GC9~vGN5g8d39@VBw0P^p2pGbdDR9IwqR9MvDds;S=1Hk{@&RvHy
zDg989g;Hwq{SiPeKaqZqpeQQhsPM=rL4?RbDSyI0KCFicC`3{kEe8*7(xeFmaQnyi
z_KG)k52p-9kpDe{2MZKhx&1>8o`yb+0>UH1qNtPyw-H3N9xSs*aKDg{`?UtofZ+J3
z_^60*8OtbzyCOn+4hrqA)6^d!d!Vc$!rYpgi1@zUed~E?G>wN6hCneYGME^t(m&*Z
zUIBsiwE8<D$TM^h@p8|ep`n%j@$rK~Mg}$V_UuiMq47vPBCIn1_)r8H8Pw3j+XVm6
zU}D!uR_TxOAqF!wXxwOId}vf~5b+vg>hz^+sBh!GQ6W^05h`z_A11uX{ei&Hpops8
z68}*8VZ?|L;l27*^H!x#MH3OyubMZDta?RN^X9xTr`(Vme2N5#!oNqJ%c%isl;v_+
za5Z_ZZaGDf=SGhnE##5;<{@s`<K@`{*`kziw!#w1wk!;1o1dM}9ymZU1@&`7zvL|T
zj3hJ6ru)-RKh2(d?m4!4^=h_u?OL{e{dyrQy#4muLLPkYz4wHy@Ok0O>^YJ*Hj}Kd
zckf>I$tRx(+2HJ%@7S3$XV}@ZXIW`!Df{{7pV@C0&I{S#_uqeK*RNk^%dc?uCcPiM
zrs`+A<Ku@1XrQBZxoj#8baQB+dz=Qkmsn%Ih4tXO*eHI0&EUt_a(<G%$<NXFU8agp
z17bAI=(A|BUDk!-_onzJiXTbwCs6zu6#p@bznbE|Mez?({K|3eKXS@{<dpxda!O0N
z4`|u4rC7RZA+(?^n|J8my*o@Hw=}kF*}P@j``Y+6YIG0rS&Md^J9OyOp?hOr!@UjZ
zy=B|>ojOt2#=dR3`*-(et=iq!xqIvS-5XPYMhzR@)2eNU&fOc-?|hH!U^I5Vue)CF
z)0yJjdq<;&Et}tUU-t%jef@f#o<8>)3@vqDE$?gHKwlpY-F@3M^VWE`>yE2+Jx`>6
zXLFAx^wyw#{d)EMseQHWaJRM<`BIeD^iKKvw`$s{y?^)a{`i21^1sjD-_PH_t-qkJ
z6<t_EZQE8_smn1i)*nhZtqip(>ouw{2#<{tZ6y5=j!Sq*1Togx&)&wRZ0Yb)fv247
zf5r7zmMVZRwoo){)20my6@bs;I@YUKk9rnifR##0n3ABLLTtlOO8oD-v~s#Ww;3Mg
zis2FLZ+zi}7vgB#dH?+R^FRFh>#sl3*mLHWUw%19_wO!Ux^$lArDso`Jo)DS{rjC7
zjmE!!|Nh-&nwrb$U`q<h;m?#G>KX&{9UVJ%Y)^NTRioRC+kC==3BkSTqUXE6{PN4k
zX&%jY@7~RS{P9Ol<0=2*i!Y#{;@^Gu9jEy>hd<H4X`KDW<#Lq}t*1Zz^wZ~yii&au
z4H^{4q<X>@oV%E`MFzN_UhB(%XJtzew%)Wx*!1-D!1D6)KNz~f+sD5JmG@z4gFTVP
z0}njV5%>{a0{;&`{E)x<?z^1u<L|ulj==lexpVx7AAaCRjvV1fj~*4_5Qk(0xSyps
zFTDBYoAb7B-#(8-ws5=MJ~AsSD{Se~rO_l;12=3B^1th@y8;~!$AkCZe?Q8ud01Fj
zXQcaQ@xOTSA}3j9dHeS5dr=uK{pqKlcwu3oyPOXnKFq)R>MMaK)sMg(&!<kE;$MIL
zwRi_j3Xser?!<GKE?l@!PJDNb(scdt#~=K+-+sIJ`RAX%`~COde@A&;ML44K32JY>
z2#2MJ`)Bbdc?x;C0r)Eb8WcdCC;<EwI+SMxs?(wX;p_&gb2q5n0e=Pm;^N{ZRFCb5
zC-OkUo;`a6{@{-jCr*euIDPuGcn6MX6V!&q{n)W%0?;;4AGo95&~^~#qmMok_@fS~
z{d3gAjT<+(`l9!1<X!=PYQy*c8T>C_zRYPD68zt%PoIw9V*v2~_~VcH`|rQcsm?jc
z%%TmW{81kV4;~Z%+z%W$All0D<HyA_Xh0tTenUG!9Ras(zjAIq!Fli}ocBD)dG`-+
z&Ku|53OOJBA?L52<NWu_myc0fY4vCD-?eMkaz8)6UL?aWrT!B2A!q=;D07r6=s{fo
zcRZu+zy0=G0eD84qr8DH_yDv3Z<Igk_{E<&5Bq|1)2EyV9p?OjL!1X5AR6{^ejm}$
zaVO{P-s61fNzN-ODpvg&{Hd>Z1MpWssS5@EN;^S20Kde2%lVMwoQHl+<qsOD4tjsY
z`Tayg#+RI5uHZcBDCYsY+)ER;h5wZ+SHR0l0s{lv5ijI{2C9dfXaO$ZBj8vQ9VmB{
zIqC>}1O7+9OLI1X&`836*w+#bgFfSYAmQ4NXy`?JlXYCeKjj$bemkT#al81_n8B6)
zAN)__5eHPS6NS%FuBZ#}6?j9T18p392EIqTQ0{0KxMEIoK7we7B>o@#r9{JkBb@jB
zSfU|-+CrB-oOj;+=kce$czK5o9ePncEJZs*-%=AD;Pu-03*`@gj0=c|enx%8o~1Sl
z8ouE?f@laQ8aDsJZ|Ax|@N8}PU%h&j(>PNFK!XAb9W~WSO>|tlc8wo>cQxNIH<CX)
zBbYy(X%a|0_ygx-zvq0^DbAxn!&h>9CZ6f9wC96Tdq$tsahKGdyY7(MH1)WLYQvxE
zc}dTnJ=;-#o(KHFC)Mcy--EBK)1lA;UI!n2cW4WLc~*bE&NhHQpFL2}fNN3-=i_A>
zqQB#OIN>z(D^+_24RU+#hCYe<)DF}qwIv$byd(9kbS<a}|90)#x%r>Qc#QKm)d$)y
z#sj4;&>rxv&;b0Y-{XbPB=Xnh^ye?l8o*y98dehxxDu%UoJcf`BRs~Ok!VobGiXrS
zGy0?+`>EWEIlmV)Q286*rS^Y7B=bp4_)~u`_@CO^QpiJSa|#^_EuaD8L2bMR{LxQt
zT@b?GcqE9wN;GUB8rE7R{Ikz<{!l5=;Nm>)oYbDtCq;f;*`7gz(w;$s(w@;Lb$(wY
zbEP`|XlEE-NX~KtXi%U!9W}KPg%(`fbNceP=Jw-nJRHPdnN2jz9Ke4s`-y+~heSg>
z(J<jhqCwT3BjxrSa!l%z`g|;n&q|-viD+p5evSQ-z@Oy%CB1s}YDY3k9`HxMh&y-&
zG(hH2Xn`BXT175{AI4kA47lFQ?aQ~#@5|pL8eS(FHWCdxR%Y@`=Syy@vne4u)2UAS
zDD7F6F*@z48GrN_3jg=(*RLb$LIJc_;0@e>yFv^4e)RX4*P!3TScS0-*RF+q_`5{I
z*7^PT=D9(96VXt;JwHW#((?2WzGV6!z9=P>+oy%{oWwBhv^~hb{ql&QK`mo+lVyzB
z@TdM>@IT?R6nFzK+<_DDMtcC>N}ZsOSIfs3e?cSozj)C=zLRKphiKR`k7%H_fc6X;
zUX*EADbuhFG^7sVk0lcgNnw0`Vz{6I7y6`rDjB2K2Q~9Q`V5R=kRt#aH*Vywz4jW1
zT%>@yPU>nW*RNmaN1jjMMfL~yjs-*mwS~8dhJVWK8GX`P+d#hBGLWyx3g%B{nE2yq
zA>2tcJW4byBpT)s4Y;by7?Y3H-2VW7;swF~#MgPC<<UnU<(oEb67<{-9SSXo>pJ>2
z-;?(MFC-e?CmKY1CK}KuDeZX;^+~HN!Tgyl6MuqeSV}Z3CK~dIj~1B4!A+u13Q@@z
zZ<p5G{{w%8|AT^pIsymaw`kEKHx1S4sEd~C*DLtxqG$OBOG5c>dmsM3+@9Z3wdeIR
z4bRCm{Db&t>GTlpNRep3C1ea5pNA8y{!xs-AF-RS7N~O?f0vIMH7YVABjZEhiuQ;$
zFn|7hL4%sVZdE6^qfJ$xW7Twhx%UmXjDhxCAh+jgSDo??@JHPb9Xb^Cz+ZXg6(M^;
zmT@>7eCEuVZW`*Mqpmu^g+6J^{M%^HL_-bzOl?;Sl+&_h%ZjM)<efTo;_>nEe8Ywf
z9OH6!b~d+Kt$fLnC8Aw_^UXJ+-+?St6D`0SV*~ms$U=}uF(1H%_I&sy8?X3-<{Rr~
zy4$lNW2}_h^D=4+x59tNjvWS)b;c<8ckSA>cT!SPMq*-ODfOeG9$tL$MLu%mNFEat
z!wU)u_|s26&7XYoNr4aM_rMo4U@X8mq0oUj3}`@q3O>YGh&=W>!}zB!1OLnX!}T*O
zWsI4UjDhxyKIz%nQ9%Ee^RNE>`#Ykdq85OEh}W0Xyua7hty?!y8|LK4XV0F^sZDUa
z4;wa2$Os>N@PXh5;0|0-M+#pl^#S_8dzj}yu0vg*J)ljC_DuDlZqKh&YtM(azW_P#
zx!Yl$zJ2>XxpL)7p$9?Ua$DxPxw$w<khgE&p5J@#y_{rgfeY|J+fV~&P@p<30PvKO
zHu~0&S5M(P@=Y{8OELz==hx<i^6gJd<6nQYjbHx#_hVGwx2=Czv0??!%gejCeED*|
zaN)w=AAImZo|cv-%AMwwf|o!8+6CwYZlI$&Ezm(=90uQGj7D35J_7SdxIsoj-GP=G
zE+YTxw<x1OtN%e{YP)N)va-H=<dH{i0MEF%I00zW3Jv$&cORcMYnG@7j2Vh<N1+4w
z0)Iv4i@5>rXb)&3Xb;ufJH~AF+ynDx_9yjkXj|Za;-$3<7A*J-?KCnnlFywxSJVS&
z0RDpp4dUa*jT7#u1JIxVXi(<8n2SNa2Hyiu+`&VjP0d@7sSuv}l7IO5`SsqiWy|B3
zL;Mx|!J7c^67<b*176TM+iW(`enUe;xyfYW-MV!X^#FgwsZK{tyrr}a<qkeVe*nHh
ze~h|Q^c#c|mfLQ3{X*bRbT8@MyLUS(!#uR-ojZ358c;sa8&dlaG$bS>@ZrOU3*K74
ze!ajSWsNe&Gw?<`K>q`G$fn>Q$l7QJXai^yNEdxD;eLbC$!p%cxryri#l3s?x|p=)
z<9)mMBVV=rqm(NE^F`o8b<0V%z^-D^9;m)K@tfcQj8Q0KC61y`L_dl$MgRZSTW|3<
z-grZdf&cvHKSey0HI<W#`nE|lM$RSN_mJCTOj`H2-SrzGzd`;%|4;34Dc;fEa0f1^
zZ?swBQz1*Fr>Bd)mD;)(-_X~9zZE`2J3zZcoq$hJ2k4X4@(`YpF6s#Nf$^N^#TSO?
zH$86?cQ^iOURCq3nzw-)=mHO+Ej;$vW1RXdF;1&5;HCiLpr1isgbVzGIS~N3gRU1|
zcmX=bH69)we-?K){)+rh<(&r_lzy=$I#Ax|gJ|p)^91k|#@ZTm`T~E{jUq!}T?c#*
zUP76p4Xwat{y$&tRq$8yKl+I3V{CO=aEFe4;>3yknP;96{H-o`1rQFr1YXBG#sJ{1
ztdEdfyZT?iUEr^t|I*mA6nu#>2y`g=e)J#c>o6Xv=|I_T+qR8A`|PuVpOrQY0Nsji
z9&!`j!86MG0ri<LYqi>c1$Q_8>Tyvm!>DDOy6Ob5X3ZKAA9Nu+Xam0BE%cqBMZulq
z)0h4tzu$yEaG~}k_@Bn_JZ1h>7cGj;Q(3=5-M|g?psdNE&d?WOEdgs#par;79)G2u
zsS|&-{zsWh)m0~u?;-!-9qV!c@D}d-_U#k>F3JGy75onT(GG|o*Z+;U3;fmkPwFS!
z`XA7Mu@mwO`akdi#v_cKC}YeyQTC_@MZb%Bz&rYU^tI^6Xig#4HHhZF8+U;}c(*P-
zuZ`c;eG&W>y#>k{G=kTOk8Y5R;G(+1xZ3h>#vK>Tk=*%j2IPT#4}Xj49-d2s%kEjT
zDwsFF5j<<wDaL}!q&q$R&3CPQ*T{GFH{CVW(pTl1E8h$M4*YZEJD2Vn`L31k-tyfb
z-`mLdVELXS-??<x;9m8+9V7b-7xwpf%iziCkQJftBREKKx!QaY?^sc(t`Ds3LSD^D
z_6?vhKhkVAk0N<LjQV_R!^XBV$lT4CicgXDH|3nqJj40WFQhd#=z_7PaDOr96F=en
zi{At;b>RS7TX}kVK0tH38PulB(Vvmb`8)NuCDbqdO#RXclFwfx**2AAV0^>SgP<MB
z8|SB;mDb6i3&lELkgUu7>>}rfFK`~bSLFX|9r?GWK71YJS*~7BSN57H`g2+4zd>-3
z`rKpGZ@!0wv1W?(MyzvTeFZvk=wd&=#QBlmZfmW#4f^SY3l}Cl`Q($azyY!o<_{Pj
z(XV4HLSGG87IF&w@QiDMt8%>%Ydl!*giaglJJ88vjqO(XV-7%b&<vU{q$=}!%yW@1
z<Y<(MGUtKZq`t6T_TZ1wdLP!xwv^SRx~OuUuf`7|fA!vn>U$ngCK$hdId_7;Y>yRs
z%%!ppaLO;7$Nwa)o5q}x)_s-z18RQ6`ViI``_ujNsyx{SV+ze*6G+aDRqw+<{X+%@
zE*O8_Uzsj+V9*CcC$HoWnEaEp?uqp_!H>tKwKlBrfFH3&g|$ws6OR8#L_MJ7k8zyl
z`x*1*%}Z6UcPsKN?vSnDm>(*1iO}alkEqTcYp+;8j;qFxCV7npYkgQ_0zdlil==rH
zf5<=TwbJVA@4yAuW_f*L-AqXzd+Gd7e8GjPIDj8xtMOy7yk;6G^JBGjI*~uklM+_0
zTp6pz19^kbamR)AHt1Bbz5t!@wr8?#xn}s&ADmkVmjOqmwKlW~taqyOhg>md&YX;#
zoSank+ADB?-UMZV3;K1eHN7sc_hFq0`cUvA)|jxiVVBpJ=1!I1>4hl*2f>d=D%ZZN
z=U;s-xcV9}>c8l*V6onXwIb*=p&M8D5qfc~uV8ILtZ~Wt&r2LE@*1Mz#{q|`)<0x2
zhr^MuYSpS(v_;JKA)kY8;DR#1{nK?RV%-qyRnV)xChN9ekk=Q`Ca^w&wZdF;n7a&c
zsrzWG-KzN?ZR_EOAI_luKUG;Dz`Ou+JCq6f9+br;*H`?*C!)nV0rb<GW&QekRhz&%
zlT%(N%aL)wCHRr@ok(!<O4atS%+JscA@i%(S=4KHD5qPk86Dg6PqD^=wYogQVZOZ9
zsJd?I|B%1a=}dV3`R8M?HUxPbcqsE~W#1t1Kv|$af*&rd-@fs1Wt*spA62|oWB(5s
zd+yx18IL{oSUSq#@y8z*{T}*VjD6_;!3!u4@FMb7uQ~mC<}?1wnJ=hKRO83A5cgVH
zUHM~7ft~|8U6e8ASJW2Wy7cO6VM^VgE<RWu&CAYy#?OEMMI}F4EBW!c`Qwp&jpIM1
z@1f)$8ykB%I5=47U9mQul9Iv~FJ3I>cfd*M3zWVR^@Fmx=sLkaSv#G-YY!270Th0G
zan4}=)>B!$^z2E_Ymt8j4jdS0GMVOpj`{QFXHJ<iWq&|G0G~d6y3hkJUAk20E|j?s
z${cr;zp}Rx<xzc1#)UK~+^57_b;^HTyLKH*?Ox0SG1g;U25U<sXYmOWCJ4G~(=}JG
z8)Y0<_Eu8z*!Nub2mVz4$eZMkpRkq)y>UcDgwVeNhZ!?wh;m1NpsbN7JfP^16@H*`
zq9QFVZ5r`%Hpxi%up4v!Tg|E3psc9umnA1B@534obo67#j^(Hetgq3y>|QTGxhs6A
z>=9A!G*<mV<@pGu^#aY$e__%m8@IaJC^~+m0oe}a4P7pH5V~}%YoL9o*AY+$=ob(V
zxS%Z1Z==ryp1XJNew^Lj8ii>8OO`B2Si5#@tTN|DJp+en)24BMe}6t=#0Y_#qW4qQ
zhY${Yqx2Wpm-yCOZ^0yHv)jm9<c~bj|Jd#JRHO%;JjQ(VIaphmG-;ApV@A6`SX?Lr
zMaK(y8EYz#+lhu%e<E*p{?&C@YMlheBa6i%`UdP(RrHFeFO)UtMxT7_*s+)XWZoiw
z<U@Up=>KcNLy>{seDh7ddi83dD@NZ4os+Vr_!sjQ`6C}?`~@$8UPT5++f&vhfdhC9
zYaGx&ZQs6K*(dl{^LEpJJ33JGGwAzJ&zm=I2LJs+W#M3w{^YM-_}0YtF9O=vt@^iG
zuZlLg!KXA;zP$z9>YH8lx4Z6mOoHn6SN_CzyT)4ar17v#ZGOa$p)b7f!j>0beDN~%
zQNM23u;Cvsz4TI*erMCBP3I|%%vWE1Rk%|a-MV$_BG#-~v+MQOUl;YMjA5u}YSUk+
z<6}LosHg~f)@zi;DdN9NXor{^gJ0jEIY`Xc(mtqQlCPgTBa+&##79{0G-NnMo>AHq
z`m*>EY0d=s^ivXRdhV|xA2W=>$O~;vnG>mH!GvF=Iq>%1ZW@MvC)kF*3GE2DD&Kb;
z*|DB4&y-}tsq)+j^GD2IF;~D`C4lBiD+w>GwPH>V+`<3I_m%k(LdLmBbFk+wNoim%
zj=2}+ewg=R-r0xdoseN5Qvq-ETevWXfxP(kQ!_*w>Z|mcq|<>O0dqE#AL<EXkg^B$
z{YS%vyajm=vL0kj$hw$sY+B_IX<*JVl<+|PjUPW=taGCeLphw<yOwXu9U$hDkli7-
zW8Q$d(>(JKkw?sToNuIZdG5LAggl5nB3M^LU4mb#%i>3hHVe6b-c+~D4Pv*V{AgSd
z{T9~buzx@qOL4t9e<1(q)G<+>m_y~Ki2N@p^$*@dUk^S-U5*|-T9hgJY1HMndtT&k
zEgT~Df3BWAjDPsv%ZR^KiN9;tE+MNa`*F~3L*_z#pg&dPf@h57YW_!frT&#YNk|Lh
zB=X02gn0teM!!sBe~vmn`f1>ebWj#pD*{azv!PEyT+FjEcJJN0w@O@G^Sw8P_!2O!
z46F`N!g$MIfV+lyGo#U0SbKuSH4Q8hi#OO?^I)(u49fwqwx(sUN{lzyTGO$B0I7F^
zr8Q4Eq*2&e^O8dvg_SjL);}RT+nhcnZH{qvdRj*IfOa-ZM!)Q-$>#Kg?5^o4Q!Sa<
znMu~JQ!~^1C1j^}o7tnCF+Cw8CCQv^jWt`cQ!+CKwCm9=pxwZR^^L~<R*NlLoIrA$
zsRc^$C}y^Ks?CyOog=@Ki^V*{M!A?1qb(^jQ_{@S%-L>FwRgBU1db3HZk}mQGp6Bp
zK)ZzOh>V$;)6JH4Mq5hAR2-!+pj}czTDG~}!2bWQy(<r{qDbQpxl#cnLUt2S%ZEgg
zup#N`Yr1=Sx)X_928b@W0iOE;IY@*Ym5YE;6Ge?KLWHR3Mu=_}kp%?AfC?@`)QB94
z3tmCv0Y*7>IkFtf_B_RPx61$apRLMQH8s=o-hBP_*T3)g^}K%7o%9P2|GV;}U#?vy
z{fDhG>8D1UvP`<{PnDjMo|2k6cEae4j2|z$%Ky8vmxS9*oP~oFFcr)LkARKfHE;l|
zvclm|m<3B=HCzRo;hXRRyb4{5C>n{TpbGQ|YC><JUFbOKj{VrhX?QBG!1v(Ca06a}
zH{jRtoA^U~7$3o!+)8T55psq^QI|eWo9H|A0_|z{wTIZQ{agECd#(MN-JMZZ!=7Nn
z`FMT@pU2Pgm&B`Lw;1hAbh4cyr%rM=&n<NCa<{nK-8T1#+v)aDk?LwSTv0Vr%~W&M
zgQ`KTP`lJ6b)}Bdj=n?tLIaF?bGiw9fbPX-@I`zb8AjHVw@Hfql0BKF@)o{}ALQTg
zZep5P?nIdv(6RD1IYSo8GWmd9D4&$=@{l|s<K0A;xQ@HdZ4TMc>h5v(8%w@)zjePe
z)?9LXtNtoV4OI!sQnpG_<J4p|UFE6@b*HK^);+D7)Qid&n$g(i^VX4g7Q7DH!AL9D
zs<oC_Z(AQ(-C-mg0^=Zq<KRTN9Il6tqCcXQ=rB5l&LN-i^b}l$7a9M4iXrJsBWVI1
zO_$L(=zFxy?#BkPAj@GztOrlw8N5||BnCQuXSl<h6z68=9_L}F-dW>pa&|h$og3s-
zSs)L}b8@7+!F|sirEXO@YK~g0o>I@Mm(@OXT%A=HRWIE~57sHhpLgm-`V;L<E{!qV
zIUJOLH^D>JCMyY!g;U`YxC8El2VfiQfXCrkcoFtO15h;bqhSalhHgR=(PR`vHRy4)
z1zkW_-~<dY!xL~WUVwX%c!J0*QcAXv?c_spkQ_3o`JQx=OQa|5XIeUl4xz&-r4CJ|
zqv$xAPAAi8G?Nz5`{^I(61tQ&(m&HRbOU{vw$k17ecEP_c7;9I{>c8!?yyhTSFs1!
zLiP+>&DOIWY&YA-j<Zg7B_G5QS9}z|jR$xEU%}V$0|pak`9FEQct?CHP72%LaEepr
zR5|xLbxw=(o^#k>1<Pu=R_>Qy$PPKcWv((9UE^+a-*zL^V0Dwa-Sqr&wO4(v`fI3}
zo}p*yIeM+$q<82G+S^2;%;2CWxC%@FzXMsI3Oo%~fZgC@@EJG;TCF428EX*CgD;o}
z+y?i-Z$e)6qga%TCZVY)%S7T+=wp;<e7J~gCYxvki(&`(CEmxm-r4MY;}p6vDp7r*
zzEgR++>3`ypO2Z-I4}vE0?^8~7Fg}D0@b3i_$Ur1fYg!Y<Q1})y}_qA4Nj}kvD@{9
z7K8OB=x+e=U<9xL0UWr7Gb+G+;7?#HI02%pm*7Iwi255Yn1+|(=kbfU1@AQs5KAVL
z#iW63G=18i+H`;&ZO>x!*ao(RU1VW=03XT|`EhYc^mh6=1Dt4QzQO4VXOA;j4wFO*
zIZbAoSbSbK%k6Tf+$TSkz1{xqV7Eo3>KF8O{ki_T*S2b3XpPfeAR1(VN-!Q3naJ6T
zPN09F2uyGW?n$EQwKR#2r_<?7gN_t?y!}Q98xd>@`<`v*QUpb(_)?u#z4ajd8-0t;
zGJbndKdJwsx9Yt=)Kus5g?01#Ey{RfmDOgQvd){x4TF7Q1mrLX?}GDTEnEQWU_D$4
z8(<^+7M_HsV5ecx8K}T`dl9NfOHl*bioQmJ41>ntI1>%P3^N&)_yH3Sb+{fc#XHD3
z;-fw3K<Zh3J%u65i)b@_m7b>OXg9l;-OnCi`|TRTq;+;Qi)A)bY!qu|ud){QK0CwC
zGarxQMZBEf$(QhE{yKk)f56-LF@Bn#=RHLq@hfq)xIrWeE|eH8ZV>_TgjjEoKhZE@
zKyHwmWs5v72fEL?-3*7dsEzud=kG?J&zlgXpvk%$PC)md$It<E8Z9>ceiY{#B&{Qd
z$w{(`j<;vokJ_gVKOuIrbEACU{k6JLWqDk<&KKIvdKB1TF#ZaB4Q@BNW+&VOC!zo<
zM@vlqokcbH5Dp{PlaVBctR-j3GjuggH(6s2pCRUnW#T#ah^K2?Xsu%3Fpv)(1Dil2
z>_hsKfh3AtO|BzDNi1>51QI0k$zRDn@+}Fcw;SeIMqi;{(@6U|gN12!w%uem+uz$!
zEQY1AyA5Bou+4lc-y@ESdCoJ=e&>+$oLnPcHb~qrBVE6nWOBk`*EQT(W3o?^!HKsJ
zvNvfR3lhOYpc(YAc3a0FMgrY}evj@#UXFa193Y>N&kes(>Lp-rKido|U}c(!%(Kd@
zN^7;X&f2K97;o=Ve^YJhD|J+zQWsPY-B(BIYjliG&{#{Is?+o&9q{_&<PQsvoKl^t
zR<G2px<h+oRL{R*AP$TH*&q+pf|Z~Zbbv4`(gK#WGE7}dttM-m)o%HqA11>9%!E}Y
z?>8FGX@@?;-^nNw%|^b6ZoWwG-vGd9V{trz1CBZ4k|*<2K8C09bUw*sodD0|**uTW
z=Eb~>SMn-e&FAx4zJS;9dcKr5@J8OmSMt?{XE*ZAd<)-ZvT&=(!|(ET{uS@wNBK#9
zig)r0+$Va7Fws{;h)5AFt`U9_BjQAY00Ijpq(~O2VvI-=>0*+|Fu2VW*&<KO7R91W
zREjE5E#`|_(P3gb%<xK_ljdYN0VmUpDe?@Px4U1t9qv&#O!ZX}W;7A4u2Fs!qvA{s
zXG*GMm8!<5G?lI<sSH)D%2cJQQq^j{s#ObAovK&={l3yAUD738(j{H;{~$w$WQjm|
zXs7$)+4%*5?4qo4Z&yuIH1~=Mr_T<S<P;YLvdXgZ0~I-i6@k*MlKf)t^SNbtMTLnu
zl{w-4!qac=-Xk)k@SXBG<L@uO_TW}??H%3>M=)40J-;v*Oe~%|)IVbQ2!B>lc7EYZ
z;V&=C9l^Xi;rRu{MI~kalAOy|rE^Qe!*ffD3jC&`oYFG?kM})I;o<qY{$Q|hdO=Pw
z=yzRz?ByC_Md-IB^Kjzyl9?6L!0mq5C`~LapAlCQ8#m$y;{(Q!Il3y~86U4>ViWwa
z=J?q|@jq$Fsmw2n^K{3>$D3AmyCTx}%k8`@)uF#k{;bvMKkicE?Q6l!`EclK{{kb9
BEIa@J

